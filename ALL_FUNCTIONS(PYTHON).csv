FUNCTION NAME,DESCRIPTION
abs(x),"Return the absolute value of a number.  The argument may be an
integer or a floating point number.  If the argument is a complex number, its
magnitude is returned. If x defines __abs__(),
abs(x) returns x.__abs__()."
all(iterable),"Return True if all elements of the iterable are true (or if the iterable
is empty).  Equivalent to:
def all(iterable):
    for element in iterable:
        if not element:
            return False
    return True"
any(iterable),"Return True if any element of the iterable is true.  If the iterable
is empty, return False.  Equivalent to:
def any(iterable):
    for element in iterable:
        if element:
            return True
    return False"
ascii(object),"As repr(), return a string containing a printable representation of an
object, but escape the non-ASCII characters in the string returned by
repr() using \x, \u or \U escapes.  This generates a string
similar to that returned by repr() in Python 2."
bin(x),"Convert an integer number to a binary string prefixed with “0b”. The result
is a valid Python expression. If x is not a Python int object, it
has to define an __index__() method that returns an integer. Some
examples:
>>> bin(3)
'0b11'
>>> bin(-10)
'-0b1010'


If prefix “0b” is desired or not, you can use either of the following ways.
>>> format(14, '#b'), format(14, 'b')
('0b1110', '1110')
>>> f'{14:#b}', f'{14:b}'
('0b1110', '1110')


See also format() for more information."
"breakpoint(*args, **kws)","This function drops you into the debugger at the call site.  Specifically,
it calls sys.breakpointhook(), passing args and kws straight
through.  By default, sys.breakpointhook() calls
pdb.set_trace() expecting no arguments.  In this case, it is
purely a convenience function so you don’t have to explicitly import
pdb or type as much code to enter the debugger.  However,
sys.breakpointhook() can be set to some other function and
breakpoint() will automatically call that, allowing you to drop into
the debugger of choice.
Raises an auditing event builtins.breakpoint with argument breakpointhook.

New in version 3.7."
callable(object),"Return True if the object argument appears callable,
False if not.  If this returns True, it is still possible that a
call fails, but if it is False, calling object will never succeed.
Note that classes are callable (calling a class returns a new instance);
instances are callable if their class has a __call__() method.

New in version 3.2: This function was first removed in Python 3.0 and then brought back
in Python 3.2."
chr(i),"Return the string representing a character whose Unicode code point is the
integer i.  For example, chr(97) returns the string 'a', while
chr(8364) returns the string '€'. This is the inverse of ord().
The valid range for the argument is from 0 through 1,114,111 (0x10FFFF in
base 16).  ValueError will be raised if i is outside that range."
@classmethod,"Transform a method into a class method.
A class method receives the class as implicit first argument, just like an
instance method receives the instance. To declare a class method, use this
idiom:
class C:
    @classmethod
    def f(cls, arg1, arg2, ...): ...


The @classmethod form is a function decorator – see
Function definitions for details.
A class method can be called either on the class (such as C.f()) or on an instance (such
as C().f()).  The instance is ignored except for its class. If a class
method is called for a derived class, the derived class object is passed as the
implied first argument.
Class methods are different than C++ or Java static methods. If you want those,
see staticmethod().
For more information on class methods, see The standard type hierarchy."
"compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1)","Compile the source into a code or AST object.  Code objects can be executed
by exec() or eval().  source can either be a normal string, a
byte string, or an AST object.  Refer to the ast module documentation
for information on how to work with AST objects.
The filename argument should give the file from which the code was read;
pass some recognizable value if it wasn’t read from a file ('<string>' is
commonly used).
The mode argument specifies what kind of code must be compiled; it can be
'exec' if source consists of a sequence of statements, 'eval' if it
consists of a single expression, or 'single' if it consists of a single
interactive statement (in the latter case, expression statements that
evaluate to something other than None will be printed).
The optional arguments flags and dont_inherit control which future
statements affect the compilation of source.  If neither
is present (or both are zero) the code is compiled with those future
statements that are in effect in the code that is calling compile().  If the
flags argument is given and dont_inherit is not (or is zero) then the
future statements specified by the flags argument are used in addition to
those that would be used anyway. If dont_inherit is a non-zero integer then
the flags argument is it – the future statements in effect around the call
to compile are ignored.
Future statements are specified by bits which can be bitwise ORed together to
specify multiple statements.  The bitfield required to specify a given feature
can be found as the compiler_flag attribute on
the _Feature instance in the __future__ module.
The optional argument flags also controls whether the compiled source is
allowed to contain top-level await, async for and async with.
When the bit ast.PyCF_ALLOW_TOP_LEVEL_AWAIT is set, the return code
object has CO_COROUTINE set in co_code, and can be interactively
executed via await eval(code_object).
The argument optimize specifies the optimization level of the compiler; the
default value of -1 selects the optimization level of the interpreter as
given by -O options.  Explicit levels are 0 (no optimization;
__debug__ is true), 1 (asserts are removed, __debug__ is false)
or 2 (docstrings are removed too).
This function raises SyntaxError if the compiled source is invalid,
and ValueError if the source contains null bytes.
If you want to parse Python code into its AST representation, see
ast.parse().
Raises an auditing event compile with arguments
source and filename. This event may also be raised by implicit
compilation.

Note
When compiling a string with multi-line code in 'single' or
'eval' mode, input must be terminated by at least one newline
character.  This is to facilitate detection of incomplete and complete
statements in the code module.


Warning
It is possible to crash the Python interpreter with a
sufficiently large/complex string when compiling to an AST
object due to stack depth limitations in Python’s AST compiler.


Changed in version 3.2: Allowed use of Windows and Mac newlines.  Also input in 'exec' mode
does not have to end in a newline anymore.  Added the optimize parameter.


Changed in version 3.5: Previously, TypeError was raised when null bytes were encountered
in source.


New in version 3.8: ast.PyCF_ALLOW_TOP_LEVEL_AWAIT can now be passed in flags to enable
support for top-level await, async for, and async with."
"delattr(object, name)","This is a relative of setattr().  The arguments are an object and a
string.  The string must be the name of one of the object’s attributes.  The
function deletes the named attribute, provided the object allows it.  For
example, delattr(x, 'foobar') is equivalent to del x.foobar."
dir([object]),"Without arguments, return the list of names in the current local scope.  With an
argument, attempt to return a list of valid attributes for that object.
If the object has a method named __dir__(), this method will be called and
must return the list of attributes. This allows objects that implement a custom
__getattr__() or __getattribute__() function to customize the way
dir() reports their attributes.
If the object does not provide __dir__(), the function tries its best to
gather information from the object’s __dict__ attribute, if defined, and
from its type object.  The resulting list is not necessarily complete, and may
be inaccurate when the object has a custom __getattr__().
The default dir() mechanism behaves differently with different types of
objects, as it attempts to produce the most relevant, rather than complete,
information:

If the object is a module object, the list contains the names of the module’s
attributes.
If the object is a type or class object, the list contains the names of its
attributes, and recursively of the attributes of its bases.
Otherwise, the list contains the object’s attributes’ names, the names of its
class’s attributes, and recursively of the attributes of its class’s base
classes.

The resulting list is sorted alphabetically.  For example:
>>> import struct
>>> dir()   # show the names in the module namespace  
['__builtins__', '__name__', 'struct']
>>> dir(struct)   # show the names in the struct module 
['Struct', '__all__', '__builtins__', '__cached__', '__doc__', '__file__',
 '__initializing__', '__loader__', '__name__', '__package__',
 '_clearcache', 'calcsize', 'error', 'pack', 'pack_into',
 'unpack', 'unpack_from']
>>> class Shape:
...     def __dir__(self):
...         return ['area', 'perimeter', 'location']
>>> s = Shape()
>>> dir(s)
['area', 'location', 'perimeter']



Note
Because dir() is supplied primarily as a convenience for use at an
interactive prompt, it tries to supply an interesting set of names more
than it tries to supply a rigorously or consistently defined set of names,
and its detailed behavior may change across releases.  For example,
metaclass attributes are not in the result list when the argument is a
class."
"divmod(a, b)","Take two (non complex) numbers as arguments and return a pair of numbers
consisting of their quotient and remainder when using integer division.  With
mixed operand types, the rules for binary arithmetic operators apply.  For
integers, the result is the same as (a // b, a % b). For floating point
numbers the result is (q, a % b), where q is usually math.floor(a /
b) but may be 1 less than that.  In any case q * b + a % b is very
close to a, if a % b is non-zero it has the same sign as b, and 0
<= abs(a % b) < abs(b)."
"enumerate(iterable, start=0)","Return an enumerate object. iterable must be a sequence, an
iterator, or some other object which supports iteration.
The __next__() method of the iterator returned by
enumerate() returns a tuple containing a count (from start which
defaults to 0) and the values obtained from iterating over iterable.
>>> seasons = ['Spring', 'Summer', 'Fall', 'Winter']
>>> list(enumerate(seasons))
[(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]
>>> list(enumerate(seasons, start=1))
[(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')]


Equivalent to:
def enumerate(sequence, start=0):
    n = start
    for elem in sequence:
        yield n, elem
        n += 1"
"eval(expression[, globals[, locals]])","The arguments are a string and optional globals and locals.  If provided,
globals must be a dictionary.  If provided, locals can be any mapping
object.
The expression argument is parsed and evaluated as a Python expression
(technically speaking, a condition list) using the globals and locals
dictionaries as global and local namespace.  If the globals dictionary is
present and does not contain a value for the key __builtins__, a
reference to the dictionary of the built-in module builtins is
inserted under that key before expression is parsed.  This means that
expression normally has full access to the standard builtins
module and restricted environments are propagated.  If the locals
dictionary is omitted it defaults to the globals dictionary.  If both
dictionaries are omitted, the expression is executed with the globals and
locals in the environment where eval() is called.  Note, eval()
does not have access to the nested scopes (non-locals) in the
enclosing environment.
The return value is the result of
the evaluated expression. Syntax errors are reported as exceptions.  Example:
>>> x = 1
>>> eval('x+1')
2


This function can also be used to execute arbitrary code objects (such as
those created by compile()).  In this case pass a code object instead
of a string.  If the code object has been compiled with 'exec' as the
mode argument, eval()’s return value will be None.
Hints: dynamic execution of statements is supported by the exec()
function.  The globals() and locals() functions
returns the current global and local dictionary, respectively, which may be
useful to pass around for use by eval() or exec().
See ast.literal_eval() for a function that can safely evaluate strings
with expressions containing only literals.
Raises an auditing event exec with the code object
as the argument. Code compilation events may also be raised."
"exec(object[, globals[, locals]])","This function supports dynamic execution of Python code. object must be
either a string or a code object.  If it is a string, the string is parsed as
a suite of Python statements which is then executed (unless a syntax error
occurs). 1 If it is a code object, it is simply executed.  In all cases,
the code that’s executed is expected to be valid as file input (see the
section “File input” in the Reference Manual). Be aware that the
return and yield statements may not be used outside of
function definitions even within the context of code passed to the
exec() function. The return value is None.
In all cases, if the optional parts are omitted, the code is executed in the
current scope.  If only globals is provided, it must be a dictionary
(and not a subclass of dictionary), which
will be used for both the global and the local variables.  If globals and
locals are given, they are used for the global and local variables,
respectively.  If provided, locals can be any mapping object.  Remember
that at module level, globals and locals are the same dictionary. If exec
gets two separate objects as globals and locals, the code will be
executed as if it were embedded in a class definition.
If the globals dictionary does not contain a value for the key
__builtins__, a reference to the dictionary of the built-in module
builtins is inserted under that key.  That way you can control what
builtins are available to the executed code by inserting your own
__builtins__ dictionary into globals before passing it to exec().
Raises an auditing event exec with the code object
as the argument. Code compilation events may also be raised.

Note
The built-in functions globals() and locals() return the current
global and local dictionary, respectively, which may be useful to pass around
for use as the second and third argument to exec().


Note
The default locals act as described for function locals() below:
modifications to the default locals dictionary should not be attempted.
Pass an explicit locals dictionary if you need to see effects of the
code on locals after function exec() returns."
"filter(function, iterable)","Construct an iterator from those elements of iterable for which function
returns true.  iterable may be either a sequence, a container which
supports iteration, or an iterator.  If function is None, the identity
function is assumed, that is, all elements of iterable that are false are
removed.
Note that filter(function, iterable) is equivalent to the generator
expression (item for item in iterable if function(item)) if function is
not None and (item for item in iterable if item) if function is
None.
See itertools.filterfalse() for the complementary function that returns
elements of iterable for which function returns false."
"format(value[, format_spec])","Convert a value to a “formatted” representation, as controlled by
format_spec.  The interpretation of format_spec will depend on the type
of the value argument, however there is a standard formatting syntax that
is used by most built-in types: Format Specification Mini-Language.
The default format_spec is an empty string which usually gives the same
effect as calling str(value).
A call to format(value, format_spec) is translated to
type(value).__format__(value, format_spec) which bypasses the instance
dictionary when searching for the value’s __format__() method.  A
TypeError exception is raised if the method search reaches
object and the format_spec is non-empty, or if either the
format_spec or the return value are not strings.

Changed in version 3.4: object().__format__(format_spec) raises TypeError
if format_spec is not an empty string."
"getattr(object, name[, default])","Return the value of the named attribute of object.  name must be a string.
If the string is the name of one of the object’s attributes, the result is the
value of that attribute.  For example, getattr(x, 'foobar') is equivalent to
x.foobar.  If the named attribute does not exist, default is returned if
provided, otherwise AttributeError is raised."
globals(),"Return a dictionary representing the current global symbol table. This is always
the dictionary of the current module (inside a function or method, this is the
module where it is defined, not the module from which it is called)."
"hasattr(object, name)","The arguments are an object and a string.  The result is True if the
string is the name of one of the object’s attributes, False if not. (This
is implemented by calling getattr(object, name) and seeing whether it
raises an AttributeError or not.)"
hash(object),"Return the hash value of the object (if it has one).  Hash values are
integers.  They are used to quickly compare dictionary keys during a
dictionary lookup.  Numeric values that compare equal have the same hash
value (even if they are of different types, as is the case for 1 and 1.0).

Note
For objects with custom __hash__() methods, note that hash()
truncates the return value based on the bit width of the host machine.
See __hash__() for details."
help([object]),"Invoke the built-in help system.  (This function is intended for interactive
use.)  If no argument is given, the interactive help system starts on the
interpreter console.  If the argument is a string, then the string is looked up
as the name of a module, function, class, method, keyword, or documentation
topic, and a help page is printed on the console.  If the argument is any other
kind of object, a help page on the object is generated.
Note that if a slash(/) appears in the parameter list of a function, when
invoking help(), it means that the parameters prior to the slash are
positional-only. For more info, see
the FAQ entry on positional-only parameters.
This function is added to the built-in namespace by the site module.

Changed in version 3.4: Changes to pydoc and inspect mean that the reported
signatures for callables are now more comprehensive and consistent."
hex(x),"Convert an integer number to a lowercase hexadecimal string prefixed with
“0x”. If x is not a Python int object, it has to define an
__index__() method that returns an integer. Some examples:
>>> hex(255)
'0xff'
>>> hex(-42)
'-0x2a'


If you want to convert an integer number to an uppercase or lower hexadecimal
string with prefix or not, you can use either of the following ways:
>>> '%#x' % 255, '%x' % 255, '%X' % 255
('0xff', 'ff', 'FF')
>>> format(255, '#x'), format(255, 'x'), format(255, 'X')
('0xff', 'ff', 'FF')
>>> f'{255:#x}', f'{255:x}', f'{255:X}'
('0xff', 'ff', 'FF')


See also format() for more information.
See also int() for converting a hexadecimal string to an
integer using a base of 16.

Note
To obtain a hexadecimal string representation for a float, use the
float.hex() method."
id(object),"Return the “identity” of an object.  This is an integer which
is guaranteed to be unique and constant for this object during its lifetime.
Two objects with non-overlapping lifetimes may have the same id()
value.

CPython implementation detail: This is the address of the object in memory."
input([prompt]),"If the prompt argument is present, it is written to standard output without
a trailing newline.  The function then reads a line from input, converts it
to a string (stripping a trailing newline), and returns that.  When EOF is
read, EOFError is raised.  Example:
>>> s = input('--> ')  
--> Monty Python's Flying Circus
>>> s  
""Monty Python's Flying Circus""


If the readline module was loaded, then input() will use it
to provide elaborate line editing and history features.
Raises an auditing event builtins.input with
argument prompt before reading input
Raises an auditing event builtins.input/result with the result after
successfully reading input."
"isinstance(object, classinfo)","Return True if the object argument is an instance of the classinfo
argument, or of a (direct, indirect or virtual) subclass thereof.  If object is not
an object of the given type, the function always returns False.
If classinfo is a tuple of type objects (or recursively, other such
tuples), return True if object is an instance of any of the types.
If classinfo is not a type or tuple of types and such tuples,
a TypeError exception is raised."
"issubclass(class, classinfo)","Return True if class is a subclass (direct, indirect or virtual) of classinfo.  A
class is considered a subclass of itself. classinfo may be a tuple of class
objects, in which case every entry in classinfo will be checked. In any other
case, a TypeError exception is raised."
"iter(object[, sentinel])","Return an iterator object.  The first argument is interpreted very
differently depending on the presence of the second argument. Without a
second argument, object must be a collection object which supports the
iteration protocol (the __iter__() method), or it must support the
sequence protocol (the __getitem__() method with integer arguments
starting at 0).  If it does not support either of those protocols,
TypeError is raised. If the second argument, sentinel, is given,
then object must be a callable object.  The iterator created in this case
will call object with no arguments for each call to its
__next__() method; if the value returned is equal to
sentinel, StopIteration will be raised, otherwise the value will
be returned.
See also Iterator Types.
One useful application of the second form of iter() is to build a
block-reader. For example, reading fixed-width blocks from a binary
database file until the end of file is reached:
from functools import partial
with open('mydata.db', 'rb') as f:
    for block in iter(partial(f.read, 64), b''):
        process_block(block)"
len(s),"Return the length (the number of items) of an object.  The argument may be a
sequence (such as a string, bytes, tuple, list, or range) or a collection
(such as a dictionary, set, or frozen set)."
locals(),"Update and return a dictionary representing the current local symbol table.
Free variables are returned by locals() when it is called in function
blocks, but not in class blocks. Note that at the module level, locals()
and globals() are the same dictionary.

Note
The contents of this dictionary should not be modified; changes may not
affect the values of local and free variables used by the interpreter."
"map(function, iterable, ...)","Return an iterator that applies function to every item of iterable,
yielding the results.  If additional iterable arguments are passed,
function must take that many arguments and is applied to the items from all
iterables in parallel.  With multiple iterables, the iterator stops when the
shortest iterable is exhausted.  For cases where the function inputs are
already arranged into argument tuples, see itertools.starmap()."
"max(iterable, *[, key, default])","Return the largest item in an iterable or the largest of two or more
arguments.
If one positional argument is provided, it should be an iterable.
The largest item in the iterable is returned.  If two or more positional
arguments are provided, the largest of the positional arguments is
returned.
There are two optional keyword-only arguments. The key argument specifies
a one-argument ordering function like that used for list.sort(). The
default argument specifies an object to return if the provided iterable is
empty. If the iterable is empty and default is not provided, a
ValueError is raised.
If multiple items are maximal, the function returns the first one
encountered.  This is consistent with other sort-stability preserving tools
such as sorted(iterable, key=keyfunc, reverse=True)[0] and
heapq.nlargest(1, iterable, key=keyfunc).

New in version 3.4: The default keyword-only argument.


Changed in version 3.8: The key can be None."
"min(iterable, *[, key, default])","Return the smallest item in an iterable or the smallest of two or more
arguments.
If one positional argument is provided, it should be an iterable.
The smallest item in the iterable is returned.  If two or more positional
arguments are provided, the smallest of the positional arguments is
returned.
There are two optional keyword-only arguments. The key argument specifies
a one-argument ordering function like that used for list.sort(). The
default argument specifies an object to return if the provided iterable is
empty. If the iterable is empty and default is not provided, a
ValueError is raised.
If multiple items are minimal, the function returns the first one
encountered.  This is consistent with other sort-stability preserving tools
such as sorted(iterable, key=keyfunc)[0] and heapq.nsmallest(1,
iterable, key=keyfunc).

New in version 3.4: The default keyword-only argument.


Changed in version 3.8: The key can be None."
"next(iterator[, default])","Retrieve the next item from the iterator by calling its
__next__() method.  If default is given, it is returned
if the iterator is exhausted, otherwise StopIteration is raised."
oct(x),"Convert an integer number to an octal string prefixed with “0o”.  The result
is a valid Python expression. If x is not a Python int object, it
has to define an __index__() method that returns an integer. For
example:
>>> oct(8)
'0o10'
>>> oct(-56)
'-0o70'


If you want to convert an integer number to octal string either with prefix
“0o” or not, you can use either of the following ways.
>>> '%#o' % 10, '%o' % 10
('0o12', '12')
>>> format(10, '#o'), format(10, 'o')
('0o12', '12')
>>> f'{10:#o}', f'{10:o}'
('0o12', '12')


See also format() for more information."
"open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)","Open file and return a corresponding file object.  If the file
cannot be opened, an OSError is raised.
file is a path-like object giving the pathname (absolute or
relative to the current working directory) of the file to be opened or an
integer file descriptor of the file to be wrapped.  (If a file descriptor is
given, it is closed when the returned I/O object is closed, unless closefd
is set to False.)
mode is an optional string that specifies the mode in which the file is
opened.  It defaults to 'r' which means open for reading in text mode.
Other common values are 'w' for writing (truncating the file if it
already exists), 'x' for exclusive creation and 'a' for appending
(which on some Unix systems, means that all writes append to the end of
the file regardless of the current seek position).  In text mode, if
encoding is not specified the encoding used is platform dependent:
locale.getpreferredencoding(False) is called to get the current locale
encoding. (For reading and writing raw bytes use binary mode and leave
encoding unspecified.)  The available modes are:






Character
Meaning



'r'
open for reading (default)

'w'
open for writing, truncating the file first

'x'
open for exclusive creation, failing if the file already exists

'a'
open for writing, appending to the end of the file if it exists

'b'
binary mode

't'
text mode (default)

'+'
open for updating (reading and writing)



The default mode is 'r' (open for reading text, synonym of 'rt').
Modes 'w+' and 'w+b' open and truncate the file.  Modes 'r+'
and 'r+b' open the file with no truncation.
As mentioned in the Overview, Python distinguishes between binary
and text I/O.  Files opened in binary mode (including 'b' in the mode
argument) return contents as bytes objects without any decoding.  In
text mode (the default, or when 't' is included in the mode argument),
the contents of the file are returned as str, the bytes having been
first decoded using a platform-dependent encoding or using the specified
encoding if given.
There is an additional mode character permitted, 'U', which no longer
has any effect, and is considered deprecated. It previously enabled
universal newlines in text mode, which became the default behaviour
in Python 3.0. Refer to the documentation of the
newline parameter for further details.

Note
Python doesn’t depend on the underlying operating system’s notion of text
files; all the processing is done by Python itself, and is therefore
platform-independent.

buffering is an optional integer used to set the buffering policy.  Pass 0
to switch buffering off (only allowed in binary mode), 1 to select line
buffering (only usable in text mode), and an integer > 1 to indicate the size
in bytes of a fixed-size chunk buffer.  When no buffering argument is
given, the default buffering policy works as follows:

Binary files are buffered in fixed-size chunks; the size of the buffer is
chosen using a heuristic trying to determine the underlying device’s “block
size” and falling back on io.DEFAULT_BUFFER_SIZE.  On many systems,
the buffer will typically be 4096 or 8192 bytes long.
“Interactive” text files (files for which isatty()
returns True) use line buffering.  Other text files use the policy
described above for binary files.

encoding is the name of the encoding used to decode or encode the file.
This should only be used in text mode.  The default encoding is platform
dependent (whatever locale.getpreferredencoding() returns), but any
text encoding supported by Python
can be used.  See the codecs module for
the list of supported encodings.
errors is an optional string that specifies how encoding and decoding
errors are to be handled—this cannot be used in binary mode.
A variety of standard error handlers are available
(listed under Error Handlers), though any
error handling name that has been registered with
codecs.register_error() is also valid.  The standard names
include:

'strict' to raise a ValueError exception if there is
an encoding error.  The default value of None has the same
effect.
'ignore' ignores errors.  Note that ignoring encoding errors
can lead to data loss.
'replace' causes a replacement marker (such as '?') to be inserted
where there is malformed data.
'surrogateescape' will represent any incorrect bytes as code
points in the Unicode Private Use Area ranging from U+DC80 to
U+DCFF.  These private code points will then be turned back into
the same bytes when the surrogateescape error handler is used
when writing data.  This is useful for processing files in an
unknown encoding.
'xmlcharrefreplace' is only supported when writing to a file.
Characters not supported by the encoding are replaced with the
appropriate XML character reference &#nnn;.
'backslashreplace' replaces malformed data by Python’s backslashed
escape sequences.
'namereplace' (also only supported when writing)
replaces unsupported characters with \N{...} escape sequences.

newline controls how universal newlines mode works (it only
applies to text mode).  It can be None, '', '\n', '\r', and
'\r\n'.  It works as follows:

When reading input from the stream, if newline is None, universal
newlines mode is enabled.  Lines in the input can end in '\n',
'\r', or '\r\n', and these are translated into '\n' before
being returned to the caller.  If it is '', universal newlines mode is
enabled, but line endings are returned to the caller untranslated.  If it
has any of the other legal values, input lines are only terminated by the
given string, and the line ending is returned to the caller untranslated.
When writing output to the stream, if newline is None, any '\n'
characters written are translated to the system default line separator,
os.linesep.  If newline is '' or '\n', no translation
takes place.  If newline is any of the other legal values, any '\n'
characters written are translated to the given string.

If closefd is False and a file descriptor rather than a filename was
given, the underlying file descriptor will be kept open when the file is
closed.  If a filename is given closefd must be True (the default)
otherwise an error will be raised.
A custom opener can be used by passing a callable as opener. The underlying
file descriptor for the file object is then obtained by calling opener with
(file, flags). opener must return an open file descriptor (passing
os.open as opener results in functionality similar to passing
None).
The newly created file is non-inheritable.
The following example uses the dir_fd parameter of the
os.open() function to open a file relative to a given directory:
>>> import os
>>> dir_fd = os.open('somedir', os.O_RDONLY)
>>> def opener(path, flags):
...     return os.open(path, flags, dir_fd=dir_fd)
...
>>> with open('spamspam.txt', 'w', opener=opener) as f:
...     print('This will be written to somedir/spamspam.txt', file=f)
...
>>> os.close(dir_fd)  # don't leak a file descriptor


The type of file object returned by the open() function
depends on the mode.  When open() is used to open a file in a text
mode ('w', 'r', 'wt', 'rt', etc.), it returns a subclass of
io.TextIOBase (specifically io.TextIOWrapper).  When used
to open a file in a binary mode with buffering, the returned class is a
subclass of io.BufferedIOBase.  The exact class varies: in read
binary mode, it returns an io.BufferedReader; in write binary and
append binary modes, it returns an io.BufferedWriter, and in
read/write mode, it returns an io.BufferedRandom.  When buffering is
disabled, the raw stream, a subclass of io.RawIOBase,
io.FileIO, is returned.
See also the file handling modules, such as, fileinput, io
(where open() is declared), os, os.path, tempfile,
and shutil.
Raises an auditing event open with arguments file, mode, flags.
The mode and flags arguments may have been modified or inferred from
the original call.


Changed in version 3.3: 
The opener parameter was added.
The 'x' mode was added.
IOError used to be raised, it is now an alias of OSError.
FileExistsError is now raised if the file opened in exclusive
creation mode ('x') already exists.





Changed in version 3.4: 
The file is now non-inheritable.




Deprecated since version 3.4, will be removed in version 3.9: The 'U' mode.



Changed in version 3.5: 
If the system call is interrupted and the signal handler does not raise an
exception, the function now retries the system call instead of raising an
InterruptedError exception (see PEP 475 for the rationale).
The 'namereplace' error handler was added.





Changed in version 3.6: 
Support added to accept objects implementing os.PathLike.
On Windows, opening a console buffer may return a subclass of
io.RawIOBase other than io.FileIO."
ord(c),"Given a string representing one Unicode character, return an integer
representing the Unicode code point of that character.  For example,
ord('a') returns the integer 97 and ord('€') (Euro sign)
returns 8364.  This is the inverse of chr()."
"pow(base, exp[, mod])","Return base to the power exp; if mod is present, return base to the
power exp, modulo mod (computed more efficiently than
pow(base, exp) % mod). The two-argument form pow(base, exp) is
equivalent to using the power operator: base**exp.
The arguments must have numeric types.  With mixed operand types, the
coercion rules for binary arithmetic operators apply.  For int
operands, the result has the same type as the operands (after coercion)
unless the second argument is negative; in that case, all arguments are
converted to float and a float result is delivered.  For example, 10**2
returns 100, but 10**-2 returns 0.01.
For int operands base and exp, if mod is present, mod must
also be of integer type and mod must be nonzero. If mod is present and
exp is negative, base must be relatively prime to mod. In that case,
pow(inv_base, -exp, mod) is returned, where inv_base is an inverse to
base modulo mod.
Here’s an example of computing an inverse for 38 modulo 97:
>>> pow(38, -1, mod=97)
23
>>> 23 * 38 % 97 == 1
True



Changed in version 3.8: For int operands, the three-argument form of pow now allows
the second argument to be negative, permitting computation of modular
inverses.


Changed in version 3.9: Allow keyword arguments.  Formerly, only positional arguments were
supported."
"print(*objects, sep=' ', end='\n', file=sys.stdout, flush=False)","Print objects to the text stream file, separated by sep and followed
by end.  sep, end, file and flush, if present, must be given as keyword
arguments.
All non-keyword arguments are converted to strings like str() does and
written to the stream, separated by sep and followed by end.  Both sep
and end must be strings; they can also be None, which means to use the
default values.  If no objects are given, print() will just write
end.
The file argument must be an object with a write(string) method; if it
is not present or None, sys.stdout will be used.  Since printed
arguments are converted to text strings, print() cannot be used with
binary mode file objects.  For these, use file.write(...) instead.
Whether output is buffered is usually determined by file, but if the
flush keyword argument is true, the stream is forcibly flushed.

Changed in version 3.3: Added the flush keyword argument."
repr(object),"Return a string containing a printable representation of an object.  For many
types, this function makes an attempt to return a string that would yield an
object with the same value when passed to eval(), otherwise the
representation is a string enclosed in angle brackets that contains the name
of the type of the object together with additional information often
including the name and address of the object.  A class can control what this
function returns for its instances by defining a __repr__() method."
reversed(seq),"Return a reverse iterator.  seq must be an object which has
a __reversed__() method or supports the sequence protocol (the
__len__() method and the __getitem__() method with integer
arguments starting at 0)."
"round(number[, ndigits])","Return number rounded to ndigits precision after the decimal
point.  If ndigits is omitted or is None, it returns the
nearest integer to its input.
For the built-in types supporting round(), values are rounded to the
closest multiple of 10 to the power minus ndigits; if two multiples are
equally close, rounding is done toward the even choice (so, for example,
both round(0.5) and round(-0.5) are 0, and round(1.5) is
2).  Any integer value is valid for ndigits (positive, zero, or
negative).  The return value is an integer if ndigits is omitted or
None.
Otherwise the return value has the same type as number.
For a general Python object number, round delegates to
number.__round__.

Note
The behavior of round() for floats can be surprising: for example,
round(2.675, 2) gives 2.67 instead of the expected 2.68.
This is not a bug: it’s a result of the fact that most decimal fractions
can’t be represented exactly as a float.  See Floating Point Arithmetic:  Issues and Limitations for
more information."
"setattr(object, name, value)","This is the counterpart of getattr().  The arguments are an object, a
string and an arbitrary value.  The string may name an existing attribute or a
new attribute.  The function assigns the value to the attribute, provided the
object allows it.  For example, setattr(x, 'foobar', 123) is equivalent to
x.foobar = 123."
"sorted(iterable, *, key=None, reverse=False)","Return a new sorted list from the items in iterable.
Has two optional arguments which must be specified as keyword arguments.
key specifies a function of one argument that is used to extract a comparison
key from each element in iterable (for example, key=str.lower).  The
default value is None (compare the elements directly).
reverse is a boolean value.  If set to True, then the list elements are
sorted as if each comparison were reversed.
Use functools.cmp_to_key() to convert an old-style cmp function to a
key function.
The built-in sorted() function is guaranteed to be stable. A sort is
stable if it guarantees not to change the relative order of elements that
compare equal — this is helpful for sorting in multiple passes (for
example, sort by department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO."
@staticmethod,"Transform a method into a static method.
A static method does not receive an implicit first argument. To declare a static
method, use this idiom:
class C:
    @staticmethod
    def f(arg1, arg2, ...): ...


The @staticmethod form is a function decorator – see
Function definitions for details.
A static method can be called either on the class (such as C.f()) or on an instance (such
as C().f()).
Static methods in Python are similar to those found in Java or C++. Also see
classmethod() for a variant that is useful for creating alternate class
constructors.
Like all decorators, it is also possible to call staticmethod as
a regular function and do something with its result.  This is needed
in some cases where you need a reference to a function from a class
body and you want to avoid the automatic transformation to instance
method.  For these cases, use this idiom:
class C:
    builtin_open = staticmethod(open)


For more information on static methods, see The standard type hierarchy."
"sum(iterable, /, start=0)","Sums start and the items of an iterable from left to right and returns the
total.  The iterable’s items are normally numbers, and the start value is not
allowed to be a string.
For some use cases, there are good alternatives to sum().
The preferred, fast way to concatenate a sequence of strings is by calling
''.join(sequence).  To add floating point values with extended precision,
see math.fsum().  To concatenate a series of iterables, consider using
itertools.chain().

Changed in version 3.8: The start parameter can be specified as a keyword argument."
"super([type[, object-or-type]])","Return a proxy object that delegates method calls to a parent or sibling
class of type.  This is useful for accessing inherited methods that have
been overridden in a class.
The object-or-type determines the method resolution order
to be searched.  The search starts from the class right after the
type.
For example, if __mro__ of object-or-type is
D -> B -> C -> A -> object and the value of type is B,
then super() searches C -> A -> object.
The __mro__ attribute of the object-or-type lists the method
resolution search order used by both getattr() and super().  The
attribute is dynamic and can change whenever the inheritance hierarchy is
updated.
If the second argument is omitted, the super object returned is unbound.  If
the second argument is an object, isinstance(obj, type) must be true.  If
the second argument is a type, issubclass(type2, type) must be true (this
is useful for classmethods).
There are two typical use cases for super.  In a class hierarchy with
single inheritance, super can be used to refer to parent classes without
naming them explicitly, thus making the code more maintainable.  This use
closely parallels the use of super in other programming languages.
The second use case is to support cooperative multiple inheritance in a
dynamic execution environment.  This use case is unique to Python and is
not found in statically compiled languages or languages that only support
single inheritance.  This makes it possible to implement “diamond diagrams”
where multiple base classes implement the same method.  Good design dictates
that this method have the same calling signature in every case (because the
order of calls is determined at runtime, because that order adapts
to changes in the class hierarchy, and because that order can include
sibling classes that are unknown prior to runtime).
For both use cases, a typical superclass call looks like this:
class C(B):
    def method(self, arg):
        super().method(arg)    # This does the same thing as:
                               # super(C, self).method(arg)


In addition to method lookups, super() also works for attribute
lookups.  One possible use case for this is calling descriptors
in a parent or sibling class.
Note that super() is implemented as part of the binding process for
explicit dotted attribute lookups such as super().__getitem__(name).
It does so by implementing its own __getattribute__() method for searching
classes in a predictable order that supports cooperative multiple inheritance.
Accordingly, super() is undefined for implicit lookups using statements or
operators such as super()[name].
Also note that, aside from the zero argument form, super() is not
limited to use inside methods.  The two argument form specifies the
arguments exactly and makes the appropriate references.  The zero
argument form only works inside a class definition, as the compiler fills
in the necessary details to correctly retrieve the class being defined,
as well as accessing the current instance for ordinary methods.
For practical suggestions on how to design cooperative classes using
super(), see guide to using super()."
vars([object]),"Return the __dict__ attribute for a module, class, instance,
or any other object with a __dict__ attribute.
Objects such as modules and instances have an updateable __dict__
attribute; however, other objects may have write restrictions on their
__dict__ attributes (for example, classes use a
types.MappingProxyType to prevent direct dictionary updates).
Without an argument, vars() acts like locals().  Note, the
locals dictionary is only useful for reads since updates to the locals
dictionary are ignored."
zip(*iterables),"Make an iterator that aggregates elements from each of the iterables.
Returns an iterator of tuples, where the i-th tuple contains
the i-th element from each of the argument sequences or iterables.  The
iterator stops when the shortest input iterable is exhausted. With a single
iterable argument, it returns an iterator of 1-tuples.  With no arguments,
it returns an empty iterator.  Equivalent to:
def zip(*iterables):
    # zip('ABCD', 'xy') --> Ax By
    sentinel = object()
    iterators = [iter(it) for it in iterables]
    while iterators:
        result = []
        for it in iterators:
            elem = next(it, sentinel)
            if elem is sentinel:
                return
            result.append(elem)
        yield tuple(result)


The left-to-right evaluation order of the iterables is guaranteed. This
makes possible an idiom for clustering a data series into n-length groups
using zip(*[iter(s)]*n).  This repeats the same iterator n times
so that each output tuple has the result of n calls to the iterator.
This has the effect of dividing the input into n-length chunks.
zip() should only be used with unequal length inputs when you don’t
care about trailing, unmatched values from the longer iterables.  If those
values are important, use itertools.zip_longest() instead.
zip() in conjunction with the * operator can be used to unzip a
list:
>>> x = [1, 2, 3]
>>> y = [4, 5, 6]
>>> zipped = zip(x, y)
>>> list(zipped)
[(1, 4), (2, 5), (3, 6)]
>>> x2, y2 = zip(*zip(x, y))
>>> x == list(x2) and y == list(y2)
True"
"__import__(name, globals=None, locals=None, fromlist=(), level=0)","Note
This is an advanced function that is not needed in everyday Python
programming, unlike importlib.import_module().

This function is invoked by the import statement.  It can be
replaced (by importing the builtins module and assigning to
builtins.__import__) in order to change semantics of the
import statement, but doing so is strongly discouraged as it
is usually simpler to use import hooks (see PEP 302) to attain the same
goals and does not cause issues with code which assumes the default import
implementation is in use.  Direct use of __import__() is also
discouraged in favor of importlib.import_module().
The function imports the module name, potentially using the given globals
and locals to determine how to interpret the name in a package context.
The fromlist gives the names of objects or submodules that should be
imported from the module given by name.  The standard implementation does
not use its locals argument at all, and uses its globals only to
determine the package context of the import statement.
level specifies whether to use absolute or relative imports. 0 (the
default) means only perform absolute imports.  Positive values for
level indicate the number of parent directories to search relative to the
directory of the module calling __import__() (see PEP 328 for the
details).
When the name variable is of the form package.module, normally, the
top-level package (the name up till the first dot) is returned, not the
module named by name.  However, when a non-empty fromlist argument is
given, the module named by name is returned.
For example, the statement import spam results in bytecode resembling the
following code:
spam = __import__('spam', globals(), locals(), [], 0)


The statement import spam.ham results in this call:
spam = __import__('spam.ham', globals(), locals(), [], 0)


Note how __import__() returns the toplevel module here because this is
the object that is bound to a name by the import statement.
On the other hand, the statement from spam.ham import eggs, sausage as
saus results in
_temp = __import__('spam.ham', globals(), locals(), ['eggs', 'sausage'], 0)
eggs = _temp.eggs
saus = _temp.sausage


Here, the spam.ham module is returned from __import__().  From this
object, the names to import are retrieved and assigned to their respective
names.
If you simply want to import a module (potentially within a package) by name,
use importlib.import_module().

Changed in version 3.3: Negative values for level are no longer supported (which also changes
the default value to 0)."
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
with_traceback(tb),"This method sets tb as the new traceback for the exception and returns
the exception object.  It is usually used in exception handling code like
this:
try:
    ...
except SomeException:
    tb = sys.exc_info()[2]
    raise OtherException(...).with_traceback(tb)"
contextvars.copy_context(),"Returns a copy of the current Context object.
The following snippet gets a copy of the current context and prints
all variables and their values that are set in it:
ctx: Context = copy_context()
print(list(ctx.items()))


The function has an O(1) complexity, i.e. works equally fast for
contexts with a few context variables and for contexts that have
a lot of them."
get([default]),"Return a value for the context variable for the current context.
If there is no value for the variable in the current context,
the method will:

return the value of the default argument of the method,
if provided; or
return the default value for the context variable,
if it was created with one; or
raise a LookupError."
set(value),"Call to set a new value for the context variable in the current
context.
The required value argument is the new value for the context
variable.
Returns a Token object that can be used
to restore the variable to its previous value via the
ContextVar.reset() method."
reset(token),"Reset the context variable to the value it had before the
ContextVar.set() that created the token was used.
For example:
var = ContextVar('var')

token = var.set('new value')
# code that uses 'var'; var.get() returns 'new value'.
var.reset(token)

# After the reset call the var has no value again, so
# var.get() would raise a LookupError."
"run(callable, *args, **kwargs)","Execute callable(*args, **kwargs) code in the context object
the run method is called on.  Return the result of the execution
or propagate an exception if one occurred.
Any changes to any context variables that callable makes will
be contained in the context object:
var = ContextVar('var')
var.set('spam')

def main():
    # 'var' was set to 'spam' before
    # calling 'copy_context()' and 'ctx.run(main)', so:
    # var.get() == ctx[var] == 'spam'

    var.set('ham')

    # Now, after setting 'var' to 'ham':
    # var.get() == ctx[var] == 'ham'

ctx = copy_context()

# Any changes that the 'main' function makes to 'var'
# will be contained in 'ctx'.
ctx.run(main)

# The 'main()' function was run in the 'ctx' context,
# so changes to 'var' are contained in it:
# ctx[var] == 'ham'

# However, outside of 'ctx', 'var' is still set to 'spam':
# var.get() == 'spam'


The method raises a RuntimeError when called on the same
context object from more than one OS thread, or when called
recursively."
copy(),Return a shallow copy of the context object.
"get(var[, default])","Return the value for var if var has the value in the context
object.  Return default otherwise.  If default is not given,
return None."
keys(),Return a list of all variables in the context object.
values(),Return a list of all variables’ values in the context object.
items(),"Return a list of 2-tuples containing all variables and their
values in the context object."
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
int.bit_length(),"Return the number of bits necessary to represent an integer in binary,
excluding the sign and leading zeros:
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6


More precisely, if x is nonzero, then x.bit_length() is the
unique positive integer k such that 2**(k-1) <= abs(x) < 2**k.
Equivalently, when abs(x) is small enough to have a correctly
rounded logarithm, then k = 1 + int(log(abs(x), 2)).
If x is zero, then x.bit_length() returns 0.
Equivalent to:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6



New in version 3.1."
"int.to_bytes(length, byteorder, *, signed=False)","Return an array of bytes representing an integer.
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'


The integer is represented using length bytes.  An OverflowError
is raised if the integer is not representable with the given number of
bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument determines whether two’s complement is used to
represent the integer.  If signed is False and a negative integer is
given, an OverflowError is raised. The default value for signed
is False.

New in version 3.2."
"classmethod int.from_bytes(bytes, byteorder, *, signed=False)","Return the integer represented by the given array of bytes.
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680


The argument bytes must either be a bytes-like object or an
iterable producing bytes.
The byteorder argument determines the byte order used to represent the
integer.  If byteorder is ""big"", the most significant byte is at the
beginning of the byte array.  If byteorder is ""little"", the most
significant byte is at the end of the byte array.  To request the native
byte order of the host system, use sys.byteorder as the byte order
value.
The signed argument indicates whether two’s complement is used to
represent the integer.

New in version 3.2."
int.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the original
integer and with a positive denominator. The integer ratio of integers
(whole numbers) is always the integer as the numerator and 1 as the
denominator.

New in version 3.8."
float.as_integer_ratio(),"Return a pair of integers whose ratio is exactly equal to the
original float and with a positive denominator.  Raises
OverflowError on infinities and a ValueError on
NaNs."
float.is_integer(),"Return True if the float instance is finite with integral
value, and False otherwise:
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False"
float.hex(),"Return a representation of a floating-point number as a hexadecimal
string.  For finite floating-point numbers, this representation
will always include a leading 0x and a trailing p and
exponent."
classmethod float.fromhex(s),"Class method to return the float represented by a hexadecimal
string s.  The string s may have leading and trailing
whitespace."
container.__iter__(),"Return an iterator object.  The object is required to support the iterator
protocol described below.  If a container supports different types of
iteration, additional methods can be provided to specifically request
iterators for those iteration types.  (An example of an object supporting
multiple forms of iteration would be a tree structure which supports both
breadth-first and depth-first traversal.)  This method corresponds to the
tp_iter slot of the type structure for Python objects in the Python/C
API."
iterator.__iter__(),"Return the iterator object itself.  This is required to allow both containers
and iterators to be used with the for and in statements.
This method corresponds to the tp_iter slot of the type structure for
Python objects in the Python/C API."
iterator.__next__(),"Return the next item from the container.  If there are no further items, raise
the StopIteration exception.  This method corresponds to the
tp_iternext slot of the type structure for Python objects in the
Python/C API."
"sort(*, key=None, reverse=False)","This method sorts the list in place, using only < comparisons
between items. Exceptions are not suppressed - if any comparison operations
fail, the entire sort operation will fail (and the list will likely be left
in a partially modified state).
sort() accepts two arguments that can only be passed by keyword
(keyword-only arguments):
key specifies a function of one argument that is used to extract a
comparison key from each list element (for example, key=str.lower).
The key corresponding to each item in the list is calculated once and
then used for the entire sorting process. The default value of None
means that list items are sorted directly without calculating a separate
key value.
The functools.cmp_to_key() utility is available to convert a 2.x
style cmp function to a key function.
reverse is a boolean value.  If set to True, then the list elements
are sorted as if each comparison were reversed.
This method modifies the sequence in place for economy of space when
sorting a large sequence.  To remind users that it operates by side
effect, it does not return the sorted sequence (use sorted() to
explicitly request a new sorted list instance).
The sort() method is guaranteed to be stable.  A sort is stable if it
guarantees not to change the relative order of elements that compare equal
— this is helpful for sorting in multiple passes (for example, sort by
department, then by salary grade).
For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even
inspect, the list is undefined.  The C implementation of Python makes the
list appear empty for the duration, and raises ValueError if it can
detect that the list has been mutated during a sort."
str.capitalize(),"Return a copy of the string with its first character capitalized and the
rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase.
This means that characters like digraphs will only have their first
letter capitalized, instead of the full character."
str.casefold(),"Return a casefolded copy of the string. Casefolded strings may be used for
caseless matching.
Casefolding is similar to lowercasing but more aggressive because it is
intended to remove all case distinctions in a string. For example, the German
lowercase letter 'ß' is equivalent to ""ss"". Since it is already
lowercase, lower() would do nothing to 'ß'; casefold()
converts it to ""ss"".
The casefolding algorithm is described in section 3.13 of the Unicode
Standard.

New in version 3.3."
"str.center(width[, fillchar])","Return centered in a string of length width. Padding is done using the
specified fillchar (default is an ASCII space). The original string is
returned if width is less than or equal to len(s)."
"str.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of substring sub in the
range [start, end].  Optional arguments start and end are
interpreted as in slice notation."
"str.encode(encoding=""utf-8"", errors=""strict"")","Return an encoded version of the string as a bytes object. Default encoding
is 'utf-8'. errors may be given to set a different error handling scheme.
The default for errors is 'strict', meaning that encoding errors raise
a UnicodeError. Other possible
values are 'ignore', 'replace', 'xmlcharrefreplace',
'backslashreplace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Changed in version 3.1: Support for keyword arguments added."
"str.endswith(suffix[, start[, end]])","Return True if the string ends with the specified suffix, otherwise return
False.  suffix can also be a tuple of suffixes to look for.  With optional
start, test beginning at that position.  With optional end, stop comparing
at that position."
str.expandtabs(tabsize=8),"Return a copy of the string where all tab characters are replaced by one or
more spaces, depending on the current column and the given tab size.  Tab
positions occur every tabsize characters (default is 8, giving tab
positions at columns 0, 8, 16 and so on).  To expand the string, the current
column is set to zero and the string is examined character by character.  If
the character is a tab (\t), one or more space characters are inserted
in the result until the current column is equal to the next tab position.
(The tab character itself is not copied.)  If the character is a newline
(\n) or return (\r), it is copied and the current column is reset to
zero.  Any other character is copied unchanged and the current column is
incremented by one regardless of how the character is represented when
printed.
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'"
"str.find(sub[, start[, end]])","Return the lowest index in the string where substring sub is found within
the slice s[start:end].  Optional arguments start and end are
interpreted as in slice notation.  Return -1 if sub is not found.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> 'Py' in 'Python'
True"
"str.format(*args, **kwargs)","Perform a string formatting operation.  The string on which this method is
called can contain literal text or replacement fields delimited by braces
{}.  Each replacement field contains either the numeric index of a
positional argument, or the name of a keyword argument.  Returns a copy of
the string where each replacement field is replaced with the string value of
the corresponding argument.
>>> ""The sum of 1 + 2 is {0}"".format(1+2)
'The sum of 1 + 2 is 3'


See Format String Syntax for a description of the various formatting options
that can be specified in format strings.

Note
When formatting a number (int, float, complex,
decimal.Decimal and subclasses) with the n type
(ex: '{:n}'.format(1234)), the function temporarily sets the
LC_CTYPE locale to the LC_NUMERIC locale to decode
decimal_point and thousands_sep fields of localeconv() if
they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is
different than the LC_CTYPE locale.  This temporary change affects
other threads.


Changed in version 3.7: When formatting a number with the n type, the function sets
temporarily the LC_CTYPE locale to the LC_NUMERIC locale in some
cases."
str.format_map(mapping),"Similar to str.format(**mapping), except that mapping is
used directly and not copied to a dict.  This is useful
if for example mapping is a dict subclass:
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'



New in version 3.2."
"str.index(sub[, start[, end]])","Like find(), but raise ValueError when the substring is
not found."
str.isalnum(),"Return True if all characters in the string are alphanumeric and there is at
least one character, False otherwise.  A character c is alphanumeric if one
of the following returns True: c.isalpha(), c.isdecimal(),
c.isdigit(), or c.isnumeric()."
str.isalpha(),"Return True if all characters in the string are alphabetic and there is at least
one character, False otherwise.  Alphabetic characters are those characters defined
in the Unicode character database as “Letter”, i.e., those with general category
property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”.  Note that this is different
from the “Alphabetic” property defined in the Unicode Standard."
str.isascii(),"Return True if the string is empty or all characters in the string are ASCII,
False otherwise.
ASCII characters have code points in the range U+0000-U+007F.

New in version 3.7."
str.isdecimal(),"Return True if all characters in the string are decimal
characters and there is at least one character, False
otherwise. Decimal characters are those that can be used to form
numbers in base 10, e.g. U+0660, ARABIC-INDIC DIGIT
ZERO.  Formally a decimal character is a character in the Unicode
General Category “Nd”."
str.isdigit(),"Return True if all characters in the string are digits and there is at least one
character, False otherwise.  Digits include decimal characters and digits that need
special handling, such as the compatibility superscript digits.
This covers digits which cannot be used to form numbers in base 10,
like the Kharosthi numbers.  Formally, a digit is a character that has the
property value Numeric_Type=Digit or Numeric_Type=Decimal."
str.isidentifier(),"Return True if the string is a valid identifier according to the language
definition, section Identifiers and keywords.
Call keyword.iskeyword() to test whether string s is a reserved
identifier, such as def and class.
Example:
>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True"
str.islower(),"Return True if all cased characters 4 in the string are lowercase and
there is at least one cased character, False otherwise."
str.isnumeric(),"Return True if all characters in the string are numeric
characters, and there is at least one character, False
otherwise. Numeric characters include digit characters, and all characters
that have the Unicode numeric value property, e.g. U+2155,
VULGAR FRACTION ONE FIFTH.  Formally, numeric characters are those with the property
value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric."
str.isprintable(),"Return True if all characters in the string are printable or the string is
empty, False otherwise.  Nonprintable characters are those characters defined
in the Unicode character database as “Other” or “Separator”, excepting the
ASCII space (0x20) which is considered printable.  (Note that printable
characters in this context are those which should not be escaped when
repr() is invoked on a string.  It has no bearing on the handling of
strings written to sys.stdout or sys.stderr.)"
str.isspace(),"Return True if there are only whitespace characters in the string and there is
at least one character, False otherwise.
A character is whitespace if in the Unicode character database
(see unicodedata), either its general category is Zs
(“Separator, space”), or its bidirectional class is one of WS,
B, or S."
str.istitle(),"Return True if the string is a titlecased string and there is at least one
character, for example uppercase characters may only follow uncased characters
and lowercase characters only cased ones.  Return False otherwise."
str.isupper(),"Return True if all cased characters 4 in the string are uppercase and
there is at least one cased character, False otherwise."
str.join(iterable),"Return a string which is the concatenation of the strings in iterable.
A TypeError will be raised if there are any non-string values in
iterable, including bytes objects.  The separator between
elements is the string providing this method."
"str.ljust(width[, fillchar])","Return the string left justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.lower(),"Return a copy of the string with all the cased characters 4 converted to
lowercase.
The lowercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.lstrip([chars]),"Return a copy of the string with leading characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a prefix; rather, all combinations of its values are stripped:
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'"
"static str.maketrans(x[, y[, z]])","This static method returns a translation table usable for str.translate().
If there is only one argument, it must be a dictionary mapping Unicode
ordinals (integers) or characters (strings of length 1) to Unicode ordinals,
strings (of arbitrary lengths) or None.  Character keys will then be
converted to ordinals.
If there are two arguments, they must be strings of equal length, and in the
resulting dictionary, each character in x will be mapped to the character at
the same position in y.  If there is a third argument, it must be a string,
whose characters will be mapped to None in the result."
str.partition(sep),"Split the string at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
the string itself, followed by two empty strings."
"str.replace(old, new[, count])","Return a copy of the string with all occurrences of substring old replaced by
new.  If the optional argument count is given, only the first count
occurrences are replaced."
"str.rfind(sub[, start[, end]])","Return the highest index in the string where substring sub is found, such
that sub is contained within s[start:end].  Optional arguments start
and end are interpreted as in slice notation.  Return -1 on failure."
"str.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the substring sub is not
found."
"str.rjust(width[, fillchar])","Return the string right justified in a string of length width. Padding is
done using the specified fillchar (default is an ASCII space). The
original string is returned if width is less than or equal to len(s)."
str.rpartition(sep),"Split the string at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself, and the part
after the separator.  If the separator is not found, return a 3-tuple containing
two empty strings, followed by the string itself."
"str.rsplit(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter string.
If maxsplit is given, at most maxsplit splits are done, the rightmost
ones.  If sep is not specified or None, any whitespace string is a
separator.  Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
str.rstrip([chars]),"Return a copy of the string with trailing characters removed.  The chars
argument is a string specifying the set of characters to be removed.  If omitted
or None, the chars argument defaults to removing whitespace.  The chars
argument is not a suffix; rather, all combinations of its values are stripped:
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'"
"str.split(sep=None, maxsplit=-1)","Return a list of the words in the string, using sep as the delimiter
string.  If maxsplit is given, at most maxsplit splits are done (thus,
the list will have at most maxsplit+1 elements).  If maxsplit is not
specified or -1, then there is no limit on the number of splits
(all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty strings (for example, '1,,2'.split(',') returns
['1', '', '2']).  The sep argument may consist of multiple characters
(for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']).
Splitting an empty string with a specified separator returns [''].
For example:
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']


If sep is not specified or is None, a different splitting algorithm is
applied: runs of consecutive whitespace are regarded as a single separator,
and the result will contain no empty strings at the start or end if the
string has leading or trailing whitespace.  Consequently, splitting an empty
string or a string consisting of just whitespace with a None separator
returns [].
For example:
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']"
str.splitlines([keepends]),"Return a list of the lines in the string, breaking at line boundaries.  Line
breaks are not included in the resulting list unless keepends is given and
true.
This method splits on the following line boundaries.  In particular, the
boundaries are a superset of universal newlines.






Representation
Description



\n
Line Feed

\r
Carriage Return

\r\n
Carriage Return + Line Feed

\v or \x0b
Line Tabulation

\f or \x0c
Form Feed

\x1c
File Separator

\x1d
Group Separator

\x1e
Record Separator

\x85
Next Line (C1 Control Code)

\u2028
Line Separator

\u2029
Paragraph Separator




Changed in version 3.2: \v and \f added to list of line boundaries.

For example:
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> """".splitlines()
[]
>>> ""One line\n"".splitlines()
['One line']


For comparison, split('\n') gives:
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']"
"str.startswith(prefix[, start[, end]])","Return True if string starts with the prefix, otherwise return False.
prefix can also be a tuple of prefixes to look for.  With optional start,
test string beginning at that position.  With optional end, stop comparing
string at that position."
str.strip([chars]),"Return a copy of the string with the leading and trailing characters removed.
The chars argument is a string specifying the set of characters to be removed.
If omitted or None, the chars argument defaults to removing whitespace.
The chars argument is not a prefix or suffix; rather, all combinations of its
values are stripped:
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'


The outermost leading and trailing chars argument values are stripped
from the string. Characters are removed from the leading end until
reaching a string character that is not contained in the set of
characters in chars. A similar action takes place on the trailing end.
For example:
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'"
str.swapcase(),"Return a copy of the string with uppercase characters converted to lowercase and
vice versa. Note that it is not necessarily true that
s.swapcase().swapcase() == s."
str.title(),"Return a titlecased version of the string where words start with an uppercase
character and the remaining characters are lowercase.
For example:
>>> 'Hello world'.title()
'Hello World'


The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(r""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase(""they're bill's friends."")
""They're Bill's Friends."""
str.translate(table),"Return a copy of the string in which each character has been mapped through
the given translation table.  The table must be an object that implements
indexing via __getitem__(), typically a mapping or
sequence.  When indexed by a Unicode ordinal (an integer), the
table object can do any of the following: return a Unicode ordinal or a
string, to map the character to one or more other characters; return
None, to delete the character from the return string; or raise a
LookupError exception, to map the character to itself.
You can use str.maketrans() to create a translation map from
character-to-character mappings in different formats.
See also the codecs module for a more flexible approach to custom
character mappings."
str.upper(),"Return a copy of the string with all the cased characters 4 converted to
uppercase.  Note that s.upper().isupper() might be False if s
contains uncased characters or if the Unicode category of the resulting
character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter,
titlecase).
The uppercasing algorithm used is described in section 3.13 of the Unicode
Standard."
str.zfill(width),"Return a copy of the string left filled with ASCII '0' digits to
make a string of length width. A leading sign prefix ('+'/'-')
is handled by inserting the padding after the sign character rather
than before. The original string is returned if width is less than
or equal to len(s).
For example:
>>> ""42"".zfill(5)
'00042'
>>> ""-42"".zfill(5)
'-0042'"
classmethod fromhex(string),"This bytes class method returns a bytes object, decoding the
given string object.  The string must contain two hexadecimal digits per
byte, with ASCII whitespace being ignored.
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'


If you want to make the hex string easier to read, you can specify a
single character separator sep parameter to include in the output.
By default between each byte.  A second optional bytes_per_sep
parameter controls the spacing.  Positive values calculate the
separator position from the right, negative values from the left.
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'



New in version 3.5.


Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep
parameters to insert separators between bytes in the hex output."
classmethod fromhex(string),"This bytearray class method returns bytearray object, decoding
the given string object.  The string must contain two hexadecimal digits
per byte, with ASCII whitespace being ignored.
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string,
not just spaces."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the instance.
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
"bytes.count(sub[, start[, end]])","Return the number of non-overlapping occurrences of subsequence sub in
the range [start, end].  Optional arguments start and end are
interpreted as in slice notation.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.decode(encoding=""utf-8"", errors=""strict"")","Return a string decoded from the given bytes.  Default encoding is
'utf-8'. errors may be given to set a different
error handling scheme.  The default for errors is 'strict', meaning
that encoding errors raise a UnicodeError.  Other possible values are
'ignore', 'replace' and any other name registered via
codecs.register_error(), see section Error Handlers. For a
list of possible encodings, see section Standard Encodings.

Note
Passing the encoding argument to str allows decoding any
bytes-like object directly, without needing to make a temporary
bytes or bytearray object.


Changed in version 3.1: Added support for keyword arguments."
"bytes.endswith(suffix[, start[, end]])","Return True if the binary data ends with the specified suffix,
otherwise return False.  suffix can also be a tuple of suffixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The suffix(es) to search for may be any bytes-like object."
"bytes.find(sub[, start[, end]])","Return the lowest index in the data where the subsequence sub is found,
such that sub is contained in the slice s[start:end].  Optional
arguments start and end are interpreted as in slice notation.  Return
-1 if sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Note
The find() method should be used only if you need to know the
position of sub.  To check if sub is a substring or not, use the
in operator:
>>> b'Py' in b'Python'
True




Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.index(sub[, start[, end]])","Like find(), but raise ValueError when the
subsequence is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.join(iterable),"Return a bytes or bytearray object which is the concatenation of the
binary data sequences in iterable.  A TypeError will be raised
if there are any values in iterable that are not bytes-like
objects, including str objects.  The
separator between elements is the contents of the bytes or
bytearray object providing this method."
"static bytes.maketrans(from, to)","This static method returns a translation table usable for
bytes.translate() that will map each character in from into the
character at the same position in to; from and to must both be
bytes-like objects and have the same length.

New in version 3.1."
bytes.partition(sep),"Split the sequence at the first occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing a copy of the original sequence, followed by two empty bytes or
bytearray objects.
The separator to search for may be any bytes-like object."
"bytes.replace(old, new[, count])","Return a copy of the sequence with all occurrences of subsequence old
replaced by new.  If the optional argument count is given, only the
first count occurrences are replaced.
The subsequence to search for and its replacement may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
"bytes.rfind(sub[, start[, end]])","Return the highest index in the sequence where the subsequence sub is
found, such that sub is contained within s[start:end].  Optional
arguments start and end are interpreted as in slice notation. Return
-1 on failure.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
"bytes.rindex(sub[, start[, end]])","Like rfind() but raises ValueError when the
subsequence sub is not found.
The subsequence to search for may be any bytes-like object or an
integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."
bytes.rpartition(sep),"Split the sequence at the last occurrence of sep, and return a 3-tuple
containing the part before the separator, the separator itself or its
bytearray copy, and the part after the separator.
If the separator is not found, return a 3-tuple
containing two empty bytes or bytearray objects, followed by a copy of the
original sequence.
The separator to search for may be any bytes-like object."
"bytes.startswith(prefix[, start[, end]])","Return True if the binary data starts with the specified prefix,
otherwise return False.  prefix can also be a tuple of prefixes to
look for.  With optional start, test beginning at that position.  With
optional end, stop comparing at that position.
The prefix(es) to search for may be any bytes-like object."
"bytes.translate(table, /, delete=b'')","Return a copy of the bytes or bytearray object where all bytes occurring in
the optional argument delete are removed, and the remaining bytes have
been mapped through the given translation table, which must be a bytes
object of length 256.
You can use the bytes.maketrans() method to create a translation
table.
Set the table argument to None for translations that only delete
characters:
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument."
"bytes.center(width[, fillbyte])","Return a copy of the object centered in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.ljust(width[, fillbyte])","Return a copy of the object left justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.lstrip([chars]),"Return a copy of the sequence with specified leading bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults
to removing ASCII whitespace.  The chars argument is not a prefix;
rather, all combinations of its values are stripped:
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rjust(width[, fillbyte])","Return a copy of the object right justified in a sequence of length width.
Padding is done using the specified fillbyte (default is an ASCII
space). For bytes objects, the original sequence is returned if
width is less than or equal to len(s).

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.rsplit(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given, at most maxsplit splits
are done, the rightmost ones.  If sep is not specified or None,
any subsequence consisting solely of ASCII whitespace is a separator.
Except for splitting from the right, rsplit() behaves like
split() which is described in detail below."
bytes.rstrip([chars]),"Return a copy of the sequence with specified trailing bytes removed.  The
chars argument is a binary sequence specifying the set of byte values to
be removed - the name refers to the fact this method is usually used with
ASCII characters.  If omitted or None, the chars argument defaults to
removing ASCII whitespace.  The chars argument is not a suffix; rather,
all combinations of its values are stripped:
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
"bytes.split(sep=None, maxsplit=-1)","Split the binary sequence into subsequences of the same type, using sep
as the delimiter string. If maxsplit is given and non-negative, at most
maxsplit splits are done (thus, the list will have at most maxsplit+1
elements).  If maxsplit is not specified or is -1, then there is no
limit on the number of splits (all possible splits are made).
If sep is given, consecutive delimiters are not grouped together and are
deemed to delimit empty subsequences (for example, b'1,,2'.split(b',')
returns [b'1', b'', b'2']).  The sep argument may consist of a
multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns
[b'1', b'2', b'3']). Splitting an empty sequence with a specified
separator returns [b''] or [bytearray(b'')] depending on the type
of object being split.  The sep argument may be any
bytes-like object.
For example:
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']


If sep is not specified or is None, a different splitting algorithm
is applied: runs of consecutive ASCII whitespace are regarded as a single
separator, and the result will contain no empty strings at the start or
end if the sequence has leading or trailing whitespace.  Consequently,
splitting an empty sequence or a sequence consisting solely of ASCII
whitespace without a specified separator returns [].
For example:
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']"
bytes.strip([chars]),"Return a copy of the sequence with specified leading and trailing bytes
removed. The chars argument is a binary sequence specifying the set of
byte values to be removed - the name refers to the fact this method is
usually used with ASCII characters.  If omitted or None, the chars
argument defaults to removing ASCII whitespace. The chars argument is
not a prefix or suffix; rather, all combinations of its values are
stripped:
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'


The binary sequence of byte values to remove may be any
bytes-like object.

Note
The bytearray version of this method does not operate in place -
it always produces a new object, even if no changes were made."
bytes.capitalize(),"Return a copy of the sequence with each byte interpreted as an ASCII
character, and the first byte capitalized and the rest lowercased.
Non-ASCII byte values are passed through unchanged.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.expandtabs(tabsize=8),"Return a copy of the sequence where all ASCII tab characters are replaced
by one or more ASCII spaces, depending on the current column and the given
tab size.  Tab positions occur every tabsize bytes (default is 8,
giving tab positions at columns 0, 8, 16 and so on).  To expand the
sequence, the current column is set to zero and the sequence is examined
byte by byte.  If the byte is an ASCII tab character (b'\t'), one or
more space characters are inserted in the result until the current column
is equal to the next tab position. (The tab character itself is not
copied.)  If the current byte is an ASCII newline (b'\n') or
carriage return (b'\r'), it is copied and the current column is reset
to zero.  Any other byte value is copied unchanged and the current column
is incremented by one regardless of how the byte value is represented when
printed:
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.isalnum(),"Return True if all bytes in the sequence are alphabetical ASCII characters
or ASCII decimal digits and the sequence is not empty, False otherwise.
Alphabetic ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal
digits are those byte values in the sequence b'0123456789'.
For example:
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False"
bytes.isalpha(),"Return True if all bytes in the sequence are alphabetic ASCII characters
and the sequence is not empty, False otherwise.  Alphabetic ASCII
characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.
For example:
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False"
bytes.isascii(),"Return True if the sequence is empty or all bytes in the sequence are ASCII,
False otherwise.
ASCII bytes are in the range 0-0x7F.

New in version 3.7."
bytes.isdigit(),"Return True if all bytes in the sequence are ASCII decimal digits
and the sequence is not empty, False otherwise. ASCII decimal digits are
those byte values in the sequence b'0123456789'.
For example:
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False"
bytes.islower(),"Return True if there is at least one lowercase ASCII character
in the sequence and no uppercase ASCII characters, False otherwise.
For example:
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.isspace(),"Return True if all bytes in the sequence are ASCII whitespace and the
sequence is not empty, False otherwise.  ASCII whitespace characters are
those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,
carriage return, vertical tab, form feed)."
bytes.istitle(),"Return True if the sequence is ASCII titlecase and the sequence is not
empty, False otherwise. See bytes.title() for more details on the
definition of “titlecase”.
For example:
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False"
bytes.isupper(),"Return True if there is at least one uppercase alphabetic ASCII character
in the sequence and no lowercase ASCII characters, False otherwise.
For example:
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."
bytes.lower(),"Return a copy of the sequence with all the uppercase ASCII characters
converted to their corresponding lowercase counterpart.
For example:
>>> b'Hello World'.lower()
b'hello world'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.splitlines(keepends=False),"Return a list of the lines in the binary sequence, breaking at ASCII
line boundaries. This method uses the universal newlines approach
to splitting lines. Line breaks are not included in the resulting list
unless keepends is given and true.
For example:
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']


Unlike split() when a delimiter string sep is given, this
method returns an empty list for the empty string, and a terminal line
break does not result in an extra line:
>>> b"""".split(b'\n'), b""Two lines\n"".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"""".splitlines(), b""One line\n"".splitlines()
([], [b'One line'])"
bytes.swapcase(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart and vice-versa.
For example:
>>> b'Hello World'.swapcase()
b'hELLO wORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
Unlike str.swapcase(), it is always the case that
bin.swapcase().swapcase() == bin for the binary versions. Case
conversions are symmetrical in ASCII, even though that is not generally
true for arbitrary Unicode code points.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.title(),"Return a titlecased version of the binary sequence where words start with
an uppercase ASCII character and the remaining characters are lowercase.
Uncased byte values are left unmodified.
For example:
>>> b'Hello world'.title()
b'Hello World'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.
All other byte values are uncased.
The algorithm uses a simple language-independent definition of a word as
groups of consecutive letters.  The definition works in many contexts but
it means that apostrophes in contractions and possessives form word
boundaries, which may not be the desired result:
>>> b""they're bill's friends from the UK"".title()
b""They'Re Bill'S Friends From The Uk""


A workaround for apostrophes can be constructed using regular expressions:
>>> import re
>>> def titlecase(s):
...     return re.sub(rb""[A-Za-z]+('[A-Za-z]+)?"",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b""they're bill's friends."")
b""They're Bill's Friends.""



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.upper(),"Return a copy of the sequence with all the lowercase ASCII characters
converted to their corresponding uppercase counterpart.
For example:
>>> b'Hello World'.upper()
b'HELLO WORLD'


Lowercase ASCII characters are those byte values in the sequence
b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters
are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
bytes.zfill(width),"Return a copy of the sequence left filled with ASCII b'0' digits to
make a sequence of length width. A leading sign prefix (b'+'/
b'-') is handled by inserting the padding after the sign character
rather than before. For bytes objects, the original sequence is
returned if width is less than or equal to len(seq).
For example:
>>> b""42"".zfill(5)
b'00042'
>>> b""-42"".zfill(5)
b'-0042'



Note
The bytearray version of this method does not operate in place - it
always produces a new object, even if no changes were made."
__eq__(exporter),"A memoryview and a PEP 3118 exporter are equal if their shapes are
equivalent and if all corresponding values are equal when the operands’
respective format codes are interpreted using struct syntax.
For the subset of struct format strings currently supported by
tolist(), v and w are equal if v.tolist() == w.tolist():
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True


If either format string is not supported by the struct module,
then the objects will always compare as unequal (even if the format
strings and buffer contents are identical):
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [(""x"", c_long), (""y"", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False


Note that, as with floating point numbers, v is w does not imply
v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format
and the logical array structure."
tobytes(order=None),"Return the data in the buffer as a bytestring.  This is equivalent to
calling the bytes constructor on the memoryview.
>>> m = memoryview(b""abc"")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'


For non-contiguous arrays the result is equal to the flattened list
representation with all elements converted to bytes. tobytes()
supports all format strings, including those that are not in
struct module syntax.

New in version 3.8: order can be {‘C’, ‘F’, ‘A’}.  When order is ‘C’ or ‘F’, the data
of the original array is converted to C or Fortran order. For contiguous
views, ‘A’ returns an exact copy of the physical memory. In particular,
in-memory Fortran order is preserved. For non-contiguous views, the
data is converted to C first. order=None is the same as order=’C’."
"hex([sep[, bytes_per_sep]])","Return a string object containing two hexadecimal digits for each
byte in the buffer.
>>> m = memoryview(b""abc"")
>>> m.hex()
'616263'



New in version 3.5.


Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports
optional sep and bytes_per_sep parameters to insert separators
between bytes in the hex output."
tolist(),"Return the data in the buffer as a list of elements.
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in
struct module syntax as well as multi-dimensional
representations."
toreadonly(),"Return a readonly version of the memoryview object.  The original
memoryview object is unchanged.
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]



New in version 3.8."
release(),"Release the underlying buffer exposed by the memoryview object.  Many
objects take special actions when a view is held on them (for example,
a bytearray would temporarily forbid resizing); therefore,
calling release() is handy to remove these restrictions (and free any
dangling resources) as soon as possible.
After this method has been called, any further operation on the view
raises a ValueError (except release() itself which can
be called multiple times):
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object


The context management protocol can be used for a similar effect,
using the with statement:
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: operation forbidden on released memoryview object



New in version 3.2."
"cast(format[, shape])","Cast a memoryview to a new format or shape. shape defaults to
[byte_length//new_itemsize], which means that the result view
will be one-dimensional. The return value is a new memoryview, but
the buffer itself is not copied. Supported casts are 1D -> C-contiguous
and C-contiguous -> 1D.
The destination format is restricted to a single element native format in
struct syntax. One of the formats must be a byte format
(‘B’, ‘b’ or ‘c’). The byte length of the result must be the same
as the original length.
Cast 1D/long to 1D/unsigned bytes:
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24


Cast 1D/unsigned bytes to 1D/char:
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: memoryview: invalid value for format ""B""
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')


Cast 1D/bytes to 3D/ints to 1D/signed char:
>>> import struct
>>> buf = struct.pack(""i""*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48


Cast 1D/unsigned long to 2D/unsigned long:
>>> buf = struct.pack(""L""*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]



New in version 3.3.


Changed in version 3.5: The source format is no longer restricted when casting to a byte view."
isdisjoint(other),"Return True if the set has no elements in common with other.  Sets are
disjoint if and only if their intersection is the empty set."
issubset(other),Test whether every element in the set is in other.
set < othe,"Test whether the set is a proper subset of other, that is,
set <= other and set != other."
issuperset(other),Test whether every element in other is in the set.
set > othe,"Test whether the set is a proper superset of other, that is, set >=
other and set != other."
union(*others),Return a new set with elements from the set and all others.
intersection(*others),Return a new set with elements common to the set and all others.
difference(*others),Return a new set with elements in the set that are not in the others.
symmetric_difference(other),Return a new set with elements in either the set or other but not both.
copy(),Return a shallow copy of the set.
update(*others),"Update the set, adding elements from all others."
intersection_update(*others),"Update the set, keeping only elements found in it and all others."
difference_update(*others),"Update the set, removing elements found in others."
symmetric_difference_update(other),"Update the set, keeping only elements found in either set, but not in both."
add(elem),Add element elem to the set.
remove(elem),"Remove element elem from the set.  Raises KeyError if elem is
not contained in the set."
discard(elem),Remove element elem from the set if it is present.
pop(),"Remove and return an arbitrary element from the set.  Raises
KeyError if the set is empty."
clear(),Remove all elements from the set.
clear(),Remove all items from the dictionary.
copy(),Return a shallow copy of the dictionary.
"classmethod fromkeys(iterable[, value])","Create a new dictionary with keys from iterable and values set to value.
fromkeys() is a class method that returns a new dictionary. value
defaults to None.  All of the values refer to just a single instance,
so it generally doesn’t make sense for value to be a mutable object
such as an empty list.  To get distinct values, use a dict
comprehension instead."
"get(key[, default])","Return the value for key if key is in the dictionary, else default.
If default is not given, it defaults to None, so that this method
never raises a KeyError."
items(),"Return a new view of the dictionary’s items ((key, value) pairs).
See the documentation of view objects."
keys(),"Return a new view of the dictionary’s keys.  See the documentation
of view objects."
"pop(key[, default])","If key is in the dictionary, remove it and return its value, else return
default.  If default is not given and key is not in the dictionary,
a KeyError is raised."
popitem(),"Remove and return a (key, value) pair from the dictionary.
Pairs are returned in LIFO order.
popitem() is useful to destructively iterate over a dictionary, as
often used in set algorithms.  If the dictionary is empty, calling
popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would
return an arbitrary key/value pair."
"setdefault(key[, default])","If key is in the dictionary, return its value.  If not, insert key
with a value of default and return default.  default defaults to
None."
update([other]),"Update the dictionary with the key/value pairs from other, overwriting
existing keys.  Return None.
update() accepts either another dictionary object or an iterable of
key/value pairs (as tuples or other iterables of length two).  If keyword
arguments are specified, the dictionary is then updated with those
key/value pairs: d.update(red=1, blue=2)."
values(),"Return a new view of the dictionary’s values.  See the
documentation of view objects.
An equality comparison between one dict.values() view and another
will always return False. This also applies when comparing
dict.values() to itself:
>>> d = {'a': 1}
>>> d.values() == d.values()
False"
contextmanager.__enter__(),"Enter the runtime context and return either this object or another object
related to the runtime context. The value returned by this method is bound to
the identifier in the as clause of with statements using
this context manager.
An example of a context manager that returns itself is a file object.
File objects return themselves from __enter__() to allow open() to be
used as the context expression in a with statement.
An example of a context manager that returns a related object is the one
returned by decimal.localcontext(). These managers set the active
decimal context to a copy of the original decimal context and then return the
copy. This allows changes to be made to the current decimal context in the body
of the with statement without affecting code outside the
with statement."
"contextmanager.__exit__(exc_type, exc_val, exc_tb)","Exit the runtime context and return a Boolean flag indicating if any exception
that occurred should be suppressed. If an exception occurred while executing the
body of the with statement, the arguments contain the exception type,
value and traceback information. Otherwise, all three arguments are None.
Returning a true value from this method will cause the with statement
to suppress the exception and continue execution with the statement immediately
following the with statement. Otherwise the exception continues
propagating after this method has finished executing. Exceptions that occur
during execution of this method will replace any exception that occurred in the
body of the with statement.
The exception passed in should never be reraised explicitly - instead, this
method should return a false value to indicate that the method completed
successfully and does not want to suppress the raised exception. This allows
context management code to easily detect whether or not an __exit__()
method has actually failed."
class.mro(),"This method can be overridden by a metaclass to customize the method
resolution order for its instances.  It is called at class instantiation, and
its result is stored in __mro__."
class.__subclasses__(),"Each class keeps a list of weak references to its immediate subclasses.  This
method returns a list of all those references still alive.
Example:
>>> int.__subclasses__()
[<class 'bool'>]"
with_traceback(tb),"This method sets tb as the new traceback for the exception and returns
the exception object.  It is usually used in exception handling code like
this:
try:
    ...
except SomeException:
    tb = sys.exc_info()[2]
    raise OtherException(...).with_traceback(tb)"
with_traceback(tb),"This method sets tb as the new traceback for the exception and returns
the exception object.  It is usually used in exception handling code like
this:
try:
    ...
except SomeException:
    tb = sys.exc_info()[2]
    raise OtherException(...).with_traceback(tb)"
with_traceback(tb),"This method sets tb as the new traceback for the exception and returns
the exception object.  It is usually used in exception handling code like
this:
try:
    ...
except SomeException:
    tb = sys.exc_info()[2]
    raise OtherException(...).with_traceback(tb)"
with_traceback(tb),"This method sets tb as the new traceback for the exception and returns
the exception object.  It is usually used in exception handling code like
this:
try:
    ...
except SomeException:
    tb = sys.exc_info()[2]
    raise OtherException(...).with_traceback(tb)"
"string.capwords(s, sep=None)","Split the argument into words using str.split(), capitalize each word
using str.capitalize(), and join the capitalized words using
str.join().  If the optional second argument sep is absent
or None, runs of whitespace characters are replaced by a single space
and leading and trailing whitespace are removed, otherwise sep is used to
split and join the words."
"format(format_string, /, *args, **kwargs)","The primary API method.  It takes a format string and
an arbitrary set of positional and keyword arguments.
It is just a wrapper that calls vformat().

Changed in version 3.7: A format string argument is now positional-only."
"vformat(format_string, args, kwargs)","This function does the actual work of formatting.  It is exposed as a
separate function for cases where you want to pass in a predefined
dictionary of arguments, rather than unpacking and repacking the
dictionary as individual arguments using the *args and **kwargs
syntax.  vformat() does the work of breaking up the format string
into character data and replacement fields.  It calls the various
methods described below."
parse(format_string),"Loop over the format_string and return an iterable of tuples
(literal_text, field_name, format_spec, conversion).  This is used
by vformat() to break the string into either literal text, or
replacement fields.
The values in the tuple conceptually represent a span of literal text
followed by a single replacement field.  If there is no literal text
(which can happen if two replacement fields occur consecutively), then
literal_text will be a zero-length string.  If there is no replacement
field, then the values of field_name, format_spec and conversion
will be None."
"get_field(field_name, args, kwargs)","Given field_name as returned by parse() (see above), convert it to
an object to be formatted.  Returns a tuple (obj, used_key).  The default
version takes strings of the form defined in PEP 3101, such as
“0[name]” or “label.title”.  args and kwargs are as passed in to
vformat().  The return value used_key has the same meaning as the
key parameter to get_value()."
"get_value(key, args, kwargs)","Retrieve a given field value.  The key argument will be either an
integer or a string.  If it is an integer, it represents the index of the
positional argument in args; if it is a string, then it represents a
named argument in kwargs.
The args parameter is set to the list of positional arguments to
vformat(), and the kwargs parameter is set to the dictionary of
keyword arguments.
For compound field names, these functions are only called for the first
component of the field name; subsequent components are handled through
normal attribute and indexing operations.
So for example, the field expression ‘0.name’ would cause
get_value() to be called with a key argument of 0.  The name
attribute will be looked up after get_value() returns by calling the
built-in getattr() function.
If the index or keyword refers to an item that does not exist, then an
IndexError or KeyError should be raised."
"check_unused_args(used_args, args, kwargs)","Implement checking for unused arguments if desired.  The arguments to this
function is the set of all argument keys that were actually referred to in
the format string (integers for positional arguments, and strings for
named arguments), and a reference to the args and kwargs that was
passed to vformat.  The set of unused args can be calculated from these
parameters.  check_unused_args() is assumed to raise an exception if
the check fails."
"format_field(value, format_spec)","format_field() simply calls the global format() built-in.  The
method is provided so that subclasses can override it."
"convert_field(value, conversion)","Converts the value (returned by get_field()) given a conversion type
(as in the tuple returned by the parse() method).  The default
version understands ‘s’ (str), ‘r’ (repr) and ‘a’ (ascii) conversion
types."
"substitute(mapping={}, /, **kwds)","Performs the template substitution, returning a new string.  mapping is
any dictionary-like object with keys that match the placeholders in the
template.  Alternatively, you can provide keyword arguments, where the
keywords are the placeholders.  When both mapping and kwds are given
and there are duplicates, the placeholders from kwds take precedence."
"safe_substitute(mapping={}, /, **kwds)","Like substitute(), except that if placeholders are missing from
mapping and kwds, instead of raising a KeyError exception, the
original placeholder will appear in the resulting string intact.  Also,
unlike with substitute(), any other appearances of the $ will
simply return $ instead of raising ValueError.
While other exceptions may still occur, this method is called “safe”
because it always tries to return a usable string instead of
raising an exception.  In another sense, safe_substitute() may be
anything other than safe, since it will silently ignore malformed
templates containing dangling delimiters, unmatched braces, or
placeholders that are not valid Python identifiers."
"re.compile(pattern, flags=0)","Compile a regular expression pattern into a regular expression object, which can be used for matching using its
match(), search() and other methods, described
below.
The expression’s behaviour can be modified by specifying a flags value.
Values can be any of the following variables, combined using bitwise OR (the
| operator).
The sequence
prog = re.compile(pattern)
result = prog.match(string)


is equivalent to
result = re.match(pattern, string)


but using re.compile() and saving the resulting regular expression
object for reuse is more efficient when the expression will be used several
times in a single program.

Note
The compiled versions of the most recent patterns passed to
re.compile() and the module-level matching functions are cached, so
programs that use only a few regular expressions at a time needn’t worry
about compiling regular expressions."
"re.search(pattern, string, flags=0)","Scan through string looking for the first location where the regular expression
pattern produces a match, and return a corresponding match object.  Return None if no position in the string matches the
pattern; note that this is different from finding a zero-length match at some
point in the string."
"re.match(pattern, string, flags=0)","If zero or more characters at the beginning of string match the regular
expression pattern, return a corresponding match object.  Return None if the string does not match the pattern;
note that this is different from a zero-length match.
Note that even in MULTILINE mode, re.match() will only match
at the beginning of the string and not at the beginning of each line.
If you want to locate a match anywhere in string, use search()
instead (see also search() vs. match())."
"re.fullmatch(pattern, string, flags=0)","If the whole string matches the regular expression pattern, return a
corresponding match object.  Return None if the
string does not match the pattern; note that this is different from a
zero-length match.

New in version 3.4."
"re.split(pattern, string, maxsplit=0, flags=0)","Split string by the occurrences of pattern.  If capturing parentheses are
used in pattern, then the text of all groups in the pattern are also returned
as part of the resulting list. If maxsplit is nonzero, at most maxsplit
splits occur, and the remainder of the string is returned as the final element
of the list.
>>> re.split(r'\W+', 'Words, words, words.')
['Words', 'words', 'words', '']
>>> re.split(r'(\W+)', 'Words, words, words.')
['Words', ', ', 'words', ', ', 'words', '.', '']
>>> re.split(r'\W+', 'Words, words, words.', 1)
['Words', 'words, words.']
>>> re.split('[a-f]+', '0a3B9', flags=re.IGNORECASE)
['0', '3', '9']


If there are capturing groups in the separator and it matches at the start of
the string, the result will start with an empty string.  The same holds for
the end of the string:
>>> re.split(r'(\W+)', '...words, words...')
['', '...', 'words', ', ', 'words', '...', '']


That way, separator components are always found at the same relative
indices within the result list.
Empty matches for the pattern split the string only when not adjacent
to a previous empty match.
>>> re.split(r'\b', 'Words, words, words.')
['', 'Words', ', ', 'words', ', ', 'words', '.']
>>> re.split(r'\W*', '...words...')
['', '', 'w', 'o', 'r', 'd', 's', '', '']
>>> re.split(r'(\W*)', '...words...')
['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', '']



Changed in version 3.1: Added the optional flags argument.


Changed in version 3.7: Added support of splitting on a pattern that could match an empty string."
"re.findall(pattern, string, flags=0)","Return all non-overlapping matches of pattern in string, as a list of
strings.  The string is scanned left-to-right, and matches are returned in
the order found.  If one or more groups are present in the pattern, return a
list of groups; this will be a list of tuples if the pattern has more than
one group.  Empty matches are included in the result.

Changed in version 3.7: Non-empty matches can now start just after a previous empty match."
"re.finditer(pattern, string, flags=0)","Return an iterator yielding match objects over
all non-overlapping matches for the RE pattern in string.  The string
is scanned left-to-right, and matches are returned in the order found.  Empty
matches are included in the result.

Changed in version 3.7: Non-empty matches can now start just after a previous empty match."
"re.sub(pattern, repl, string, count=0, flags=0)","Return the string obtained by replacing the leftmost non-overlapping occurrences
of pattern in string by the replacement repl.  If the pattern isn’t found,
string is returned unchanged.  repl can be a string or a function; if it is
a string, any backslash escapes in it are processed.  That is, \n is
converted to a single newline character, \r is converted to a carriage return, and
so forth.  Unknown escapes of ASCII letters are reserved for future use and
treated as errors.  Other unknown escapes such as \& are left alone.
Backreferences, such
as \6, are replaced with the substring matched by group 6 in the pattern.
For example:
>>> re.sub(r'def\s+([a-zA-Z_][a-zA-Z_0-9]*)\s*\(\s*\):',
...        r'static PyObject*\npy_\1(void)\n{',
...        'def myfunc():')
'static PyObject*\npy_myfunc(void)\n{'


If repl is a function, it is called for every non-overlapping occurrence of
pattern.  The function takes a single match object
argument, and returns the replacement string.  For example:
>>> def dashrepl(matchobj):
...     if matchobj.group(0) == '-': return ' '
...     else: return '-'
>>> re.sub('-{1,2}', dashrepl, 'pro----gram-files')
'pro--gram files'
>>> re.sub(r'\sAND\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE)
'Baked Beans & Spam'


The pattern may be a string or a pattern object.
The optional argument count is the maximum number of pattern occurrences to be
replaced; count must be a non-negative integer.  If omitted or zero, all
occurrences will be replaced. Empty matches for the pattern are replaced only
when not adjacent to a previous empty match, so sub('x*', '-', 'abxd') returns
'-a-b--d-'.
In string-type repl arguments, in addition to the character escapes and
backreferences described above,
\g<name> will use the substring matched by the group named name, as
defined by the (?P<name>...) syntax. \g<number> uses the corresponding
group number; \g<2> is therefore equivalent to \2, but isn’t ambiguous
in a replacement such as \g<2>0.  \20 would be interpreted as a
reference to group 20, not a reference to group 2 followed by the literal
character '0'.  The backreference \g<0> substitutes in the entire
substring matched by the RE.

Changed in version 3.1: Added the optional flags argument.


Changed in version 3.5: Unmatched groups are replaced with an empty string.


Changed in version 3.6: Unknown escapes in pattern consisting of '\' and an ASCII letter
now are errors.


Changed in version 3.7: Unknown escapes in repl consisting of '\' and an ASCII letter
now are errors.


Changed in version 3.7: Empty matches for the pattern are replaced when adjacent to a previous
non-empty match."
"re.subn(pattern, repl, string, count=0, flags=0)","Perform the same operation as sub(), but return a tuple (new_string,
number_of_subs_made).

Changed in version 3.1: Added the optional flags argument.


Changed in version 3.5: Unmatched groups are replaced with an empty string."
re.escape(pattern),"Escape special characters in pattern.
This is useful if you want to match an arbitrary literal string that may
have regular expression metacharacters in it.  For example:
>>> print(re.escape('http://www.python.org'))
http://www\.python\.org

>>> legal_chars = string.ascii_lowercase + string.digits + ""!#$%&'*+-.^_`|~:""
>>> print('[%s]+' % re.escape(legal_chars))
[abcdefghijklmnopqrstuvwxyz0123456789!\#\$%\&'\*\+\-\.\^_`\|\~:]+

>>> operators = ['+', '-', '*', '/', '**']
>>> print('|'.join(map(re.escape, sorted(operators, reverse=True))))
/|\-|\+|\*\*|\*


This function must not be used for the replacement string in sub()
and subn(), only backslashes should be escaped.  For example:
>>> digits_re = r'\d+'
>>> sample = '/usr/sbin/sendmail - 0 errors, 12 warnings'
>>> print(re.sub(digits_re, digits_re.replace('\\', r'\\'), sample))
/usr/sbin/sendmail - \d+ errors, \d+ warnings



Changed in version 3.3: The '_' character is no longer escaped.


Changed in version 3.7: Only characters that can have special meaning in a regular expression
are escaped. As a result, '!', '""', '%', ""'"", ',',
'/', ':', ';', '<', '=', '>', '@', and
""`"" are no longer escaped."
re.purge(),Clear the regular expression cache.
"Pattern.search(string[, pos[, endpos]])","Scan through string looking for the first location where this regular
expression produces a match, and return a corresponding match object.  Return None if no position in the string matches the
pattern; note that this is different from finding a zero-length match at some
point in the string.
The optional second parameter pos gives an index in the string where the
search is to start; it defaults to 0.  This is not completely equivalent to
slicing the string; the '^' pattern character matches at the real beginning
of the string and at positions just after a newline, but not necessarily at the
index where the search is to start.
The optional parameter endpos limits how far the string will be searched; it
will be as if the string is endpos characters long, so only the characters
from pos to endpos - 1 will be searched for a match.  If endpos is less
than pos, no match will be found; otherwise, if rx is a compiled regular
expression object, rx.search(string, 0, 50) is equivalent to
rx.search(string[:50], 0).
>>> pattern = re.compile(""d"")
>>> pattern.search(""dog"")     # Match at index 0
<re.Match object; span=(0, 1), match='d'>
>>> pattern.search(""dog"", 1)  # No match; search doesn't include the ""d"""
"Pattern.match(string[, pos[, endpos]])","If zero or more characters at the beginning of string match this regular
expression, return a corresponding match object.
Return None if the string does not match the pattern; note that this is
different from a zero-length match.
The optional pos and endpos parameters have the same meaning as for the
search() method.
>>> pattern = re.compile(""o"")
>>> pattern.match(""dog"")      # No match as ""o"" is not at the start of ""dog"".
>>> pattern.match(""dog"", 1)   # Match as ""o"" is the 2nd character of ""dog"".
<re.Match object; span=(1, 2), match='o'>


If you want to locate a match anywhere in string, use
search() instead (see also search() vs. match())."
"Pattern.fullmatch(string[, pos[, endpos]])","If the whole string matches this regular expression, return a corresponding
match object.  Return None if the string does not
match the pattern; note that this is different from a zero-length match.
The optional pos and endpos parameters have the same meaning as for the
search() method.
>>> pattern = re.compile(""o[gh]"")
>>> pattern.fullmatch(""dog"")      # No match as ""o"" is not at the start of ""dog"".
>>> pattern.fullmatch(""ogre"")     # No match as not the full string matches.
>>> pattern.fullmatch(""doggie"", 1, 3)   # Matches within given limits.
<re.Match object; span=(1, 3), match='og'>



New in version 3.4."
"Pattern.split(string, maxsplit=0)","Identical to the split() function, using the compiled pattern."
"Pattern.findall(string[, pos[, endpos]])","Similar to the findall() function, using the compiled pattern, but
also accepts optional pos and endpos parameters that limit the search
region like for search()."
"Pattern.finditer(string[, pos[, endpos]])","Similar to the finditer() function, using the compiled pattern, but
also accepts optional pos and endpos parameters that limit the search
region like for search()."
"Pattern.sub(repl, string, count=0)","Identical to the sub() function, using the compiled pattern."
"Pattern.subn(repl, string, count=0)","Identical to the subn() function, using the compiled pattern."
Match.expand(template),"Return the string obtained by doing backslash substitution on the template
string template, as done by the sub() method.
Escapes such as \n are converted to the appropriate characters,
and numeric backreferences (\1, \2) and named backreferences
(\g<1>, \g<name>) are replaced by the contents of the
corresponding group.

Changed in version 3.5: Unmatched groups are replaced with an empty string."
"Match.group([group1, ...])","Returns one or more subgroups of the match.  If there is a single argument, the
result is a single string; if there are multiple arguments, the result is a
tuple with one item per argument. Without arguments, group1 defaults to zero
(the whole match is returned). If a groupN argument is zero, the corresponding
return value is the entire matching string; if it is in the inclusive range
[1..99], it is the string matching the corresponding parenthesized group.  If a
group number is negative or larger than the number of groups defined in the
pattern, an IndexError exception is raised. If a group is contained in a
part of the pattern that did not match, the corresponding result is None.
If a group is contained in a part of the pattern that matched multiple times,
the last match is returned.
>>> m = re.match(r""(\w+) (\w+)"", ""Isaac Newton, physicist"")
>>> m.group(0)       # The entire match
'Isaac Newton'
>>> m.group(1)       # The first parenthesized subgroup.
'Isaac'
>>> m.group(2)       # The second parenthesized subgroup.
'Newton'
>>> m.group(1, 2)    # Multiple arguments give us a tuple.
('Isaac', 'Newton')


If the regular expression uses the (?P<name>...) syntax, the groupN
arguments may also be strings identifying groups by their group name.  If a
string argument is not used as a group name in the pattern, an IndexError
exception is raised.
A moderately complicated example:
>>> m = re.match(r""(?P<first_name>\w+) (?P<last_name>\w+)"", ""Malcolm Reynolds"")
>>> m.group('first_name')
'Malcolm'
>>> m.group('last_name')
'Reynolds'


Named groups can also be referred to by their index:
>>> m.group(1)
'Malcolm'
>>> m.group(2)
'Reynolds'


If a group matches multiple times, only the last match is accessible:
>>> m = re.match(r""(..)+"", ""a1b2c3"")  # Matches 3 times.
>>> m.group(1)                        # Returns only the last match.
'c3'"
Match.__getitem__(g),"This is identical to m.group(g).  This allows easier access to
an individual group from a match:
>>> m = re.match(r""(\w+) (\w+)"", ""Isaac Newton, physicist"")
>>> m[0]       # The entire match
'Isaac Newton'
>>> m[1]       # The first parenthesized subgroup.
'Isaac'
>>> m[2]       # The second parenthesized subgroup.
'Newton'



New in version 3.6."
Match.groups(default=None),"Return a tuple containing all the subgroups of the match, from 1 up to however
many groups are in the pattern.  The default argument is used for groups that
did not participate in the match; it defaults to None.
For example:
>>> m = re.match(r""(\d+)\.(\d+)"", ""24.1632"")
>>> m.groups()
('24', '1632')


If we make the decimal place and everything after it optional, not all groups
might participate in the match.  These groups will default to None unless
the default argument is given:
>>> m = re.match(r""(\d+)\.?(\d+)?"", ""24"")
>>> m.groups()      # Second group defaults to None.
('24', None)
>>> m.groups('0')   # Now, the second group defaults to '0'.
('24', '0')"
Match.groupdict(default=None),"Return a dictionary containing all the named subgroups of the match, keyed by
the subgroup name.  The default argument is used for groups that did not
participate in the match; it defaults to None.  For example:
>>> m = re.match(r""(?P<first_name>\w+) (?P<last_name>\w+)"", ""Malcolm Reynolds"")
>>> m.groupdict()
{'first_name': 'Malcolm', 'last_name': 'Reynolds'}"
Match.start([group]),"Return the indices of the start and end of the substring matched by group;
group defaults to zero (meaning the whole matched substring). Return -1 if
group exists but did not contribute to the match.  For a match object m, and
a group g that did contribute to the match, the substring matched by group g
(equivalent to m.group(g)) is
m.string[m.start(g):m.end(g)]


Note that m.start(group) will equal m.end(group) if group matched a
null string.  For example, after m = re.search('b(c?)', 'cba'),
m.start(0) is 1, m.end(0) is 2, m.start(1) and m.end(1) are both
2, and m.start(2) raises an IndexError exception.
An example that will remove remove_this from email addresses:
>>> email = ""tony@tiremove_thisger.net""
>>> m = re.search(""remove_this"", email)
>>> email[:m.start()] + email[m.end():]
'tony@tiger.net'"
Match.span([group]),"For a match m, return the 2-tuple (m.start(group), m.end(group)). Note
that if group did not contribute to the match, this is (-1, -1).
group defaults to zero, the entire match."
"difflib.context_diff(a, b, fromfile='', tofile='', fromfiledate='', tofiledate='', n=3, lineterm='\n')","Compare a and b (lists of strings); return a delta (a generator
generating the delta lines) in context diff format.
Context diffs are a compact way of showing just the lines that have changed plus
a few lines of context.  The changes are shown in a before/after style.  The
number of context lines is set by n which defaults to three.
By default, the diff control lines (those with *** or ---) are created
with a trailing newline.  This is helpful so that inputs created from
io.IOBase.readlines() result in diffs that are suitable for use with
io.IOBase.writelines() since both the inputs and outputs have trailing
newlines.
For inputs that do not have trailing newlines, set the lineterm argument to
"""" so that the output will be uniformly newline free.
The context diff format normally has a header for filenames and modification
times.  Any or all of these may be specified using strings for fromfile,
tofile, fromfiledate, and tofiledate.  The modification times are normally
expressed in the ISO 8601 format. If not specified, the
strings default to blanks.
>>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
>>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
>>> sys.stdout.writelines(context_diff(s1, s2, fromfile='before.py', tofile='after.py'))
*** before.py
--- after.py
***************
*** 1,4 ****
! bacon
! eggs
! ham
  guido
--- 1,4 ----
! python
! eggy
! hamster
  guido


See A command-line interface to difflib for a more detailed example."
"difflib.get_close_matches(word, possibilities, n=3, cutoff=0.6)","Return a list of the best “good enough” matches.  word is a sequence for which
close matches are desired (typically a string), and possibilities is a list of
sequences against which to match word (typically a list of strings).
Optional argument n (default 3) is the maximum number of close matches to
return; n must be greater than 0.
Optional argument cutoff (default 0.6) is a float in the range [0, 1].
Possibilities that don’t score at least that similar to word are ignored.
The best (no more than n) matches among the possibilities are returned in a
list, sorted by similarity score, most similar first.
>>> get_close_matches('appel', ['ape', 'apple', 'peach', 'puppy'])
['apple', 'ape']
>>> import keyword
>>> get_close_matches('wheel', keyword.kwlist)
['while']
>>> get_close_matches('pineapple', keyword.kwlist)
[]
>>> get_close_matches('accept', keyword.kwlist)
['except']"
"difflib.ndiff(a, b, linejunk=None, charjunk=IS_CHARACTER_JUNK)","Compare a and b (lists of strings); return a Differ-style
delta (a generator generating the delta lines).
Optional keyword parameters linejunk and charjunk are filtering functions
(or None):
linejunk: A function that accepts a single string argument, and returns
true if the string is junk, or false if not. The default is None. There
is also a module-level function IS_LINE_JUNK(), which filters out lines
without visible characters, except for at most one pound character ('#')
– however the underlying SequenceMatcher class does a dynamic
analysis of which lines are so frequent as to constitute noise, and this
usually works better than using this function.
charjunk: A function that accepts a character (a string of length 1), and
returns if the character is junk, or false if not. The default is module-level
function IS_CHARACTER_JUNK(), which filters out whitespace characters (a
blank or tab; it’s a bad idea to include newline in this!).
Tools/scripts/ndiff.py is a command-line front-end to this function.
>>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
...              'ore\ntree\nemu\n'.splitlines(keepends=True))
>>> print(''.join(diff), end="""")
- one
?  ^
+ ore
?  ^
- two
- three
?  -
+ tree
+ emu"
"difflib.restore(sequence, which)","Return one of the two sequences that generated a delta.
Given a sequence produced by Differ.compare() or ndiff(), extract
lines originating from file 1 or 2 (parameter which), stripping off line
prefixes.
Example:
>>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
...              'ore\ntree\nemu\n'.splitlines(keepends=True))
>>> diff = list(diff) # materialize the generated delta into a list
>>> print(''.join(restore(diff, 1)), end="""")
one
two
three
>>> print(''.join(restore(diff, 2)), end="""")
ore
tree
emu"
"difflib.unified_diff(a, b, fromfile='', tofile='', fromfiledate='', tofiledate='', n=3, lineterm='\n')","Compare a and b (lists of strings); return a delta (a generator
generating the delta lines) in unified diff format.
Unified diffs are a compact way of showing just the lines that have changed plus
a few lines of context.  The changes are shown in an inline style (instead of
separate before/after blocks).  The number of context lines is set by n which
defaults to three.
By default, the diff control lines (those with ---, +++, or @@) are
created with a trailing newline.  This is helpful so that inputs created from
io.IOBase.readlines() result in diffs that are suitable for use with
io.IOBase.writelines() since both the inputs and outputs have trailing
newlines.
For inputs that do not have trailing newlines, set the lineterm argument to
"""" so that the output will be uniformly newline free.
The context diff format normally has a header for filenames and modification
times.  Any or all of these may be specified using strings for fromfile,
tofile, fromfiledate, and tofiledate.  The modification times are normally
expressed in the ISO 8601 format. If not specified, the
strings default to blanks.
>>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
>>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
>>> sys.stdout.writelines(unified_diff(s1, s2, fromfile='before.py', tofile='after.py'))
--- before.py
+++ after.py
@@ -1,4 +1,4 @@
-bacon
-eggs
-ham
+python
+eggy
+hamster
 guido


See A command-line interface to difflib for a more detailed example."
"difflib.diff_bytes(dfunc, a, b, fromfile=b'', tofile=b'', fromfiledate=b'', tofiledate=b'', n=3, lineterm=b'\n')","Compare a and b (lists of bytes objects) using dfunc; yield a
sequence of delta lines (also bytes) in the format returned by dfunc.
dfunc must be a callable, typically either unified_diff() or
context_diff().
Allows you to compare data with unknown or inconsistent encoding. All
inputs except n must be bytes objects, not str. Works by losslessly
converting all inputs (except n) to str, and calling dfunc(a, b,
fromfile, tofile, fromfiledate, tofiledate, n, lineterm). The output of
dfunc is then converted back to bytes, so the delta lines that you
receive have the same unknown/inconsistent encodings as a and b.

New in version 3.5."
difflib.IS_LINE_JUNK(line),"Return True for ignorable lines.  The line line is ignorable if line is
blank or contains a single '#', otherwise it is not ignorable.  Used as a
default for parameter linejunk in ndiff() in older versions."
difflib.IS_CHARACTER_JUNK(ch),"Return True for ignorable characters.  The character ch is ignorable if ch
is a space or tab, otherwise it is not ignorable.  Used as a default for
parameter charjunk in ndiff()."
"__init__(tabsize=8, wrapcolumn=None, linejunk=None, charjunk=IS_CHARACTER_JUNK)","Initializes instance of HtmlDiff.
tabsize is an optional keyword argument to specify tab stop spacing and
defaults to 8.
wrapcolumn is an optional keyword to specify column number where lines are
broken and wrapped, defaults to None where lines are not wrapped.
linejunk and charjunk are optional keyword arguments passed into ndiff()
(used by HtmlDiff to generate the side by side HTML differences).  See
ndiff() documentation for argument default values and descriptions."
"make_file(fromlines, tolines, fromdesc='', todesc='', context=False, numlines=5, *, charset='utf-8')","Compares fromlines and tolines (lists of strings) and returns a string which
is a complete HTML file containing a table showing line by line differences with
inter-line and intra-line changes highlighted.
fromdesc and todesc are optional keyword arguments to specify from/to file
column header strings (both default to an empty string).
context and numlines are both optional keyword arguments. Set context to
True when contextual differences are to be shown, else the default is
False to show the full files. numlines defaults to 5.  When context
is True numlines controls the number of context lines which surround the
difference highlights.  When context is False numlines controls the
number of lines which are shown before a difference highlight when using the
“next” hyperlinks (setting to zero would cause the “next” hyperlinks to place
the next difference highlight at the top of the browser without any leading
context).

Note
fromdesc and todesc are interpreted as unescaped HTML and should be
properly escaped while receiving input from untrusted sources.


Changed in version 3.5: charset keyword-only argument was added.  The default charset of
HTML document changed from 'ISO-8859-1' to 'utf-8'."
"make_table(fromlines, tolines, fromdesc='', todesc='', context=False, numlines=5)","Compares fromlines and tolines (lists of strings) and returns a string which
is a complete HTML table showing line by line differences with inter-line and
intra-line changes highlighted.
The arguments for this method are the same as those for the make_file()
method."
"set_seqs(a, b)",Set the two sequences to be compared.
set_seq1(a),"Set the first sequence to be compared.  The second sequence to be compared
is not changed."
set_seq2(b),"Set the second sequence to be compared.  The first sequence to be compared
is not changed."
"find_longest_match(alo, ahi, blo, bhi)","Find longest matching block in a[alo:ahi] and b[blo:bhi].
If isjunk was omitted or None, find_longest_match() returns
(i, j, k) such that a[i:i+k] is equal to b[j:j+k], where alo
<= i <= i+k <= ahi and blo <= j <= j+k <= bhi. For all (i', j',
k') meeting those conditions, the additional conditions k >= k', i
<= i', and if i == i', j <= j' are also met. In other words, of
all maximal matching blocks, return one that starts earliest in a, and
of all those maximal matching blocks that start earliest in a, return
the one that starts earliest in b.
>>> s = SequenceMatcher(None, "" abcd"", ""abcd abcd"")
>>> s.find_longest_match(0, 5, 0, 9)
Match(a=0, b=4, size=5)


If isjunk was provided, first the longest matching block is determined
as above, but with the additional restriction that no junk element appears
in the block.  Then that block is extended as far as possible by matching
(only) junk elements on both sides. So the resulting block never matches
on junk except as identical junk happens to be adjacent to an interesting
match.
Here’s the same example as before, but considering blanks to be junk. That
prevents ' abcd' from matching the ' abcd' at the tail end of the
second sequence directly.  Instead only the 'abcd' can match, and
matches the leftmost 'abcd' in the second sequence:
>>> s = SequenceMatcher(lambda x: x=="" "", "" abcd"", ""abcd abcd"")
>>> s.find_longest_match(0, 5, 0, 9)
Match(a=1, b=0, size=4)


If no blocks match, this returns (alo, blo, 0).
This method returns a named tuple Match(a, b, size)."
get_matching_blocks(),"Return list of triples describing non-overlapping matching subsequences.
Each triple is of the form (i, j, n),
and means that a[i:i+n] == b[j:j+n].  The
triples are monotonically increasing in i and j.
The last triple is a dummy, and has the value (len(a), len(b), 0).  It
is the only triple with n == 0.  If (i, j, n) and (i', j', n')
are adjacent triples in the list, and the second is not the last triple in
the list, then i+n < i' or j+n < j'; in other words, adjacent
triples always describe non-adjacent equal blocks.
>>> s = SequenceMatcher(None, ""abxcd"", ""abcd"")
>>> s.get_matching_blocks()
[Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]"
get_opcodes(),"Return list of 5-tuples describing how to turn a into b. Each tuple is
of the form (tag, i1, i2, j1, j2).  The first tuple has i1 == j1 ==
0, and remaining tuples have i1 equal to the i2 from the preceding
tuple, and, likewise, j1 equal to the previous j2.
The tag values are strings, with these meanings:






Value
Meaning



'replace'
a[i1:i2] should be replaced by
b[j1:j2].

'delete'
a[i1:i2] should be deleted.  Note that
j1 == j2 in this case.

'insert'
b[j1:j2] should be inserted at
a[i1:i1]. Note that i1 == i2 in
this case.

'equal'
a[i1:i2] == b[j1:j2] (the sub-sequences
are equal).



For example:
>>> a = ""qabxcd""
>>> b = ""abycdf""
>>> s = SequenceMatcher(None, a, b)
>>> for tag, i1, i2, j1, j2 in s.get_opcodes():
...     print('{:7}   a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format(
...         tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2]))
delete    a[0:1] --> b[0:0]      'q' --> ''
equal     a[1:3] --> b[0:2]     'ab' --> 'ab'
replace   a[3:4] --> b[2:3]      'x' --> 'y'
equal     a[4:6] --> b[3:5]     'cd' --> 'cd'
insert    a[6:6] --> b[5:6]       '' --> 'f'"
get_grouped_opcodes(n=3),"Return a generator of groups with up to n lines of context.
Starting with the groups returned by get_opcodes(), this method
splits out smaller change clusters and eliminates intervening ranges which
have no changes.
The groups are returned in the same format as get_opcodes()."
ratio(),"Return a measure of the sequences’ similarity as a float in the range [0,
1].
Where T is the total number of elements in both sequences, and M is the
number of matches, this is 2.0*M / T. Note that this is 1.0 if the
sequences are identical, and 0.0 if they have nothing in common.
This is expensive to compute if get_matching_blocks() or
get_opcodes() hasn’t already been called, in which case you may want
to try quick_ratio() or real_quick_ratio() first to get an
upper bound.

Note
Caution: The result of a ratio() call may depend on the order of
the arguments. For instance:
>>> SequenceMatcher(None, 'tide', 'diet').ratio()
0.25
>>> SequenceMatcher(None, 'diet', 'tide').ratio()
0.5"
quick_ratio(),Return an upper bound on ratio() relatively quickly.
real_quick_ratio(),Return an upper bound on ratio() very quickly.
"compare(a, b)","Compare two sequences of lines, and generate the delta (a sequence of lines).
Each sequence must contain individual single-line strings ending with
newlines.  Such sequences can be obtained from the
readlines() method of file-like objects.  The delta
generated also consists of newline-terminated strings, ready to be
printed as-is via the writelines() method of a
file-like object."
"textwrap.wrap(text, width=70, **kwargs)","Wraps the single paragraph in text (a string) so every line is at most
width characters long.  Returns a list of output lines, without final
newlines.
Optional keyword arguments correspond to the instance attributes of
TextWrapper, documented below.  width defaults to 70.
See the TextWrapper.wrap() method for additional details on how
wrap() behaves."
"textwrap.fill(text, width=70, **kwargs)","Wraps the single paragraph in text, and returns a single string containing the
wrapped paragraph.  fill() is shorthand for
""\n"".join(wrap(text, ...))


In particular, fill() accepts exactly the same keyword arguments as
wrap()."
"textwrap.shorten(text, width, **kwargs)","Collapse and truncate the given text to fit in the given width.
First the whitespace in text is collapsed (all whitespace is replaced by
single spaces).  If the result fits in the width, it is returned.
Otherwise, enough words are dropped from the end so that the remaining words
plus the placeholder fit within width:
>>> textwrap.shorten(""Hello  world!"", width=12)
'Hello world!'
>>> textwrap.shorten(""Hello  world!"", width=11)
'Hello [...]'
>>> textwrap.shorten(""Hello world"", width=10, placeholder=""..."")
'Hello...'


Optional keyword arguments correspond to the instance attributes of
TextWrapper, documented below.  Note that the whitespace is
collapsed before the text is passed to the TextWrapper fill()
function, so changing the value of tabsize, expand_tabs,
drop_whitespace, and replace_whitespace will have no effect.

New in version 3.4."
textwrap.dedent(text),"Remove any common leading whitespace from every line in text.
This can be used to make triple-quoted strings line up with the left edge of the
display, while still presenting them in the source code in indented form.
Note that tabs and spaces are both treated as whitespace, but they are not
equal: the lines ""  hello"" and ""\thello"" are considered to have no
common leading whitespace.
Lines containing only whitespace are ignored in the input and normalized to a
single newline character in the output.
For example:
def test():
    # end first line with \ to avoid the empty line!
    s = '''\
    hello
      world
    '''
    print(repr(s))          # prints '    hello\n      world\n    '
    print(repr(dedent(s)))  # prints 'hello\n  world\n'"
"textwrap.indent(text, prefix, predicate=None)","Add prefix to the beginning of selected lines in text.
Lines are separated by calling text.splitlines(True).
By default, prefix is added to all lines that do not consist
solely of whitespace (including any line endings).
For example:
>>> s = 'hello\n\n \nworld'
>>> indent(s, '  ')
'  hello\n\n \n  world'


The optional predicate argument can be used to control which lines
are indented. For example, it is easy to add prefix to even empty
and whitespace-only lines:
>>> print(indent(s, '+ ', lambda line: True))
+ hello
+
+
+ world



New in version 3.3."
wrap(text),"Wraps the single paragraph in text (a string) so every line is at most
width characters long.  All wrapping options are taken from
instance attributes of the TextWrapper instance.  Returns a list
of output lines, without final newlines.  If the wrapped output has no
content, the returned list is empty."
fill(text),"Wraps the single paragraph in text, and returns a single string
containing the wrapped paragraph."
unicodedata.lookup(name),"Look up character by name.  If a character with the given name is found, return
the corresponding character.  If not found, KeyError is raised.

Changed in version 3.3: Support for name aliases 1 and named sequences 2 has been added."
"unicodedata.name(chr[, default])","Returns the name assigned to the character chr as a string. If no
name is defined, default is returned, or, if not given, ValueError is
raised."
"unicodedata.decimal(chr[, default])","Returns the decimal value assigned to the character chr as integer.
If no such value is defined, default is returned, or, if not given,
ValueError is raised."
"unicodedata.digit(chr[, default])","Returns the digit value assigned to the character chr as integer.
If no such value is defined, default is returned, or, if not given,
ValueError is raised."
"unicodedata.numeric(chr[, default])","Returns the numeric value assigned to the character chr as float.
If no such value is defined, default is returned, or, if not given,
ValueError is raised."
unicodedata.category(chr),"Returns the general category assigned to the character chr as
string."
unicodedata.bidirectional(chr),"Returns the bidirectional class assigned to the character chr as
string. If no such value is defined, an empty string is returned."
unicodedata.combining(chr),"Returns the canonical combining class assigned to the character chr
as integer. Returns 0 if no combining class is defined."
unicodedata.east_asian_width(chr),"Returns the east asian width assigned to the character chr as
string."
unicodedata.mirrored(chr),"Returns the mirrored property assigned to the character chr as
integer. Returns 1 if the character has been identified as a “mirrored”
character in bidirectional text, 0 otherwise."
unicodedata.decomposition(chr),"Returns the character decomposition mapping assigned to the character
chr as string. An empty string is returned in case no such mapping is
defined."
"unicodedata.normalize(form, unistr)","Return the normal form form for the Unicode string unistr. Valid values for
form are ‘NFC’, ‘NFKC’, ‘NFD’, and ‘NFKD’.
The Unicode standard defines various normalization forms of a Unicode string,
based on the definition of canonical equivalence and compatibility equivalence.
In Unicode, several characters can be expressed in various way. For example, the
character U+00C7 (LATIN CAPITAL LETTER C WITH CEDILLA) can also be expressed as
the sequence U+0043 (LATIN CAPITAL LETTER C) U+0327 (COMBINING CEDILLA).
For each character, there are two normal forms: normal form C and normal form D.
Normal form D (NFD) is also known as canonical decomposition, and translates
each character into its decomposed form. Normal form C (NFC) first applies a
canonical decomposition, then composes pre-combined characters again.
In addition to these two forms, there are two additional normal forms based on
compatibility equivalence. In Unicode, certain characters are supported which
normally would be unified with other characters. For example, U+2160 (ROMAN
NUMERAL ONE) is really the same thing as U+0049 (LATIN CAPITAL LETTER I).
However, it is supported in Unicode for compatibility with existing character
sets (e.g. gb2312).
The normal form KD (NFKD) will apply the compatibility decomposition, i.e.
replace all compatibility characters with their equivalents. The normal form KC
(NFKC) first applies the compatibility decomposition, followed by the canonical
composition.
Even if two unicode strings are normalized and look the same to
a human reader, if one has combining characters and the other
doesn’t, they may not compare equal."
"unicodedata.is_normalized(form, unistr)","Return whether the Unicode string unistr is in the normal form form. Valid
values for form are ‘NFC’, ‘NFKC’, ‘NFD’, and ‘NFKD’.

New in version 3.8."
stringprep.in_table_a1(code),Determine whether code is in tableA.1 (Unassigned code points in Unicode 3.2).
stringprep.in_table_b1(code),Determine whether code is in tableB.1 (Commonly mapped to nothing).
stringprep.map_table_b2(code),"Return the mapped value for code according to tableB.2 (Mapping for
case-folding used with NFKC)."
stringprep.map_table_b3(code),"Return the mapped value for code according to tableB.3 (Mapping for
case-folding used with no normalization)."
stringprep.in_table_c11(code),Determine whether code is in tableC.1.1  (ASCII space characters).
stringprep.in_table_c12(code),Determine whether code is in tableC.1.2  (Non-ASCII space characters).
stringprep.in_table_c11_c12(code),"Determine whether code is in tableC.1  (Space characters, union of C.1.1 and
C.1.2)."
stringprep.in_table_c21(code),Determine whether code is in tableC.2.1  (ASCII control characters).
stringprep.in_table_c22(code),Determine whether code is in tableC.2.2  (Non-ASCII control characters).
stringprep.in_table_c21_c22(code),"Determine whether code is in tableC.2  (Control characters, union of C.2.1 and
C.2.2)."
stringprep.in_table_c3(code),Determine whether code is in tableC.3  (Private use).
stringprep.in_table_c4(code),Determine whether code is in tableC.4  (Non-character code points).
stringprep.in_table_c5(code),Determine whether code is in tableC.5  (Surrogate codes).
stringprep.in_table_c6(code),Determine whether code is in tableC.6  (Inappropriate for plain text).
stringprep.in_table_c7(code),"Determine whether code is in tableC.7  (Inappropriate for canonical
representation)."
stringprep.in_table_c8(code),"Determine whether code is in tableC.8  (Change display properties or are
deprecated)."
stringprep.in_table_c9(code),Determine whether code is in tableC.9  (Tagging characters).
stringprep.in_table_d1(code),"Determine whether code is in tableD.1  (Characters with bidirectional property
“R” or “AL”)."
stringprep.in_table_d2(code),"Determine whether code is in tableD.2  (Characters with bidirectional property
“L”)."
readline.parse_and_bind(string),"Execute the init line provided in the string argument. This calls
rl_parse_and_bind() in the underlying library."
readline.read_init_file([filename]),"Execute a readline initialization file. The default filename is the last filename
used. This calls rl_read_init_file() in the underlying library."
readline.get_line_buffer(),"Return the current contents of the line buffer (rl_line_buffer
in the underlying library)."
readline.insert_text(string),"Insert text into the line buffer at the cursor position.  This calls
rl_insert_text() in the underlying library, but ignores
the return value."
readline.redisplay(),"Change what’s displayed on the screen to reflect the current contents of the
line buffer.  This calls rl_redisplay() in the underlying library."
readline.read_history_file([filename]),"Load a readline history file, and append it to the history list.
The default filename is ~/.history.  This calls
read_history() in the underlying library."
readline.write_history_file([filename]),"Save the history list to a readline history file, overwriting any
existing file.  The default filename is ~/.history.  This calls
write_history() in the underlying library."
"readline.append_history_file(nelements[, filename])","Append the last nelements items of history to a file.  The default filename is
~/.history.  The file must already exist.  This calls
append_history() in the underlying library.  This function
only exists if Python was compiled for a version of the library
that supports it.

New in version 3.5."
readline.get_history_length(),"Set or return the desired number of lines to save in the history file.
The write_history_file() function uses this value to truncate
the history file, by calling history_truncate_file() in
the underlying library.  Negative values imply
unlimited history file size."
readline.clear_history(),"Clear the current history.  This calls clear_history() in the
underlying library.  The Python function only exists if Python was
compiled for a version of the library that supports it."
readline.get_current_history_length(),"Return the number of items currently in the history.  (This is different from
get_history_length(), which returns the maximum number of lines that will
be written to a history file.)"
readline.get_history_item(index),"Return the current contents of history item at index.  The item index
is one-based.  This calls history_get() in the underlying library."
readline.remove_history_item(pos),"Remove history item specified by its position from the history.
The position is zero-based.  This calls remove_history() in
the underlying library."
"readline.replace_history_item(pos, line)","Replace history item specified by its position with line.
The position is zero-based.  This calls replace_history_entry()
in the underlying library."
readline.add_history(line),"Append line to the history buffer, as if it was the last line typed.
This calls add_history() in the underlying library."
readline.set_auto_history(enabled),"Enable or disable automatic calls to add_history() when reading
input via readline.  The enabled argument should be a Boolean value
that when true, enables auto history, and that when false, disables
auto history.

New in version 3.6.


CPython implementation detail: Auto history is enabled by default, and changes to this do not persist
across multiple sessions."
readline.set_startup_hook([function]),"Set or remove the function invoked by the rl_startup_hook
callback of the underlying library.  If function is specified, it will
be used as the new hook function; if omitted or None, any function
already installed is removed.  The hook is called with no
arguments just before readline prints the first prompt."
readline.set_pre_input_hook([function]),"Set or remove the function invoked by the rl_pre_input_hook
callback of the underlying library.  If function is specified, it will
be used as the new hook function; if omitted or None, any
function already installed is removed.  The hook is called
with no arguments after the first prompt has been printed and just before
readline starts reading input characters.  This function only exists
if Python was compiled for a version of the library that supports it."
readline.set_completer([function]),"Set or remove the completer function.  If function is specified, it will be
used as the new completer function; if omitted or None, any completer
function already installed is removed.  The completer function is called as
function(text, state), for state in 0, 1, 2, …, until it
returns a non-string value.  It should return the next possible completion
starting with text.
The installed completer function is invoked by the entry_func callback
passed to rl_completion_matches() in the underlying library.
The text string comes from the first parameter to the
rl_attempted_completion_function callback of the
underlying library."
readline.get_completer(),"Get the completer function, or None if no completer function has been set."
readline.get_completion_type(),"Get the type of completion being attempted.  This returns the
rl_completion_type variable in the underlying library as
an integer."
readline.get_begidx(),"Get the beginning or ending index of the completion scope.
These indexes are the start and end arguments passed to the
rl_attempted_completion_function callback of the
underlying library."
readline.set_completer_delims(string),"Set or get the word delimiters for completion.  These determine the
start of the word to be considered for completion (the completion scope).
These functions access the rl_completer_word_break_characters
variable in the underlying library."
readline.set_completion_display_matches_hook([function]),"Set or remove the completion display function.  If function is
specified, it will be used as the new completion display function;
if omitted or None, any completion display function already
installed is removed.  This sets or clears the
rl_completion_display_matches_hook callback in the
underlying library.  The completion display function is called as
function(substitution, [matches], longest_match_length) once
each time matches need to be displayed."
"Completer.complete(text, state)","Return the stateth completion for text.
If called for text that doesn’t include a period character ('.'), it will
complete from names currently defined in __main__, builtins and
keywords (as defined by the keyword module).
If called for a dotted name, it will try to evaluate anything without obvious
side-effects (functions will not be evaluated, but it can generate calls to
__getattr__()) up to the last part, and find matches for the rest via the
dir() function.  Any exception raised during the evaluation of the
expression is caught, silenced and None is returned."
"struct.pack(format, v1, v2, ...)","Return a bytes object containing the values v1, v2, … packed according
to the format string format.  The arguments must match the values required by
the format exactly."
"struct.pack_into(format, buffer, offset, v1, v2, ...)","Pack the values v1, v2, … according to the format string format and
write the packed bytes into the writable buffer buffer starting at
position offset.  Note that offset is a required argument."
"struct.unpack(format, buffer)","Unpack from the buffer buffer (presumably packed by pack(format, ...))
according to the format string format.  The result is a tuple even if it
contains exactly one item.  The buffer’s size in bytes must match the
size required by the format, as reflected by calcsize()."
"struct.unpack_from(format, buffer, offset=0)","Unpack from buffer starting at position offset, according to the format
string format.  The result is a tuple even if it contains exactly one
item.  The buffer’s size in bytes, starting at position offset, must be at
least the size required by the format, as reflected by calcsize()."
"struct.iter_unpack(format, buffer)","Iteratively unpack from the buffer buffer according to the format
string format.  This function returns an iterator which will read
equally-sized chunks from the buffer until all its contents have been
consumed.  The buffer’s size in bytes must be a multiple of the size
required by the format, as reflected by calcsize().
Each iteration yields a tuple as specified by the format string.

New in version 3.4."
struct.calcsize(format),"Return the size of the struct (and hence of the bytes object produced by
pack(format, ...)) corresponding to the format string format."
"pack(v1, v2, ...)","Identical to the pack() function, using the compiled format.
(len(result) will equal size.)"
"pack_into(buffer, offset, v1, v2, ...)","Identical to the pack_into() function, using the compiled format."
unpack(buffer),"Identical to the unpack() function, using the compiled format.
The buffer’s size in bytes must equal size."
"unpack_from(buffer, offset=0)","Identical to the unpack_from() function, using the compiled format.
The buffer’s size in bytes, starting at position offset, must be at least
size."
iter_unpack(buffer),"Identical to the iter_unpack() function, using the compiled format.
The buffer’s size in bytes must be a multiple of size.

New in version 3.4."
"codecs.encode(obj, encoding='utf-8', errors='strict')","Encodes obj using the codec registered for encoding.
Errors may be given to set the desired error handling scheme. The
default error handler is 'strict' meaning that encoding errors raise
ValueError (or a more codec specific subclass, such as
UnicodeEncodeError). Refer to Codec Base Classes for more
information on codec error handling."
"codecs.decode(obj, encoding='utf-8', errors='strict')","Decodes obj using the codec registered for encoding.
Errors may be given to set the desired error handling scheme. The
default error handler is 'strict' meaning that decoding errors raise
ValueError (or a more codec specific subclass, such as
UnicodeDecodeError). Refer to Codec Base Classes for more
information on codec error handling."
codecs.lookup(encoding),"Looks up the codec info in the Python codec registry and returns a
CodecInfo object as defined below.
Encodings are first looked up in the registry’s cache. If not found, the list of
registered search functions is scanned. If no CodecInfo object is
found, a LookupError is raised. Otherwise, the CodecInfo object
is stored in the cache and returned to the caller."
codecs.getencoder(encoding),"Look up the codec for the given encoding and return its encoder function.
Raises a LookupError in case the encoding cannot be found."
codecs.getdecoder(encoding),"Look up the codec for the given encoding and return its decoder function.
Raises a LookupError in case the encoding cannot be found."
codecs.getincrementalencoder(encoding),"Look up the codec for the given encoding and return its incremental encoder
class or factory function.
Raises a LookupError in case the encoding cannot be found or the codec
doesn’t support an incremental encoder."
codecs.getincrementaldecoder(encoding),"Look up the codec for the given encoding and return its incremental decoder
class or factory function.
Raises a LookupError in case the encoding cannot be found or the codec
doesn’t support an incremental decoder."
codecs.getreader(encoding),"Look up the codec for the given encoding and return its StreamReader
class or factory function.
Raises a LookupError in case the encoding cannot be found."
codecs.getwriter(encoding),"Look up the codec for the given encoding and return its StreamWriter
class or factory function.
Raises a LookupError in case the encoding cannot be found."
codecs.register(search_function),"Register a codec search function. Search functions are expected to take one
argument, being the encoding name in all lower case letters, and return a
CodecInfo object. In case a search function cannot find
a given encoding, it should return None.

Note
Search function registration is not currently reversible,
which may cause problems in some cases, such as unit testing or
module reloading."
"codecs.open(filename, mode='r', encoding=None, errors='strict', buffering=-1)","Open an encoded file using the given mode and return an instance of
StreamReaderWriter, providing transparent encoding/decoding.
The default file mode is 'r', meaning to open the file in read mode.

Note
Underlying encoded files are always opened in binary mode.
No automatic conversion of '\n' is done on reading and writing.
The mode argument may be any binary mode acceptable to the built-in
open() function; the 'b' is automatically added.

encoding specifies the encoding which is to be used for the file.
Any encoding that encodes to and decodes from bytes is allowed, and
the data types supported by the file methods depend on the codec used.
errors may be given to define the error handling. It defaults to 'strict'
which causes a ValueError to be raised in case an encoding error occurs.
buffering has the same meaning as for the built-in open() function.
It defaults to -1 which means that the default buffer size will be used."
"codecs.EncodedFile(file, data_encoding, file_encoding=None, errors='strict')","Return a StreamRecoder instance, a wrapped version of file
which provides transparent transcoding. The original file is closed
when the wrapped version is closed.
Data written to the wrapped file is decoded according to the given
data_encoding and then written to the original file as bytes using
file_encoding. Bytes read from the original file are decoded
according to file_encoding, and the result is encoded
using data_encoding.
If file_encoding is not given, it defaults to data_encoding.
errors may be given to define the error handling. It defaults to
'strict', which causes ValueError to be raised in case an encoding
error occurs."
"codecs.iterencode(iterator, encoding, errors='strict', **kwargs)","Uses an incremental encoder to iteratively encode the input provided by
iterator. This function is a generator.
The errors argument (as well as any
other keyword argument) is passed through to the incremental encoder.
This function requires that the codec accept text str objects
to encode. Therefore it does not support bytes-to-bytes encoders such as
base64_codec."
"codecs.iterdecode(iterator, encoding, errors='strict', **kwargs)","Uses an incremental decoder to iteratively decode the input provided by
iterator. This function is a generator.
The errors argument (as well as any
other keyword argument) is passed through to the incremental decoder.
This function requires that the codec accept bytes objects
to decode. Therefore it does not support text-to-text encoders such as
rot_13, although rot_13 may be used equivalently with
iterencode()."
"codecs.register_error(name, error_handler)","Register the error handling function error_handler under the name name.
The error_handler argument will be called during encoding and decoding
in case of an error, when name is specified as the errors parameter.
For encoding, error_handler will be called with a UnicodeEncodeError
instance, which contains information about the location of the error. The
error handler must either raise this or a different exception, or return a
tuple with a replacement for the unencodable part of the input and a position
where encoding should continue. The replacement may be either str or
bytes. If the replacement is bytes, the encoder will simply copy
them into the output buffer. If the replacement is a string, the encoder will
encode the replacement. Encoding continues on original input at the
specified position. Negative position values will be treated as being
relative to the end of the input string. If the resulting position is out of
bound an IndexError will be raised.
Decoding and translating works similarly, except UnicodeDecodeError or
UnicodeTranslateError will be passed to the handler and that the
replacement from the error handler will be put into the output directly."
codecs.lookup_error(name),"Return the error handler previously registered under the name name.
Raises a LookupError in case the handler cannot be found."
codecs.strict_errors(exception),"Implements the 'strict' error handling: each encoding or
decoding error raises a UnicodeError."
codecs.replace_errors(exception),"Implements the 'replace' error handling (for text encodings only): substitutes '?' for encoding errors
(to be encoded by the codec), and '\ufffd' (the Unicode replacement
character) for decoding errors."
codecs.ignore_errors(exception),"Implements the 'ignore' error handling: malformed data is ignored and
encoding or decoding is continued without further notice."
codecs.xmlcharrefreplace_errors(exception),"Implements the 'xmlcharrefreplace' error handling (for encoding with
text encodings only): the
unencodable character is replaced by an appropriate XML character reference."
codecs.backslashreplace_errors(exception),"Implements the 'backslashreplace' error handling (for
text encodings only): malformed data is
replaced by a backslashed escape sequence."
codecs.namereplace_errors(exception),"Implements the 'namereplace' error handling (for encoding with
text encodings only): the
unencodable character is replaced by a \N{...} escape sequence.

New in version 3.5."
encodings.idna.nameprep(label),"Return the nameprepped version of label. The implementation currently assumes
query strings, so AllowUnassigned is true."
encodings.idna.ToASCII(label),"Convert a label to ASCII, as specified in RFC 3490. UseSTD3ASCIIRules is
assumed to be false."
encodings.idna.ToUnicode(label),"Convert a label to Unicode, as specified in RFC 3490."
"Codec.encode(input[, errors])","Encodes the object input and returns a tuple (output object, length consumed).
For instance, text encoding converts
a string object to a bytes object using a particular
character set encoding (e.g., cp1252 or iso-8859-1).
The errors argument defines the error handling to apply.
It defaults to 'strict' handling.
The method may not store state in the Codec instance. Use
StreamWriter for codecs which have to keep state in order to make
encoding efficient.
The encoder must be able to handle zero length input and return an empty object
of the output object type in this situation."
"Codec.decode(input[, errors])","Decodes the object input and returns a tuple (output object, length
consumed). For instance, for a text encoding, decoding converts
a bytes object encoded using a particular
character set encoding to a string object.
For text encodings and bytes-to-bytes codecs,
input must be a bytes object or one which provides the read-only
buffer interface – for example, buffer objects and memory mapped files.
The errors argument defines the error handling to apply.
It defaults to 'strict' handling.
The method may not store state in the Codec instance. Use
StreamReader for codecs which have to keep state in order to make
decoding efficient.
The decoder must be able to handle zero length input and return an empty object
of the output object type in this situation."
"encode(object[, final])","Encodes object (taking the current state of the encoder into account)
and returns the resulting encoded object. If this is the last call to
encode() final must be true (the default is false)."
reset(),"Reset the encoder to the initial state. The output is discarded: call
.encode(object, final=True), passing an empty byte or text string
if necessary, to reset the encoder and to get the output."
getstate(),"Return the current state of the encoder which must be an integer. The
implementation should make sure that 0 is the most common
state. (States that are more complicated than integers can be converted
into an integer by marshaling/pickling the state and encoding the bytes
of the resulting string into an integer.)"
setstate(state),"Set the state of the encoder to state. state must be an encoder state
returned by getstate()."
"decode(object[, final])","Decodes object (taking the current state of the decoder into account)
and returns the resulting decoded object. If this is the last call to
decode() final must be true (the default is false). If final is
true the decoder must decode the input completely and must flush all
buffers. If this isn’t possible (e.g. because of incomplete byte sequences
at the end of the input) it must initiate error handling just like in the
stateless case (which might raise an exception)."
reset(),Reset the decoder to the initial state.
getstate(),"Return the current state of the decoder. This must be a tuple with two
items, the first must be the buffer containing the still undecoded
input. The second must be an integer and can be additional state
info. (The implementation should make sure that 0 is the most common
additional state info.) If this additional state info is 0 it must be
possible to set the decoder to the state which has no input buffered and
0 as the additional state info, so that feeding the previously
buffered input to the decoder returns it to the previous state without
producing any output. (Additional state info that is more complicated than
integers can be converted into an integer by marshaling/pickling the info
and encoding the bytes of the resulting string into an integer.)"
setstate(state),"Set the state of the decoder to state. state must be a decoder state
returned by getstate()."
write(object),Writes the object’s contents encoded to the stream.
writelines(list),"Writes the concatenated list of strings to the stream (possibly by reusing
the write() method). The standard bytes-to-bytes codecs
do not support this method."
reset(),"Flushes and resets the codec buffers used for keeping state.
Calling this method should ensure that the data on the output is put into
a clean state that allows appending of new fresh data without having to
rescan the whole stream to recover state."
"read([size[, chars[, firstline]]])","Decodes data from the stream and returns the resulting object.
The chars argument indicates the number of decoded
code points or bytes to return. The read() method will
never return more data than requested, but it might return less,
if there is not enough available.
The size argument indicates the approximate maximum
number of encoded bytes or code points to read
for decoding. The decoder can modify this setting as
appropriate. The default value -1 indicates to read and decode as much as
possible. This parameter is intended to
prevent having to decode huge files in one step.
The firstline flag indicates that
it would be sufficient to only return the first
line, if there are decoding errors on later lines.
The method should use a greedy read strategy meaning that it should read
as much data as is allowed within the definition of the encoding and the
given size, e.g.  if optional encoding endings or state markers are
available on the stream, these should be read too."
"readline([size[, keepends]])","Read one line from the input stream and return the decoded data.
size, if given, is passed as size argument to the stream’s
read() method.
If keepends is false line-endings will be stripped from the lines
returned."
"readlines([sizehint[, keepends]])","Read all lines available on the input stream and return them as a list of
lines.
Line-endings are implemented using the codec’s decode() method and
are included in the list entries if keepends is true.
sizehint, if given, is passed as the size argument to the stream’s
read() method."
reset(),"Resets the codec buffers used for keeping state.
Note that no stream repositioning should take place. This method is
primarily intended to be able to recover from decoding errors."
timedelta.total_seconds(),"Return the total number of seconds contained in the duration. Equivalent to
td / timedelta(seconds=1). For interval units other than seconds, use the
division form directly (e.g. td / timedelta(microseconds=1)).
Note that for very large time intervals (greater than 270 years on
most platforms) this method will lose microsecond accuracy.

New in version 3.2."
classmethod date.today(),"Return the current local date.
This is equivalent to date.fromtimestamp(time.time())."
classmethod date.fromtimestamp(timestamp),"Return the local date corresponding to the POSIX timestamp, such as is
returned by time.time().
This may raise OverflowError, if the timestamp is out
of the range of values supported by the platform C localtime()
function, and OSError on localtime() failure.
It’s common for this to be restricted to years from 1970 through 2038. Note
that on non-POSIX systems that include leap seconds in their notion of a
timestamp, leap seconds are ignored by fromtimestamp().

Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp
is out of the range of values supported by the platform C
localtime() function. Raise OSError instead of
ValueError on localtime() failure."
classmethod date.fromordinal(ordinal),"Return the date corresponding to the proleptic Gregorian ordinal, where
January 1 of year 1 has ordinal 1.
ValueError is raised unless 1 <= ordinal <=
date.max.toordinal(). For any date d,
date.fromordinal(d.toordinal()) == d."
classmethod date.fromisoformat(date_string),"Return a date corresponding to a date_string given in the format
YYYY-MM-DD:
>>> from datetime import date
>>> date.fromisoformat('2019-12-04')
datetime.date(2019, 12, 4)


This is the inverse of date.isoformat(). It only supports the format
YYYY-MM-DD.

New in version 3.7."
"classmethod date.fromisocalendar(year, week, day)","Return a date corresponding to the ISO calendar date specified by
year, week and day. This is the inverse of the function date.isocalendar().

New in version 3.8."
"date.replace(year=self.year, month=self.month, day=self.day)","Return a date with the same value, except for those parameters given new
values by whichever keyword arguments are specified.
Example:
>>> from datetime import date
>>> d = date(2002, 12, 31)
>>> d.replace(day=26)
datetime.date(2002, 12, 26)"
date.timetuple(),"Return a time.struct_time such as returned by time.localtime().
The hours, minutes and seconds are 0, and the DST flag is -1.
d.timetuple() is equivalent to:
time.struct_time((d.year, d.month, d.day, 0, 0, 0, d.weekday(), yday, -1))


where yday = d.toordinal() - date(d.year, 1, 1).toordinal() + 1
is the day number within the current year starting with 1 for January 1st."
date.toordinal(),"Return the proleptic Gregorian ordinal of the date, where January 1 of year 1
has ordinal 1. For any date object d,
date.fromordinal(d.toordinal()) == d."
date.weekday(),"Return the day of the week as an integer, where Monday is 0 and Sunday is 6.
For example, date(2002, 12, 4).weekday() == 2, a Wednesday. See also
isoweekday()."
date.isoweekday(),"Return the day of the week as an integer, where Monday is 1 and Sunday is 7.
For example, date(2002, 12, 4).isoweekday() == 3, a Wednesday. See also
weekday(), isocalendar()."
date.isocalendar(),"Return a 3-tuple, (ISO year, ISO week number, ISO weekday).
The ISO calendar is a widely used variant of the Gregorian calendar. 3
The ISO year consists of 52 or 53 full weeks, and where a week starts on a
Monday and ends on a Sunday. The first week of an ISO year is the first
(Gregorian) calendar week of a year containing a Thursday. This is called week
number 1, and the ISO year of that Thursday is the same as its Gregorian year.
For example, 2004 begins on a Thursday, so the first week of ISO year 2004
begins on Monday, 29 Dec 2003 and ends on Sunday, 4 Jan 2004:
>>> from datetime import date
>>> date(2003, 12, 29).isocalendar()
(2004, 1, 1)
>>> date(2004, 1, 4).isocalendar()
(2004, 1, 7)"
date.isoformat(),"Return a string representing the date in ISO 8601 format, YYYY-MM-DD:
>>> from datetime import date
>>> date(2002, 12, 4).isoformat()
'2002-12-04'


This is the inverse of date.fromisoformat()."
date.__str__(),"For a date d, str(d) is equivalent to d.isoformat()."
date.ctime(),"Return a string representing the date:
>>> from datetime import date
>>> date(2002, 12, 4).ctime()
'Wed Dec  4 00:00:00 2002'


d.ctime() is equivalent to:
time.ctime(time.mktime(d.timetuple()))


on platforms where the native C
ctime() function (which time.ctime() invokes, but which
date.ctime() does not invoke) conforms to the C standard."
date.strftime(format),"Return a string representing the date, controlled by an explicit format string.
Format codes referring to hours, minutes or seconds will see 0 values. For a
complete list of formatting directives, see
strftime() and strptime() Behavior."
date.__format__(format),"Same as date.strftime(). This makes it possible to specify a format
string for a date object in formatted string
literals and when using str.format(). For a
complete list of formatting directives, see
strftime() and strptime() Behavior."
classmethod datetime.today(),"Return the current local datetime, with tzinfo None.
Equivalent to:
datetime.fromtimestamp(time.time())


See also now(), fromtimestamp().
This method is functionally equivalent to now(), but without a
tz parameter."
classmethod datetime.now(tz=None),"Return the current local date and time.
If optional argument tz is None
or not specified, this is like today(), but, if possible, supplies more
precision than can be gotten from going through a time.time() timestamp
(for example, this may be possible on platforms supplying the C
gettimeofday() function).
If tz is not None, it must be an instance of a tzinfo subclass,
and the current date and time are converted to tz’s time zone.
This function is preferred over today() and utcnow()."
classmethod datetime.utcnow(),"Return the current UTC date and time, with tzinfo None.
This is like now(), but returns the current UTC date and time, as a naive
datetime object. An aware current UTC datetime can be obtained by
calling datetime.now(timezone.utc). See also now().

Warning
Because naive datetime objects are treated by many datetime methods
as local times, it is preferred to use aware datetimes to represent times
in UTC. As such, the recommended way to create an object representing the
current time in UTC is by calling datetime.now(timezone.utc)."
"classmethod datetime.fromtimestamp(timestamp, tz=None)","Return the local date and time corresponding to the POSIX timestamp, such as is
returned by time.time(). If optional argument tz is None or not
specified, the timestamp is converted to the platform’s local date and time, and
the returned datetime object is naive.
If tz is not None, it must be an instance of a tzinfo subclass, and the
timestamp is converted to tz’s time zone.
fromtimestamp() may raise OverflowError, if the timestamp is out of
the range of values supported by the platform C localtime() or
gmtime() functions, and OSError on localtime() or
gmtime() failure.
It’s common for this to be restricted to years in
1970 through 2038. Note that on non-POSIX systems that include leap seconds in
their notion of a timestamp, leap seconds are ignored by fromtimestamp(),
and then it’s possible to have two timestamps differing by a second that yield
identical datetime objects. This method is preferred over
utcfromtimestamp().

Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp
is out of the range of values supported by the platform C
localtime() or gmtime() functions. Raise OSError
instead of ValueError on localtime() or gmtime()
failure.


Changed in version 3.6: fromtimestamp() may return instances with fold set to 1."
classmethod datetime.utcfromtimestamp(timestamp),"Return the UTC datetime corresponding to the POSIX timestamp, with
tzinfo None.  (The resulting object is naive.)
This may raise OverflowError, if the timestamp is
out of the range of values supported by the platform C gmtime() function,
and OSError on gmtime() failure.
It’s common for this to be restricted to years in 1970 through 2038.
To get an aware datetime object, call fromtimestamp():
datetime.fromtimestamp(timestamp, timezone.utc)


On the POSIX compliant platforms, it is equivalent to the following
expression:
datetime(1970, 1, 1, tzinfo=timezone.utc) + timedelta(seconds=timestamp)


except the latter formula always supports the full years range: between
MINYEAR and MAXYEAR inclusive.

Warning
Because naive datetime objects are treated by many datetime methods
as local times, it is preferred to use aware datetimes to represent times
in UTC. As such, the recommended way to create an object representing a
specific timestamp in UTC is by calling
datetime.fromtimestamp(timestamp, tz=timezone.utc).


Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp
is out of the range of values supported by the platform C
gmtime() function. Raise OSError instead of
ValueError on gmtime() failure."
classmethod datetime.fromordinal(ordinal),"Return the datetime corresponding to the proleptic Gregorian ordinal,
where January 1 of year 1 has ordinal 1. ValueError is raised unless 1
<= ordinal <= datetime.max.toordinal(). The hour, minute, second and
microsecond of the result are all 0, and tzinfo is None."
"classmethod datetime.combine(date, time, tzinfo=self.tzinfo)","Return a new datetime object whose date components are equal to the
given date object’s, and whose time components
are equal to the given time object’s. If the tzinfo
argument is provided, its value is used to set the tzinfo attribute
of the result, otherwise the tzinfo attribute of the time argument
is used.
For any datetime object d,
d == datetime.combine(d.date(), d.time(), d.tzinfo). If date is a
datetime object, its time components and tzinfo attributes
are ignored.

Changed in version 3.6: Added the tzinfo argument."
classmethod datetime.fromisoformat(date_string),"Return a datetime corresponding to a date_string in one of the
formats emitted by date.isoformat() and datetime.isoformat().
Specifically, this function supports strings in the format:
YYYY-MM-DD[*HH[:MM[:SS[.fff[fff]]]][+HH:MM[:SS[.ffffff]]]]


where * can match any single character.

Caution
This does not support parsing arbitrary ISO 8601 strings - it is only intended
as the inverse operation of datetime.isoformat(). A more full-featured
ISO 8601 parser, dateutil.parser.isoparse is available in the third-party package
dateutil.

Examples:
>>> from datetime import datetime
>>> datetime.fromisoformat('2011-11-04')
datetime.datetime(2011, 11, 4, 0, 0)
>>> datetime.fromisoformat('2011-11-04T00:05:23')
datetime.datetime(2011, 11, 4, 0, 5, 23)
>>> datetime.fromisoformat('2011-11-04 00:05:23.283')
datetime.datetime(2011, 11, 4, 0, 5, 23, 283000)
>>> datetime.fromisoformat('2011-11-04 00:05:23.283+00:00')
datetime.datetime(2011, 11, 4, 0, 5, 23, 283000, tzinfo=datetime.timezone.utc)
>>> datetime.fromisoformat('2011-11-04T00:05:23+04:00')   
datetime.datetime(2011, 11, 4, 0, 5, 23,
    tzinfo=datetime.timezone(datetime.timedelta(seconds=14400)))



New in version 3.7."
"classmethod datetime.fromisocalendar(year, week, day)","Return a datetime corresponding to the ISO calendar date specified
by year, week and day. The non-date components of the datetime are populated
with their normal default values. This is the inverse of the function
datetime.isocalendar().

New in version 3.8."
"classmethod datetime.strptime(date_string, format)","Return a datetime corresponding to date_string, parsed according to
format.
This is equivalent to:
datetime(*(time.strptime(date_string, format)[0:6]))


ValueError is raised if the date_string and format
can’t be parsed by time.strptime() or if it returns a value which isn’t a
time tuple. For a complete list of formatting directives, see
strftime() and strptime() Behavior."
datetime.date(),"Return date object with same year, month and day."
datetime.time(),"Return time object with same hour, minute, second, microsecond and fold.
tzinfo is None. See also method timetz().

Changed in version 3.6: The fold value is copied to the returned time object."
datetime.timetz(),"Return time object with same hour, minute, second, microsecond, fold, and
tzinfo attributes. See also method time().

Changed in version 3.6: The fold value is copied to the returned time object."
"datetime.replace(year=self.year, month=self.month, day=self.day, hour=self.hour, minute=self.minute, second=self.second, microsecond=self.microsecond, tzinfo=self.tzinfo, * fold=0)","Return a datetime with the same attributes, except for those attributes given
new values by whichever keyword arguments are specified. Note that
tzinfo=None can be specified to create a naive datetime from an aware
datetime with no conversion of date and time data.

New in version 3.6: Added the fold argument."
datetime.astimezone(tz=None),"Return a datetime object with new tzinfo attribute tz,
adjusting the date and time data so the result is the same UTC time as
self, but in tz’s local time.
If provided, tz must be an instance of a tzinfo subclass, and its
utcoffset() and dst() methods must not return None. If self
is naive, it is presumed to represent time in the system timezone.
If called without arguments (or with tz=None) the system local
timezone is assumed for the target timezone. The .tzinfo attribute of the converted
datetime instance will be set to an instance of timezone
with the zone name and offset obtained from the OS.
If self.tzinfo is tz, self.astimezone(tz) is equal to self:  no
adjustment of date or time data is performed. Else the result is local
time in the timezone tz, representing the same UTC time as self:  after
astz = dt.astimezone(tz), astz - astz.utcoffset() will have
the same date and time data as dt - dt.utcoffset().
If you merely want to attach a time zone object tz to a datetime dt without
adjustment of date and time data, use dt.replace(tzinfo=tz). If you
merely want to remove the time zone object from an aware datetime dt without
conversion of date and time data, use dt.replace(tzinfo=None).
Note that the default tzinfo.fromutc() method can be overridden in a
tzinfo subclass to affect the result returned by astimezone().
Ignoring error cases, astimezone() acts like:
def astimezone(self, tz):
    if self.tzinfo is tz:
        return self
    # Convert self to UTC, and attach the new time zone object.
    utc = (self - self.utcoffset()).replace(tzinfo=tz)
    # Convert from UTC to tz's local time.
    return tz.fromutc(utc)



Changed in version 3.3: tz now can be omitted.


Changed in version 3.6: The astimezone() method can now be called on naive instances that
are presumed to represent system local time."
datetime.utcoffset(),"If tzinfo is None, returns None, else returns
self.tzinfo.utcoffset(self), and raises an exception if the latter doesn’t
return None or a timedelta object with magnitude less than one day.

Changed in version 3.7: The UTC offset is not restricted to a whole number of minutes."
datetime.dst(),"If tzinfo is None, returns None, else returns
self.tzinfo.dst(self), and raises an exception if the latter doesn’t return
None or a timedelta object with magnitude less than one day.

Changed in version 3.7: The DST offset is not restricted to a whole number of minutes."
datetime.tzname(),"If tzinfo is None, returns None, else returns
self.tzinfo.tzname(self), raises an exception if the latter doesn’t return
None or a string object,"
datetime.timetuple(),"Return a time.struct_time such as returned by time.localtime().
d.timetuple() is equivalent to:
time.struct_time((d.year, d.month, d.day,
                  d.hour, d.minute, d.second,
                  d.weekday(), yday, dst))


where yday = d.toordinal() - date(d.year, 1, 1).toordinal() + 1
is the day number within the current year starting with 1 for January
1st. The tm_isdst flag of the result is set according to the
dst() method: tzinfo is None or dst() returns
None, tm_isdst is set to -1; else if dst() returns a
non-zero value, tm_isdst is set to 1; else tm_isdst is
set to 0."
datetime.utctimetuple(),"If datetime instance d is naive, this is the same as
d.timetuple() except that tm_isdst is forced to 0 regardless of what
d.dst() returns. DST is never in effect for a UTC time.
If d is aware, d is normalized to UTC time, by subtracting
d.utcoffset(), and a time.struct_time for the
normalized time is returned. tm_isdst is forced to 0. Note
that an OverflowError may be raised if d.year was
MINYEAR or MAXYEAR and UTC adjustment spills over a year
boundary.

Warning
Because naive datetime objects are treated by many datetime methods
as local times, it is preferred to use aware datetimes to represent times
in UTC; as a result, using utcfromtimetuple may give misleading
results. If you have a naive datetime representing UTC, use
datetime.replace(tzinfo=timezone.utc) to make it aware, at which point
you can use datetime.timetuple()."
datetime.toordinal(),"Return the proleptic Gregorian ordinal of the date. The same as
self.date().toordinal()."
datetime.timestamp(),"Return POSIX timestamp corresponding to the datetime
instance. The return value is a float similar to that
returned by time.time().
Naive datetime instances are assumed to represent local
time and this method relies on the platform C mktime()
function to perform the conversion. Since datetime
supports wider range of values than mktime() on many
platforms, this method may raise OverflowError for times far
in the past or far in the future.
For aware datetime instances, the return value is computed
as:
(dt - datetime(1970, 1, 1, tzinfo=timezone.utc)).total_seconds()



New in version 3.3.


Changed in version 3.6: The timestamp() method uses the fold attribute to
disambiguate the times during a repeated interval.


Note
There is no method to obtain the POSIX timestamp directly from a
naive datetime instance representing UTC time. If your
application uses this convention and your system timezone is not
set to UTC, you can obtain the POSIX timestamp by supplying
tzinfo=timezone.utc:
timestamp = dt.replace(tzinfo=timezone.utc).timestamp()


or by calculating the timestamp directly:
timestamp = (dt - datetime(1970, 1, 1)) / timedelta(seconds=1)"
datetime.weekday(),"Return the day of the week as an integer, where Monday is 0 and Sunday is 6.
The same as self.date().weekday(). See also isoweekday()."
datetime.isoweekday(),"Return the day of the week as an integer, where Monday is 1 and Sunday is 7.
The same as self.date().isoweekday(). See also weekday(),
isocalendar()."
datetime.isocalendar(),"Return a 3-tuple, (ISO year, ISO week number, ISO weekday). The same as
self.date().isocalendar()."
"datetime.isoformat(sep='T', timespec='auto')","Return a string representing the date and time in ISO 8601 format:

YYYY-MM-DDTHH:MM:SS.ffffff, if microsecond is not 0
YYYY-MM-DDTHH:MM:SS, if microsecond is 0

If utcoffset() does not return None, a string is
appended, giving the UTC offset:

YYYY-MM-DDTHH:MM:SS.ffffff+HH:MM[:SS[.ffffff]], if microsecond
is not 0
YYYY-MM-DDTHH:MM:SS+HH:MM[:SS[.ffffff]],  if microsecond is 0

Examples:
>>> from datetime import datetime, timezone
>>> datetime(2019, 5, 18, 15, 17, 8, 132263).isoformat()
'2019-05-18T15:17:08.132263'
>>> datetime(2019, 5, 18, 15, 17, tzinfo=timezone.utc).isoformat()
'2019-05-18T15:17:00+00:00'


The optional argument sep (default 'T') is a one-character separator,
placed between the date and time portions of the result. For example:
>>> from datetime import tzinfo, timedelta, datetime
>>> class TZ(tzinfo):
...     """"""A time zone with an arbitrary, constant -06:39 offset.""""""
...     def utcoffset(self, dt):
...         return timedelta(hours=-6, minutes=-39)
...
>>> datetime(2002, 12, 25, tzinfo=TZ()).isoformat(' ')
'2002-12-25 00:00:00-06:39'
>>> datetime(2009, 11, 27, microsecond=100, tzinfo=TZ()).isoformat()
'2009-11-27T00:00:00.000100-06:39'


The optional argument timespec specifies the number of additional
components of the time to include (the default is 'auto').
It can be one of the following:

'auto': Same as 'seconds' if microsecond is 0,
same as 'microseconds' otherwise.
'hours': Include the hour in the two-digit HH format.
'minutes': Include hour and minute in HH:MM format.
'seconds': Include hour, minute, and second
in HH:MM:SS format.
'milliseconds': Include full time, but truncate fractional second
part to milliseconds. HH:MM:SS.sss format.
'microseconds': Include full time in HH:MM:SS.ffffff format.


Note
Excluded time components are truncated, not rounded.

ValueError will be raised on an invalid timespec argument:
>>> from datetime import datetime
>>> datetime.now().isoformat(timespec='minutes')   
'2002-12-25T00:00'
>>> dt = datetime(2015, 1, 1, 12, 30, 59, 0)
>>> dt.isoformat(timespec='microseconds')
'2015-01-01T12:30:59.000000'



New in version 3.6: Added the timespec argument."
datetime.__str__(),"For a datetime instance d, str(d) is equivalent to
d.isoformat(' ')."
datetime.ctime(),"Return a string representing the date and time:
>>> from datetime import datetime
>>> datetime(2002, 12, 4, 20, 30, 40).ctime()
'Wed Dec  4 20:30:40 2002'


The output string will not include time zone information, regardless
of whether the input is aware or naive.
d.ctime() is equivalent to:
time.ctime(time.mktime(d.timetuple()))


on platforms where the native C ctime() function
(which time.ctime() invokes, but which
datetime.ctime() does not invoke) conforms to the C standard."
datetime.strftime(format),"Return a string representing the date and time, controlled by an explicit format
string. For a complete list of formatting directives, see
strftime() and strptime() Behavior."
datetime.__format__(format),"Same as datetime.strftime(). This makes it possible to specify a format
string for a datetime object in formatted string
literals and when using str.format(). For a
complete list of formatting directives, see
strftime() and strptime() Behavior."
classmethod time.fromisoformat(time_string),"Return a time corresponding to a time_string in one of the
formats emitted by time.isoformat(). Specifically, this function supports
strings in the format:
HH[:MM[:SS[.fff[fff]]]][+HH:MM[:SS[.ffffff]]]



Caution
This does not support parsing arbitrary ISO 8601 strings. It is only
intended as the inverse operation of time.isoformat().

Examples:
>>> from datetime import time
>>> time.fromisoformat('04:23:01')
datetime.time(4, 23, 1)
>>> time.fromisoformat('04:23:01.000384')
datetime.time(4, 23, 1, 384)
>>> time.fromisoformat('04:23:01+04:00')
datetime.time(4, 23, 1, tzinfo=datetime.timezone(datetime.timedelta(seconds=14400)))



New in version 3.7."
"time.replace(hour=self.hour, minute=self.minute, second=self.second, microsecond=self.microsecond, tzinfo=self.tzinfo, * fold=0)","Return a time with the same value, except for those attributes given
new values by whichever keyword arguments are specified. Note that
tzinfo=None can be specified to create a naive time from an
aware time, without conversion of the time data.

New in version 3.6: Added the fold argument."
time.isoformat(timespec='auto'),"Return a string representing the time in ISO 8601 format, one of:

HH:MM:SS.ffffff, if microsecond is not 0
HH:MM:SS, if microsecond is 0
HH:MM:SS.ffffff+HH:MM[:SS[.ffffff]], if utcoffset() does not return None
HH:MM:SS+HH:MM[:SS[.ffffff]], if microsecond is 0 and utcoffset() does not return None

The optional argument timespec specifies the number of additional
components of the time to include (the default is 'auto').
It can be one of the following:

'auto': Same as 'seconds' if microsecond is 0,
same as 'microseconds' otherwise.
'hours': Include the hour in the two-digit HH format.
'minutes': Include hour and minute in HH:MM format.
'seconds': Include hour, minute, and second
in HH:MM:SS format.
'milliseconds': Include full time, but truncate fractional second
part to milliseconds. HH:MM:SS.sss format.
'microseconds': Include full time in HH:MM:SS.ffffff format.


Note
Excluded time components are truncated, not rounded.

ValueError will be raised on an invalid timespec argument.
Example:
>>> from datetime import time
>>> time(hour=12, minute=34, second=56, microsecond=123456).isoformat(timespec='minutes')
'12:34'
>>> dt = time(hour=12, minute=34, second=56, microsecond=0)
>>> dt.isoformat(timespec='microseconds')
'12:34:56.000000'
>>> dt.isoformat(timespec='auto')
'12:34:56'



New in version 3.6: Added the timespec argument."
time.__str__(),"For a time t, str(t) is equivalent to t.isoformat()."
time.strftime(format),"Return a string representing the time, controlled by an explicit format
string. For a complete list of formatting directives, see
strftime() and strptime() Behavior."
time.__format__(format),"Same as time.strftime(). This makes it possible to specify a format string
for a time object in formatted string
literals and when using str.format(). For a
complete list of formatting directives, see
strftime() and strptime() Behavior."
time.utcoffset(),"If tzinfo is None, returns None, else returns
self.tzinfo.utcoffset(None), and raises an exception if the latter doesn’t
return None or a timedelta object with magnitude less than one day.

Changed in version 3.7: The UTC offset is not restricted to a whole number of minutes."
time.dst(),"If tzinfo is None, returns None, else returns
self.tzinfo.dst(None), and raises an exception if the latter doesn’t return
None, or a timedelta object with magnitude less than one day.

Changed in version 3.7: The DST offset is not restricted to a whole number of minutes."
time.tzname(),"If tzinfo is None, returns None, else returns
self.tzinfo.tzname(None), or raises an exception if the latter doesn’t
return None or a string object."
tzinfo.utcoffset(dt),"Return offset of local time from UTC, as a timedelta object that is
positive east of UTC. If local time is west of UTC, this should be negative.
This represents the total offset from UTC; for example, if a
tzinfo object represents both time zone and DST adjustments,
utcoffset() should return their sum. If the UTC offset isn’t known,
return None. Else the value returned must be a timedelta object
strictly between -timedelta(hours=24) and timedelta(hours=24)
(the magnitude of the offset must be less than one day). Most implementations
of utcoffset() will probably look like one of these two:
return CONSTANT                 # fixed-offset class
return CONSTANT + self.dst(dt)  # daylight-aware class


If utcoffset() does not return None, dst() should not return
None either.
The default implementation of utcoffset() raises
NotImplementedError.

Changed in version 3.7: The UTC offset is not restricted to a whole number of minutes."
tzinfo.dst(dt),"Return the daylight saving time (DST) adjustment, as a timedelta
object or
None if DST information isn’t known.
Return timedelta(0) if DST is not in effect.
If DST is in effect, return the offset as a timedelta object
(see utcoffset() for details). Note that DST offset, if applicable, has
already been added to the UTC offset returned by utcoffset(), so there’s
no need to consult dst() unless you’re interested in obtaining DST info
separately. For example, datetime.timetuple() calls its tzinfo
attribute’s dst() method to determine how the tm_isdst flag
should be set, and tzinfo.fromutc() calls dst() to account for
DST changes when crossing time zones.
An instance tz of a tzinfo subclass that models both standard and
daylight times must be consistent in this sense:
tz.utcoffset(dt) - tz.dst(dt)
must return the same result for every datetime dt with dt.tzinfo ==
tz  For sane tzinfo subclasses, this expression yields the time
zone’s “standard offset”, which should not depend on the date or the time, but
only on geographic location. The implementation of datetime.astimezone()
relies on this, but cannot detect violations; it’s the programmer’s
responsibility to ensure it. If a tzinfo subclass cannot guarantee
this, it may be able to override the default implementation of
tzinfo.fromutc() to work correctly with astimezone() regardless.
Most implementations of dst() will probably look like one of these two:
def dst(self, dt):
    # a fixed-offset class:  doesn't account for DST
    return timedelta(0)


or:
def dst(self, dt):
    # Code to set dston and dstoff to the time zone's DST
    # transition times based on the input dt.year, and expressed
    # in standard local time.

    if dston <= dt.replace(tzinfo=None) < dstoff:
        return timedelta(hours=1)
    else:
        return timedelta(0)


The default implementation of dst() raises NotImplementedError.

Changed in version 3.7: The DST offset is not restricted to a whole number of minutes."
tzinfo.tzname(dt),"Return the time zone name corresponding to the datetime object dt, as
a string. Nothing about string names is defined by the datetime module,
and there’s no requirement that it mean anything in particular. For example,
“GMT”, “UTC”, “-500”, “-5:00”, “EDT”, “US/Eastern”, “America/New York” are all
valid replies. Return None if a string name isn’t known. Note that this is
a method rather than a fixed string primarily because some tzinfo
subclasses will wish to return different names depending on the specific value
of dt passed, especially if the tzinfo class is accounting for
daylight time.
The default implementation of tzname() raises NotImplementedError."
tzinfo.fromutc(dt),"This is called from the default datetime.astimezone()
implementation. When called from that, dt.tzinfo is self, and dt’s
date and time data are to be viewed as expressing a UTC time. The purpose
of fromutc() is to adjust the date and time data, returning an
equivalent datetime in self’s local time.
Most tzinfo subclasses should be able to inherit the default
fromutc() implementation without problems. It’s strong enough to handle
fixed-offset time zones, and time zones accounting for both standard and
daylight time, and the latter even if the DST transition times differ in
different years. An example of a time zone the default fromutc()
implementation may not handle correctly in all cases is one where the standard
offset (from UTC) depends on the specific date and time passed, which can happen
for political reasons. The default implementations of astimezone() and
fromutc() may not produce the result you want if the result is one of the
hours straddling the moment the standard offset changes.
Skipping code for error cases, the default fromutc() implementation acts
like:
def fromutc(self, dt):
    # raise ValueError error if dt.tzinfo is not self
    dtoff = dt.utcoffset()
    dtdst = dt.dst()
    # raise ValueError if dtoff is None or dtdst is None
    delta = dtoff - dtdst  # this is self's standard offset
    if delta:
        dt += delta   # convert to standard local time
        dtdst = dt.dst()
        # raise ValueError if dtdst is None
    if dtdst:
        return dt + dtdst
    else:
        return dt"
timezone.utcoffset(dt),"Return the fixed value specified when the timezone instance is
constructed.
The dt argument is ignored. The return value is a timedelta
instance equal to the difference between the local time and UTC.

Changed in version 3.7: The UTC offset is not restricted to a whole number of minutes."
timezone.tzname(dt),"Return the fixed value specified when the timezone instance
is constructed.
If name is not provided in the constructor, the name returned by
tzname(dt) is generated from the value of the offset as follows. If
offset is timedelta(0), the name is “UTC”, otherwise it is a string in
the format UTC±HH:MM, where ± is the sign of offset, HH and MM are
two digits of offset.hours and offset.minutes respectively.

Changed in version 3.6: Name generated from offset=timedelta(0) is now plain ‘UTC’, not
'UTC+00:00'."
timezone.dst(dt),Always returns None.
timezone.fromutc(dt),"Return dt + offset. The dt argument must be an aware
datetime instance, with tzinfo set to self."
calendar.setfirstweekday(weekday),"Sets the weekday (0 is Monday, 6 is Sunday) to start each week. The
values MONDAY, TUESDAY, WEDNESDAY, THURSDAY,
FRIDAY, SATURDAY, and SUNDAY are provided for
convenience. For example, to set the first weekday to Sunday:
import calendar
calendar.setfirstweekday(calendar.SUNDAY)"
calendar.firstweekday(),Returns the current setting for the weekday to start each week.
calendar.isleap(year),"Returns True if year is a leap year, otherwise False."
"calendar.leapdays(y1, y2)","Returns the number of leap years in the range from y1 to y2 (exclusive),
where y1 and y2 are years.
This function works for ranges spanning a century change."
"calendar.weekday(year, month, day)","Returns the day of the week (0 is Monday) for year (1970–…),
month (1–12), day (1–31)."
calendar.weekheader(n),"Return a header containing abbreviated weekday names. n specifies the width in
characters for one weekday."
"calendar.monthrange(year, month)","Returns weekday of first day of the month and number of days in month,  for the
specified year and month."
"calendar.monthcalendar(year, month)","Returns a matrix representing a month’s calendar.  Each row represents a week;
days outside of the month a represented by zeros. Each week begins with Monday
unless set by setfirstweekday()."
"calendar.prmonth(theyear, themonth, w=0, l=0)",Prints a month’s calendar as returned by month().
"calendar.month(theyear, themonth, w=0, l=0)","Returns a month’s calendar in a multi-line string using the formatmonth()
of the TextCalendar class."
"calendar.prcal(year, w=0, l=0, c=6, m=3)",Prints the calendar for an entire year as returned by  calendar().
"calendar.calendar(year, w=2, l=1, c=6, m=3)","Returns a 3-column calendar for an entire year as a multi-line string using
the formatyear() of the TextCalendar class."
calendar.timegm(tuple),"An unrelated but handy function that takes a time tuple such as returned by
the gmtime() function in the time module, and returns the
corresponding Unix timestamp value, assuming an epoch of 1970, and the POSIX
encoding.  In fact, time.gmtime() and timegm() are each others’
inverse."
iterweekdays(),"Return an iterator for the week day numbers that will be used for one
week.  The first value from the iterator will be the same as the value of
the firstweekday property."
"itermonthdates(year, month)","Return an iterator for the month month (1–12) in the year year. This
iterator will return all days (as datetime.date objects) for the
month and all days before the start of the month or after the end of the
month that are required to get a complete week."
"itermonthdays(year, month)","Return an iterator for the month month in the year year similar to
itermonthdates(), but not restricted by the datetime.date
range. Days returned will simply be day of the month numbers.  For the
days outside of the specified month, the day number is 0."
"itermonthdays2(year, month)","Return an iterator for the month month in the year year similar to
itermonthdates(), but not restricted by the datetime.date
range. Days returned will be tuples consisting of a day of the month
number and a week day number."
"itermonthdays3(year, month)","Return an iterator for the month month in the year year similar to
itermonthdates(), but not restricted by the datetime.date
range. Days returned will be tuples consisting of a year, a month and a day
of the month numbers.

New in version 3.7."
"itermonthdays4(year, month)","Return an iterator for the month month in the year year similar to
itermonthdates(), but not restricted by the datetime.date
range. Days returned will be tuples consisting of a year, a month, a day
of the month, and a day of the week numbers.

New in version 3.7."
"monthdatescalendar(year, month)","Return a list of the weeks in the month month of the year as full
weeks.  Weeks are lists of seven datetime.date objects."
"monthdays2calendar(year, month)","Return a list of the weeks in the month month of the year as full
weeks.  Weeks are lists of seven tuples of day numbers and weekday
numbers."
"monthdayscalendar(year, month)","Return a list of the weeks in the month month of the year as full
weeks.  Weeks are lists of seven day numbers."
"yeardatescalendar(year, width=3)","Return the data for the specified year ready for formatting. The return
value is a list of month rows. Each month row contains up to width
months (defaulting to 3). Each month contains between 4 and 6 weeks and
each week contains 1–7 days. Days are datetime.date objects."
"yeardays2calendar(year, width=3)","Return the data for the specified year ready for formatting (similar to
yeardatescalendar()). Entries in the week lists are tuples of day
numbers and weekday numbers. Day numbers outside this month are zero."
"yeardayscalendar(year, width=3)","Return the data for the specified year ready for formatting (similar to
yeardatescalendar()). Entries in the week lists are day numbers. Day
numbers outside this month are zero."
"formatmonth(theyear, themonth, w=0, l=0)","Return a month’s calendar in a multi-line string. If w is provided, it
specifies the width of the date columns, which are centered. If l is
given, it specifies the number of lines that each week will use. Depends
on the first weekday as specified in the constructor or set by the
setfirstweekday() method."
"prmonth(theyear, themonth, w=0, l=0)",Print a month’s calendar as returned by formatmonth().
"formatyear(theyear, w=2, l=1, c=6, m=3)","Return a m-column calendar for an entire year as a multi-line string.
Optional parameters w, l, and c are for date column width, lines per
week, and number of spaces between month columns, respectively. Depends on
the first weekday as specified in the constructor or set by the
setfirstweekday() method.  The earliest year for which a calendar
can be generated is platform-dependent."
"pryear(theyear, w=2, l=1, c=6, m=3)",Print the calendar for an entire year as returned by formatyear().
"formatmonth(theyear, themonth, withyear=True)","Return a month’s calendar as an HTML table. If withyear is true the year
will be included in the header, otherwise just the month name will be
used."
"formatyear(theyear, width=3)","Return a year’s calendar as an HTML table. width (defaulting to 3)
specifies the number of months per row."
"formatyearpage(theyear, width=3, css='calendar.css', encoding=None)","Return a year’s calendar as a complete HTML page. width (defaulting to
3) specifies the number of months per row. css is the name for the
cascading style sheet to be used. None can be passed if no style
sheet should be used. encoding specifies the encoding to be used for the
output (defaulting to the system default encoding)."
"collections.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)","Returns a new tuple subclass named typename.  The new subclass is used to
create tuple-like objects that have fields accessible by attribute lookup as
well as being indexable and iterable.  Instances of the subclass also have a
helpful docstring (with typename and field_names) and a helpful __repr__()
method which lists the tuple contents in a name=value format.
The field_names are a sequence of strings such as ['x', 'y'].
Alternatively, field_names can be a single string with each fieldname
separated by whitespace and/or commas, for example 'x y' or 'x, y'.
Any valid Python identifier may be used for a fieldname except for names
starting with an underscore.  Valid identifiers consist of letters, digits,
and underscores but do not start with a digit or underscore and cannot be
a keyword such as class, for, return, global, pass,
or raise.
If rename is true, invalid fieldnames are automatically replaced
with positional names.  For example, ['abc', 'def', 'ghi', 'abc'] is
converted to ['abc', '_1', 'ghi', '_3'], eliminating the keyword
def and the duplicate fieldname abc.
defaults can be None or an iterable of default values.
Since fields with a default value must come after any fields without a
default, the defaults are applied to the rightmost parameters.  For
example, if the fieldnames are ['x', 'y', 'z'] and the defaults are
(1, 2), then x will be a required argument, y will default to
1, and z will default to 2.
If module is defined, the __module__ attribute of the named tuple is
set to that value.
Named tuple instances do not have per-instance dictionaries, so they are
lightweight and require no more memory than regular tuples.

Changed in version 3.1: Added support for rename.


Changed in version 3.6: The verbose and rename parameters became
keyword-only arguments.


Changed in version 3.6: Added the module parameter.


Changed in version 3.7: Removed the verbose parameter and the _source attribute.


Changed in version 3.7: Added the defaults parameter and the _field_defaults
attribute."
new_child(m=None),"Returns a new ChainMap containing a new map followed by
all of the maps in the current instance.  If m is specified,
it becomes the new map at the front of the list of mappings; if not
specified, an empty dict is used, so that a call to d.new_child()
is equivalent to: ChainMap({}, *d.maps).  This method is used for
creating subcontexts that can be updated without altering values in any
of the parent mappings.

Changed in version 3.4: The optional m parameter was added."
elements(),"Return an iterator over elements repeating each as many times as its
count.  Elements are returned in the order first encountered. If an
element’s count is less than one, elements() will ignore it.
>>> c = Counter(a=4, b=2, c=0, d=-2)
>>> sorted(c.elements())
['a', 'a', 'a', 'a', 'b', 'b']"
most_common([n]),"Return a list of the n most common elements and their counts from the
most common to the least.  If n is omitted or None,
most_common() returns all elements in the counter.
Elements with equal counts are ordered in the order first encountered:
>>> Counter('abracadabra').most_common(3)
[('a', 5), ('b', 2), ('r', 2)]"
subtract([iterable-or-mapping]),"Elements are subtracted from an iterable or from another mapping
(or counter).  Like dict.update() but subtracts counts instead
of replacing them.  Both inputs and outputs may be zero or negative.
>>> c = Counter(a=4, b=2, c=0, d=-2)
>>> d = Counter(a=1, b=2, c=3, d=4)
>>> c.subtract(d)
>>> c
Counter({'a': 3, 'b': 0, 'c': -3, 'd': -6})



New in version 3.2."
fromkeys(iterable),This class method is not implemented for Counter objects.
update([iterable-or-mapping]),"Elements are counted from an iterable or added-in from another
mapping (or counter).  Like dict.update() but adds counts
instead of replacing them.  Also, the iterable is expected to be a
sequence of elements, not a sequence of (key, value) pairs."
append(x),Add x to the right side of the deque.
appendleft(x),Add x to the left side of the deque.
clear(),Remove all elements from the deque leaving it with length 0.
copy(),"Create a shallow copy of the deque.

New in version 3.5."
count(x),"Count the number of deque elements equal to x.

New in version 3.2."
extend(iterable),"Extend the right side of the deque by appending elements from the iterable
argument."
extendleft(iterable),"Extend the left side of the deque by appending elements from iterable.
Note, the series of left appends results in reversing the order of
elements in the iterable argument."
"index(x[, start[, stop]])","Return the position of x in the deque (at or after index start
and before index stop).  Returns the first match or raises
ValueError if not found.

New in version 3.5."
"insert(i, x)","Insert x into the deque at position i.
If the insertion would cause a bounded deque to grow beyond maxlen,
an IndexError is raised.

New in version 3.5."
pop(),"Remove and return an element from the right side of the deque. If no
elements are present, raises an IndexError."
popleft(),"Remove and return an element from the left side of the deque. If no
elements are present, raises an IndexError."
remove(value),"Remove the first occurrence of value.  If not found, raises a
ValueError."
reverse(),"Reverse the elements of the deque in-place and then return None.

New in version 3.2."
rotate(n=1),"Rotate the deque n steps to the right.  If n is negative, rotate
to the left.
When the deque is not empty, rotating one step to the right is equivalent
to d.appendleft(d.pop()), and rotating one step to the left is
equivalent to d.append(d.popleft())."
__missing__(key),"If the default_factory attribute is None, this raises a
KeyError exception with the key as argument.
If default_factory is not None, it is called without arguments
to provide a default value for the given key, this value is inserted in
the dictionary for the key, and returned.
If calling default_factory raises an exception this exception is
propagated unchanged.
This method is called by the __getitem__() method of the
dict class when the requested key is not found; whatever it
returns or raises is then returned or raised by __getitem__().
Note that __missing__() is not called for any operations besides
__getitem__(). This means that get() will, like normal
dictionaries, return None as a default rather than using
default_factory."
classmethod somenamedtuple._make(iterable),"Class method that makes a new instance from an existing sequence or iterable.
>>> t = [11, 22]
>>> Point._make(t)
Point(x=11, y=22)"
somenamedtuple._asdict(),"Return a new dict which maps field names to their corresponding
values:
>>> p = Point(x=11, y=22)
>>> p._asdict()
{'x': 11, 'y': 22}



Changed in version 3.1: Returns an OrderedDict instead of a regular dict.


Changed in version 3.8: Returns a regular dict instead of an OrderedDict.
As of Python 3.7, regular dicts are guaranteed to be ordered.  If the
extra features of OrderedDict are required, the suggested
remediation is to cast the result to the desired type:
OrderedDict(nt._asdict())."
somenamedtuple._replace(**kwargs),"Return a new instance of the named tuple replacing specified fields with new
values:
>>> p = Point(x=11, y=22)
>>> p._replace(x=33)
Point(x=33, y=22)

>>> for partnum, record in inventory.items():
...     inventory[partnum] = record._replace(price=newprices[partnum], timestamp=time.now())"
popitem(last=True),"The popitem() method for ordered dictionaries returns and removes a
(key, value) pair.  The pairs are returned in
LIFO order if last is true
or FIFO order if false."
"move_to_end(key, last=True)","Move an existing key to either end of an ordered dictionary.  The item
is moved to the right end if last is true (the default) or to the
beginning if last is false.  Raises KeyError if the key does
not exist:
>>> d = OrderedDict.fromkeys('abcde')
>>> d.move_to_end('b')
>>> ''.join(d.keys())
'acdeb'
>>> d.move_to_end('b', last=False)
>>> ''.join(d.keys())
'bacde'



New in version 3.2."
"heapq.heappush(heap, item)","Push the value item onto the heap, maintaining the heap invariant."
heapq.heappop(heap),"Pop and return the smallest item from the heap, maintaining the heap
invariant.  If the heap is empty, IndexError is raised.  To access the
smallest item without popping it, use heap[0]."
"heapq.heappushpop(heap, item)","Push item on the heap, then pop and return the smallest item from the
heap.  The combined action runs more efficiently than heappush()
followed by a separate call to heappop()."
heapq.heapify(x),"Transform list x into a heap, in-place, in linear time."
"heapq.heapreplace(heap, item)","Pop and return the smallest item from the heap, and also push the new item.
The heap size doesn’t change. If the heap is empty, IndexError is raised.
This one step operation is more efficient than a heappop() followed by
heappush() and can be more appropriate when using a fixed-size heap.
The pop/push combination always returns an element from the heap and replaces
it with item.
The value returned may be larger than the item added.  If that isn’t
desired, consider using heappushpop() instead.  Its push/pop
combination returns the smaller of the two values, leaving the larger value
on the heap."
"heapq.merge(*iterables, key=None, reverse=False)","Merge multiple sorted inputs into a single sorted output (for example, merge
timestamped entries from multiple log files).  Returns an iterator
over the sorted values.
Similar to sorted(itertools.chain(*iterables)) but returns an iterable, does
not pull the data into memory all at once, and assumes that each of the input
streams is already sorted (smallest to largest).
Has two optional arguments which must be specified as keyword arguments.
key specifies a key function of one argument that is used to
extract a comparison key from each input element.  The default value is
None (compare the elements directly).
reverse is a boolean value.  If set to True, then the input elements
are merged as if each comparison were reversed. To achieve behavior similar
to sorted(itertools.chain(*iterables), reverse=True), all iterables must
be sorted from largest to smallest.

Changed in version 3.5: Added the optional key and reverse parameters."
"heapq.nlargest(n, iterable, key=None)","Return a list with the n largest elements from the dataset defined by
iterable.  key, if provided, specifies a function of one argument that is
used to extract a comparison key from each element in iterable (for example,
key=str.lower).  Equivalent to:  sorted(iterable, key=key,
reverse=True)[:n]."
"heapq.nsmallest(n, iterable, key=None)","Return a list with the n smallest elements from the dataset defined by
iterable.  key, if provided, specifies a function of one argument that is
used to extract a comparison key from each element in iterable (for example,
key=str.lower).  Equivalent to:  sorted(iterable, key=key)[:n]."
"bisect.bisect_left(a, x, lo=0, hi=len(a))","Locate the insertion point for x in a to maintain sorted order.
The parameters lo and hi may be used to specify a subset of the list
which should be considered; by default the entire list is used.  If x is
already present in a, the insertion point will be before (to the left of)
any existing entries.  The return value is suitable for use as the first
parameter to list.insert() assuming that a is already sorted.
The returned insertion point i partitions the array a into two halves so
that all(val < x for val in a[lo:i]) for the left side and
all(val >= x for val in a[i:hi]) for the right side."
"bisect.bisect_right(a, x, lo=0, hi=len(a))","Similar to bisect_left(), but returns an insertion point which comes
after (to the right of) any existing entries of x in a.
The returned insertion point i partitions the array a into two halves so
that all(val <= x for val in a[lo:i]) for the left side and
all(val > x for val in a[i:hi]) for the right side."
"bisect.insort_left(a, x, lo=0, hi=len(a))","Insert x in a in sorted order.  This is equivalent to
a.insert(bisect.bisect_left(a, x, lo, hi), x) assuming that a is
already sorted.  Keep in mind that the O(log n) search is dominated by
the slow O(n) insertion step."
"bisect.insort_right(a, x, lo=0, hi=len(a))","Similar to insort_left(), but inserting x in a after any existing
entries of x."
array.append(x),Append a new item with value x to the end of the array.
array.buffer_info(),"Return a tuple (address, length) giving the current memory address and the
length in elements of the buffer used to hold array’s contents.  The size of the
memory buffer in bytes can be computed as array.buffer_info()[1] *
array.itemsize.  This is occasionally useful when working with low-level (and
inherently unsafe) I/O interfaces that require memory addresses, such as certain
ioctl() operations.  The returned numbers are valid as long as the array
exists and no length-changing operations are applied to it.

Note
When using array objects from code written in C or C++ (the only way to
effectively make use of this information), it makes more sense to use the buffer
interface supported by array objects.  This method is maintained for backward
compatibility and should be avoided in new code.  The buffer interface is
documented in Buffer Protocol."
array.byteswap(),"“Byteswap” all items of the array.  This is only supported for values which are
1, 2, 4, or 8 bytes in size; for other types of values, RuntimeError is
raised.  It is useful when reading data from a file written on a machine with a
different byte order."
array.count(x),Return the number of occurrences of x in the array.
array.extend(iterable),"Append items from iterable to the end of the array.  If iterable is another
array, it must have exactly the same type code; if not, TypeError will
be raised.  If iterable is not an array, it must be iterable and its elements
must be the right type to be appended to the array."
array.frombytes(s),"Appends items from the string, interpreting the string as an array of machine
values (as if it had been read from a file using the fromfile() method).

New in version 3.2: fromstring() is renamed to frombytes() for clarity."
"array.fromfile(f, n)","Read n items (as machine values) from the file object f and append
them to the end of the array.  If less than n items are available,
EOFError is raised, but the items that were available are still
inserted into the array. f must be a real built-in file object; something
else with a read() method won’t do."
array.fromlist(list),"Append items from the list.  This is equivalent to for x in list:
a.append(x) except that if there is a type error, the array is unchanged."
array.fromstring(),"Deprecated alias for frombytes().

Deprecated since version 3.2, will be removed in version 3.9."
array.fromunicode(s),"Extends this array with data from the given unicode string.  The array must
be a type 'u' array; otherwise a ValueError is raised.  Use
array.frombytes(unicodestring.encode(enc)) to append Unicode data to an
array of some other type."
array.index(x),"Return the smallest i such that i is the index of the first occurrence of
x in the array."
"array.insert(i, x)","Insert a new item with value x in the array before position i. Negative
values are treated as being relative to the end of the array."
array.pop([i]),"Removes the item with the index i from the array and returns it. The optional
argument defaults to -1, so that by default the last item is removed and
returned."
array.remove(x),Remove the first occurrence of x from the array.
array.reverse(),Reverse the order of the items in the array.
array.tobytes(),"Convert the array to an array of machine values and return the bytes
representation (the same sequence of bytes that would be written to a file by
the tofile() method.)

New in version 3.2: tostring() is renamed to tobytes() for clarity."
array.tofile(f),Write all items (as machine values) to the file object f.
array.tolist(),Convert the array to an ordinary list with the same items.
array.tostring(),"Deprecated alias for tobytes().

Deprecated since version 3.2, will be removed in version 3.9."
array.tounicode(),"Convert the array to a unicode string.  The array must be a type 'u' array;
otherwise a ValueError is raised. Use array.tobytes().decode(enc) to
obtain a unicode string from an array of some other type."
"weakref.proxy(object[, callback])","Return a proxy to object which uses a weak reference.  This supports use of
the proxy in most contexts instead of requiring the explicit dereferencing used
with weak reference objects.  The returned object will have a type of either
ProxyType or CallableProxyType, depending on whether object is
callable.  Proxy objects are not hashable regardless of the referent; this
avoids a number of problems related to their fundamentally mutable nature, and
prevent their use as dictionary keys.  callback is the same as the parameter
of the same name to the ref() function.

Changed in version 3.8: Extended the operator support on proxy objects to include the matrix
multiplication operators @ and @=."
weakref.getweakrefcount(object),Return the number of weak references and proxies which refer to object.
weakref.getweakrefs(object),Return a list of all weak reference and proxy objects which refer to object.
WeakKeyDictionary.keyrefs(),Return an iterable of the weak references to the keys.
WeakValueDictionary.valuerefs(),Return an iterable of the weak references to the values.
__call__(),"If self is alive then mark it as dead and return the result of
calling func(*args, **kwargs).  If self is dead then return
None."
detach(),"If self is alive then mark it as dead and return the tuple
(obj, func, args, kwargs).  If self is dead then return
None."
peek(),"If self is alive then return the tuple (obj, func, args,
kwargs).  If self is dead then return None."
"types.new_class(name, bases=(), kwds=None, exec_body=None)","Creates a class object dynamically using the appropriate metaclass.
The first three arguments are the components that make up a class
definition header: the class name, the base classes (in order), the
keyword arguments (such as metaclass).
The exec_body argument is a callback that is used to populate the
freshly created class namespace. It should accept the class namespace
as its sole argument and update the namespace directly with the class
contents. If no callback is provided, it has the same effect as passing
in lambda ns: ns.

New in version 3.3."
"types.prepare_class(name, bases=(), kwds=None)","Calculates the appropriate metaclass and creates the class namespace.
The arguments are the components that make up a class definition header:
the class name, the base classes (in order) and the keyword arguments
(such as metaclass).
The return value is a 3-tuple: metaclass, namespace, kwds
metaclass is the appropriate metaclass, namespace is the
prepared class namespace and kwds is an updated copy of the passed
in kwds argument with any 'metaclass' entry removed. If no kwds
argument is passed in, this will be an empty dict.

New in version 3.3.


Changed in version 3.6: The default value for the namespace element of the returned
tuple has changed.  Now an insertion-order-preserving mapping is
used when the metaclass does not have a __prepare__ method."
types.resolve_bases(bases),"Resolve MRO entries dynamically as specified by PEP 560.
This function looks for items in bases that are not instances of
type, and returns a tuple where each such object that has
an __mro_entries__ method is replaced with an unpacked result of
calling this method.  If a bases item is an instance of type,
or it doesn’t have an __mro_entries__ method, then it is included in
the return tuple unchanged.

New in version 3.7."
"types.DynamicClassAttribute(fget=None, fset=None, fdel=None, doc=None)","Route attribute access on a class to __getattr__.
This is a descriptor, used to define attributes that act differently when
accessed through an instance and through a class.  Instance access remains
normal, but access to an attribute through a class will be routed to the
class’s __getattr__ method; this is done by raising AttributeError.
This allows one to have properties active on an instance, and have virtual
attributes on the class with the same name (see Enum for an example).

New in version 3.4."
types.coroutine(gen_func),"This function transforms a generator function into a
coroutine function which returns a generator-based coroutine.
The generator-based coroutine is still a generator iterator,
but is also considered to be a coroutine object and is
awaitable.  However, it may not necessarily implement
the __await__() method.
If gen_func is a generator function, it will be modified in-place.
If gen_func is not a generator function, it will be wrapped. If it
returns an instance of collections.abc.Generator, the instance
will be wrapped in an awaitable proxy object.  All other types
of objects will be returned as is.

New in version 3.5."
replace(**kwargs),"Return a copy of the code object with new values for the specified fields.

New in version 3.8."
copy(),Return a shallow copy of the underlying mapping.
"get(key[, default])","Return the value for key if key is in the underlying mapping, else
default.  If default is not given, it defaults to None, so that
this method never raises a KeyError."
items(),"Return a new view of the underlying mapping’s items ((key, value)
pairs)."
keys(),Return a new view of the underlying mapping’s keys.
values(),Return a new view of the underlying mapping’s values.
copy.copy(x),Return a shallow copy of x.
"copy.deepcopy(x[, memo])",Return a deep copy of x.
"pprint.pformat(object, indent=1, width=80, depth=None, *, compact=False, sort_dicts=True)","Return the formatted representation of object as a string.  indent,
width, depth, compact and sort_dicts will be passed to the
PrettyPrinter constructor as formatting parameters.

Changed in version 3.4: Added the compact parameter.


Changed in version 3.8: Added the sort_dicts parameter."
"pprint.pp(object, *args, sort_dicts=False, **kwargs)","Prints the formatted representation of object followed by a newline.
If sort_dicts is false (the default), dictionaries will be displayed with
their keys in insertion order, otherwise the dict keys will be sorted.
args and kwargs will be passed to pprint() as formatting
parameters.

New in version 3.8."
"pprint.pprint(object, stream=None, indent=1, width=80, depth=None, *, compact=False, sort_dicts=True)","Prints the formatted representation of object on stream, followed by a
newline.  If stream is None, sys.stdout is used.  This may be used
in the interactive interpreter instead of the print() function for
inspecting values (you can even reassign print = pprint.pprint for use
within a scope).  indent, width, depth, compact and sort_dicts will
be passed to the PrettyPrinter constructor as formatting parameters.

Changed in version 3.4: Added the compact parameter.


Changed in version 3.8: Added the sort_dicts parameter.
>>> import pprint
>>> stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']
>>> stuff.insert(0, stuff)
>>> pprint.pprint(stuff)
[<Recursion on list with id=...>,
 'spam',
 'eggs',
 'lumberjack',
 'knights',
 'ni']"
pprint.isreadable(object),"Determine if the formatted representation of object is “readable,” or can be
used to reconstruct the value using eval().  This always returns False
for recursive objects.
>>> pprint.isreadable(stuff)
False"
pprint.isrecursive(object),Determine if object requires a recursive representation.
pprint.saferepr(object),"Return a string representation of object, protected against recursive data
structures.  If the representation of object exposes a recursive entry, the
recursive reference will be represented as <Recursion on typename with
id=number>.  The representation is not otherwise formatted.
>>> pprint.saferepr(stuff)
""[<Recursion on list with id=...>, 'spam', 'eggs', 'lumberjack', 'knights', 'ni']"""
PrettyPrinter.pformat(object),"Return the formatted representation of object.  This takes into account the
options passed to the PrettyPrinter constructor."
PrettyPrinter.pprint(object),"Print the formatted representation of object on the configured stream,
followed by a newline."
PrettyPrinter.isreadable(object),"Determine if the formatted representation of the object is “readable,” or can be
used to reconstruct the value using eval().  Note that this returns
False for recursive objects.  If the depth parameter of the
PrettyPrinter is set and the object is deeper than allowed, this
returns False."
PrettyPrinter.isrecursive(object),Determine if the object requires a recursive representation.
"PrettyPrinter.format(object, context, maxlevels, level)","Returns three values: the formatted version of object as a string, a flag
indicating whether the result is readable, and a flag indicating whether
recursion was detected.  The first argument is the object to be presented.  The
second is a dictionary which contains the id() of objects that are part of
the current presentation context (direct and indirect containers for object
that are affecting the presentation) as the keys; if an object needs to be
presented which is already represented in context, the third return value
should be True.  Recursive calls to the format() method should add
additional entries for containers to this dictionary.  The third argument,
maxlevels, gives the requested limit to recursion; this will be 0 if there
is no requested limit.  This argument should be passed unmodified to recursive
calls. The fourth argument, level, gives the current level; recursive calls
should be passed a value less than that of the current call."
reprlib.repr(obj),"This is the repr() method of aRepr.  It returns a string
similar to that returned by the built-in function of the same name, but with
limits on most sizes."
"@reprlib.recursive_repr(fillvalue=""..."")","Decorator for __repr__() methods to detect recursive calls within the
same thread.  If a recursive call is made, the fillvalue is returned,
otherwise, the usual __repr__() call is made.  For example:
>>> from reprlib import recursive_repr
>>> class MyList(list):
...     @recursive_repr()
...     def __repr__(self):
...         return '<' + '|'.join(map(repr, self)) + '>'
...
>>> m = MyList('abc')
>>> m.append(m)
>>> m.append('x')
>>> print(m)
<'a'|'b'|'c'|...|'x'>



New in version 3.2."
Repr.repr(obj),"The equivalent to the built-in repr() that uses the formatting imposed by
the instance."
"Repr.repr1(obj, level)","Recursive implementation used by repr().  This uses the type of obj to
determine which formatting method to call, passing it obj and level.  The
type-specific methods should call repr1() to perform recursive formatting,
with level - 1 for the value of level in the recursive  call."
"Repr.repr_TYPE(obj, level","Formatting methods for specific types are implemented as methods with a name
based on the type name.  In the method name, TYPE is replaced by
'_'.join(type(obj).__name__.split()). Dispatch to these methods is
handled by repr1(). Type-specific methods which need to recursively
format a value should call self.repr1(subobj, level - 1)."
enum.unique(),Enum class decorator that ensures only one name is bound to any one value.
@enum.uniqu,
abstractmethod conjugate(),"Abstract. Returns the complex conjugate. For example, (1+3j).conjugate()
== (1-3j)."
math.ceil(x),"Return the ceiling of x, the smallest integer greater than or equal to x.
If x is not a float, delegates to x.__ceil__(), which should return an
Integral value."
"math.comb(n, k)","Return the number of ways to choose k items from n items without repetition
and without order.
Evaluates to n! / (k! * (n - k)!) when k <= n and evaluates
to zero when k > n.
Also called the binomial coefficient because it is equivalent
to the coefficient of k-th term in polynomial expansion of the
expression (1 + x) ** n.
Raises TypeError if either of the arguments are not integers.
Raises ValueError if either of the arguments are negative.

New in version 3.8."
"math.copysign(x, y)","Return a float with the magnitude (absolute value) of x but the sign of
y.  On platforms that support signed zeros, copysign(1.0, -0.0)
returns -1.0."
math.fabs(x),Return the absolute value of x.
math.factorial(x),"Return x factorial as an integer.  Raises ValueError if x is not integral or
is negative."
math.floor(x),"Return the floor of x, the largest integer less than or equal to x.
If x is not a float, delegates to x.__floor__(), which should return an
Integral value."
"math.fmod(x, y)","Return fmod(x, y), as defined by the platform C library. Note that the
Python expression x % y may not return the same result.  The intent of the C
standard is that fmod(x, y) be exactly (mathematically; to infinite
precision) equal to x - n*y for some integer n such that the result has
the same sign as x and magnitude less than abs(y).  Python’s x % y
returns a result with the sign of y instead, and may not be exactly computable
for float arguments. For example, fmod(-1e-100, 1e100) is -1e-100, but
the result of Python’s -1e-100 % 1e100 is 1e100-1e-100, which cannot be
represented exactly as a float, and rounds to the surprising 1e100.  For
this reason, function fmod() is generally preferred when working with
floats, while Python’s x % y is preferred when working with integers."
math.frexp(x),"Return the mantissa and exponent of x as the pair (m, e).  m is a float
and e is an integer such that x == m * 2**e exactly. If x is zero,
returns (0.0, 0), otherwise 0.5 <= abs(m) < 1.  This is used to “pick
apart” the internal representation of a float in a portable way."
math.fsum(iterable),"Return an accurate floating point sum of values in the iterable.  Avoids
loss of precision by tracking multiple intermediate partial sums:
>>> sum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])
0.9999999999999999
>>> fsum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])
1.0


The algorithm’s accuracy depends on IEEE-754 arithmetic guarantees and the
typical case where the rounding mode is half-even.  On some non-Windows
builds, the underlying C library uses extended precision addition and may
occasionally double-round an intermediate sum causing it to be off in its
least significant bit.
For further discussion and two alternative approaches, see the ASPN cookbook
recipes for accurate floating point summation."
"math.gcd(a, b)","Return the greatest common divisor of the integers a and b.  If either
a or b is nonzero, then the value of gcd(a, b) is the largest
positive integer that divides both a and b.  gcd(0, 0) returns
0.

New in version 3.5."
"math.isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0)","Return True if the values a and b are close to each other and
False otherwise.
Whether or not two values are considered close is determined according to
given absolute and relative tolerances.
rel_tol is the relative tolerance – it is the maximum allowed difference
between a and b, relative to the larger absolute value of a or b.
For example, to set a tolerance of 5%, pass rel_tol=0.05.  The default
tolerance is 1e-09, which assures that the two values are the same
within about 9 decimal digits.  rel_tol must be greater than zero.
abs_tol is the minimum absolute tolerance – useful for comparisons near
zero. abs_tol must be at least zero.
If no errors occur, the result will be:
abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol).
The IEEE 754 special values of NaN, inf, and -inf will be
handled according to IEEE rules.  Specifically, NaN is not considered
close to any other value, including NaN.  inf and -inf are only
considered close to themselves.

New in version 3.5.


See also
PEP 485 – A function for testing approximate equality"
math.isfinite(x),"Return True if x is neither an infinity nor a NaN, and
False otherwise.  (Note that 0.0 is considered finite.)

New in version 3.2."
math.isinf(x),"Return True if x is a positive or negative infinity, and
False otherwise."
math.isnan(x),"Return True if x is a NaN (not a number), and False otherwise."
"math.ldexp(x, i)","Return x * (2**i).  This is essentially the inverse of function
frexp()."
math.modf(x),"Return the fractional and integer parts of x.  Both results carry the sign
of x and are floats."
"math.perm(n, k=None)","Return the number of ways to choose k items from n items
without repetition and with order.
Evaluates to n! / (n - k)! when k <= n and evaluates
to zero when k > n.
If k is not specified or is None, then k defaults to n
and the function returns n!.
Raises TypeError if either of the arguments are not integers.
Raises ValueError if either of the arguments are negative.

New in version 3.8."
"math.prod(iterable, *, start=1)","Calculate the product of all the elements in the input iterable.
The default start value for the product is 1.
When the iterable is empty, return the start value.  This function is
intended specifically for use with numeric values and may reject
non-numeric types.

New in version 3.8."
"math.remainder(x, y)","Return the IEEE 754-style remainder of x with respect to y.  For
finite x and finite nonzero y, this is the difference x - n*y,
where n is the closest integer to the exact value of the quotient x /
y.  If x / y is exactly halfway between two consecutive integers, the
nearest even integer is used for n.  The remainder r = remainder(x,
y) thus always satisfies abs(r) <= 0.5 * abs(y).
Special cases follow IEEE 754: in particular, remainder(x, math.inf) is
x for any finite x, and remainder(x, 0) and
remainder(math.inf, x) raise ValueError for any non-NaN x.
If the result of the remainder operation is zero, that zero will have
the same sign as x.
On platforms using IEEE 754 binary floating-point, the result of this
operation is always exactly representable: no rounding error is introduced.

New in version 3.7."
math.trunc(x),"Return the Real value x truncated to an
Integral (usually an integer). Delegates to
x.__trunc__()."
math.exp(x),"Return e raised to the power x, where e = 2.718281… is the base
of natural logarithms.  This is usually more accurate than math.e ** x
or pow(math.e, x)."
math.expm1(x),"Return e raised to the power x, minus 1.  Here e is the base of natural
logarithms.  For small floats x, the subtraction in exp(x) - 1
can result in a significant loss of precision; the expm1()
function provides a way to compute this quantity to full precision:
>>> from math import exp, expm1
>>> exp(1e-5) - 1  # gives result accurate to 11 places
1.0000050000069649e-05
>>> expm1(1e-5)    # result accurate to full precision
1.0000050000166668e-05



New in version 3.2."
"math.log(x[, base])","With one argument, return the natural logarithm of x (to base e).
With two arguments, return the logarithm of x to the given base,
calculated as log(x)/log(base)."
math.log1p(x),"Return the natural logarithm of 1+x (base e). The
result is calculated in a way which is accurate for x near zero."
math.log2(x),"Return the base-2 logarithm of x. This is usually more accurate than
log(x, 2).

New in version 3.3.


See also
int.bit_length() returns the number of bits necessary to represent
an integer in binary, excluding the sign and leading zeros."
math.log10(x),"Return the base-10 logarithm of x.  This is usually more accurate
than log(x, 10)."
"math.pow(x, y)","Return x raised to the power y.  Exceptional cases follow
Annex ‘F’ of the C99 standard as far as possible.  In particular,
pow(1.0, x) and pow(x, 0.0) always return 1.0, even
when x is a zero or a NaN.  If both x and y are finite,
x is negative, and y is not an integer then pow(x, y)
is undefined, and raises ValueError.
Unlike the built-in ** operator, math.pow() converts both
its arguments to type float.  Use ** or the built-in
pow() function for computing exact integer powers."
math.sqrt(x),Return the square root of x.
math.acos(x),"Return the arc cosine of x, in radians."
math.asin(x),"Return the arc sine of x, in radians."
math.atan(x),"Return the arc tangent of x, in radians."
"math.atan2(y, x)","Return atan(y / x), in radians. The result is between -pi and pi.
The vector in the plane from the origin to point (x, y) makes this angle
with the positive X axis. The point of atan2() is that the signs of both
inputs are known to it, so it can compute the correct quadrant for the angle.
For example, atan(1) and atan2(1, 1) are both pi/4, but atan2(-1,
-1) is -3*pi/4."
math.cos(x),Return the cosine of x radians.
"math.dist(p, q)","Return the Euclidean distance between two points p and q, each
given as a sequence (or iterable) of coordinates.  The two points
must have the same dimension.
Roughly equivalent to:
sqrt(sum((px - qx) ** 2.0 for px, qx in zip(p, q)))



New in version 3.8."
math.hypot(*coordinates),"Return the Euclidean norm, sqrt(sum(x**2 for x in coordinates)).
This is the length of the vector from the origin to the point
given by the coordinates.
For a two dimensional point (x, y), this is equivalent to computing
the hypotenuse of a right triangle using the Pythagorean theorem,
sqrt(x*x + y*y).

Changed in version 3.8: Added support for n-dimensional points. Formerly, only the two
dimensional case was supported."
math.sin(x),Return the sine of x radians.
math.tan(x),Return the tangent of x radians.
math.degrees(x),Convert angle x from radians to degrees.
math.radians(x),Convert angle x from degrees to radians.
math.acosh(x),Return the inverse hyperbolic cosine of x.
math.asinh(x),Return the inverse hyperbolic sine of x.
math.atanh(x),Return the inverse hyperbolic tangent of x.
math.cosh(x),Return the hyperbolic cosine of x.
math.sinh(x),Return the hyperbolic sine of x.
math.tanh(x),Return the hyperbolic tangent of x.
math.erf(x),"Return the error function at
x.
The erf() function can be used to compute traditional statistical
functions such as the cumulative standard normal distribution:
def phi(x):
    'Cumulative distribution function for the standard normal distribution'
    return (1.0 + erf(x / sqrt(2.0))) / 2.0



New in version 3.2."
math.erfc(x),"Return the complementary error function at x.  The complementary error
function is defined as
1.0 - erf(x).  It is used for large values of x where a subtraction
from one would cause a loss of significance.

New in version 3.2."
math.gamma(x),"Return the Gamma function at
x.

New in version 3.2."
math.lgamma(x),"Return the natural logarithm of the absolute value of the Gamma
function at x.

New in version 3.2."
cmath.polar(x),"Return the representation of x in polar coordinates.  Returns a
pair (r, phi) where r is the modulus of x and phi is the
phase of x.  polar(x) is equivalent to (abs(x),
phase(x))."
"cmath.rect(r, phi)","Return the complex number x with polar coordinates r and phi.
Equivalent to r * (math.cos(phi) + math.sin(phi)*1j)."
cmath.exp(x),"Return e raised to the power x, where e is the base of natural
logarithms."
cmath.log10(x),"Return the base-10 logarithm of x. This has the same branch cut as
log()."
cmath.sqrt(x),Return the square root of x. This has the same branch cut as log().
cmath.asin(x),Return the arc sine of x. This has the same branch cuts as acos().
cmath.cos(x),Return the cosine of x.
cmath.sin(x),Return the sine of x.
cmath.tan(x),Return the tangent of x.
cmath.cosh(x),Return the hyperbolic cosine of x.
cmath.sinh(x),Return the hyperbolic sine of x.
cmath.tanh(x),Return the hyperbolic tangent of x.
cmath.isfinite(x),"Return True if both the real and imaginary parts of x are finite, and
False otherwise.

New in version 3.2."
cmath.isinf(x),"Return True if either the real or the imaginary part of x is an
infinity, and False otherwise."
cmath.isnan(x),"Return True if either the real or the imaginary part of x is a NaN,
and False otherwise."
"cmath.isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0)","Return True if the values a and b are close to each other and
False otherwise.
Whether or not two values are considered close is determined according to
given absolute and relative tolerances.
rel_tol is the relative tolerance – it is the maximum allowed difference
between a and b, relative to the larger absolute value of a or b.
For example, to set a tolerance of 5%, pass rel_tol=0.05.  The default
tolerance is 1e-09, which assures that the two values are the same
within about 9 decimal digits.  rel_tol must be greater than zero.
abs_tol is the minimum absolute tolerance – useful for comparisons near
zero. abs_tol must be at least zero.
If no errors occur, the result will be:
abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol).
The IEEE 754 special values of NaN, inf, and -inf will be
handled according to IEEE rules.  Specifically, NaN is not considered
close to any other value, including NaN.  inf and -inf are only
considered close to themselves.

New in version 3.5.


See also
PEP 485 – A function for testing approximate equality"
decimal.getcontext(),Return the current context for the active thread.
decimal.setcontext(c),Set the current context for the active thread to c.
decimal.localcontext(ctx=None),"Return a context manager that will set the current context for the active thread
to a copy of ctx on entry to the with-statement and restore the previous context
when exiting the with-statement. If no context is specified, a copy of the
current context is used.
For example, the following code sets the current decimal precision to 42 places,
performs a calculation, and then automatically restores the previous context:
from decimal import localcontext

with localcontext() as ctx:
    ctx.prec = 42   # Perform a high precision calculation
    s = calculate_something()
s = +s  # Round the final result back to the default precision"
adjusted(),"Return the adjusted exponent after shifting out the coefficient’s
rightmost digits until only the lead digit remains:
Decimal('321e+5').adjusted() returns seven.  Used for determining the
position of the most significant digit with respect to the decimal point."
as_integer_ratio(),"Return a pair (n, d) of integers that represent the given
Decimal instance as a fraction, in lowest terms and
with a positive denominator:
>>> Decimal('-3.14').as_integer_ratio()
(-157, 50)


The conversion is exact.  Raise OverflowError on infinities and ValueError
on NaNs."
as_tuple(),"Return a named tuple representation of the number:
DecimalTuple(sign, digits, exponent)."
canonical(),"Return the canonical encoding of the argument.  Currently, the encoding of
a Decimal instance is always canonical, so this operation returns
its argument unchanged."
"compare(other, context=None)","Compare the values of two Decimal instances.  compare() returns a
Decimal instance, and if either operand is a NaN then the result is a
NaN:
a or b is a NaN  ==> Decimal('NaN')
a < b            ==> Decimal('-1')
a == b           ==> Decimal('0')
a > b            ==> Decimal('1')"
"compare_signal(other, context=None)","This operation is identical to the compare() method, except that all
NaNs signal.  That is, if neither operand is a signaling NaN then any
quiet NaN operand is treated as though it were a signaling NaN."
"compare_total(other, context=None)","Compare two operands using their abstract representation rather than their
numerical value.  Similar to the compare() method, but the result
gives a total ordering on Decimal instances.  Two
Decimal instances with the same numeric value but different
representations compare unequal in this ordering:
>>> Decimal('12.0').compare_total(Decimal('12'))
Decimal('-1')


Quiet and signaling NaNs are also included in the total ordering.  The
result of this function is Decimal('0') if both operands have the same
representation, Decimal('-1') if the first operand is lower in the
total order than the second, and Decimal('1') if the first operand is
higher in the total order than the second operand.  See the specification
for details of the total order.
This operation is unaffected by context and is quiet: no flags are changed
and no rounding is performed.  As an exception, the C version may raise
InvalidOperation if the second operand cannot be converted exactly."
"compare_total_mag(other, context=None)","Compare two operands using their abstract representation rather than their
value as in compare_total(), but ignoring the sign of each operand.
x.compare_total_mag(y) is equivalent to
x.copy_abs().compare_total(y.copy_abs()).
This operation is unaffected by context and is quiet: no flags are changed
and no rounding is performed.  As an exception, the C version may raise
InvalidOperation if the second operand cannot be converted exactly."
conjugate(),"Just returns self, this method is only to comply with the Decimal
Specification."
copy_abs(),"Return the absolute value of the argument.  This operation is unaffected
by the context and is quiet: no flags are changed and no rounding is
performed."
copy_negate(),"Return the negation of the argument.  This operation is unaffected by the
context and is quiet: no flags are changed and no rounding is performed."
"copy_sign(other, context=None)","Return a copy of the first operand with the sign set to be the same as the
sign of the second operand.  For example:
>>> Decimal('2.3').copy_sign(Decimal('-1.5'))
Decimal('-2.3')


This operation is unaffected by context and is quiet: no flags are changed
and no rounding is performed.  As an exception, the C version may raise
InvalidOperation if the second operand cannot be converted exactly."
exp(context=None),"Return the value of the (natural) exponential function e**x at the
given number.  The result is correctly rounded using the
ROUND_HALF_EVEN rounding mode.
>>> Decimal(1).exp()
Decimal('2.718281828459045235360287471')
>>> Decimal(321).exp()
Decimal('2.561702493119680037517373933E+139')"
from_float(f),"Classmethod that converts a float to a decimal number, exactly.
Note Decimal.from_float(0.1) is not the same as Decimal(‘0.1’).
Since 0.1 is not exactly representable in binary floating point, the
value is stored as the nearest representable value which is
0x1.999999999999ap-4.  That equivalent value in decimal is
0.1000000000000000055511151231257827021181583404541015625.

Note
From Python 3.2 onwards, a Decimal instance
can also be constructed directly from a float.

>>> Decimal.from_float(0.1)
Decimal('0.1000000000000000055511151231257827021181583404541015625')
>>> Decimal.from_float(float('nan'))
Decimal('NaN')
>>> Decimal.from_float(float('inf'))
Decimal('Infinity')
>>> Decimal.from_float(float('-inf'))
Decimal('-Infinity')



New in version 3.1."
"fma(other, third, context=None)","Fused multiply-add.  Return self*other+third with no rounding of the
intermediate product self*other.
>>> Decimal(2).fma(3, 5)
Decimal('11')"
is_canonical(),"Return True if the argument is canonical and False
otherwise.  Currently, a Decimal instance is always canonical, so
this operation always returns True."
is_finite(),"Return True if the argument is a finite number, and
False if the argument is an infinity or a NaN."
is_infinite(),"Return True if the argument is either positive or negative
infinity and False otherwise."
is_nan(),"Return True if the argument is a (quiet or signaling) NaN and
False otherwise."
is_normal(context=None),"Return True if the argument is a normal finite number.  Return
False if the argument is zero, subnormal, infinite or a NaN."
is_qnan(),"Return True if the argument is a quiet NaN, and
False otherwise."
is_signed(),"Return True if the argument has a negative sign and
False otherwise.  Note that zeros and NaNs can both carry signs."
is_snan(),"Return True if the argument is a signaling NaN and False
otherwise."
is_subnormal(context=None),"Return True if the argument is subnormal, and False
otherwise."
is_zero(),"Return True if the argument is a (positive or negative) zero and
False otherwise."
ln(context=None),"Return the natural (base e) logarithm of the operand.  The result is
correctly rounded using the ROUND_HALF_EVEN rounding mode."
log10(context=None),"Return the base ten logarithm of the operand.  The result is correctly
rounded using the ROUND_HALF_EVEN rounding mode."
logb(context=None),"For a nonzero number, return the adjusted exponent of its operand as a
Decimal instance.  If the operand is a zero then
Decimal('-Infinity') is returned and the DivisionByZero flag
is raised.  If the operand is an infinity then Decimal('Infinity') is
returned."
"logical_and(other, context=None)","logical_and() is a logical operation which takes two logical
operands (see Logical operands).  The result is the
digit-wise and of the two operands."
logical_invert(context=None),"logical_invert() is a logical operation.  The
result is the digit-wise inversion of the operand."
"logical_or(other, context=None)","logical_or() is a logical operation which takes two logical
operands (see Logical operands).  The result is the
digit-wise or of the two operands."
"logical_xor(other, context=None)","logical_xor() is a logical operation which takes two logical
operands (see Logical operands).  The result is the
digit-wise exclusive or of the two operands."
"max(other, context=None)","Like max(self, other) except that the context rounding rule is applied
before returning and that NaN values are either signaled or
ignored (depending on the context and whether they are signaling or
quiet)."
"max_mag(other, context=None)","Similar to the max() method, but the comparison is done using the
absolute values of the operands."
"min(other, context=None)","Like min(self, other) except that the context rounding rule is applied
before returning and that NaN values are either signaled or
ignored (depending on the context and whether they are signaling or
quiet)."
"min_mag(other, context=None)","Similar to the min() method, but the comparison is done using the
absolute values of the operands."
next_minus(context=None),"Return the largest number representable in the given context (or in the
current thread’s context if no context is given) that is smaller than the
given operand."
next_plus(context=None),"Return the smallest number representable in the given context (or in the
current thread’s context if no context is given) that is larger than the
given operand."
"next_toward(other, context=None)","If the two operands are unequal, return the number closest to the first
operand in the direction of the second operand.  If both operands are
numerically equal, return a copy of the first operand with the sign set to
be the same as the sign of the second operand."
normalize(context=None),"Normalize the number by stripping the rightmost trailing zeros and
converting any result equal to Decimal('0') to
Decimal('0e0'). Used for producing canonical values for attributes
of an equivalence class. For example, Decimal('32.100') and
Decimal('0.321000e+2') both normalize to the equivalent value
Decimal('32.1')."
number_class(context=None),"Return a string describing the class of the operand.  The returned value
is one of the following ten strings.

""-Infinity"", indicating that the operand is negative infinity.
""-Normal"", indicating that the operand is a negative normal number.
""-Subnormal"", indicating that the operand is negative and subnormal.
""-Zero"", indicating that the operand is a negative zero.
""+Zero"", indicating that the operand is a positive zero.
""+Subnormal"", indicating that the operand is positive and subnormal.
""+Normal"", indicating that the operand is a positive normal number.
""+Infinity"", indicating that the operand is positive infinity.
""NaN"", indicating that the operand is a quiet NaN (Not a Number).
""sNaN"", indicating that the operand is a signaling NaN."
"quantize(exp, rounding=None, context=None)","Return a value equal to the first operand after rounding and having the
exponent of the second operand.
>>> Decimal('1.41421356').quantize(Decimal('1.000'))
Decimal('1.414')


Unlike other operations, if the length of the coefficient after the
quantize operation would be greater than precision, then an
InvalidOperation is signaled. This guarantees that, unless there
is an error condition, the quantized exponent is always equal to that of
the right-hand operand.
Also unlike other operations, quantize never signals Underflow, even if
the result is subnormal and inexact.
If the exponent of the second operand is larger than that of the first
then rounding may be necessary.  In this case, the rounding mode is
determined by the rounding argument if given, else by the given
context argument; if neither argument is given the rounding mode of
the current thread’s context is used.
An error is returned whenever the resulting exponent is greater than
Emax or less than Etiny."
radix(),"Return Decimal(10), the radix (base) in which the Decimal
class does all its arithmetic.  Included for compatibility with the
specification."
"remainder_near(other, context=None)","Return the remainder from dividing self by other.  This differs from
self % other in that the sign of the remainder is chosen so as to
minimize its absolute value.  More precisely, the return value is
self - n * other where n is the integer nearest to the exact
value of self / other, and if two integers are equally near then the
even one is chosen.
If the result is zero then its sign will be the sign of self.
>>> Decimal(18).remainder_near(Decimal(10))
Decimal('-2')
>>> Decimal(25).remainder_near(Decimal(10))
Decimal('5')
>>> Decimal(35).remainder_near(Decimal(10))
Decimal('-5')"
"rotate(other, context=None)","Return the result of rotating the digits of the first operand by an amount
specified by the second operand.  The second operand must be an integer in
the range -precision through precision.  The absolute value of the second
operand gives the number of places to rotate.  If the second operand is
positive then rotation is to the left; otherwise rotation is to the right.
The coefficient of the first operand is padded on the left with zeros to
length precision if necessary.  The sign and exponent of the first operand
are unchanged."
"same_quantum(other, context=None)","Test whether self and other have the same exponent or whether both are
NaN.
This operation is unaffected by context and is quiet: no flags are changed
and no rounding is performed.  As an exception, the C version may raise
InvalidOperation if the second operand cannot be converted exactly."
"scaleb(other, context=None)","Return the first operand with exponent adjusted by the second.
Equivalently, return the first operand multiplied by 10**other.  The
second operand must be an integer."
"shift(other, context=None)","Return the result of shifting the digits of the first operand by an amount
specified by the second operand.  The second operand must be an integer in
the range -precision through precision.  The absolute value of the second
operand gives the number of places to shift.  If the second operand is
positive then the shift is to the left; otherwise the shift is to the
right.  Digits shifted into the coefficient are zeros.  The sign and
exponent of the first operand are unchanged."
sqrt(context=None),Return the square root of the argument to full precision.
to_eng_string(context=None),"Convert to a string, using engineering notation if an exponent is needed.
Engineering notation has an exponent which is a multiple of 3.  This
can leave up to 3 digits to the left of the decimal place and may
require the addition of either one or two trailing zeros.
For example, this converts Decimal('123E+1') to Decimal('1.23E+3')."
"to_integral(rounding=None, context=None)","Identical to the to_integral_value() method.  The to_integral
name has been kept for compatibility with older versions."
"to_integral_exact(rounding=None, context=None)","Round to the nearest integer, signaling Inexact or
Rounded as appropriate if rounding occurs.  The rounding mode is
determined by the rounding parameter if given, else by the given
context.  If neither parameter is given then the rounding mode of the
current context is used."
"to_integral_value(rounding=None, context=None)","Round to the nearest integer without signaling Inexact or
Rounded.  If given, applies rounding; otherwise, uses the
rounding method in either the supplied context or the current context."
clear_flags(),Resets all of the flags to 0.
clear_traps(),"Resets all of the traps to 0.

New in version 3.3."
copy(),Return a duplicate of the context.
copy_decimal(num),Return a copy of the Decimal instance num.
create_decimal(num),"Creates a new Decimal instance from num but using self as
context. Unlike the Decimal constructor, the context precision,
rounding method, flags, and traps are applied to the conversion.
This is useful because constants are often given to a greater precision
than is needed by the application.  Another benefit is that rounding
immediately eliminates unintended effects from digits beyond the current
precision. In the following example, using unrounded inputs means that
adding zero to a sum can change the result:
>>> getcontext().prec = 3
>>> Decimal('3.4445') + Decimal('1.0023')
Decimal('4.45')
>>> Decimal('3.4445') + Decimal(0) + Decimal('1.0023')
Decimal('4.44')


This method implements the to-number operation of the IBM specification.
If the argument is a string, no leading or trailing whitespace or
underscores are permitted."
create_decimal_from_float(f),"Creates a new Decimal instance from a float f but rounding using self
as the context.  Unlike the Decimal.from_float() class method,
the context precision, rounding method, flags, and traps are applied to
the conversion.
>>> context = Context(prec=5, rounding=ROUND_DOWN)
>>> context.create_decimal_from_float(math.pi)
Decimal('3.1415')
>>> context = Context(prec=5, traps=[Inexact])
>>> context.create_decimal_from_float(math.pi)
Traceback (most recent call last):
    ...
decimal.Inexact: None



New in version 3.1."
Etiny(),"Returns a value equal to Emin - prec + 1 which is the minimum exponent
value for subnormal results.  When underflow occurs, the exponent is set
to Etiny."
Etop(),Returns a value equal to Emax - prec + 1.
abs(x),Returns the absolute value of x.
"add(x, y)",Return the sum of x and y.
canonical(x),Returns the same Decimal object x.
"compare(x, y)",Compares x and y numerically.
"compare_signal(x, y)",Compares the values of the two operands numerically.
"compare_total(x, y)",Compares two operands using their abstract representation.
"compare_total_mag(x, y)","Compares two operands using their abstract representation, ignoring sign."
copy_abs(x),Returns a copy of x with the sign set to 0.
copy_negate(x),Returns a copy of x with the sign inverted.
"copy_sign(x, y)",Copies the sign from y to x.
"divide(x, y)",Return x divided by y.
"divide_int(x, y)","Return x divided by y, truncated to an integer."
"divmod(x, y)",Divides two numbers and returns the integer part of the result.
exp(x),Returns e ** x.
"fma(x, y, z)","Returns x multiplied by y, plus z."
is_canonical(x),Returns True if x is canonical; otherwise returns False.
is_finite(x),Returns True if x is finite; otherwise returns False.
is_infinite(x),Returns True if x is infinite; otherwise returns False.
is_nan(x),Returns True if x is a qNaN or sNaN; otherwise returns False.
is_normal(x),Returns True if x is a normal number; otherwise returns False.
is_qnan(x),Returns True if x is a quiet NaN; otherwise returns False.
is_signed(x),Returns True if x is negative; otherwise returns False.
is_snan(x),Returns True if x is a signaling NaN; otherwise returns False.
is_subnormal(x),Returns True if x is subnormal; otherwise returns False.
is_zero(x),Returns True if x is a zero; otherwise returns False.
ln(x),Returns the natural (base e) logarithm of x.
log10(x),Returns the base 10 logarithm of x.
logb(x),Returns the exponent of the magnitude of the operand’s MSD.
"logical_and(x, y)",Applies the logical operation and between each operand’s digits.
logical_invert(x),Invert all the digits in x.
"logical_or(x, y)",Applies the logical operation or between each operand’s digits.
"logical_xor(x, y)",Applies the logical operation xor between each operand’s digits.
"max(x, y)",Compares two values numerically and returns the maximum.
"max_mag(x, y)",Compares the values numerically with their sign ignored.
"min(x, y)",Compares two values numerically and returns the minimum.
"min_mag(x, y)",Compares the values numerically with their sign ignored.
minus(x),Minus corresponds to the unary prefix minus operator in Python.
"multiply(x, y)",Return the product of x and y.
next_minus(x),Returns the largest representable number smaller than x.
next_plus(x),Returns the smallest representable number larger than x.
"next_toward(x, y)","Returns the number closest to x, in direction towards y."
normalize(x),Reduces x to its simplest form.
number_class(x),Returns an indication of the class of x.
plus(x),"Plus corresponds to the unary prefix plus operator in Python.  This
operation applies the context precision and rounding, so it is not an
identity operation."
"power(x, y, modulo=None)","Return x to the power of y, reduced modulo modulo if given.
With two arguments, compute x**y.  If x is negative then y
must be integral.  The result will be inexact unless y is integral and
the result is finite and can be expressed exactly in ‘precision’ digits.
The rounding mode of the context is used. Results are always correctly-rounded
in the Python version.

Changed in version 3.3: The C module computes power() in terms of the correctly-rounded
exp() and ln() functions. The result is well-defined but
only “almost always correctly-rounded”.

With three arguments, compute (x**y) % modulo.  For the three argument
form, the following restrictions on the arguments hold:


all three arguments must be integral
y must be nonnegative
at least one of x or y must be nonzero
modulo must be nonzero and have at most ‘precision’ digits


The value resulting from Context.power(x, y, modulo) is
equal to the value that would be obtained by computing (x**y)
% modulo with unbounded precision, but is computed more
efficiently.  The exponent of the result is zero, regardless of
the exponents of x, y and modulo.  The result is
always exact."
"quantize(x, y)","Returns a value equal to x (rounded), having the exponent of y."
radix(),"Just returns 10, as this is Decimal, :)"
"remainder(x, y)","Returns the remainder from integer division.
The sign of the result, if non-zero, is the same as that of the original
dividend."
"remainder_near(x, y)","Returns x - y * n, where n is the integer nearest the exact value
of x / y (if the result is 0 then its sign will be the sign of x)."
"rotate(x, y)","Returns a rotated copy of x, y times."
"same_quantum(x, y)",Returns True if the two operands have the same exponent.
"scaleb(x, y)",Returns the first operand after adding the second value its exp.
"shift(x, y)","Returns a shifted copy of x, y times."
sqrt(x),Square root of a non-negative number to context precision.
"subtract(x, y)",Return the difference between x and y.
to_eng_string(x),"Convert to a string, using engineering notation if an exponent is needed.
Engineering notation has an exponent which is a multiple of 3.  This
can leave up to 3 digits to the left of the decimal place and may
require the addition of either one or two trailing zeros."
to_integral_exact(x),Rounds to an integer.
to_sci_string(x),Converts a number to a string using scientific notation.
"fractions.gcd(a, b)","Return the greatest common divisor of the integers a and b.  If either
a or b is nonzero, then the absolute value of gcd(a, b) is the
largest integer that divides both a and b.  gcd(a,b) has the same
sign as b if b is nonzero; otherwise it takes the sign of a.  gcd(0,
0) returns 0.

Deprecated since version 3.5: Use math.gcd() instead."
as_integer_ratio(),"Return a tuple of two integers, whose ratio is equal
to the Fraction and with a positive denominator.

New in version 3.8."
from_float(flt),"This class method constructs a Fraction representing the exact
value of flt, which must be a float. Beware that
Fraction.from_float(0.3) is not the same value as Fraction(3, 10).

Note
From Python 3.2 onwards, you can also construct a
Fraction instance directly from a float."
from_decimal(dec),"This class method constructs a Fraction representing the exact
value of dec, which must be a decimal.Decimal instance.

Note
From Python 3.2 onwards, you can also construct a
Fraction instance directly from a decimal.Decimal
instance."
limit_denominator(max_denominator=1000000),"Finds and returns the closest Fraction to self that has
denominator at most max_denominator.  This method is useful for finding
rational approximations to a given floating-point number:
>>> from fractions import Fraction
>>> Fraction('3.1415926535897932').limit_denominator(1000)
Fraction(355, 113)


or for recovering a rational number that’s represented as a float:
>>> from math import pi, cos
>>> Fraction(cos(pi/3))
Fraction(4503599627370497, 9007199254740992)
>>> Fraction(cos(pi/3)).limit_denominator()
Fraction(1, 2)
>>> Fraction(1.1).limit_denominator()
Fraction(11, 10)"
__floor__(),"Returns the greatest int <= self.  This method can
also be accessed through the math.floor() function:
>>> from math import floor
>>> floor(Fraction(355, 113))
3"
__ceil__(),"Returns the least int >= self.  This method can
also be accessed through the math.ceil() function."
__round__(),"The first version returns the nearest int to self,
rounding half to even. The second version rounds self to the
nearest multiple of Fraction(1, 10**ndigits) (logically, if
ndigits is negative), again rounding half toward even.  This
method can also be accessed through the round() function."
"random.seed(a=None, version=2)","Initialize the random number generator.
If a is omitted or None, the current system time is used.  If
randomness sources are provided by the operating system, they are used
instead of the system time (see the os.urandom() function for details
on availability).
If a is an int, it is used directly.
With version 2 (the default), a str, bytes, or bytearray
object gets converted to an int and all of its bits are used.
With version 1 (provided for reproducing random sequences from older versions
of Python), the algorithm for str and bytes generates a
narrower range of seeds.

Changed in version 3.2: Moved to the version 2 scheme which uses all of the bits in a string seed."
random.getstate(),"Return an object capturing the current internal state of the generator.  This
object can be passed to setstate() to restore the state."
random.setstate(state),"state should have been obtained from a previous call to getstate(), and
setstate() restores the internal state of the generator to what it was at
the time getstate() was called."
random.getrandbits(k),"Returns a Python integer with k random bits. This method is supplied with
the MersenneTwister generator and some other generators may also provide it
as an optional part of the API. When available, getrandbits() enables
randrange() to handle arbitrarily large ranges."
random.randrange(stop),"Return a randomly selected element from range(start, stop, step).  This is
equivalent to choice(range(start, stop, step)), but doesn’t actually build a
range object.
The positional argument pattern matches that of range().  Keyword arguments
should not be used because the function may use them in unexpected ways.

Changed in version 3.2: randrange() is more sophisticated about producing equally distributed
values.  Formerly it used a style like int(random()*n) which could produce
slightly uneven distributions."
"random.randint(a, b)","Return a random integer N such that a <= N <= b.  Alias for
randrange(a, b+1)."
random.choice(seq),"Return a random element from the non-empty sequence seq. If seq is empty,
raises IndexError."
"random.choices(population, weights=None, *, cum_weights=None, k=1)","Return a k sized list of elements chosen from the population with replacement.
If the population is empty, raises IndexError.
If a weights sequence is specified, selections are made according to the
relative weights.  Alternatively, if a cum_weights sequence is given, the
selections are made according to the cumulative weights (perhaps computed
using itertools.accumulate()).  For example, the relative weights
[10, 5, 30, 5] are equivalent to the cumulative weights
[10, 15, 45, 50].  Internally, the relative weights are converted to
cumulative weights before making selections, so supplying the cumulative
weights saves work.
If neither weights nor cum_weights are specified, selections are made
with equal probability.  If a weights sequence is supplied, it must be
the same length as the population sequence.  It is a TypeError
to specify both weights and cum_weights.
The weights or cum_weights can use any numeric type that interoperates
with the float values returned by random() (that includes
integers, floats, and fractions but excludes decimals).  Weights are
assumed to be non-negative.
For a given seed, the choices() function with equal weighting
typically produces a different sequence than repeated calls to
choice().  The algorithm used by choices() uses floating
point arithmetic for internal consistency and speed.  The algorithm used
by choice() defaults to integer arithmetic with repeated selections
to avoid small biases from round-off error.

New in version 3.6."
"random.shuffle(x[, random])","Shuffle the sequence x in place.
The optional argument random is a 0-argument function returning a random
float in [0.0, 1.0); by default, this is the function random().
To shuffle an immutable sequence and return a new shuffled list, use
sample(x, k=len(x)) instead.
Note that even for small len(x), the total number of permutations of x
can quickly grow larger than the period of most random number generators.
This implies that most permutations of a long sequence can never be
generated.  For example, a sequence of length 2080 is the largest that
can fit within the period of the Mersenne Twister random number generator."
"random.sample(population, k)","Return a k length list of unique elements chosen from the population sequence
or set. Used for random sampling without replacement.
Returns a new list containing elements from the population while leaving the
original population unchanged.  The resulting list is in selection order so that
all sub-slices will also be valid random samples.  This allows raffle winners
(the sample) to be partitioned into grand prize and second place winners (the
subslices).
Members of the population need not be hashable or unique.  If the population
contains repeats, then each occurrence is a possible selection in the sample.
To choose a sample from a range of integers, use a range() object as an
argument.  This is especially fast and space efficient for sampling from a large
population:  sample(range(10000000), k=60).
If the sample size is larger than the population size, a ValueError
is raised."
random.random(),"Return the next random floating point number in the range [0.0, 1.0)."
"random.uniform(a, b)","Return a random floating point number N such that a <= N <= b for
a <= b and b <= N <= a for b < a.
The end-point value b may or may not be included in the range
depending on floating-point rounding in the equation a + (b-a) * random()."
"random.triangular(low, high, mode)","Return a random floating point number N such that low <= N <= high and
with the specified mode between those bounds.  The low and high bounds
default to zero and one.  The mode argument defaults to the midpoint
between the bounds, giving a symmetric distribution."
"random.betavariate(alpha, beta)","Beta distribution.  Conditions on the parameters are alpha > 0 and
beta > 0. Returned values range between 0 and 1."
random.expovariate(lambd),"Exponential distribution.  lambd is 1.0 divided by the desired
mean.  It should be nonzero.  (The parameter would be called
“lambda”, but that is a reserved word in Python.)  Returned values
range from 0 to positive infinity if lambd is positive, and from
negative infinity to 0 if lambd is negative."
"random.gammavariate(alpha, beta)","Gamma distribution.  (Not the gamma function!)  Conditions on the
parameters are alpha > 0 and beta > 0.
The probability distribution function is:
          x ** (alpha - 1) * math.exp(-x / beta)
pdf(x) =  --------------------------------------
            math.gamma(alpha) * beta ** alpha"
"random.gauss(mu, sigma)","Gaussian distribution.  mu is the mean, and sigma is the standard
deviation.  This is slightly faster than the normalvariate() function
defined below."
"random.lognormvariate(mu, sigma)","Log normal distribution.  If you take the natural logarithm of this
distribution, you’ll get a normal distribution with mean mu and standard
deviation sigma.  mu can have any value, and sigma must be greater than
zero."
"random.normalvariate(mu, sigma)","Normal distribution.  mu is the mean, and sigma is the standard deviation."
"random.vonmisesvariate(mu, kappa)","mu is the mean angle, expressed in radians between 0 and 2*pi, and kappa
is the concentration parameter, which must be greater than or equal to zero.  If
kappa is equal to zero, this distribution reduces to a uniform random angle
over the range 0 to 2*pi."
random.paretovariate(alpha),Pareto distribution.  alpha is the shape parameter.
"random.weibullvariate(alpha, beta)","Weibull distribution.  alpha is the scale parameter and beta is the shape
parameter."
statistics.fmean(data),"Convert data to floats and compute the arithmetic mean.
This runs faster than the mean() function and it always returns a
float.  The data may be a sequence or iterable.  If the input
dataset is empty, raises a StatisticsError.
>>> fmean([3.5, 4.0, 5.25])
4.25



New in version 3.8."
statistics.geometric_mean(data),"Convert data to floats and compute the geometric mean.
The geometric mean indicates the central tendency or typical value of the
data using the product of the values (as opposed to the arithmetic mean
which uses their sum).
Raises a StatisticsError if the input dataset is empty,
if it contains a zero, or if it contains a negative value.
The data may be a sequence or iterable.
No special efforts are made to achieve exact results.
(However, this may change in the future.)
>>> round(geometric_mean([54, 24, 36]), 1)
36.0



New in version 3.8."
statistics.harmonic_mean(data),"Return the harmonic mean of data, a sequence or iterable of
real-valued numbers.
The harmonic mean, sometimes called the subcontrary mean, is the
reciprocal of the arithmetic mean() of the reciprocals of the
data. For example, the harmonic mean of three values a, b and c
will be equivalent to 3/(1/a + 1/b + 1/c).  If one of the values
is zero, the result will be zero.
The harmonic mean is a type of average, a measure of the central
location of the data.  It is often appropriate when averaging
rates or ratios, for example speeds.
Suppose a car travels 10 km at 40 km/hr, then another 10 km at 60 km/hr.
What is the average speed?
>>> harmonic_mean([40, 60])
48.0


Suppose an investor purchases an equal value of shares in each of
three companies, with P/E (price/earning) ratios of 2.5, 3 and 10.
What is the average P/E ratio for the investor’s portfolio?
>>> harmonic_mean([2.5, 3, 10])  # For an equal investment portfolio.
3.6


StatisticsError is raised if data is empty, or any element
is less than zero.
The current algorithm has an early-out when it encounters a zero
in the input.  This means that the subsequent inputs are not tested
for validity.  (This behavior may change in the future.)

New in version 3.6."
statistics.median(data),"Return the median (middle value) of numeric data, using the common “mean of
middle two” method.  If data is empty, StatisticsError is raised.
data can be a sequence or iterable.
The median is a robust measure of central location and is less affected by
the presence of outliers.  When the number of data points is odd, the
middle data point is returned:
>>> median([1, 3, 5])
3


When the number of data points is even, the median is interpolated by taking
the average of the two middle values:
>>> median([1, 3, 5, 7])
4.0


This is suited for when your data is discrete, and you don’t mind that the
median may not be an actual data point.
If the data is ordinal (supports order operations) but not numeric (doesn’t
support addition), consider using median_low() or median_high()
instead."
statistics.median_low(data),"Return the low median of numeric data.  If data is empty,
StatisticsError is raised.  data can be a sequence or iterable.
The low median is always a member of the data set.  When the number of data
points is odd, the middle value is returned.  When it is even, the smaller of
the two middle values is returned.
>>> median_low([1, 3, 5])
3
>>> median_low([1, 3, 5, 7])
3


Use the low median when your data are discrete and you prefer the median to
be an actual data point rather than interpolated."
statistics.median_high(data),"Return the high median of data.  If data is empty, StatisticsError
is raised.  data can be a sequence or iterable.
The high median is always a member of the data set.  When the number of data
points is odd, the middle value is returned.  When it is even, the larger of
the two middle values is returned.
>>> median_high([1, 3, 5])
3
>>> median_high([1, 3, 5, 7])
5


Use the high median when your data are discrete and you prefer the median to
be an actual data point rather than interpolated."
"statistics.median_grouped(data, interval=1)","Return the median of grouped continuous data, calculated as the 50th
percentile, using interpolation.  If data is empty, StatisticsError
is raised.  data can be a sequence or iterable.
>>> median_grouped([52, 52, 53, 54])
52.5


In the following example, the data are rounded, so that each value represents
the midpoint of data classes, e.g. 1 is the midpoint of the class 0.5–1.5, 2
is the midpoint of 1.5–2.5, 3 is the midpoint of 2.5–3.5, etc.  With the data
given, the middle value falls somewhere in the class 3.5–4.5, and
interpolation is used to estimate it:
>>> median_grouped([1, 2, 2, 3, 4, 4, 4, 4, 4, 5])
3.7


Optional argument interval represents the class interval, and defaults
to 1.  Changing the class interval naturally will change the interpolation:
>>> median_grouped([1, 3, 3, 5, 7], interval=1)
3.25
>>> median_grouped([1, 3, 3, 5, 7], interval=2)
3.5


This function does not check whether the data points are at least
interval apart.

CPython implementation detail: Under some circumstances, median_grouped() may coerce data points to
floats.  This behaviour is likely to change in the future.


See also

“Statistics for the Behavioral Sciences”, Frederick J Gravetter and
Larry B Wallnau (8th Edition).
The SSMEDIAN
function in the Gnome Gnumeric spreadsheet, including this discussion."
statistics.mode(data),"Return the single most common data point from discrete or nominal data.
The mode (when it exists) is the most typical value and serves as a
measure of central location.
If there are multiple modes with the same frequency, returns the first one
encountered in the data.  If the smallest or largest of those is
desired instead, use min(multimode(data)) or max(multimode(data)).
If the input data is empty, StatisticsError is raised.
mode assumes discrete data and returns a single value. This is the
standard treatment of the mode as commonly taught in schools:
>>> mode([1, 1, 2, 3, 3, 3, 3, 4])
3


The mode is unique in that it is the only statistic in this package that
also applies to nominal (non-numeric) data:
>>> mode([""red"", ""blue"", ""blue"", ""red"", ""green"", ""red"", ""red""])
'red'



Changed in version 3.8: Now handles multimodal datasets by returning the first mode encountered.
Formerly, it raised StatisticsError when more than one mode was
found."
statistics.multimode(data),"Return a list of the most frequently occurring values in the order they
were first encountered in the data.  Will return more than one result if
there are multiple modes or an empty list if the data is empty:
>>> multimode('aabbbbccddddeeffffgg')
['b', 'd', 'f']
>>> multimode('')
[]



New in version 3.8."
"statistics.pstdev(data, mu=None)","Return the population standard deviation (the square root of the population
variance).  See pvariance() for arguments and other details.
>>> pstdev([1.5, 2.5, 2.5, 2.75, 3.25, 4.75])
0.986893273527251"
"statistics.stdev(data, xbar=None)","Return the sample standard deviation (the square root of the sample
variance).  See variance() for arguments and other details.
>>> stdev([1.5, 2.5, 2.5, 2.75, 3.25, 4.75])
1.0810874155219827"
"statistics.quantiles(data, *, n=4, method='exclusive')","Divide data into n continuous intervals with equal probability.
Returns a list of n - 1 cut points separating the intervals.
Set n to 4 for quartiles (the default).  Set n to 10 for deciles.  Set
n to 100 for percentiles which gives the 99 cuts points that separate
data into 100 equal sized groups.  Raises StatisticsError if n
is not least 1.
The data can be any iterable containing sample data.  For meaningful
results, the number of data points in data should be larger than n.
Raises StatisticsError if there are not at least two data points.
The cut points are linearly interpolated from the
two nearest data points.  For example, if a cut point falls one-third
of the distance between two sample values, 100 and 112, the
cut-point will evaluate to 104.
The method for computing quantiles can be varied depending on
whether the data includes or excludes the lowest and
highest possible values from the population.
The default method is “exclusive” and is used for data sampled from
a population that can have more extreme values than found in the
samples.  The portion of the population falling below the i-th of
m sorted data points is computed as i / (m + 1).  Given nine
sample values, the method sorts them and assigns the following
percentiles: 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%.
Setting the method to “inclusive” is used for describing population
data or for samples that are known to include the most extreme values
from the population.  The minimum value in data is treated as the 0th
percentile and the maximum value is treated as the 100th percentile.
The portion of the population falling below the i-th of m sorted
data points is computed as (i - 1) / (m - 1).  Given 11 sample
values, the method sorts them and assigns the following percentiles:
0%, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%.
# Decile cut points for empirically sampled data
>>> data = [105, 129, 87, 86, 111, 111, 89, 81, 108, 92, 110,
...         100, 75, 105, 103, 109, 76, 119, 99, 91, 103, 129,
...         106, 101, 84, 111, 74, 87, 86, 103, 103, 106, 86,
...         111, 75, 87, 102, 121, 111, 88, 89, 101, 106, 95,
...         103, 107, 101, 81, 109, 104]
>>> [round(q, 1) for q in quantiles(data, n=10)]
[81.0, 86.2, 89.0, 99.4, 102.5, 103.6, 106.0, 109.8, 111.0]



New in version 3.8."
classmethod from_samples(data),"Makes a normal distribution instance with mu and sigma parameters
estimated from the data using fmean() and stdev().
The data can be any iterable and should consist of values
that can be converted to type float.  If data does not
contain at least two elements, raises StatisticsError because it
takes at least one point to estimate a central value and at least two
points to estimate dispersion."
"samples(n, *, seed=None)","Generates n random samples for a given mean and standard deviation.
Returns a list of float values.
If seed is given, creates a new instance of the underlying random
number generator.  This is useful for creating reproducible results,
even in a multi-threading context."
pdf(x),"Using a probability density function (pdf), compute
the relative likelihood that a random variable X will be near the
given value x.  Mathematically, it is the limit of the ratio P(x <=
X < x+dx) / dx as dx approaches zero.
The relative likelihood is computed as the probability of a sample
occurring in a narrow range divided by the width of the range (hence
the word “density”).  Since the likelihood is relative to other points,
its value can be greater than 1.0."
cdf(x),"Using a cumulative distribution function (cdf),
compute the probability that a random variable X will be less than or
equal to x.  Mathematically, it is written P(X <= x)."
inv_cdf(p),"Compute the inverse cumulative distribution function, also known as the
quantile function
or the percent-point
function.  Mathematically, it is written x : P(X <= x) = p.
Finds the value x of the random variable X such that the
probability of the variable being less than or equal to that value
equals the given probability p."
overlap(other),"Measures the agreement between two normal probability distributions.
Returns a value between 0.0 and 1.0 giving the overlapping area for
the two probability density functions."
quantiles(n=4),"Divide the normal distribution into n continuous intervals with
equal probability.  Returns a list of (n - 1) cut points separating
the intervals.
Set n to 4 for quartiles (the default).  Set n to 10 for deciles.
Set n to 100 for percentiles which gives the 99 cuts points that
separate the normal distribution into 100 equal sized groups."
"itertools.accumulate(iterable[, func, *, initial=None])","Make an iterator that returns accumulated sums, or accumulated
results of other binary functions (specified via the optional
func argument).
If func is supplied, it should be a function
of two arguments. Elements of the input iterable may be any type
that can be accepted as arguments to func. (For example, with
the default operation of addition, elements may be any addable
type including Decimal or
Fraction.)
Usually, the number of elements output matches the input iterable.
However, if the keyword argument initial is provided, the
accumulation leads off with the initial value so that the output
has one more element than the input iterable.
Roughly equivalent to:
def accumulate(iterable, func=operator.add, *, initial=None):
    'Return running totals'
    # accumulate([1,2,3,4,5]) --> 1 3 6 10 15
    # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115
    # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120
    it = iter(iterable)
    total = initial
    if initial is None:
        try:
            total = next(it)
        except StopIteration:
            return
    yield total
    for element in it:
        total = func(total, element)
        yield total


There are a number of uses for the func argument.  It can be set to
min() for a running minimum, max() for a running maximum, or
operator.mul() for a running product.  Amortization tables can be
built by accumulating interest and applying payments.  First-order
recurrence relations
can be modeled by supplying the initial value in the iterable and using only
the accumulated total in func argument:
>>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8]
>>> list(accumulate(data, operator.mul))     # running product
[3, 12, 72, 144, 144, 1296, 0, 0, 0, 0]
>>> list(accumulate(data, max))              # running maximum
[3, 4, 6, 6, 6, 9, 9, 9, 9, 9]

# Amortize a 5% loan of 1000 with 4 annual payments of 90
>>> cashflows = [1000, -90, -90, -90, -90]
>>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt))
[1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001]

# Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map
>>> logistic_map = lambda x, _:  r * x * (1 - x)
>>> r = 3.8
>>> x0 = 0.4
>>> inputs = repeat(x0, 36)     # only the initial value is used
>>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)]
['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63',
 '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57',
 '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32',
 '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60']


See functools.reduce() for a similar function that returns only the
final accumulated value.

New in version 3.2.


Changed in version 3.3: Added the optional func parameter.


Changed in version 3.8: Added the optional initial parameter."
itertools.chain(*iterables),"Make an iterator that returns elements from the first iterable until it is
exhausted, then proceeds to the next iterable, until all of the iterables are
exhausted.  Used for treating consecutive sequences as a single sequence.
Roughly equivalent to:
def chain(*iterables):
    # chain('ABC', 'DEF') --> A B C D E F
    for it in iterables:
        for element in it:
            yield element"
"itertools.combinations(iterable, r)","Return r length subsequences of elements from the input iterable.
Combinations are emitted in lexicographic sort order.  So, if the
input iterable is sorted, the combination tuples will be produced
in sorted order.
Elements are treated as unique based on their position, not on their
value.  So if the input elements are unique, there will be no repeat
values in each combination.
Roughly equivalent to:
def combinations(iterable, r):
    # combinations('ABCD', 2) --> AB AC AD BC BD CD
    # combinations(range(4), 3) --> 012 013 023 123
    pool = tuple(iterable)
    n = len(pool)
    if r > n:
        return
    indices = list(range(r))
    yield tuple(pool[i] for i in indices)
    while True:
        for i in reversed(range(r)):
            if indices[i] != i + n - r:
                break
        else:
            return
        indices[i] += 1
        for j in range(i+1, r):
            indices[j] = indices[j-1] + 1
        yield tuple(pool[i] for i in indices)


The code for combinations() can be also expressed as a subsequence
of permutations() after filtering entries where the elements are not
in sorted order (according to their position in the input pool):
def combinations(iterable, r):
    pool = tuple(iterable)
    n = len(pool)
    for indices in permutations(range(n), r):
        if sorted(indices) == list(indices):
            yield tuple(pool[i] for i in indices)


The number of items returned is n! / r! / (n-r)! when 0 <= r <= n
or zero when r > n."
"itertools.combinations_with_replacement(iterable, r)","Return r length subsequences of elements from the input iterable
allowing individual elements to be repeated more than once.
Combinations are emitted in lexicographic sort order.  So, if the
input iterable is sorted, the combination tuples will be produced
in sorted order.
Elements are treated as unique based on their position, not on their
value.  So if the input elements are unique, the generated combinations
will also be unique.
Roughly equivalent to:
def combinations_with_replacement(iterable, r):
    # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC
    pool = tuple(iterable)
    n = len(pool)
    if not n and r:
        return
    indices = [0] * r
    yield tuple(pool[i] for i in indices)
    while True:
        for i in reversed(range(r)):
            if indices[i] != n - 1:
                break
        else:
            return
        indices[i:] = [indices[i] + 1] * (r - i)
        yield tuple(pool[i] for i in indices)


The code for combinations_with_replacement() can be also expressed as
a subsequence of product() after filtering entries where the elements
are not in sorted order (according to their position in the input pool):
def combinations_with_replacement(iterable, r):
    pool = tuple(iterable)
    n = len(pool)
    for indices in product(range(n), repeat=r):
        if sorted(indices) == list(indices):
            yield tuple(pool[i] for i in indices)


The number of items returned is (n+r-1)! / r! / (n-1)! when n > 0.

New in version 3.1."
"itertools.compress(data, selectors)","Make an iterator that filters elements from data returning only those that
have a corresponding element in selectors that evaluates to True.
Stops when either the data or selectors iterables has been exhausted.
Roughly equivalent to:
def compress(data, selectors):
    # compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F
    return (d for d, s in zip(data, selectors) if s)



New in version 3.1."
"itertools.count(start=0, step=1)","Make an iterator that returns evenly spaced values starting with number start. Often
used as an argument to map() to generate consecutive data points.
Also, used with zip() to add sequence numbers.  Roughly equivalent to:
def count(start=0, step=1):
    # count(10) --> 10 11 12 13 14 ...
    # count(2.5, 0.5) -> 2.5 3.0 3.5 ...
    n = start
    while True:
        yield n
        n += step


When counting with floating point numbers, better accuracy can sometimes be
achieved by substituting multiplicative code such as: (start + step * i
for i in count()).

Changed in version 3.1: Added step argument and allowed non-integer arguments."
itertools.cycle(iterable),"Make an iterator returning elements from the iterable and saving a copy of each.
When the iterable is exhausted, return elements from the saved copy.  Repeats
indefinitely.  Roughly equivalent to:
def cycle(iterable):
    # cycle('ABCD') --> A B C D A B C D A B C D ...
    saved = []
    for element in iterable:
        yield element
        saved.append(element)
    while saved:
        for element in saved:
              yield element


Note, this member of the toolkit may require significant auxiliary storage
(depending on the length of the iterable)."
"itertools.dropwhile(predicate, iterable)","Make an iterator that drops elements from the iterable as long as the predicate
is true; afterwards, returns every element.  Note, the iterator does not produce
any output until the predicate first becomes false, so it may have a lengthy
start-up time.  Roughly equivalent to:
def dropwhile(predicate, iterable):
    # dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1
    iterable = iter(iterable)
    for x in iterable:
        if not predicate(x):
            yield x
            break
    for x in iterable:
        yield x"
"itertools.filterfalse(predicate, iterable)","Make an iterator that filters elements from iterable returning only those for
which the predicate is False. If predicate is None, return the items
that are false. Roughly equivalent to:
def filterfalse(predicate, iterable):
    # filterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8
    if predicate is None:
        predicate = bool
    for x in iterable:
        if not predicate(x):
            yield x"
"itertools.groupby(iterable, key=None)","Make an iterator that returns consecutive keys and groups from the iterable.
The key is a function computing a key value for each element.  If not
specified or is None, key defaults to an identity function and returns
the element unchanged.  Generally, the iterable needs to already be sorted on
the same key function.
The operation of groupby() is similar to the uniq filter in Unix.  It
generates a break or new group every time the value of the key function changes
(which is why it is usually necessary to have sorted the data using the same key
function).  That behavior differs from SQL’s GROUP BY which aggregates common
elements regardless of their input order.
The returned group is itself an iterator that shares the underlying iterable
with groupby().  Because the source is shared, when the groupby()
object is advanced, the previous group is no longer visible.  So, if that data
is needed later, it should be stored as a list:
groups = []
uniquekeys = []
data = sorted(data, key=keyfunc)
for k, g in groupby(data, keyfunc):
    groups.append(list(g))      # Store group iterator as a list
    uniquekeys.append(k)


groupby() is roughly equivalent to:
class groupby:
    # [k for k, g in groupby('AAAABBBCCDAABBB')] --> A B C D A B
    # [list(g) for k, g in groupby('AAAABBBCCD')] --> AAAA BBB CC D
    def __init__(self, iterable, key=None):
        if key is None:
            key = lambda x: x
        self.keyfunc = key
        self.it = iter(iterable)
        self.tgtkey = self.currkey = self.currvalue = object()
    def __iter__(self):
        return self
    def __next__(self):
        self.id = object()
        while self.currkey == self.tgtkey:
            self.currvalue = next(self.it)    # Exit on StopIteration
            self.currkey = self.keyfunc(self.currvalue)
        self.tgtkey = self.currkey
        return (self.currkey, self._grouper(self.tgtkey, self.id))
    def _grouper(self, tgtkey, id):
        while self.id is id and self.currkey == tgtkey:
            yield self.currvalue
            try:
                self.currvalue = next(self.it)
            except StopIteration:
                return
            self.currkey = self.keyfunc(self.currvalue)"
"itertools.islice(iterable, stop)","Make an iterator that returns selected elements from the iterable. If start is
non-zero, then elements from the iterable are skipped until start is reached.
Afterward, elements are returned consecutively unless step is set higher than
one which results in items being skipped.  If stop is None, then iteration
continues until the iterator is exhausted, if at all; otherwise, it stops at the
specified position.  Unlike regular slicing, islice() does not support
negative values for start, stop, or step.  Can be used to extract related
fields from data where the internal structure has been flattened (for example, a
multi-line report may list a name field on every third line).  Roughly equivalent to:
def islice(iterable, *args):
    # islice('ABCDEFG', 2) --> A B
    # islice('ABCDEFG', 2, 4) --> C D
    # islice('ABCDEFG', 2, None) --> C D E F G
    # islice('ABCDEFG', 0, None, 2) --> A C E G
    s = slice(*args)
    start, stop, step = s.start or 0, s.stop or sys.maxsize, s.step or 1
    it = iter(range(start, stop, step))
    try:
        nexti = next(it)
    except StopIteration:
        # Consume *iterable* up to the *start* position.
        for i, element in zip(range(start), iterable):
            pass
        return
    try:
        for i, element in enumerate(iterable):
            if i == nexti:
                yield element
                nexti = next(it)
    except StopIteration:
        # Consume to *stop*.
        for i, element in zip(range(i + 1, stop), iterable):
            pass


If start is None, then iteration starts at zero. If step is None,
then the step defaults to one."
"itertools.permutations(iterable, r=None)","Return successive r length permutations of elements in the iterable.
If r is not specified or is None, then r defaults to the length
of the iterable and all possible full-length permutations
are generated.
Permutations are emitted in lexicographic sort order.  So, if the
input iterable is sorted, the permutation tuples will be produced
in sorted order.
Elements are treated as unique based on their position, not on their
value.  So if the input elements are unique, there will be no repeat
values in each permutation.
Roughly equivalent to:
def permutations(iterable, r=None):
    # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC
    # permutations(range(3)) --> 012 021 102 120 201 210
    pool = tuple(iterable)
    n = len(pool)
    r = n if r is None else r
    if r > n:
        return
    indices = list(range(n))
    cycles = list(range(n, n-r, -1))
    yield tuple(pool[i] for i in indices[:r])
    while n:
        for i in reversed(range(r)):
            cycles[i] -= 1
            if cycles[i] == 0:
                indices[i:] = indices[i+1:] + indices[i:i+1]
                cycles[i] = n - i
            else:
                j = cycles[i]
                indices[i], indices[-j] = indices[-j], indices[i]
                yield tuple(pool[i] for i in indices[:r])
                break
        else:
            return


The code for permutations() can be also expressed as a subsequence of
product(), filtered to exclude entries with repeated elements (those
from the same position in the input pool):
def permutations(iterable, r=None):
    pool = tuple(iterable)
    n = len(pool)
    r = n if r is None else r
    for indices in product(range(n), repeat=r):
        if len(set(indices)) == r:
            yield tuple(pool[i] for i in indices)


The number of items returned is n! / (n-r)! when 0 <= r <= n
or zero when r > n."
"itertools.product(*iterables, repeat=1)","Cartesian product of input iterables.
Roughly equivalent to nested for-loops in a generator expression. For example,
product(A, B) returns the same as ((x,y) for x in A for y in B).
The nested loops cycle like an odometer with the rightmost element advancing
on every iteration.  This pattern creates a lexicographic ordering so that if
the input’s iterables are sorted, the product tuples are emitted in sorted
order.
To compute the product of an iterable with itself, specify the number of
repetitions with the optional repeat keyword argument.  For example,
product(A, repeat=4) means the same as product(A, A, A, A).
This function is roughly equivalent to the following code, except that the
actual implementation does not build up intermediate results in memory:
def product(*args, repeat=1):
    # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy
    # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111
    pools = [tuple(pool) for pool in args] * repeat
    result = [[]]
    for pool in pools:
        result = [x+[y] for x in result for y in pool]
    for prod in result:
        yield tuple(prod)"
"itertools.repeat(object[, times])","Make an iterator that returns object over and over again. Runs indefinitely
unless the times argument is specified. Used as argument to map() for
invariant parameters to the called function.  Also used with zip() to
create an invariant part of a tuple record.
Roughly equivalent to:
def repeat(object, times=None):
    # repeat(10, 3) --> 10 10 10
    if times is None:
        while True:
            yield object
    else:
        for i in range(times):
            yield object


A common use for repeat is to supply a stream of constant values to map
or zip:
>>> list(map(pow, range(10), repeat(2)))
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
"itertools.starmap(function, iterable)","Make an iterator that computes the function using arguments obtained from
the iterable.  Used instead of map() when argument parameters are already
grouped in tuples from a single iterable (the data has been “pre-zipped”).  The
difference between map() and starmap() parallels the distinction
between function(a,b) and function(*c). Roughly equivalent to:
def starmap(function, iterable):
    # starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000
    for args in iterable:
        yield function(*args)"
"itertools.takewhile(predicate, iterable)","Make an iterator that returns elements from the iterable as long as the
predicate is true.  Roughly equivalent to:
def takewhile(predicate, iterable):
    # takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4
    for x in iterable:
        if predicate(x):
            yield x
        else:
            break"
"itertools.tee(iterable, n=2)","Return n independent iterators from a single iterable.
The following Python code helps explain what tee does (although the actual
implementation is more complex and uses only a single underlying
FIFO queue).
Roughly equivalent to:
def tee(iterable, n=2):
    it = iter(iterable)
    deques = [collections.deque() for i in range(n)]
    def gen(mydeque):
        while True:
            if not mydeque:             # when the local deque is empty
                try:
                    newval = next(it)   # fetch a new value and
                except StopIteration:
                    return
                for d in deques:        # load it to all the deques
                    d.append(newval)
            yield mydeque.popleft()
    return tuple(gen(d) for d in deques)


Once tee() has made a split, the original iterable should not be
used anywhere else; otherwise, the iterable could get advanced without
the tee objects being informed.
tee iterators are not threadsafe. A RuntimeError may be
raised when using simultaneously iterators returned by the same tee()
call, even if the original iterable is threadsafe.
This itertool may require significant auxiliary storage (depending on how
much temporary data needs to be stored). In general, if one iterator uses
most or all of the data before another iterator starts, it is faster to use
list() instead of tee()."
"itertools.zip_longest(*iterables, fillvalue=None)","Make an iterator that aggregates elements from each of the iterables. If the
iterables are of uneven length, missing values are filled-in with fillvalue.
Iteration continues until the longest iterable is exhausted.  Roughly equivalent to:
def zip_longest(*args, fillvalue=None):
    # zip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-
    iterators = [iter(it) for it in args]
    num_active = len(iterators)
    if not num_active:
        return
    while True:
        values = []
        for i, it in enumerate(iterators):
            try:
                value = next(it)
            except StopIteration:
                num_active -= 1
                if not num_active:
                    return
                iterators[i] = repeat(fillvalue)
                value = fillvalue
            values.append(value)
        yield tuple(values)


If one of the iterables is potentially infinite, then the zip_longest()
function should be wrapped with something that limits the number of calls
(for example islice() or takewhile()).  If not specified,
fillvalue defaults to None."
classmethod chain.from_iterable(iterable),"Alternate constructor for chain().  Gets chained inputs from a
single iterable argument that is evaluated lazily.  Roughly equivalent to:
def from_iterable(iterables):
    # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F
    for it in iterables:
        for element in it:
            yield element"
@functools.cached_property(func),"Transform a method of a class into a property whose value is computed once
and then cached as a normal attribute for the life of the instance. Similar
to property(), with the addition of caching. Useful for expensive
computed properties of instances that are otherwise effectively immutable.
Example:
class DataSet:
    def __init__(self, sequence_of_numbers):
        self._data = sequence_of_numbers

    @cached_property
    def stdev(self):
        return statistics.stdev(self._data)

    @cached_property
    def variance(self):
        return statistics.variance(self._data)



New in version 3.8.


Note
This decorator requires that the __dict__ attribute on each instance
be a mutable mapping. This means it will not work with some types, such as
metaclasses (since the __dict__ attributes on type instances are
read-only proxies for the class namespace), and those that specify
__slots__ without including __dict__ as one of the defined slots
(as such classes don’t provide a __dict__ attribute at all)."
functools.cmp_to_key(func),"Transform an old-style comparison function to a key function.  Used
with tools that accept key functions (such as sorted(), min(),
max(), heapq.nlargest(), heapq.nsmallest(),
itertools.groupby()).  This function is primarily used as a transition
tool for programs being converted from Python 2 which supported the use of
comparison functions.
A comparison function is any callable that accept two arguments, compares them,
and returns a negative number for less-than, zero for equality, or a positive
number for greater-than.  A key function is a callable that accepts one
argument and returns another value to be used as the sort key.
Example:
sorted(iterable, key=cmp_to_key(locale.strcoll))  # locale-aware sort order


For sorting examples and a brief sorting tutorial, see Sorting HOW TO.

New in version 3.2."
@functools.lru_cache(user_function),"Decorator to wrap a function with a memoizing callable that saves up to the
maxsize most recent calls.  It can save time when an expensive or I/O bound
function is periodically called with the same arguments.
Since a dictionary is used to cache results, the positional and keyword
arguments to the function must be hashable.
Distinct argument patterns may be considered to be distinct calls with
separate cache entries.  For example, f(a=1, b=2) and f(b=2, a=1)
differ in their keyword argument order and may have two separate cache
entries.
If user_function is specified, it must be a callable. This allows the
lru_cache decorator to be applied directly to a user function, leaving
the maxsize at its default value of 128:
@lru_cache
def count_vowels(sentence):
    sentence = sentence.casefold()
    return sum(sentence.count(vowel) for vowel in 'aeiou')


If maxsize is set to None, the LRU feature is disabled and the cache can
grow without bound.  The LRU feature performs best when maxsize is a
power-of-two.
If typed is set to true, function arguments of different types will be
cached separately.  For example, f(3) and f(3.0) will be treated
as distinct calls with distinct results.
To help measure the effectiveness of the cache and tune the maxsize
parameter, the wrapped function is instrumented with a cache_info()
function that returns a named tuple showing hits, misses,
maxsize and currsize.  In a multi-threaded environment, the hits
and misses are approximate.
The decorator also provides a cache_clear() function for clearing or
invalidating the cache.
The original underlying function is accessible through the
__wrapped__ attribute.  This is useful for introspection, for
bypassing the cache, or for rewrapping the function with a different cache.
An LRU (least recently used) cache works
best when the most recent calls are the best predictors of upcoming calls (for
example, the most popular articles on a news server tend to change each day).
The cache’s size limit assures that the cache does not grow without bound on
long-running processes such as web servers.
In general, the LRU cache should only be used when you want to reuse
previously computed values.  Accordingly, it doesn’t make sense to cache
functions with side-effects, functions that need to create distinct mutable
objects on each call, or impure functions such as time() or random().
Example of an LRU cache for static web content:
@lru_cache(maxsize=32)
def get_pep(num):
    'Retrieve text of a Python Enhancement Proposal'
    resource = 'http://www.python.org/dev/peps/pep-%04d/' % num
    try:
        with urllib.request.urlopen(resource) as s:
            return s.read()
    except urllib.error.HTTPError:
        return 'Not Found'

>>> for n in 8, 290, 308, 320, 8, 218, 320, 279, 289, 320, 9991:
...     pep = get_pep(n)
...     print(n, len(pep))

>>> get_pep.cache_info()
CacheInfo(hits=3, misses=8, maxsize=32, currsize=8)


Example of efficiently computing
Fibonacci numbers
using a cache to implement a
dynamic programming
technique:
@lru_cache(maxsize=None)
def fib(n):
    if n < 2:
        return n
    return fib(n-1) + fib(n-2)

>>> [fib(n) for n in range(16)]
[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]

>>> fib.cache_info()
CacheInfo(hits=28, misses=16, maxsize=None, currsize=16)



New in version 3.2.


Changed in version 3.3: Added the typed option.


Changed in version 3.8: Added the user_function option."
@functools.total_ordering,"Given a class defining one or more rich comparison ordering methods, this
class decorator supplies the rest.  This simplifies the effort involved
in specifying all of the possible rich comparison operations:
The class must define one of __lt__(), __le__(),
__gt__(), or __ge__().
In addition, the class should supply an __eq__() method.
For example:
@total_ordering
class Student:
    def _is_valid_operand(self, other):
        return (hasattr(other, ""lastname"") and
                hasattr(other, ""firstname""))
    def __eq__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.lastname.lower(), self.firstname.lower()) ==
                (other.lastname.lower(), other.firstname.lower()))
    def __lt__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.lastname.lower(), self.firstname.lower()) <
                (other.lastname.lower(), other.firstname.lower()))



Note
While this decorator makes it easy to create well behaved totally
ordered types, it does come at the cost of slower execution and
more complex stack traces for the derived comparison methods. If
performance benchmarking indicates this is a bottleneck for a given
application, implementing all six rich comparison methods instead is
likely to provide an easy speed boost.


New in version 3.2.


Changed in version 3.4: Returning NotImplemented from the underlying comparison function for
unrecognised types is now supported."
"functools.partial(func, /, *args, **keywords)","Return a new partial object which when called
will behave like func called with the positional arguments args
and keyword arguments keywords. If more arguments are supplied to the
call, they are appended to args. If additional keyword arguments are
supplied, they extend and override keywords.
Roughly equivalent to:
def partial(func, /, *args, **keywords):
    def newfunc(*fargs, **fkeywords):
        newkeywords = {**keywords, **fkeywords}
        return func(*args, *fargs, **newkeywords)
    newfunc.func = func
    newfunc.args = args
    newfunc.keywords = keywords
    return newfunc


The partial() is used for partial function application which “freezes”
some portion of a function’s arguments and/or keywords resulting in a new object
with a simplified signature.  For example, partial() can be used to create
a callable that behaves like the int() function where the base argument
defaults to two:
>>> from functools import partial
>>> basetwo = partial(int, base=2)
>>> basetwo.__doc__ = 'Convert base 2 string to an int.'
>>> basetwo('10010')
18"
"functools.reduce(function, iterable[, initializer])","Apply function of two arguments cumulatively to the items of iterable, from
left to right, so as to reduce the iterable to a single value.  For example,
reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates ((((1+2)+3)+4)+5).
The left argument, x, is the accumulated value and the right argument, y, is
the update value from the iterable.  If the optional initializer is present,
it is placed before the items of the iterable in the calculation, and serves as
a default when the iterable is empty.  If initializer is not given and
iterable contains only one item, the first item is returned.
Roughly equivalent to:
def reduce(function, iterable, initializer=None):
    it = iter(iterable)
    if initializer is None:
        value = next(it)
    else:
        value = initializer
    for element in it:
        value = function(value, element)
    return value


See itertools.accumulate() for an iterator that yields all intermediate
values."
@functools.singledispatch,"Transform a function into a single-dispatch generic function.
To define a generic function, decorate it with the @singledispatch
decorator. Note that the dispatch happens on the type of the first argument,
create your function accordingly:
>>> from functools import singledispatch
>>> @singledispatch
... def fun(arg, verbose=False):
...     if verbose:
...         print(""Let me just say,"", end="" "")
...     print(arg)


To add overloaded implementations to the function, use the register()
attribute of the generic function.  It is a decorator.  For functions
annotated with types, the decorator will infer the type of the first
argument automatically:
>>> @fun.register
... def _(arg: int, verbose=False):
...     if verbose:
...         print(""Strength in numbers, eh?"", end="" "")
...     print(arg)
...
>>> @fun.register
... def _(arg: list, verbose=False):
...     if verbose:
...         print(""Enumerate this:"")
...     for i, elem in enumerate(arg):
...         print(i, elem)


For code which doesn’t use type annotations, the appropriate type
argument can be passed explicitly to the decorator itself:
>>> @fun.register(complex)
... def _(arg, verbose=False):
...     if verbose:
...         print(""Better than complicated."", end="" "")
...     print(arg.real, arg.imag)
...


To enable registering lambdas and pre-existing functions, the
register() attribute can be used in a functional form:
>>> def nothing(arg, verbose=False):
...     print(""Nothing."")
...
>>> fun.register(type(None), nothing)


The register() attribute returns the undecorated function which
enables decorator stacking, pickling, as well as creating unit tests for
each variant independently:
>>> @fun.register(float)
... @fun.register(Decimal)
... def fun_num(arg, verbose=False):
...     if verbose:
...         print(""Half of your number:"", end="" "")
...     print(arg / 2)
...
>>> fun_num is fun
False


When called, the generic function dispatches on the type of the first
argument:
>>> fun(""Hello, world."")
Hello, world.
>>> fun(""test."", verbose=True)
Let me just say, test.
>>> fun(42, verbose=True)
Strength in numbers, eh? 42
>>> fun(['spam', 'spam', 'eggs', 'spam'], verbose=True)
Enumerate this:
0 spam
1 spam
2 eggs
3 spam
>>> fun(None)
Nothing.
>>> fun(1.23)
0.615


Where there is no registered implementation for a specific type, its
method resolution order is used to find a more generic implementation.
The original function decorated with @singledispatch is registered
for the base object type, which means it is used if no better
implementation is found.
To check which implementation will the generic function choose for
a given type, use the dispatch() attribute:
>>> fun.dispatch(float)
<function fun_num at 0x1035a2840>
>>> fun.dispatch(dict)    # note: default implementation
<function fun at 0x103fe0000>


To access all registered implementations, use the read-only registry
attribute:
>>> fun.registry.keys()
dict_keys([<class 'NoneType'>, <class 'int'>, <class 'object'>,
          <class 'decimal.Decimal'>, <class 'list'>,
          <class 'float'>])
>>> fun.registry[float]
<function fun_num at 0x1035a2840>
>>> fun.registry[object]
<function fun at 0x103fe0000>



New in version 3.4.


Changed in version 3.7: The register() attribute supports using type annotations."
"functools.update_wrapper(wrapper, wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES)","Update a wrapper function to look like the wrapped function. The optional
arguments are tuples to specify which attributes of the original function are
assigned directly to the matching attributes on the wrapper function and which
attributes of the wrapper function are updated with the corresponding attributes
from the original function. The default values for these arguments are the
module level constants WRAPPER_ASSIGNMENTS (which assigns to the wrapper
function’s __module__, __name__, __qualname__, __annotations__
and __doc__, the documentation string) and WRAPPER_UPDATES (which
updates the wrapper function’s __dict__, i.e. the instance dictionary).
To allow access to the original function for introspection and other purposes
(e.g. bypassing a caching decorator such as lru_cache()), this function
automatically adds a __wrapped__ attribute to the wrapper that refers to
the function being wrapped.
The main intended use for this function is in decorator functions which
wrap the decorated function and return the wrapper. If the wrapper function is
not updated, the metadata of the returned function will reflect the wrapper
definition rather than the original function definition, which is typically less
than helpful.
update_wrapper() may be used with callables other than functions. Any
attributes named in assigned or updated that are missing from the object
being wrapped are ignored (i.e. this function will not attempt to set them
on the wrapper function). AttributeError is still raised if the
wrapper function itself is missing any attributes named in updated.

New in version 3.2: Automatic addition of the __wrapped__ attribute.


New in version 3.2: Copying of the __annotations__ attribute by default.


Changed in version 3.2: Missing attributes no longer trigger an AttributeError.


Changed in version 3.4: The __wrapped__ attribute now always refers to the wrapped
function, even if that function defined a __wrapped__ attribute.
(see bpo-17482)"
"@functools.wraps(wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES)","This is a convenience function for invoking update_wrapper() as a
function decorator when defining a wrapper function.  It is equivalent to
partial(update_wrapper, wrapped=wrapped, assigned=assigned, updated=updated).
For example:
>>> from functools import wraps
>>> def my_decorator(f):
...     @wraps(f)
...     def wrapper(*args, **kwds):
...         print('Calling decorated function')
...         return f(*args, **kwds)
...     return wrapper
...
>>> @my_decorator
... def example():
...     """"""Docstring""""""
...     print('Called example function')
...
>>> example()
Calling decorated function
Called example function
>>> example.__name__
'example'
>>> example.__doc__
'Docstring'


Without the use of this decorator factory, the name of the example function
would have been 'wrapper', and the docstring of the original example()
would have been lost."
"operator.lt(a, b)","Perform “rich comparisons” between a and b. Specifically, lt(a, b) is
equivalent to a < b, le(a, b) is equivalent to a <= b, eq(a,
b) is equivalent to a == b, ne(a, b) is equivalent to a != b,
gt(a, b) is equivalent to a > b and ge(a, b) is equivalent to a
>= b.  Note that these functions can return any value, which may
or may not be interpretable as a Boolean value.  See
Comparisons for more information about rich comparisons."
operator.not_(obj),"Return the outcome of not obj.  (Note that there is no
__not__() method for object instances; only the interpreter core defines
this operation.  The result is affected by the __bool__() and
__len__() methods.)"
operator.truth(obj),"Return True if obj is true, and False otherwise.  This is
equivalent to using the bool constructor."
"operator.is_(a, b)",Return a is b.  Tests object identity.
"operator.is_not(a, b)",Return a is not b.  Tests object identity.
operator.abs(obj),Return the absolute value of obj.
"operator.add(a, b)","Return a + b, for a and b numbers."
"operator.and_(a, b)",Return the bitwise and of a and b.
"operator.floordiv(a, b)",Return a // b.
operator.index(a),Return a converted to an integer.  Equivalent to a.__index__().
operator.inv(obj),Return the bitwise inverse of the number obj.  This is equivalent to ~obj.
"operator.lshift(a, b)",Return a shifted left by b.
"operator.mod(a, b)",Return a % b.
"operator.mul(a, b)","Return a * b, for a and b numbers."
"operator.matmul(a, b)","Return a @ b.

New in version 3.5."
operator.neg(obj),Return obj negated (-obj).
"operator.or_(a, b)",Return the bitwise or of a and b.
operator.pos(obj),Return obj positive (+obj).
"operator.pow(a, b)","Return a ** b, for a and b numbers."
"operator.rshift(a, b)",Return a shifted right by b.
"operator.sub(a, b)",Return a - b.
"operator.truediv(a, b)","Return a / b where 2/3 is .66 rather than 0.  This is also known as
“true” division."
"operator.xor(a, b)",Return the bitwise exclusive or of a and b.
"operator.concat(a, b)",Return a + b for a and b sequences.
"operator.contains(a, b)",Return the outcome of the test b in a. Note the reversed operands.
"operator.countOf(a, b)",Return the number of occurrences of b in a.
"operator.delitem(a, b)",Remove the value of a at index b.
"operator.getitem(a, b)",Return the value of a at index b.
"operator.indexOf(a, b)",Return the index of the first of occurrence of b in a.
"operator.setitem(a, b, c)",Set the value of a at index b to c.
"operator.length_hint(obj, default=0)","Return an estimated length for the object o. First try to return its
actual length, then an estimate using object.__length_hint__(), and
finally return the default value.

New in version 3.4."
operator.attrgetter(attr),"Return a callable object that fetches attr from its operand.
If more than one attribute is requested, returns a tuple of attributes.
The attribute names can also contain dots. For example:

After f = attrgetter('name'), the call f(b) returns b.name.
After f = attrgetter('name', 'date'), the call f(b) returns
(b.name, b.date).
After f = attrgetter('name.first', 'name.last'), the call f(b)
returns (b.name.first, b.name.last).

Equivalent to:
def attrgetter(*items):
    if any(not isinstance(item, str) for item in items):
        raise TypeError('attribute name must be a string')
    if len(items) == 1:
        attr = items[0]
        def g(obj):
            return resolve_attr(obj, attr)
    else:
        def g(obj):
            return tuple(resolve_attr(obj, attr) for attr in items)
    return g

def resolve_attr(obj, attr):
    for name in attr.split("".""):
        obj = getattr(obj, name)
    return obj"
operator.itemgetter(item),"Return a callable object that fetches item from its operand using the
operand’s __getitem__() method.  If multiple items are specified,
returns a tuple of lookup values.  For example:

After f = itemgetter(2), the call f(r) returns r[2].
After g = itemgetter(2, 5, 3), the call g(r) returns
(r[2], r[5], r[3]).

Equivalent to:
def itemgetter(*items):
    if len(items) == 1:
        item = items[0]
        def g(obj):
            return obj[item]
    else:
        def g(obj):
            return tuple(obj[item] for item in items)
    return g


The items can be any type accepted by the operand’s __getitem__()
method.  Dictionaries accept any hashable value.  Lists, tuples, and
strings accept an index or a slice:
>>> itemgetter('name')({'name': 'tu', 'age': 18})
'tu'
>>> itemgetter(1)('ABCDEFG')
'B'
>>> itemgetter(1,3,5)('ABCDEFG')
('B', 'D', 'F')
>>> itemgetter(slice(2,None))('ABCDEFG')
'CDEFG'


>>> soldier = dict(rank='captain', name='dotterbart')
>>> itemgetter('rank')(soldier)
'captain'


Example of using itemgetter() to retrieve specific fields from a
tuple record:
>>> inventory = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]
>>> getcount = itemgetter(1)
>>> list(map(getcount, inventory))
[3, 2, 5, 1]
>>> sorted(inventory, key=getcount)
[('orange', 1), ('banana', 2), ('apple', 3), ('pear', 5)]"
"operator.methodcaller(name, /, *args, **kwargs)","Return a callable object that calls the method name on its operand.  If
additional arguments and/or keyword arguments are given, they will be given
to the method as well.  For example:

After f = methodcaller('name'), the call f(b) returns b.name().
After f = methodcaller('name', 'foo', bar=1), the call f(b)
returns b.name('foo', bar=1).

Equivalent to:
def methodcaller(name, /, *args, **kwargs):
    def caller(obj):
        return getattr(obj, name)(*args, **kwargs)
    return caller"
"operator.iadd(a, b)","a = iadd(a, b) is equivalent to a += b."
"operator.iand(a, b)","a = iand(a, b) is equivalent to a &= b."
"operator.iconcat(a, b)","a = iconcat(a, b) is equivalent to a += b for a and b sequences."
"operator.ifloordiv(a, b)","a = ifloordiv(a, b) is equivalent to a //= b."
"operator.ilshift(a, b)","a = ilshift(a, b) is equivalent to a <<= b."
"operator.imod(a, b)","a = imod(a, b) is equivalent to a %= b."
"operator.imul(a, b)","a = imul(a, b) is equivalent to a *= b."
"operator.imatmul(a, b)","a = imatmul(a, b) is equivalent to a @= b.

New in version 3.5."
"operator.ior(a, b)","a = ior(a, b) is equivalent to a |= b."
"operator.ipow(a, b)","a = ipow(a, b) is equivalent to a **= b."
"operator.irshift(a, b)","a = irshift(a, b) is equivalent to a >>= b."
"operator.isub(a, b)","a = isub(a, b) is equivalent to a -= b."
"operator.itruediv(a, b)","a = itruediv(a, b) is equivalent to a /= b."
"operator.ixor(a, b)","a = ixor(a, b) is equivalent to a ^= b."
PurePath.as_posix(),"Return a string representation of the path with forward slashes (/):
>>> p = PureWindowsPath('c:\\windows')
>>> str(p)
'c:\\windows'
>>> p.as_posix()
'c:/windows'"
PurePath.as_uri(),"Represent the path as a file URI.  ValueError is raised if
the path isn’t absolute.
>>> p = PurePosixPath('/etc/passwd')
>>> p.as_uri()
'file:///etc/passwd'
>>> p = PureWindowsPath('c:/Windows')
>>> p.as_uri()
'file:///c:/Windows'"
PurePath.is_absolute(),"Return whether the path is absolute or not.  A path is considered absolute
if it has both a root and (if the flavour allows) a drive:
>>> PurePosixPath('/a/b').is_absolute()
True
>>> PurePosixPath('a/b').is_absolute()
False

>>> PureWindowsPath('c:/a/b').is_absolute()
True
>>> PureWindowsPath('/a/b').is_absolute()
False
>>> PureWindowsPath('c:').is_absolute()
False
>>> PureWindowsPath('//some/share').is_absolute()
True"
PurePath.is_reserved(),"With PureWindowsPath, return True if the path is considered
reserved under Windows, False otherwise.  With PurePosixPath,
False is always returned.
>>> PureWindowsPath('nul').is_reserved()
True
>>> PurePosixPath('nul').is_reserved()
False


File system calls on reserved paths can fail mysteriously or have
unintended effects."
PurePath.joinpath(*other),"Calling this method is equivalent to combining the path with each of
the other arguments in turn:
>>> PurePosixPath('/etc').joinpath('passwd')
PurePosixPath('/etc/passwd')
>>> PurePosixPath('/etc').joinpath(PurePosixPath('passwd'))
PurePosixPath('/etc/passwd')
>>> PurePosixPath('/etc').joinpath('init.d', 'apache2')
PurePosixPath('/etc/init.d/apache2')
>>> PureWindowsPath('c:').joinpath('/Program Files')
PureWindowsPath('c:/Program Files')"
PurePath.match(pattern),"Match this path against the provided glob-style pattern.  Return True
if matching is successful, False otherwise.
If pattern is relative, the path can be either relative or absolute,
and matching is done from the right:
>>> PurePath('a/b.py').match('*.py')
True
>>> PurePath('/a/b/c.py').match('b/*.py')
True
>>> PurePath('/a/b/c.py').match('a/*.py')
False


If pattern is absolute, the path must be absolute, and the whole path
must match:
>>> PurePath('/a.py').match('/*.py')
True
>>> PurePath('a/b.py').match('/*.py')
False


As with other methods, case-sensitivity is observed:
>>> PureWindowsPath('b.py').match('*.PY')
True"
PurePath.relative_to(*other),"Compute a version of this path relative to the path represented by
other.  If it’s impossible, ValueError is raised:
>>> p = PurePosixPath('/etc/passwd')
>>> p.relative_to('/')
PurePosixPath('etc/passwd')
>>> p.relative_to('/etc')
PurePosixPath('passwd')
>>> p.relative_to('/usr')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""pathlib.py"", line 694, in relative_to
    .format(str(self), str(formatted)))
ValueError: '/etc/passwd' does not start with '/usr'"
PurePath.with_name(name),"Return a new path with the name changed.  If the original path
doesn’t have a name, ValueError is raised:
>>> p = PureWindowsPath('c:/Downloads/pathlib.tar.gz')
>>> p.with_name('setup.py')
PureWindowsPath('c:/Downloads/setup.py')
>>> p = PureWindowsPath('c:/')
>>> p.with_name('setup.py')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/antoine/cpython/default/Lib/pathlib.py"", line 751, in with_name
    raise ValueError(""%r has an empty name"" % (self,))
ValueError: PureWindowsPath('c:/') has an empty name"
PurePath.with_suffix(suffix),"Return a new path with the suffix changed.  If the original path
doesn’t have a suffix, the new suffix is appended instead.  If the
suffix is an empty string, the original suffix is removed:
>>> p = PureWindowsPath('c:/Downloads/pathlib.tar.gz')
>>> p.with_suffix('.bz2')
PureWindowsPath('c:/Downloads/pathlib.tar.bz2')
>>> p = PureWindowsPath('README')
>>> p.with_suffix('.txt')
PureWindowsPath('README.txt')
>>> p = PureWindowsPath('README.txt')
>>> p.with_suffix('')
PureWindowsPath('README')"
classmethod Path.cwd(),"Return a new path object representing the current directory (as returned
by os.getcwd()):
>>> Path.cwd()
PosixPath('/home/antoine/pathlib')"
classmethod Path.home(),"Return a new path object representing the user’s home directory (as
returned by os.path.expanduser() with ~ construct):
>>> Path.home()
PosixPath('/home/antoine')



New in version 3.5."
Path.stat(),"Return information about this path (similarly to os.stat()).
The result is looked up at each call to this method.
>>> p = Path('setup.py')
>>> p.stat().st_size
956
>>> p.stat().st_mtime
1327883547.852554"
Path.chmod(mode),"Change the file mode and permissions, like os.chmod():
>>> p = Path('setup.py')
>>> p.stat().st_mode
33277
>>> p.chmod(0o444)
>>> p.stat().st_mode
33060"
Path.exists(),"Whether the path points to an existing file or directory:
>>> Path('.').exists()
True
>>> Path('setup.py').exists()
True
>>> Path('/etc').exists()
True
>>> Path('nonexistentfile').exists()
False



Note
If the path points to a symlink, exists() returns whether the
symlink points to an existing file or directory."
Path.expanduser(),"Return a new path with expanded ~ and ~user constructs,
as returned by os.path.expanduser():
>>> p = PosixPath('~/films/Monty Python')
>>> p.expanduser()
PosixPath('/home/eric/films/Monty Python')



New in version 3.5."
Path.glob(pattern),"Glob the given relative pattern in the directory represented by this path,
yielding all matching files (of any kind):
>>> sorted(Path('.').glob('*.py'))
[PosixPath('pathlib.py'), PosixPath('setup.py'), PosixPath('test_pathlib.py')]
>>> sorted(Path('.').glob('*/*.py'))
[PosixPath('docs/conf.py')]


The “**” pattern means “this directory and all subdirectories,
recursively”.  In other words, it enables recursive globbing:
>>> sorted(Path('.').glob('**/*.py'))
[PosixPath('build/lib/pathlib.py'),
 PosixPath('docs/conf.py'),
 PosixPath('pathlib.py'),
 PosixPath('setup.py'),
 PosixPath('test_pathlib.py')]



Note
Using the “**” pattern in large directory trees may consume
an inordinate amount of time."
Path.group(),"Return the name of the group owning the file.  KeyError is raised
if the file’s gid isn’t found in the system database."
Path.is_dir(),"Return True if the path points to a directory (or a symbolic link
pointing to a directory), False if it points to another kind of file.
False is also returned if the path doesn’t exist or is a broken symlink;
other errors (such as permission errors) are propagated."
Path.is_file(),"Return True if the path points to a regular file (or a symbolic link
pointing to a regular file), False if it points to another kind of file.
False is also returned if the path doesn’t exist or is a broken symlink;
other errors (such as permission errors) are propagated."
Path.is_mount(),"Return True if the path is a mount point: a point in a
file system where a different file system has been mounted.  On POSIX, the
function checks whether path’s parent, path/.., is on a different
device than path, or whether path/.. and path point to the same
i-node on the same device — this should detect mount points for all Unix
and POSIX variants.  Not implemented on Windows.

New in version 3.7."
Path.is_symlink(),"Return True if the path points to a symbolic link, False otherwise.
False is also returned if the path doesn’t exist; other errors (such
as permission errors) are propagated."
Path.is_socket(),"Return True if the path points to a Unix socket (or a symbolic link
pointing to a Unix socket), False if it points to another kind of file.
False is also returned if the path doesn’t exist or is a broken symlink;
other errors (such as permission errors) are propagated."
Path.is_fifo(),"Return True if the path points to a FIFO (or a symbolic link
pointing to a FIFO), False if it points to another kind of file.
False is also returned if the path doesn’t exist or is a broken symlink;
other errors (such as permission errors) are propagated."
Path.is_block_device(),"Return True if the path points to a block device (or a symbolic link
pointing to a block device), False if it points to another kind of file.
False is also returned if the path doesn’t exist or is a broken symlink;
other errors (such as permission errors) are propagated."
Path.is_char_device(),"Return True if the path points to a character device (or a symbolic link
pointing to a character device), False if it points to another kind of file.
False is also returned if the path doesn’t exist or is a broken symlink;
other errors (such as permission errors) are propagated."
Path.iterdir(),"When the path points to a directory, yield path objects of the directory
contents:
>>> p = Path('docs')
>>> for child in p.iterdir(): child
...
PosixPath('docs/conf.py')
PosixPath('docs/_templates')
PosixPath('docs/make.bat')
PosixPath('docs/index.rst')
PosixPath('docs/_build')
PosixPath('docs/_static')
PosixPath('docs/Makefile')"
Path.lchmod(mode),"Like Path.chmod() but, if the path points to a symbolic link, the
symbolic link’s mode is changed rather than its target’s."
Path.lstat(),"Like Path.stat() but, if the path points to a symbolic link, return
the symbolic link’s information rather than its target’s."
"Path.mkdir(mode=0o777, parents=False, exist_ok=False)","Create a new directory at this given path.  If mode is given, it is
combined with the process’ umask value to determine the file mode
and access flags.  If the path already exists, FileExistsError
is raised.
If parents is true, any missing parents of this path are created
as needed; they are created with the default permissions without taking
mode into account (mimicking the POSIX mkdir -p command).
If parents is false (the default), a missing parent raises
FileNotFoundError.
If exist_ok is false (the default), FileExistsError is
raised if the target directory already exists.
If exist_ok is true, FileExistsError exceptions will be
ignored (same behavior as the POSIX mkdir -p command), but only if the
last path component is not an existing non-directory file.

Changed in version 3.5: The exist_ok parameter was added."
"Path.open(mode='r', buffering=-1, encoding=None, errors=None, newline=None)","Open the file pointed to by the path, like the built-in open()
function does:
>>> p = Path('setup.py')
>>> with p.open() as f:
...     f.readline()
...
'#!/usr/bin/env python3\n'"
Path.owner(),"Return the name of the user owning the file.  KeyError is raised
if the file’s uid isn’t found in the system database."
Path.read_bytes(),"Return the binary contents of the pointed-to file as a bytes object:
>>> p = Path('my_binary_file')
>>> p.write_bytes(b'Binary file contents')
20
>>> p.read_bytes()
b'Binary file contents'



New in version 3.5."
"Path.read_text(encoding=None, errors=None)","Return the decoded contents of the pointed-to file as a string:
>>> p = Path('my_text_file')
>>> p.write_text('Text file contents')
18
>>> p.read_text()
'Text file contents'


The file is opened and then closed. The optional parameters have the same
meaning as in open().

New in version 3.5."
Path.rename(target),"Rename this file or directory to the given target, and return a new Path
instance pointing to target.  On Unix, if target exists and is a file,
it will be replaced silently if the user has permission.  target can be
either a string or another path object:
>>> p = Path('foo')
>>> p.open('w').write('some text')
9
>>> target = Path('bar')
>>> p.rename(target)
PosixPath('bar')
>>> target.open().read()
'some text'



Changed in version 3.8: Added return value, return the new Path instance."
Path.replace(target),"Rename this file or directory to the given target, and return a new Path
instance pointing to target.  If target points to an existing file or
directory, it will be unconditionally replaced.

Changed in version 3.8: Added return value, return the new Path instance."
Path.resolve(strict=False),"Make the path absolute, resolving any symlinks.  A new path object is
returned:
>>> p = Path()
>>> p
PosixPath('.')
>>> p.resolve()
PosixPath('/home/antoine/pathlib')


“..” components are also eliminated (this is the only method to do so):
>>> p = Path('docs/../setup.py')
>>> p.resolve()
PosixPath('/home/antoine/pathlib/setup.py')


If the path doesn’t exist and strict is True, FileNotFoundError
is raised.  If strict is False, the path is resolved as far as possible
and any remainder is appended without checking whether it exists.  If an
infinite loop is encountered along the resolution path, RuntimeError
is raised.

New in version 3.6: The strict argument (pre-3.6 behavior is strict)."
Path.rglob(pattern),"This is like calling Path.glob() with “**/” added in front of the
given relative pattern:
>>> sorted(Path().rglob(""*.py""))
[PosixPath('build/lib/pathlib.py'),
 PosixPath('docs/conf.py'),
 PosixPath('pathlib.py'),
 PosixPath('setup.py'),
 PosixPath('test_pathlib.py')]"
Path.rmdir(),Remove this directory.  The directory must be empty.
Path.samefile(other_path),"Return whether this path points to the same file as other_path, which
can be either a Path object, or a string.  The semantics are similar
to os.path.samefile() and os.path.samestat().
An OSError can be raised if either file cannot be accessed for some
reason.
>>> p = Path('spam')
>>> q = Path('eggs')
>>> p.samefile(q)
False
>>> p.samefile('spam')
True



New in version 3.5."
"Path.symlink_to(target, target_is_directory=False)","Make this path a symbolic link to target.  Under Windows,
target_is_directory must be true (default False) if the link’s target
is a directory.  Under POSIX, target_is_directory’s value is ignored.
>>> p = Path('mylink')
>>> p.symlink_to('setup.py')
>>> p.resolve()
PosixPath('/home/antoine/pathlib/setup.py')
>>> p.stat().st_size
956
>>> p.lstat().st_size
8



Note
The order of arguments (link, target) is the reverse
of os.symlink()’s."
"Path.touch(mode=0o666, exist_ok=True)","Create a file at this given path.  If mode is given, it is combined
with the process’ umask value to determine the file mode and access
flags.  If the file already exists, the function succeeds if exist_ok
is true (and its modification time is updated to the current time),
otherwise FileExistsError is raised."
Path.unlink(missing_ok=False),"Remove this file or symbolic link.  If the path points to a directory,
use Path.rmdir() instead.
If missing_ok is false (the default), FileNotFoundError is
raised if the path does not exist.
If missing_ok is true, FileNotFoundError exceptions will be
ignored (same behavior as the POSIX rm -f command).

Changed in version 3.8: The missing_ok parameter was added."
Path.link_to(target),"Create a hard link pointing to a path named target.

Changed in version 3.8."
Path.write_bytes(data),"Open the file pointed to in bytes mode, write data to it, and close the
file:
>>> p = Path('my_binary_file')
>>> p.write_bytes(b'Binary file contents')
20
>>> p.read_bytes()
b'Binary file contents'


An existing file of the same name is overwritten.

New in version 3.5."
"Path.write_text(data, encoding=None, errors=None)","Open the file pointed to in text mode, write data to it, and close the
file:
>>> p = Path('my_text_file')
>>> p.write_text('Text file contents')
18
>>> p.read_text()
'Text file contents'


An existing file of the same name is overwritten. The optional parameters
have the same meaning as in open().

New in version 3.5."
os.path.abspath(path),"Return a normalized absolutized version of the pathname path. On most
platforms, this is equivalent to calling the function normpath() as
follows: normpath(join(os.getcwd(), path)).

Changed in version 3.6: Accepts a path-like object."
os.path.basename(path),"Return the base name of pathname path.  This is the second element of the
pair returned by passing path to the function split().  Note that
the result of this function is different
from the Unix basename program; where basename for
'/foo/bar/' returns 'bar', the basename() function returns an
empty string ('').

Changed in version 3.6: Accepts a path-like object."
os.path.commonpath(paths),"Return the longest common sub-path of each pathname in the sequence
paths.  Raise ValueError if paths contain both absolute
and relative pathnames, the paths are on the different drives or
if paths is empty.  Unlike commonprefix(), this returns a
valid path.
Availability: Unix, Windows.

New in version 3.5.


Changed in version 3.6: Accepts a sequence of path-like objects."
os.path.commonprefix(list),"Return the longest path prefix (taken character-by-character) that is a
prefix of all paths in  list.  If list is empty, return the empty string
('').

Note
This function may return invalid paths because it works a
character at a time.  To obtain a valid path, see
commonpath().
>>> os.path.commonprefix(['/usr/lib', '/usr/local/lib'])
'/usr/l'

>>> os.path.commonpath(['/usr/lib', '/usr/local/lib'])
'/usr'




Changed in version 3.6: Accepts a path-like object."
os.path.dirname(path),"Return the directory name of pathname path.  This is the first element of
the pair returned by passing path to the function split().

Changed in version 3.6: Accepts a path-like object."
os.path.exists(path),"Return True if path refers to an existing path or an open
file descriptor.  Returns False for broken symbolic links.  On
some platforms, this function may return False if permission is
not granted to execute os.stat() on the requested file, even
if the path physically exists.

Changed in version 3.3: path can now be an integer: True is returned if it is an
 open file descriptor, False otherwise.


Changed in version 3.6: Accepts a path-like object."
os.path.lexists(path),"Return True if path refers to an existing path. Returns True for
broken symbolic links.   Equivalent to exists() on platforms lacking
os.lstat().

Changed in version 3.6: Accepts a path-like object."
os.path.expanduser(path),"On Unix and Windows, return the argument with an initial component of ~ or
~user replaced by that user’s home directory.
On Unix, an initial ~ is replaced by the environment variable HOME
if it is set; otherwise the current user’s home directory is looked up in the
password directory through the built-in module pwd. An initial ~user
is looked up directly in the password directory.
On Windows, USERPROFILE will be used if set, otherwise a combination
of HOMEPATH and HOMEDRIVE will be used.  An initial
~user is handled by stripping the last directory component from the created
user path derived above.
If the expansion fails or if the path does not begin with a tilde, the path is
returned unchanged.

Changed in version 3.6: Accepts a path-like object.


Changed in version 3.8: No longer uses HOME on Windows."
os.path.expandvars(path),"Return the argument with environment variables expanded.  Substrings of the form
$name or ${name} are replaced by the value of environment variable
name.  Malformed variable names and references to non-existing variables are
left unchanged.
On Windows, %name% expansions are supported in addition to $name and
${name}.

Changed in version 3.6: Accepts a path-like object."
os.path.getatime(path),"Return the time of last access of path.  The return value is a floating point number giving
the number of seconds since the epoch (see the  time module).  Raise
OSError if the file does not exist or is inaccessible."
os.path.getmtime(path),"Return the time of last modification of path.  The return value is a floating point number
giving the number of seconds since the epoch (see the  time module).
Raise OSError if the file does not exist or is inaccessible.

Changed in version 3.6: Accepts a path-like object."
os.path.getctime(path),"Return the system’s ctime which, on some systems (like Unix) is the time of the
last metadata change, and, on others (like Windows), is the creation time for path.
The return value is a number giving the number of seconds since the epoch (see
the  time module).  Raise OSError if the file does not exist or
is inaccessible.

Changed in version 3.6: Accepts a path-like object."
os.path.getsize(path),"Return the size, in bytes, of path.  Raise OSError if the file does
not exist or is inaccessible.

Changed in version 3.6: Accepts a path-like object."
os.path.isabs(path),"Return True if path is an absolute pathname.  On Unix, that means it
begins with a slash, on Windows that it begins with a (back)slash after chopping
off a potential drive letter.

Changed in version 3.6: Accepts a path-like object."
os.path.isfile(path),"Return True if path is an existing regular file.
This follows symbolic links, so both islink() and isfile() can
be true for the same path.

Changed in version 3.6: Accepts a path-like object."
os.path.isdir(path),"Return True if path is an existing directory.  This
follows symbolic links, so both islink() and isdir() can be true
for the same path.

Changed in version 3.6: Accepts a path-like object."
os.path.islink(path),"Return True if path refers to an existing directory
entry that is a symbolic link.  Always False if symbolic links are not
supported by the Python runtime.

Changed in version 3.6: Accepts a path-like object."
os.path.ismount(path),"Return True if pathname path is a mount point: a point in a
file system where a different file system has been mounted.  On POSIX, the
function checks whether path’s parent, path/.., is on a different
device than path, or whether path/.. and path point to the same
i-node on the same device — this should detect mount points for all Unix
and POSIX variants.  It is not able to reliably detect bind mounts on the
same filesystem.  On Windows, a drive letter root and a share UNC are
always mount points, and for any other path GetVolumePathName is called
to see if it is different from the input path.

New in version 3.4: Support for detecting non-root mount points on Windows.


Changed in version 3.6: Accepts a path-like object."
"os.path.join(path, *paths)","Join one or more path components intelligently.  The return value is the
concatenation of path and any members of *paths with exactly one
directory separator (os.sep) following each non-empty part except the
last, meaning that the result will only end in a separator if the last
part is empty.  If a component is an absolute path, all previous
components are thrown away and joining continues from the absolute path
component.
On Windows, the drive letter is not reset when an absolute path component
(e.g., r'\foo') is encountered.  If a component contains a drive
letter, all previous components are thrown away and the drive letter is
reset.  Note that since there is a current directory for each drive,
os.path.join(""c:"", ""foo"") represents a path relative to the current
directory on drive C: (c:foo), not c:\foo.

Changed in version 3.6: Accepts a path-like object for path and paths."
os.path.normcase(path),"Normalize the case of a pathname.  On Windows, convert all characters in the
pathname to lowercase, and also convert forward slashes to backward slashes.
On other operating systems, return the path unchanged.

Changed in version 3.6: Accepts a path-like object."
os.path.normpath(path),"Normalize a pathname by collapsing redundant separators and up-level
references so that A//B, A/B/, A/./B and A/foo/../B all
become A/B.  This string manipulation may change the meaning of a path
that contains symbolic links.  On Windows, it converts forward slashes to
backward slashes. To normalize case, use normcase().

Changed in version 3.6: Accepts a path-like object."
os.path.realpath(path),"Return the canonical path of the specified filename, eliminating any symbolic
links encountered in the path (if they are supported by the operating
system).

Note
When symbolic link cycles occur, the returned path will be one member of
the cycle, but no guarantee is made about which member that will be.


Changed in version 3.6: Accepts a path-like object.


Changed in version 3.8: Symbolic links and junctions are now resolved on Windows."
"os.path.relpath(path, start=os.curdir)","Return a relative filepath to path either from the current directory or
from an optional start directory.  This is a path computation:  the
filesystem is not accessed to confirm the existence or nature of path or
start.
start defaults to os.curdir.
Availability: Unix, Windows.

Changed in version 3.6: Accepts a path-like object."
"os.path.samefile(path1, path2)","Return True if both pathname arguments refer to the same file or directory.
This is determined by the device number and i-node number and raises an
exception if an os.stat() call on either pathname fails.
Availability: Unix, Windows.

Changed in version 3.2: Added Windows support.


Changed in version 3.4: Windows now uses the same implementation as all other platforms.


Changed in version 3.6: Accepts a path-like object."
"os.path.sameopenfile(fp1, fp2)","Return True if the file descriptors fp1 and fp2 refer to the same file.
Availability: Unix, Windows.

Changed in version 3.2: Added Windows support.


Changed in version 3.6: Accepts a path-like object."
"os.path.samestat(stat1, stat2)","Return True if the stat tuples stat1 and stat2 refer to the same file.
These structures may have been returned by os.fstat(),
os.lstat(), or os.stat().  This function implements the
underlying comparison used by samefile() and sameopenfile().
Availability: Unix, Windows.

Changed in version 3.4: Added Windows support.


Changed in version 3.6: Accepts a path-like object."
os.path.split(path),"Split the pathname path into a pair, (head, tail) where tail is the
last pathname component and head is everything leading up to that.  The
tail part will never contain a slash; if path ends in a slash, tail
will be empty.  If there is no slash in path, head will be empty.  If
path is empty, both head and tail are empty.  Trailing slashes are
stripped from head unless it is the root (one or more slashes only).  In
all cases, join(head, tail) returns a path to the same location as path
(but the strings may differ).  Also see the functions dirname() and
basename().

Changed in version 3.6: Accepts a path-like object."
os.path.splitdrive(path),"Split the pathname path into a pair (drive, tail) where drive is either
a mount point or the empty string.  On systems which do not use drive
specifications, drive will always be the empty string.  In all cases, drive
+ tail will be the same as path.
On Windows, splits a pathname into drive/UNC sharepoint and relative path.
If the path contains a drive letter, drive will contain everything
up to and including the colon.
e.g. splitdrive(""c:/dir"") returns (""c:"", ""/dir"")
If the path contains a UNC path, drive will contain the host name
and share, up to but not including the fourth separator.
e.g. splitdrive(""//host/computer/dir"") returns (""//host/computer"", ""/dir"")

Changed in version 3.6: Accepts a path-like object."
os.path.splitext(path),"Split the pathname path into a pair (root, ext)  such that root + ext ==
path, and ext is empty or begins with a period and contains at most one
period. Leading periods on the basename are  ignored; splitext('.cshrc')
returns  ('.cshrc', '').

Changed in version 3.6: Accepts a path-like object."
"fileinput.input(files=None, inplace=False, backup='', *, mode='r', openhook=None)","Create an instance of the FileInput class.  The instance will be used
as global state for the functions of this module, and is also returned to use
during iteration.  The parameters to this function will be passed along to the
constructor of the FileInput class.
The FileInput instance can be used as a context manager in the
with statement.  In this example, input is closed after the
with statement is exited, even if an exception occurs:
with fileinput.input(files=('spam.txt', 'eggs.txt')) as f:
    for line in f:
        process(line)



Changed in version 3.2: Can be used as a context manager.


Changed in version 3.8: The keyword parameters mode and openhook are now keyword-only."
fileinput.filename(),"Return the name of the file currently being read.  Before the first line has
been read, returns None."
fileinput.fileno(),"Return the integer “file descriptor” for the current file. When no file is
opened (before the first line and between files), returns -1."
fileinput.lineno(),"Return the cumulative line number of the line that has just been read.  Before
the first line has been read, returns 0.  After the last line of the last
file has been read, returns the line number of that line."
fileinput.filelineno(),"Return the line number in the current file.  Before the first line has been
read, returns 0.  After the last line of the last file has been read,
returns the line number of that line within the file."
fileinput.isfirstline(),"Return True if the line just read is the first line of its file, otherwise
return False."
fileinput.isstdin(),"Return True if the last line was read from sys.stdin, otherwise return
False."
fileinput.nextfile(),"Close the current file so that the next iteration will read the first line from
the next file (if any); lines not read from the file will not count towards the
cumulative line count.  The filename is not changed until after the first line
of the next file has been read.  Before the first line has been read, this
function has no effect; it cannot be used to skip the first file.  After the
last line of the last file has been read, this function has no effect."
fileinput.close(),Close the sequence.
"fileinput.hook_compressed(filename, mode)","Transparently opens files compressed with gzip and bzip2 (recognized by the
extensions '.gz' and '.bz2') using the gzip and bz2
modules.  If the filename extension is not '.gz' or '.bz2', the file is
opened normally (ie, using open() without any decompression).
Usage example:  fi = fileinput.FileInput(openhook=fileinput.hook_compressed)"
"fileinput.hook_encoded(encoding, errors=None)","Returns a hook which opens each file with open(), using the given
encoding and errors to read the file.
Usage example: fi =
fileinput.FileInput(openhook=fileinput.hook_encoded(""utf-8"",
""surrogateescape""))

Changed in version 3.6: Added the optional errors parameter."
stat.S_ISDIR(mode),Return non-zero if the mode is from a directory.
stat.S_ISCHR(mode),Return non-zero if the mode is from a character special device file.
stat.S_ISBLK(mode),Return non-zero if the mode is from a block special device file.
stat.S_ISREG(mode),Return non-zero if the mode is from a regular file.
stat.S_ISFIFO(mode),Return non-zero if the mode is from a FIFO (named pipe).
stat.S_ISLNK(mode),Return non-zero if the mode is from a symbolic link.
stat.S_ISSOCK(mode),Return non-zero if the mode is from a socket.
stat.S_ISDOOR(mode),"Return non-zero if the mode is from a door.

New in version 3.4."
stat.S_ISPORT(mode),"Return non-zero if the mode is from an event port.

New in version 3.4."
stat.S_ISWHT(mode),"Return non-zero if the mode is from a whiteout.

New in version 3.4."
stat.S_IMODE(mode),"Return the portion of the file’s mode that can be set by
os.chmod()—that is, the file’s permission bits, plus the sticky
bit, set-group-id, and set-user-id bits (on systems that support them)."
stat.S_IFMT(mode),"Return the portion of the file’s mode that describes the file type (used by the
S_IS*() functions above)."
stat.filemode(mode),"Convert a file’s mode to a string of the form ‘-rwxrwxrwx’.

New in version 3.3.


Changed in version 3.4: The function supports S_IFDOOR, S_IFPORT and
S_IFWHT."
"filecmp.cmp(f1, f2, shallow=True)","Compare the files named f1 and f2, returning True if they seem equal,
False otherwise.
If shallow is true, files with identical os.stat() signatures are
taken to be equal.  Otherwise, the contents of the files are compared.
Note that no external programs are called from this function, giving it
portability and efficiency.
This function uses a cache for past comparisons and the results,
with cache entries invalidated if the os.stat() information for the
file changes.  The entire cache may be cleared using clear_cache()."
"filecmp.cmpfiles(dir1, dir2, common, shallow=True)","Compare the files in the two directories dir1 and dir2 whose names are
given by common.
Returns three lists of file names: match, mismatch,
errors.  match contains the list of files that match, mismatch contains
the names of those that don’t, and errors lists the names of files which
could not be compared.  Files are listed in errors if they don’t exist in
one of the directories, the user lacks permission to read them or if the
comparison could not be done for some other reason.
The shallow parameter has the same meaning and default value as for
filecmp.cmp().
For example, cmpfiles('a', 'b', ['c', 'd/e']) will compare a/c with
b/c and a/d/e with b/d/e.  'c' and 'd/e' will each be in
one of the three returned lists."
filecmp.clear_cache(),"Clear the filecmp cache. This may be useful if a file is compared so quickly
after it is modified that it is within the mtime resolution of
the underlying filesystem.

New in version 3.4."
report(),Print (to sys.stdout) a comparison between a and b.
report_partial_closure(),"Print a comparison between a and b and common immediate
subdirectories."
report_full_closure(),"Print a comparison between a and b and common subdirectories
(recursively)."
"tempfile.TemporaryFile(mode='w+b', buffering=None, encoding=None, newline=None, suffix=None, prefix=None, dir=None, *, errors=None)","Return a file-like object that can be used as a temporary storage area.
The file is created securely, using the same rules as mkstemp(). It will be destroyed as soon
as it is closed (including an implicit close when the object is garbage
collected).  Under Unix, the directory entry for the file is either not created at all or is removed
immediately after the file is created.  Other platforms do not support
this; your code should not rely on a temporary file created using this
function having or not having a visible name in the file system.
The resulting object can be used as a context manager (see
Examples).  On completion of the context or
destruction of the file object the temporary file will be removed
from the filesystem.
The mode parameter defaults to 'w+b' so that the file created can
be read and written without being closed.  Binary mode is used so that it
behaves consistently on all platforms without regard for the data that is
stored.  buffering, encoding, errors and newline are interpreted as for
open().
The dir, prefix and suffix parameters have the same meaning and
defaults as with mkstemp().
The returned object is a true file object on POSIX platforms.  On other
platforms, it is a file-like object whose file attribute is the
underlying true file object.
The os.O_TMPFILE flag is used if it is available and works
(Linux-specific, requires Linux kernel 3.11 or later).
Raises an auditing event tempfile.mkstemp with argument fullpath.

Changed in version 3.5: The os.O_TMPFILE flag is now used if available.


Changed in version 3.8: Added errors parameter."
"tempfile.NamedTemporaryFile(mode='w+b', buffering=None, encoding=None, newline=None, suffix=None, prefix=None, dir=None, delete=True, *, errors=None)","This function operates exactly as TemporaryFile() does, except that
the file is guaranteed to have a visible name in the file system (on
Unix, the directory entry is not unlinked).  That name can be retrieved
from the name attribute of the returned
file-like object.  Whether the name can be
used to open the file a second time, while the named temporary file is
still open, varies across platforms (it can be so used on Unix; it cannot
on Windows NT or later).  If delete is true (the default), the file is
deleted as soon as it is closed.
The returned object is always a file-like object whose file
attribute is the underlying true file object. This file-like object can
be used in a with statement, just like a normal file.
Raises an auditing event tempfile.mkstemp with argument fullpath.

Changed in version 3.8: Added errors parameter."
"tempfile.SpooledTemporaryFile(max_size=0, mode='w+b', buffering=None, encoding=None, newline=None, suffix=None, prefix=None, dir=None, *, errors=None)","This function operates exactly as TemporaryFile() does, except that
data is spooled in memory until the file size exceeds max_size, or
until the file’s fileno() method is called, at which point the
contents are written to disk and operation proceeds as with
TemporaryFile().
The resulting file has one additional method, rollover(), which
causes the file to roll over to an on-disk file regardless of its size.
The returned object is a file-like object whose _file attribute
is either an io.BytesIO or io.TextIOWrapper object
(depending on whether binary or text mode was specified) or a true file
object, depending on whether rollover() has been called.  This
file-like object can be used in a with statement, just like
a normal file.

Changed in version 3.3: the truncate method now accepts a size argument.


Changed in version 3.8: Added errors parameter."
"tempfile.TemporaryDirectory(suffix=None, prefix=None, dir=None)","This function securely creates a temporary directory using the same rules as mkdtemp().
The resulting object can be used as a context manager (see
Examples).  On completion of the context or destruction
of the temporary directory object the newly created temporary directory
and all its contents are removed from the filesystem.
The directory name can be retrieved from the name attribute of the
returned object.  When the returned object is used as a context manager, the
name will be assigned to the target of the as clause in
the with statement, if there is one.
The directory can be explicitly cleaned up by calling the
cleanup() method.
Raises an auditing event tempfile.mkdtemp with argument fullpath.

New in version 3.2."
"tempfile.mkstemp(suffix=None, prefix=None, dir=None, text=False)","Creates a temporary file in the most secure manner possible.  There are
no race conditions in the file’s creation, assuming that the platform
properly implements the os.O_EXCL flag for os.open().  The
file is readable and writable only by the creating user ID.  If the
platform uses permission bits to indicate whether a file is executable,
the file is executable by no one.  The file descriptor is not inherited
by child processes.
Unlike TemporaryFile(), the user of mkstemp() is responsible
for deleting the temporary file when done with it.
If suffix is not None, the file name will end with that suffix,
otherwise there will be no suffix.  mkstemp() does not put a dot
between the file name and the suffix; if you need one, put it at the
beginning of suffix.
If prefix is not None, the file name will begin with that prefix;
otherwise, a default prefix is used.  The default is the return value of
gettempprefix() or gettempprefixb(), as appropriate.
If dir is not None, the file will be created in that directory;
otherwise, a default directory is used.  The default directory is chosen
from a platform-dependent list, but the user of the application can
control the directory location by setting the TMPDIR, TEMP or TMP
environment variables.  There is thus no guarantee that the generated
filename will have any nice properties, such as not requiring quoting
when passed to external commands via os.popen().
If any of suffix, prefix, and dir are not
None, they must be the same type.
If they are bytes, the returned name will be bytes instead of str.
If you want to force a bytes return value with otherwise default behavior,
pass suffix=b''.
If text is specified, it indicates whether to open the file in binary
mode (the default) or text mode.  On some platforms, this makes no
difference.
mkstemp() returns a tuple containing an OS-level handle to an open
file (as would be returned by os.open()) and the absolute pathname
of that file, in that order.
Raises an auditing event tempfile.mkstemp with argument fullpath.

Changed in version 3.5: suffix, prefix, and dir may now be supplied in bytes in order to
obtain a bytes return value.  Prior to this, only str was allowed.
suffix and prefix now accept and default to None to cause
an appropriate default value to be used.


Changed in version 3.6: The dir parameter now accepts a path-like object."
"tempfile.mkdtemp(suffix=None, prefix=None, dir=None)","Creates a temporary directory in the most secure manner possible. There
are no race conditions in the directory’s creation.  The directory is
readable, writable, and searchable only by the creating user ID.
The user of mkdtemp() is responsible for deleting the temporary
directory and its contents when done with it.
The prefix, suffix, and dir arguments are the same as for
mkstemp().
mkdtemp() returns the absolute pathname of the new directory.
Raises an auditing event tempfile.mkdtemp with argument fullpath.

Changed in version 3.5: suffix, prefix, and dir may now be supplied in bytes in order to
obtain a bytes return value.  Prior to this, only str was allowed.
suffix and prefix now accept and default to None to cause
an appropriate default value to be used.


Changed in version 3.6: The dir parameter now accepts a path-like object."
tempfile.gettempdir(),"Return the name of the directory used for temporary files. This
defines the default value for the dir argument to all functions
in this module.
Python searches a standard list of directories to find one which
the calling user can create files in.  The list is:

The directory named by the TMPDIR environment variable.
The directory named by the TEMP environment variable.
The directory named by the TMP environment variable.
A platform-specific location:

On Windows, the directories C:\TEMP, C:\TMP,
\TEMP, and \TMP, in that order.
On all other platforms, the directories /tmp, /var/tmp, and
/usr/tmp, in that order.


As a last resort, the current working directory.

The result of this search is cached, see the description of
tempdir below."
tempfile.gettempdirb(),"Same as gettempdir() but the return value is in bytes.

New in version 3.5."
tempfile.gettempprefix(),"Return the filename prefix used to create temporary files.  This does not
contain the directory component."
tempfile.gettempprefixb(),"Same as gettempprefix() but the return value is in bytes.

New in version 3.5."
"tempfile.mktemp(suffix='', prefix='tmp', dir=None)","Deprecated since version 2.3: Use mkstemp() instead.

Return an absolute pathname of a file that did not exist at the time the
call is made.  The prefix, suffix, and dir arguments are similar
to those of mkstemp(), except that bytes file names, suffix=None
and prefix=None are not supported.

Warning
Use of this function may introduce a security hole in your program.  By
the time you get around to doing anything with the file name it returns,
someone else may have beaten you to the punch.  mktemp() usage can
be replaced easily with NamedTemporaryFile(), passing it the
delete=False parameter:
>>> f = NamedTemporaryFile(delete=False)
>>> f.name
'/tmp/tmptjujjt'
>>> f.write(b""Hello World!\n"")
13
>>> f.close()
>>> os.unlink(f.name)
>>> os.path.exists(f.name)
False"
"glob.glob(pathname, *, recursive=False)","Return a possibly-empty list of path names that match pathname, which must be
a string containing a path specification. pathname can be either absolute
(like /usr/src/Python-1.5/Makefile) or relative (like
../../Tools/*/*.gif), and can contain shell-style wildcards. Broken
symlinks are included in the results (as in the shell). Whether or not the
results are sorted depends on the file system.
If recursive is true, the pattern “**” will match any files and zero or
more directories, subdirectories and symbolic links to directories. If the
pattern is followed by an os.sep or os.altsep then files will not
match.
Raises an auditing event glob.glob with arguments pathname, recursive.

Note
Using the “**” pattern in large directory trees may consume
an inordinate amount of time.


Changed in version 3.5: Support for recursive globs using “**”."
"glob.iglob(pathname, *, recursive=False)","Return an iterator which yields the same values as glob()
without actually storing them all simultaneously.
Raises an auditing event glob.glob with arguments pathname, recursive."
glob.escape(pathname),"Escape all special characters ('?', '*' and '[').
This is useful if you want to match an arbitrary literal string that may
have special characters in it.  Special characters in drive/UNC
sharepoints are not escaped, e.g. on Windows
escape('//?/c:/Quo vadis?.txt') returns '//?/c:/Quo vadis[?].txt'.

New in version 3.4."
"fnmatch.fnmatch(filename, pattern)","Test whether the filename string matches the pattern string, returning
True or False.  Both parameters are case-normalized
using os.path.normcase(). fnmatchcase() can be used to perform a
case-sensitive comparison, regardless of whether that’s standard for the
operating system.
This example will print all file names in the current directory with the
extension .txt:
import fnmatch
import os

for file in os.listdir('.'):
    if fnmatch.fnmatch(file, '*.txt'):
        print(file)"
"fnmatch.fnmatchcase(filename, pattern)","Test whether filename matches pattern, returning True or
False; the comparison is case-sensitive and does not apply
os.path.normcase()."
"fnmatch.filter(names, pattern)","Return the subset of the list of names that match pattern. It is the same as
[n for n in names if fnmatch(n, pattern)], but implemented more efficiently."
fnmatch.translate(pattern),"Return the shell-style pattern converted to a regular expression for
using with re.match().
Example:
>>> import fnmatch, re
>>>
>>> regex = fnmatch.translate('*.txt')
>>> regex
'(?s:.*\\.txt)\\Z'
>>> reobj = re.compile(regex)
>>> reobj.match('foobar.txt')
<re.Match object; span=(0, 10), match='foobar.txt'>"
"linecache.getline(filename, lineno, module_globals=None)","Get line lineno from file named filename. This function will never raise an
exception — it will return '' on errors (the terminating newline character
will be included for lines that are found).
If a file named filename is not found, the function first checks
for a PEP 302 __loader__ in module_globals.
If there is such a loader and it defines a get_source method,
then that determines the source lines
(if get_source() returns None, then '' is returned).
Finally, if filename is a relative filename,
it is looked up relative to the entries in the module search path, sys.path."
linecache.clearcache(),"Clear the cache.  Use this function if you no longer need lines from files
previously read using getline()."
linecache.checkcache(filename=None),"Check the cache for validity.  Use this function if files in the cache  may have
changed on disk, and you require the updated version.  If filename is omitted,
it will check all the entries in the cache."
"linecache.lazycache(filename, module_globals)","Capture enough detail about a non-file-based module to permit getting its
lines later via getline() even if module_globals is None in the later
call. This avoids doing I/O until a line is actually needed, without having
to carry the module globals around indefinitely.

New in version 3.5."
"shutil.copyfileobj(fsrc, fdst[, length])","Copy the contents of the file-like object fsrc to the file-like object fdst.
The integer length, if given, is the buffer size. In particular, a negative
length value means to copy the data without looping over the source data in
chunks; by default the data is read in chunks to avoid uncontrolled memory
consumption. Note that if the current file position of the fsrc object is not
0, only the contents from the current file position to the end of the file will
be copied."
"shutil.copyfile(src, dst, *, follow_symlinks=True)","Copy the contents (no metadata) of the file named src to a file named
dst and return dst in the most efficient way possible.
src and dst are path-like objects or path names given as strings.
dst must be the complete target file name; look at copy()
for a copy that accepts a target directory path.  If src and dst
specify the same file, SameFileError is raised.
The destination location must be writable; otherwise, an OSError
exception will be raised. If dst already exists, it will be replaced.
Special files such as character or block devices and pipes cannot be
copied with this function.
If follow_symlinks is false and src is a symbolic link,
a new symbolic link will be created instead of copying the
file src points to.
Raises an auditing event shutil.copyfile with arguments src, dst.

Changed in version 3.3: IOError used to be raised instead of OSError.
Added follow_symlinks argument.
Now returns dst.


Changed in version 3.4: Raise SameFileError instead of Error.  Since the former is
a subclass of the latter, this change is backward compatible.


Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to
copy the file more efficiently. See
Platform-dependent efficient copy operations section."
"shutil.copymode(src, dst, *, follow_symlinks=True)","Copy the permission bits from src to dst.  The file contents, owner, and
group are unaffected.  src and dst are path-like objects or path names
given as strings.
If follow_symlinks is false, and both src and dst are symbolic links,
copymode() will attempt to modify the mode of dst itself (rather
than the file it points to).  This functionality is not available on every
platform; please see copystat() for more information.  If
copymode() cannot modify symbolic links on the local platform, and it
is asked to do so, it will do nothing and return.
Raises an auditing event shutil.copymode with arguments src, dst.

Changed in version 3.3: Added follow_symlinks argument."
"shutil.copystat(src, dst, *, follow_symlinks=True)","Copy the permission bits, last access time, last modification time, and
flags from src to dst.  On Linux, copystat() also copies the
“extended attributes” where possible.  The file contents, owner, and
group are unaffected.  src and dst are path-like objects or path
names given as strings.
If follow_symlinks is false, and src and dst both
refer to symbolic links, copystat() will operate on
the symbolic links themselves rather than the files the
symbolic links refer to—reading the information from the
src symbolic link, and writing the information to the
dst symbolic link.

Note
Not all platforms provide the ability to examine and
modify symbolic links.  Python itself can tell you what
functionality is locally available.

If os.chmod in os.supports_follow_symlinks is
True, copystat() can modify the permission
bits of a symbolic link.
If os.utime in os.supports_follow_symlinks is
True, copystat() can modify the last access
and modification times of a symbolic link.
If os.chflags in os.supports_follow_symlinks is
True, copystat() can modify the flags of
a symbolic link.  (os.chflags is not available on
all platforms.)

On platforms where some or all of this functionality
is unavailable, when asked to modify a symbolic link,
copystat() will copy everything it can.
copystat() never returns failure.
Please see os.supports_follow_symlinks
for more information.

Raises an auditing event shutil.copystat with arguments src, dst.

Changed in version 3.3: Added follow_symlinks argument and support for Linux extended attributes."
"shutil.copy(src, dst, *, follow_symlinks=True)","Copies the file src to the file or directory dst.  src and dst
should be strings.  If dst specifies a directory, the file will be
copied into dst using the base filename from src.  Returns the
path to the newly created file.
If follow_symlinks is false, and src is a symbolic link,
dst will be created as a symbolic link.  If follow_symlinks
is true and src is a symbolic link, dst will be a copy of
the file src refers to.
copy() copies the file data and the file’s permission
mode (see os.chmod()).  Other metadata, like the
file’s creation and modification times, is not preserved.
To preserve all file metadata from the original, use
copy2() instead.
Raises an auditing event shutil.copyfile with arguments src, dst.
Raises an auditing event shutil.copymode with arguments src, dst.

Changed in version 3.3: Added follow_symlinks argument.
Now returns path to the newly created file.


Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to
copy the file more efficiently. See
Platform-dependent efficient copy operations section."
"shutil.copy2(src, dst, *, follow_symlinks=True)","Identical to copy() except that copy2()
also attempts to preserve file metadata.
When follow_symlinks is false, and src is a symbolic
link, copy2() attempts to copy all metadata from the
src symbolic link to the newly-created dst symbolic link.
However, this functionality is not available on all platforms.
On platforms where some or all of this functionality is
unavailable, copy2() will preserve all the metadata
it can; copy2() never raises an exception because it
cannot preserve file metadata.
copy2() uses copystat() to copy the file metadata.
Please see copystat() for more information
about platform support for modifying symbolic link metadata.
Raises an auditing event shutil.copyfile with arguments src, dst.
Raises an auditing event shutil.copystat with arguments src, dst.

Changed in version 3.3: Added follow_symlinks argument, try to copy extended
file system attributes too (currently Linux only).
Now returns path to the newly created file.


Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to
copy the file more efficiently. See
Platform-dependent efficient copy operations section."
shutil.ignore_patterns(*patterns),"This factory function creates a function that can be used as a callable for
copytree()’s ignore argument, ignoring files and directories that
match one of the glob-style patterns provided.  See the example below."
"shutil.copytree(src, dst, symlinks=False, ignore=None, copy_function=copy2, ignore_dangling_symlinks=False, dirs_exist_ok=False)","Recursively copy an entire directory tree rooted at src to a directory
named dst and return the destination directory. dirs_exist_ok dictates
whether to raise an exception in case dst or any missing parent directory
already exists.
Permissions and times of directories are copied with copystat(),
individual files are copied using copy2().
If symlinks is true, symbolic links in the source tree are represented as
symbolic links in the new tree and the metadata of the original links will
be copied as far as the platform allows; if false or omitted, the contents
and metadata of the linked files are copied to the new tree.
When symlinks is false, if the file pointed by the symlink doesn’t
exist, an exception will be added in the list of errors raised in
an Error exception at the end of the copy process.
You can set the optional ignore_dangling_symlinks flag to true if you
want to silence this exception. Notice that this option has no effect
on platforms that don’t support os.symlink().
If ignore is given, it must be a callable that will receive as its
arguments the directory being visited by copytree(), and a list of its
contents, as returned by os.listdir().  Since copytree() is
called recursively, the ignore callable will be called once for each
directory that is copied.  The callable must return a sequence of directory
and file names relative to the current directory (i.e. a subset of the items
in its second argument); these names will then be ignored in the copy
process.  ignore_patterns() can be used to create such a callable that
ignores names based on glob-style patterns.
If exception(s) occur, an Error is raised with a list of reasons.
If copy_function is given, it must be a callable that will be used to copy
each file. It will be called with the source path and the destination path
as arguments. By default, copy2() is used, but any function
that supports the same signature (like copy()) can be used.
Raises an auditing event shutil.copytree with arguments src, dst.

Changed in version 3.3: Copy metadata when symlinks is false.
Now returns dst.


Changed in version 3.2: Added the copy_function argument to be able to provide a custom copy
function.
Added the ignore_dangling_symlinks argument to silent dangling symlinks
errors when symlinks is false.


Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to
copy the file more efficiently. See
Platform-dependent efficient copy operations section.


New in version 3.8: The dirs_exist_ok parameter."
"shutil.rmtree(path, ignore_errors=False, onerror=None)","Delete an entire directory tree; path must point to a directory (but not a
symbolic link to a directory).  If ignore_errors is true, errors resulting
from failed removals will be ignored; if false or omitted, such errors are
handled by calling a handler specified by onerror or, if that is omitted,
they raise an exception.

Note
On platforms that support the necessary fd-based functions a symlink
attack resistant version of rmtree() is used by default.  On other
platforms, the rmtree() implementation is susceptible to a symlink
attack: given proper timing and circumstances, attackers can manipulate
symlinks on the filesystem to delete files they wouldn’t be able to access
otherwise.  Applications can use the rmtree.avoids_symlink_attacks
function attribute to determine which case applies.

If onerror is provided, it must be a callable that accepts three
parameters: function, path, and excinfo.
The first parameter, function, is the function which raised the exception;
it depends on the platform and implementation.  The second parameter,
path, will be the path name passed to function.  The third parameter,
excinfo, will be the exception information returned by
sys.exc_info().  Exceptions raised by onerror will not be caught.
Raises an auditing event shutil.rmtree with argument path.

Changed in version 3.3: Added a symlink attack resistant version that is used automatically
if platform supports fd-based functions.


Changed in version 3.8: On Windows, will no longer delete the contents of a directory junction
before removing the junction.



rmtree.avoids_symlink_attacks¶
Indicates whether the current platform and implementation provides a
symlink attack resistant version of rmtree().  Currently this is
only true for platforms supporting fd-based directory access functions.

New in version 3.3."
"shutil.move(src, dst, copy_function=copy2)","Recursively move a file or directory (src) to another location (dst)
and return the destination.
If the destination is an existing directory, then src is moved inside that
directory. If the destination already exists but is not a directory, it may
be overwritten depending on os.rename() semantics.
If the destination is on the current filesystem, then os.rename() is
used. Otherwise, src is copied to dst using copy_function and then
removed.  In case of symlinks, a new symlink pointing to the target of src
will be created in or as dst and src will be removed.
If copy_function is given, it must be a callable that takes two arguments
src and dst, and will be used to copy src to dest if
os.rename() cannot be used.  If the source is a directory,
copytree() is called, passing it the copy_function(). The
default copy_function is copy2().  Using copy() as the
copy_function allows the move to succeed when it is not possible to also
copy the metadata, at the expense of not copying any of the metadata.
Raises an auditing event shutil.move with arguments src, dst.

Changed in version 3.3: Added explicit symlink handling for foreign filesystems, thus adapting
it to the behavior of GNU’s mv.
Now returns dst.


Changed in version 3.5: Added the copy_function keyword argument.


Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to
copy the file more efficiently. See
Platform-dependent efficient copy operations section."
shutil.disk_usage(path),"Return disk usage statistics about the given path as a named tuple
with the attributes total, used and free, which are the amount of
total, used and free space, in bytes. path may be a file or a
directory.

New in version 3.3.


Changed in version 3.8: On Windows, path can now be a file or directory.

Availability: Unix, Windows."
"shutil.chown(path, user=None, group=None)","Change owner user and/or group of the given path.
user can be a system user name or a uid; the same applies to group. At
least one argument is required.
See also os.chown(), the underlying function.
Raises an auditing event shutil.chown with arguments path, user, group.
Availability: Unix.

New in version 3.3."
"shutil.which(cmd, mode=os.F_OK | os.X_OK, path=None)","Return the path to an executable which would be run if the given cmd was
called.  If no cmd would be called, return None.
mode is a permission mask passed to os.access(), by default
determining if the file exists and executable.
When no path is specified, the results of os.environ() are used,
returning either the “PATH” value or a fallback of os.defpath.
On Windows, the current directory is always prepended to the path whether
or not you use the default or provide your own, which is the behavior the
command shell uses when finding executables.  Additionally, when finding the
cmd in the path, the PATHEXT environment variable is checked.  For
example, if you call shutil.which(""python""), which() will search
PATHEXT to know that it should look for python.exe within the path
directories.  For example, on Windows:
>>> shutil.which(""python"")
'C:\\Python33\\python.EXE'



New in version 3.3.


Changed in version 3.8: The bytes type is now accepted.  If cmd type is
bytes, the result type is also bytes."
"shutil.make_archive(base_name, format[, root_dir[, base_dir[, verbose[, dry_run[, owner[, group[, logger]]]]]]])","Create an archive file (such as zip or tar) and return its name.
base_name is the name of the file to create, including the path, minus
any format-specific extension. format is the archive format: one of
“zip” (if the zlib module is available), “tar”, “gztar” (if the
zlib module is available), “bztar” (if the bz2 module is
available), or “xztar” (if the lzma module is available).
root_dir is a directory that will be the root directory of the
archive; for example, we typically chdir into root_dir before creating the
archive.
base_dir is the directory where we start archiving from;
i.e. base_dir will be the common prefix of all files and
directories in the archive.
root_dir and base_dir both default to the current directory.
If dry_run is true, no archive is created, but the operations that would be
executed are logged to logger.
owner and group are used when creating a tar archive. By default,
uses the current owner and group.
logger must be an object compatible with PEP 282, usually an instance of
logging.Logger.
The verbose argument is unused and deprecated.
Raises an auditing event shutil.make_archive with arguments base_name, format, root_dir, base_dir.

Changed in version 3.8: The modern pax (POSIX.1-2001) format is now used instead of
the legacy GNU format for archives created with format=""tar""."
shutil.get_archive_formats(),"Return a list of supported formats for archiving.
Each element of the returned sequence is a tuple (name, description).
By default shutil provides these formats:

zip: ZIP file (if the zlib module is available).
tar: Uncompressed tar file. Uses POSIX.1-2001 pax format for new archives.
gztar: gzip’ed tar-file (if the zlib module is available).
bztar: bzip2’ed tar-file (if the bz2 module is available).
xztar: xz’ed tar-file (if the lzma module is available).

You can register new formats or provide your own archiver for any existing
formats, by using register_archive_format()."
"shutil.register_archive_format(name, function[, extra_args[, description]])","Register an archiver for the format name.
function is the callable that will be used to unpack archives. The callable
will receive the base_name of the file to create, followed by the
base_dir (which defaults to os.curdir) to start archiving from.
Further arguments are passed as keyword arguments: owner, group,
dry_run and logger (as passed in make_archive()).
If given, extra_args is a sequence of (name, value) pairs that will be
used as extra keywords arguments when the archiver callable is used.
description is used by get_archive_formats() which returns the
list of archivers.  Defaults to an empty string."
shutil.unregister_archive_format(name),Remove the archive format name from the list of supported formats.
"shutil.unpack_archive(filename[, extract_dir[, format]])","Unpack an archive. filename is the full path of the archive.
extract_dir is the name of the target directory where the archive is
unpacked. If not provided, the current working directory is used.
format is the archive format: one of “zip”, “tar”, “gztar”, “bztar”, or
“xztar”.  Or any other format registered with
register_unpack_format().  If not provided, unpack_archive()
will use the archive file name extension and see if an unpacker was
registered for that extension.  In case none is found,
a ValueError is raised.
Raises an auditing event shutil.unpack_archive with arguments filename, extract_dir, format.

Changed in version 3.7: Accepts a path-like object for filename and extract_dir."
"shutil.register_unpack_format(name, extensions, function[, extra_args[, description]])","Registers an unpack format. name is the name of the format and
extensions is a list of extensions corresponding to the format, like
.zip for Zip files.
function is the callable that will be used to unpack archives. The
callable will receive the path of the archive, followed by the directory
the archive must be extracted to.
When provided, extra_args is a sequence of (name, value) tuples that
will be passed as keywords arguments to the callable.
description can be provided to describe the format, and will be returned
by the get_unpack_formats() function."
shutil.unregister_unpack_format(name),Unregister an unpack format. name is the name of the format.
shutil.get_unpack_formats(),"Return a list of all registered formats for unpacking.
Each element of the returned sequence is a tuple
(name, extensions, description).
By default shutil provides these formats:

zip: ZIP file (unpacking compressed files works only if the corresponding
module is available).
tar: uncompressed tar file.
gztar: gzip’ed tar-file (if the zlib module is available).
bztar: bzip2’ed tar-file (if the bz2 module is available).
xztar: xz’ed tar-file (if the lzma module is available).

You can register new formats or provide your own unpacker for any existing
formats, by using register_unpack_format()."
"shutil.get_terminal_size(fallback=(columns, lines))","Get the size of the terminal window.
For each of the two dimensions, the environment variable, COLUMNS
and LINES respectively, is checked. If the variable is defined and
the value is a positive integer, it is used.
When COLUMNS or LINES is not defined, which is the common case,
the terminal connected to sys.__stdout__ is queried
by invoking os.get_terminal_size().
If the terminal size cannot be successfully queried, either because
the system doesn’t support querying, or because we are not
connected to a terminal, the value given in fallback parameter
is used. fallback defaults to (80, 24) which is the default
size used by many terminal emulators.
The value returned is a named tuple of type os.terminal_size.
See also: The Single UNIX Specification, Version 2,
Other Environment Variables.

New in version 3.3."
"pickle.dump(obj, file, protocol=None, *, fix_imports=True, buffer_callback=None)","Write the pickled representation of the object obj to the open
file object file.  This is equivalent to
Pickler(file, protocol).dump(obj).
Arguments file, protocol, fix_imports and buffer_callback have
the same meaning as in the Pickler constructor.

Changed in version 3.8: The buffer_callback argument was added."
"pickle.dumps(obj, protocol=None, *, fix_imports=True, buffer_callback=None)","Return the pickled representation of the object obj as a bytes object,
instead of writing it to a file.
Arguments protocol, fix_imports and buffer_callback have the same
meaning as in the Pickler constructor.

Changed in version 3.8: The buffer_callback argument was added."
"pickle.load(file, *, fix_imports=True, encoding=""ASCII"", errors=""strict"", buffers=None)","Read the pickled representation of an object from the open file object
file and return the reconstituted object hierarchy specified therein.
This is equivalent to Unpickler(file).load().
The protocol version of the pickle is detected automatically, so no
protocol argument is needed.  Bytes past the pickled representation
of the object are ignored.
Arguments file, fix_imports, encoding, errors, strict and buffers
have the same meaning as in the Unpickler constructor.

Changed in version 3.8: The buffers argument was added."
"pickle.loads(bytes_object, *, fix_imports=True, encoding=""ASCII"", errors=""strict"", buffers=None)","Return the reconstituted object hierarchy of the pickled representation
bytes_object of an object.
The protocol version of the pickle is detected automatically, so no
protocol argument is needed.  Bytes past the pickled representation
of the object are ignored.
Arguments file, fix_imports, encoding, errors, strict and buffers
have the same meaning as in the Unpickler constructor.

Changed in version 3.8: The buffers argument was added."
dump(obj),"Write the pickled representation of obj to the open file object given in
the constructor."
persistent_id(obj),"Do nothing by default.  This exists so a subclass can override it.
If persistent_id() returns None, obj is pickled as usual.  Any
other value causes Pickler to emit the returned value as a
persistent ID for obj.  The meaning of this persistent ID should be
defined by Unpickler.persistent_load().  Note that the value
returned by persistent_id() cannot itself have a persistent ID.
See Persistence of External Objects for details and examples of uses."
"reducer_override(self, obj)","Special reducer that can be defined in Pickler subclasses. This
method has priority over any reducer in the dispatch_table.  It
should conform to the same interface as a __reduce__() method, and
can optionally return NotImplemented to fallback on
dispatch_table-registered reducers to pickle obj.
For a detailed example, see Custom Reduction for Types, Functions, and Other Objects.

New in version 3.8."
load(),"Read the pickled representation of an object from the open file object
given in the constructor, and return the reconstituted object hierarchy
specified therein.  Bytes past the pickled representation of the object
are ignored."
persistent_load(pid),"Raise an UnpicklingError by default.
If defined, persistent_load() should return the object specified by
the persistent ID pid.  If an invalid persistent ID is encountered, an
UnpicklingError should be raised.
See Persistence of External Objects for details and examples of uses."
"find_class(module, name)","Import module if necessary and return the object called name from it,
where the module and name arguments are str objects.  Note,
unlike its name suggests, find_class() is also used for finding
functions.
Subclasses may override this to gain control over what type of objects and
how they can be loaded, potentially reducing security risks. Refer to
Restricting Globals for details.
Raises an auditing event pickle.find_class with arguments module, name."
raw(),"Return a memoryview of the memory area underlying this buffer.
The returned object is a one-dimensional, C-contiguous memoryview
with format B (unsigned bytes).  BufferError is raised if
the buffer is neither C- nor Fortran-contiguous."
release(),Release the underlying buffer exposed by the PickleBuffer object.
object.__getnewargs_ex__(),"In protocols 2 and newer, classes that implements the
__getnewargs_ex__() method can dictate the values passed to the
__new__() method upon unpickling.  The method must return a pair
(args, kwargs) where args is a tuple of positional arguments
and kwargs a dictionary of named arguments for constructing the
object.  Those will be passed to the __new__() method upon
unpickling.
You should implement this method if the __new__() method of your
class requires keyword-only arguments.  Otherwise, it is recommended for
compatibility to implement __getnewargs__().

Changed in version 3.6: __getnewargs_ex__() is now used in protocols 2 and 3."
object.__getnewargs__(),"This method serves a similar purpose as __getnewargs_ex__(), but
supports only positional arguments.  It must return a tuple of arguments
args which will be passed to the __new__() method upon unpickling.
__getnewargs__() will not be called if __getnewargs_ex__() is
defined.

Changed in version 3.6: Before Python 3.6, __getnewargs__() was called instead of
__getnewargs_ex__() in protocols 2 and 3."
object.__getstate__(),"Classes can further influence how their instances are pickled; if the class
defines the method __getstate__(), it is called and the returned object
is pickled as the contents for the instance, instead of the contents of the
instance’s dictionary.  If the __getstate__() method is absent, the
instance’s __dict__ is pickled as usual."
object.__setstate__(state),"Upon unpickling, if the class defines __setstate__(), it is called with
the unpickled state.  In that case, there is no requirement for the state
object to be a dictionary.  Otherwise, the pickled state must be a dictionary
and its items are assigned to the new instance’s dictionary.

Note
If __getstate__() returns a false value, the __setstate__()
method will not be called upon unpickling."
object.__reduce__(),"The interface is currently defined as follows.  The __reduce__() method
takes no argument and shall return either a string or preferably a tuple (the
returned object is often referred to as the “reduce value”).
If a string is returned, the string should be interpreted as the name of a
global variable.  It should be the object’s local name relative to its
module; the pickle module searches the module namespace to determine the
object’s module.  This behaviour is typically useful for singletons.
When a tuple is returned, it must be between two and six items long.
Optional items can either be omitted, or None can be provided as their
value.  The semantics of each item are in order:

A callable object that will be called to create the initial version of the
object.
A tuple of arguments for the callable object.  An empty tuple must be given
if the callable does not accept any argument.
Optionally, the object’s state, which will be passed to the object’s
__setstate__() method as previously described.  If the object has no
such method then, the value must be a dictionary and it will be added to
the object’s __dict__ attribute.
Optionally, an iterator (and not a sequence) yielding successive items.
These items will be appended to the object either using
obj.append(item) or, in batch, using obj.extend(list_of_items).
This is primarily used for list subclasses, but may be used by other
classes as long as they have append() and extend() methods with
the appropriate signature.  (Whether append() or extend() is
used depends on which pickle protocol version is used as well as the number
of items to append, so both must be supported.)
Optionally, an iterator (not a sequence) yielding successive key-value
pairs.  These items will be stored to the object using obj[key] =
value.  This is primarily used for dictionary subclasses, but may be used
by other classes as long as they implement __setitem__().
Optionally, a callable with a (obj, state) signature. This
callable allows the user to programmatically control the state-updating
behavior of a specific object, instead of using obj’s static
__setstate__() method. If not None, this callable will have
priority over obj’s __setstate__().

New in version 3.8: The optional sixth tuple item, (obj, state), was added."
object.__reduce_ex__(protocol),"Alternatively, a __reduce_ex__() method may be defined.  The only
difference is this method should take a single integer argument, the protocol
version.  When defined, pickle will prefer it over the __reduce__()
method.  In addition, __reduce__() automatically becomes a synonym for
the extended version.  The main use for this method is to provide
backwards-compatible reduce values for older Python releases."
copyreg.constructor(object),"Declares object to be a valid constructor.  If object is not callable (and
hence not valid as a constructor), raises TypeError."
"copyreg.pickle(type, function, constructor=None)","Declares that function should be used as a “reduction” function for objects
of type type.  function should return either a string or a tuple
containing two or three elements.
The optional constructor parameter, if provided, is a callable object which
can be used to reconstruct the object when called with the tuple of arguments
returned by function at pickling time.  TypeError will be raised if
object is a class or constructor is not callable.
See the pickle module for more details on the interface
expected of function and constructor.  Note that the
dispatch_table attribute of a pickler
object or subclass of pickle.Pickler can also be used for
declaring reduction functions."
"shelve.open(filename, flag='c', protocol=None, writeback=False)","Open a persistent dictionary.  The filename specified is the base filename for
the underlying database.  As a side-effect, an extension may be added to the
filename and more than one file may be created.  By default, the underlying
database file is opened for reading and writing.  The optional flag parameter
has the same interpretation as the flag parameter of dbm.open().
By default, version 3 pickles are used to serialize values.  The version of the
pickle protocol can be specified with the protocol parameter.
Because of Python semantics, a shelf cannot know when a mutable
persistent-dictionary entry is modified.  By default modified objects are
written only when assigned to the shelf (see Example).  If the
optional writeback parameter is set to True, all entries accessed are also
cached in memory, and written back on sync() and
close(); this can make it handier to mutate mutable entries in
the persistent dictionary, but, if many entries are accessed, it can consume
vast amounts of memory for the cache, and it can make the close operation
very slow since all accessed entries are written back (there is no way to
determine which accessed entries are mutable, nor which ones were actually
mutated).

Note
Do not rely on the shelf being closed automatically; always call
close() explicitly when you don’t need it any more, or
use shelve.open() as a context manager:
with shelve.open('spam') as db:
    db['eggs'] = 'eggs'"
Shelf.sync(),"Write back all entries in the cache if the shelf was opened with writeback
set to True.  Also empty the cache and synchronize the persistent
dictionary on disk, if feasible.  This is called automatically when the shelf
is closed with close()."
Shelf.close(),"Synchronize and close the persistent dict object.  Operations on a closed
shelf will fail with a ValueError."
"marshal.dump(value, file[, version])","Write the value on the open file.  The value must be a supported type.  The
file must be a writeable binary file.
If the value has (or contains an object that has) an unsupported type, a
ValueError exception is raised — but garbage data will also be written
to the file.  The object will not be properly read back by load().
The version argument indicates the data format that dump should use
(see below)."
marshal.load(file),"Read one value from the open file and return it.  If no valid value is read
(e.g. because the data has a different Python version’s incompatible marshal
format), raise EOFError, ValueError or TypeError.  The
file must be a readable binary file.

Note
If an object containing an unsupported type was marshalled with dump(),
load() will substitute None for the unmarshallable type."
"marshal.dumps(value[, version])","Return the bytes object that would be written to a file by dump(value, file).  The
value must be a supported type.  Raise a ValueError exception if value
has (or contains an object that has) an unsupported type.
The version argument indicates the data format that dumps should use
(see below)."
marshal.loads(bytes),"Convert the bytes-like object to a value.  If no valid value is found, raise
EOFError, ValueError or TypeError.  Extra bytes in the
input are ignored."
dbm.whichdb(filename),"This function attempts to guess which of the several simple database modules
available — dbm.gnu, dbm.ndbm or dbm.dumb — should
be used to open a given file.
Returns one of the following values: None if the file can’t be opened
because it’s unreadable or doesn’t exist; the empty string ('') if the
file’s format can’t be guessed; or a string containing the required module
name, such as 'dbm.ndbm' or 'dbm.gnu'."
"dbm.open(file, flag='r', mode=0o666)","Open the database file file and return a corresponding object.
If the database file already exists, the whichdb() function is used to
determine its type and the appropriate module is used; if it does not exist,
the first module listed above that can be imported is used.
The optional flag argument can be:






Value
Meaning



'r'
Open existing database for reading only
(default)

'w'
Open existing database for reading and
writing

'c'
Open database for reading and writing,
creating it if it doesn’t exist

'n'
Always create a new, empty database, open
for reading and writing



The optional mode argument is the Unix mode of the file, used only when the
database has to be created.  It defaults to octal 0o666 (and will be
modified by the prevailing umask)."
"dbm.gnu.open(filename[, flag[, mode]])","Open a gdbm database and return a gdbm object.  The filename
argument is the name of the database file.
The optional flag argument can be:






Value
Meaning



'r'
Open existing database for reading only
(default)

'w'
Open existing database for reading and
writing

'c'
Open database for reading and writing,
creating it if it doesn’t exist

'n'
Always create a new, empty database, open
for reading and writing



The following additional characters may be appended to the flag to control
how the database is opened:






Value
Meaning



'f'
Open the database in fast mode.  Writes
to the database will not be synchronized.

's'
Synchronized mode. This will cause changes
to the database to be immediately written
to the file.

'u'
Do not lock database.



Not all flags are valid for all versions of gdbm.  The module constant
open_flags is a string of supported flag characters.  The exception
error is raised if an invalid flag is specified.
The optional mode argument is the Unix mode of the file, used only when the
database has to be created.  It defaults to octal 0o666.
In addition to the dictionary-like methods, gdbm objects have the
following methods:


gdbm.firstkey()¶
It’s possible to loop over every key in the database using this method  and the
nextkey() method.  The traversal is ordered by gdbm’s internal
hash values, and won’t be sorted by the key values.  This method returns
the starting key.



gdbm.nextkey(key)¶
Returns the key that follows key in the traversal.  The following code prints
every key in the database db, without having to create a list in memory that
contains them all:
k = db.firstkey()
while k != None:
    print(k)
    k = db.nextkey(k)





gdbm.reorganize()¶
If you have carried out a lot of deletions and would like to shrink the space
used by the gdbm file, this routine will reorganize the database.  gdbm
objects will not shorten the length of a database file except by using this
reorganization; otherwise, deleted file space will be kept and reused as new
(key, value) pairs are added.



gdbm.sync()¶
When the database has been opened in fast mode, this method forces any
unwritten data to be written to the disk.



gdbm.close()¶
Close the gdbm database."
"dbm.ndbm.open(filename[, flag[, mode]])","Open a dbm database and return a ndbm object.  The filename argument is the
name of the database file (without the .dir or .pag extensions).
The optional flag argument must be one of these values:






Value
Meaning



'r'
Open existing database for reading only
(default)

'w'
Open existing database for reading and
writing

'c'
Open database for reading and writing,
creating it if it doesn’t exist

'n'
Always create a new, empty database, open
for reading and writing



The optional mode argument is the Unix mode of the file, used only when the
database has to be created.  It defaults to octal 0o666 (and will be
modified by the prevailing umask).
In addition to the dictionary-like methods, ndbm objects
provide the following method:


ndbm.close()¶
Close the ndbm database."
"dbm.dumb.open(filename[, flag[, mode]])","Open a dumbdbm database and return a dumbdbm object.  The filename argument is
the basename of the database file (without any specific extensions).  When a
dumbdbm database is created, files with .dat and .dir extensions
are created.
The optional flag argument can be:






Value
Meaning



'r'
Open existing database for reading only
(default)

'w'
Open existing database for reading and
writing

'c'
Open database for reading and writing,
creating it if it doesn’t exist

'n'
Always create a new, empty database, open
for reading and writing



The optional mode argument is the Unix mode of the file, used only when the
database has to be created.  It defaults to octal 0o666 (and will be modified
by the prevailing umask).

Warning
It is possible to crash the Python interpreter when loading a database
with a sufficiently large/complex entry due to stack depth limitations in
Python’s AST compiler.


Changed in version 3.5: open() always creates a new database when the flag has the value
'n'.


Changed in version 3.8: A database opened with flags 'r' is now read-only.  Opening with
flags 'r' and 'w' no longer creates a database if it does not
exist.

In addition to the methods provided by the
collections.abc.MutableMapping class, dumbdbm objects
provide the following methods:


dumbdbm.sync()¶
Synchronize the on-disk directory and data files.  This method is called
by the Shelve.sync() method.



dumbdbm.close()¶
Close the dumbdbm database."
gdbm.firstkey(),"It’s possible to loop over every key in the database using this method  and the
nextkey() method.  The traversal is ordered by gdbm’s internal
hash values, and won’t be sorted by the key values.  This method returns
the starting key."
gdbm.nextkey(key),"Returns the key that follows key in the traversal.  The following code prints
every key in the database db, without having to create a list in memory that
contains them all:
k = db.firstkey()
while k != None:
    print(k)
    k = db.nextkey(k)"
gdbm.reorganize(),"If you have carried out a lot of deletions and would like to shrink the space
used by the gdbm file, this routine will reorganize the database.  gdbm
objects will not shorten the length of a database file except by using this
reorganization; otherwise, deleted file space will be kept and reused as new
(key, value) pairs are added."
gdbm.sync(),"When the database has been opened in fast mode, this method forces any
unwritten data to be written to the disk."
gdbm.close(),Close the gdbm database.
ndbm.close(),Close the ndbm database.
dumbdbm.sync(),"Synchronize the on-disk directory and data files.  This method is called
by the Shelve.sync() method."
dumbdbm.close(),Close the dumbdbm database.
"sqlite3.connect(database[, timeout, detect_types, isolation_level, check_same_thread, factory, cached_statements, uri])","Opens a connection to the SQLite database file database. By default returns a
Connection object, unless a custom factory is given.
database is a path-like object giving the pathname (absolute or
relative to the current  working directory) of the database file to be opened.
You can use "":memory:"" to open a database connection to a database that
resides in RAM instead of on disk.
When a database is accessed by multiple connections, and one of the processes
modifies the database, the SQLite database is locked until that transaction is
committed. The timeout parameter specifies how long the connection should wait
for the lock to go away until raising an exception. The default for the timeout
parameter is 5.0 (five seconds).
For the isolation_level parameter, please see the
isolation_level property of Connection objects.
SQLite natively supports only the types TEXT, INTEGER, REAL, BLOB and NULL. If
you want to use other types you must add support for them yourself. The
detect_types parameter and the using custom converters registered with the
module-level register_converter() function allow you to easily do that.
detect_types defaults to 0 (i. e. off, no type detection), you can set it to
any combination of PARSE_DECLTYPES and PARSE_COLNAMES to turn
type detection on.
By default, check_same_thread is True and only the creating thread may
use the connection. If set False, the returned connection may be shared
across multiple threads. When using multiple threads with the same connection
writing operations should be serialized by the user to avoid data corruption.
By default, the sqlite3 module uses its Connection class for the
connect call.  You can, however, subclass the Connection class and make
connect() use your class instead by providing your class for the factory
parameter.
Consult the section SQLite and Python types of this manual for details.
The sqlite3 module internally uses a statement cache to avoid SQL parsing
overhead. If you want to explicitly set the number of statements that are cached
for the connection, you can set the cached_statements parameter. The currently
implemented default is to cache 100 statements.
If uri is true, database is interpreted as a URI. This allows you
to specify options. For example, to open a database in read-only mode
you can use:
db = sqlite3.connect('file:path/to/database?mode=ro', uri=True)


More information about this feature, including a list of recognized options, can
be found in the SQLite URI documentation.
Raises an auditing event sqlite3.connect with argument database.

Changed in version 3.4: Added the uri parameter.


Changed in version 3.7: database can now also be a path-like object, not only a string."
"sqlite3.register_converter(typename, callable)","Registers a callable to convert a bytestring from the database into a custom
Python type. The callable will be invoked for all database values that are of
the type typename. Confer the parameter detect_types of the connect()
function for how the type detection works. Note that typename and the name of
the type in your query are matched in case-insensitive manner."
"sqlite3.register_adapter(type, callable)","Registers a callable to convert the custom Python type type into one of
SQLite’s supported types. The callable callable accepts as single parameter
the Python value, and must return a value of the following types: int,
float, str or bytes."
sqlite3.complete_statement(sql),"Returns True if the string sql contains one or more complete SQL
statements terminated by semicolons. It does not verify that the SQL is
syntactically correct, only that there are no unclosed string literals and the
statement is terminated by a semicolon.
This can be used to build a shell for SQLite, as in the following example:
# A minimal SQLite shell for experiments

import sqlite3

con = sqlite3.connect("":memory:"")
con.isolation_level = None
cur = con.cursor()

buffer = """"

print(""Enter your SQL commands to execute in sqlite3."")
print(""Enter a blank line to exit."")

while True:
    line = input()
    if line == """":
        break
    buffer += line
    if sqlite3.complete_statement(buffer):
        try:
            buffer = buffer.strip()
            cur.execute(buffer)

            if buffer.lstrip().upper().startswith(""SELECT""):
                print(cur.fetchall())
        except sqlite3.Error as e:
            print(""An error occurred:"", e.args[0])
        buffer = """"

con.close()"
sqlite3.enable_callback_tracebacks(flag),"By default you will not get any tracebacks in user-defined functions,
aggregates, converters, authorizer callbacks etc. If you want to debug them,
you can call this function with flag set to True. Afterwards, you will
get tracebacks from callbacks on sys.stderr. Use False to
disable the feature again."
cursor(factory=Cursor),"The cursor method accepts a single optional parameter factory. If
supplied, this must be a callable returning an instance of Cursor
or its subclasses."
commit(),"This method commits the current transaction. If you don’t call this method,
anything you did since the last call to commit() is not visible from
other database connections. If you wonder why you don’t see the data you’ve
written to the database, please check you didn’t forget to call this method."
rollback(),"This method rolls back any changes to the database since the last call to
commit()."
close(),"This closes the database connection. Note that this does not automatically
call commit(). If you just close your database connection without
calling commit() first, your changes will be lost!"
"execute(sql[, parameters])","This is a nonstandard shortcut that creates a cursor object by calling
the cursor() method, calls the cursor’s
execute() method with the parameters given, and returns
the cursor."
"executemany(sql[, parameters])","This is a nonstandard shortcut that creates a cursor object by
calling the cursor() method, calls the cursor’s
executemany() method with the parameters given, and
returns the cursor."
executescript(sql_script),"This is a nonstandard shortcut that creates a cursor object by
calling the cursor() method, calls the cursor’s
executescript() method with the given sql_script, and
returns the cursor."
"create_function(name, num_params, func, *, deterministic=False)","Creates a user-defined function that you can later use from within SQL
statements under the function name name. num_params is the number of
parameters the function accepts (if num_params is -1, the function may
take any number of arguments), and func is a Python callable that is
called as the SQL function. If deterministic is true, the created function
is marked as deterministic, which
allows SQLite to perform additional optimizations. This flag is supported by
SQLite 3.8.3 or higher, NotSupportedError will be raised if used
with older versions.
The function can return any of the types supported by SQLite: bytes, str, int,
float and None.

Changed in version 3.8: The deterministic parameter was added.

Example:
import sqlite3
import hashlib

def md5sum(t):
    return hashlib.md5(t).hexdigest()

con = sqlite3.connect("":memory:"")
con.create_function(""md5"", 1, md5sum)
cur = con.cursor()
cur.execute(""select md5(?)"", (b""foo"",))
print(cur.fetchone()[0])

con.close()"
"create_aggregate(name, num_params, aggregate_class)","Creates a user-defined aggregate function.
The aggregate class must implement a step method, which accepts the number
of parameters num_params (if num_params is -1, the function may take
any number of arguments), and a finalize method which will return the
final result of the aggregate.
The finalize method can return any of the types supported by SQLite:
bytes, str, int, float and None.
Example:
import sqlite3

class MySum:
    def __init__(self):
        self.count = 0

    def step(self, value):
        self.count += value

    def finalize(self):
        return self.count

con = sqlite3.connect("":memory:"")
con.create_aggregate(""mysum"", 1, MySum)
cur = con.cursor()
cur.execute(""create table test(i)"")
cur.execute(""insert into test(i) values (1)"")
cur.execute(""insert into test(i) values (2)"")
cur.execute(""select mysum(i) from test"")
print(cur.fetchone()[0])

con.close()"
"create_collation(name, callable)","Creates a collation with the specified name and callable. The callable will
be passed two string arguments. It should return -1 if the first is ordered
lower than the second, 0 if they are ordered equal and 1 if the first is ordered
higher than the second.  Note that this controls sorting (ORDER BY in SQL) so
your comparisons don’t affect other SQL operations.
Note that the callable will get its parameters as Python bytestrings, which will
normally be encoded in UTF-8.
The following example shows a custom collation that sorts “the wrong way”:
import sqlite3

def collate_reverse(string1, string2):
    if string1 == string2:
        return 0
    elif string1 < string2:
        return 1
    else:
        return -1

con = sqlite3.connect("":memory:"")
con.create_collation(""reverse"", collate_reverse)

cur = con.cursor()
cur.execute(""create table test(x)"")
cur.executemany(""insert into test(x) values (?)"", [(""a"",), (""b"",)])
cur.execute(""select x from test order by x collate reverse"")
for row in cur:
    print(row)
con.close()


To remove a collation, call create_collation with None as callable:
con.create_collation(""reverse"", None)"
interrupt(),"You can call this method from a different thread to abort any queries that might
be executing on the connection. The query will then abort and the caller will
get an exception."
set_authorizer(authorizer_callback),"This routine registers a callback. The callback is invoked for each attempt to
access a column of a table in the database. The callback should return
SQLITE_OK if access is allowed, SQLITE_DENY if the entire SQL
statement should be aborted with an error and SQLITE_IGNORE if the
column should be treated as a NULL value. These constants are available in the
sqlite3 module.
The first argument to the callback signifies what kind of operation is to be
authorized. The second and third argument will be arguments or None
depending on the first argument. The 4th argument is the name of the database
(“main”, “temp”, etc.) if applicable. The 5th argument is the name of the
inner-most trigger or view that is responsible for the access attempt or
None if this access attempt is directly from input SQL code.
Please consult the SQLite documentation about the possible values for the first
argument and the meaning of the second and third argument depending on the first
one. All necessary constants are available in the sqlite3 module."
"set_progress_handler(handler, n)","This routine registers a callback. The callback is invoked for every n
instructions of the SQLite virtual machine. This is useful if you want to
get called from SQLite during long-running operations, for example to update
a GUI.
If you want to clear any previously installed progress handler, call the
method with None for handler.
Returning a non-zero value from the handler function will terminate the
currently executing query and cause it to raise an OperationalError
exception."
set_trace_callback(trace_callback),"Registers trace_callback to be called for each SQL statement that is
actually executed by the SQLite backend.
The only argument passed to the callback is the statement (as string) that
is being executed. The return value of the callback is ignored. Note that
the backend does not only run statements passed to the Cursor.execute()
methods.  Other sources include the transaction management of the Python
module and the execution of triggers defined in the current database.
Passing None as trace_callback will disable the trace callback.

New in version 3.3."
enable_load_extension(enabled),"This routine allows/disallows the SQLite engine to load SQLite extensions
from shared libraries.  SQLite extensions can define new functions,
aggregates or whole new virtual table implementations.  One well-known
extension is the fulltext-search extension distributed with SQLite.
Loadable extensions are disabled by default. See 1.

New in version 3.2.

import sqlite3

con = sqlite3.connect("":memory:"")

# enable extension loading
con.enable_load_extension(True)

# Load the fulltext search extension
con.execute(""select load_extension('./fts3.so')"")

# alternatively you can load the extension using an API call:
# con.load_extension(""./fts3.so"")

# disable extension loading again
con.enable_load_extension(False)

# example from SQLite wiki
con.execute(""create virtual table recipe using fts3(name, ingredients)"")
con.executescript(""""""
    insert into recipe (name, ingredients) values ('broccoli stew', 'broccoli peppers cheese tomatoes');
    insert into recipe (name, ingredients) values ('pumpkin stew', 'pumpkin onions garlic celery');
    insert into recipe (name, ingredients) values ('broccoli pie', 'broccoli cheese onions flour');
    insert into recipe (name, ingredients) values ('pumpkin pie', 'pumpkin sugar flour butter');
    """""")
for row in con.execute(""select rowid, name, ingredients from recipe where name match 'pie'""):
    print(row)

con.close()"
load_extension(path),"This routine loads a SQLite extension from a shared library.  You have to
enable extension loading with enable_load_extension() before you can
use this routine.
Loadable extensions are disabled by default. See 1.

New in version 3.2."
iterdump(),"Returns an iterator to dump the database in an SQL text format.  Useful when
saving an in-memory database for later restoration.  This function provides
the same capabilities as the .dump command in the sqlite3
shell.
Example:
# Convert file existing_db.db to SQL dump file dump.sql
import sqlite3

con = sqlite3.connect('existing_db.db')
with open('dump.sql', 'w') as f:
    for line in con.iterdump():
        f.write('%s\n' % line)
con.close()"
"backup(target, *, pages=0, progress=None, name=""main"", sleep=0.250)","This method makes a backup of a SQLite database even while it’s being accessed
by other clients, or concurrently by the same connection.  The copy will be
written into the mandatory argument target, that must be another
Connection instance.
By default, or when pages is either 0 or a negative integer, the entire
database is copied in a single step; otherwise the method performs a loop
copying up to pages pages at a time.
If progress is specified, it must either be None or a callable object that
will be executed at each iteration with three integer arguments, respectively
the status of the last iteration, the remaining number of pages still to be
copied and the total number of pages.
The name argument specifies the database name that will be copied: it must be
a string containing either ""main"", the default, to indicate the main
database, ""temp"" to indicate the temporary database or the name specified
after the AS keyword in an ATTACH DATABASE statement for an attached
database.
The sleep argument specifies the number of seconds to sleep by between
successive attempts to backup remaining pages, can be specified either as an
integer or a floating point value.
Example 1, copy an existing database into another:
import sqlite3

def progress(status, remaining, total):
    print(f'Copied {total-remaining} of {total} pages...')

con = sqlite3.connect('existing_db.db')
bck = sqlite3.connect('backup.db')
with bck:
    con.backup(bck, pages=1, progress=progress)
bck.close()
con.close()


Example 2, copy an existing database into a transient copy:
import sqlite3

source = sqlite3.connect('existing_db.db')
dest = sqlite3.connect(':memory:')
source.backup(dest)


Availability: SQLite 3.6.11 or higher

New in version 3.7."
"execute(sql[, parameters])","Executes an SQL statement. The SQL statement may be parameterized (i. e.
placeholders instead of SQL literals). The sqlite3 module supports two
kinds of placeholders: question marks (qmark style) and named placeholders
(named style).
Here’s an example of both styles:
import sqlite3

con = sqlite3.connect("":memory:"")
cur = con.cursor()
cur.execute(""create table people (name_last, age)"")

who = ""Yeltsin""
age = 72

# This is the qmark style:
cur.execute(""insert into people values (?, ?)"", (who, age))

# And this is the named style:
cur.execute(""select * from people where name_last=:who and age=:age"", {""who"": who, ""age"": age})

print(cur.fetchone())

con.close()


execute() will only execute a single SQL statement. If you try to execute
more than one statement with it, it will raise a Warning. Use
executescript() if you want to execute multiple SQL statements with one
call."
"executemany(sql, seq_of_parameters)","Executes an SQL command against all parameter sequences or mappings found in
the sequence seq_of_parameters.  The sqlite3 module also allows
using an iterator yielding parameters instead of a sequence.
import sqlite3

class IterChars:
    def __init__(self):
        self.count = ord('a')

    def __iter__(self):
        return self

    def __next__(self):
        if self.count > ord('z'):
            raise StopIteration
        self.count += 1
        return (chr(self.count - 1),) # this is a 1-tuple

con = sqlite3.connect("":memory:"")
cur = con.cursor()
cur.execute(""create table characters(c)"")

theIter = IterChars()
cur.executemany(""insert into characters(c) values (?)"", theIter)

cur.execute(""select c from characters"")
print(cur.fetchall())

con.close()


Here’s a shorter example using a generator:
import sqlite3
import string

def char_generator():
    for c in string.ascii_lowercase:
        yield (c,)

con = sqlite3.connect("":memory:"")
cur = con.cursor()
cur.execute(""create table characters(c)"")

cur.executemany(""insert into characters(c) values (?)"", char_generator())

cur.execute(""select c from characters"")
print(cur.fetchall())

con.close()"
executescript(sql_script),"This is a nonstandard convenience method for executing multiple SQL statements
at once. It issues a COMMIT statement first, then executes the SQL script it
gets as a parameter.
sql_script can be an instance of str.
Example:
import sqlite3

con = sqlite3.connect("":memory:"")
cur = con.cursor()
cur.executescript(""""""
    create table person(
        firstname,
        lastname,
        age
    );

    create table book(
        title,
        author,
        published
    );

    insert into book(title, author, published)
    values (
        'Dirk Gently''s Holistic Detective Agency',
        'Douglas Adams',
        1987
    );
    """""")
con.close()"
fetchone(),"Fetches the next row of a query result set, returning a single sequence,
or None when no more data is available."
fetchmany(size=cursor.arraysize),"Fetches the next set of rows of a query result, returning a list.  An empty
list is returned when no more rows are available.
The number of rows to fetch per call is specified by the size parameter.
If it is not given, the cursor’s arraysize determines the number of rows
to be fetched. The method should try to fetch as many rows as indicated by
the size parameter. If this is not possible due to the specified number of
rows not being available, fewer rows may be returned.
Note there are performance considerations involved with the size parameter.
For optimal performance, it is usually best to use the arraysize attribute.
If the size parameter is used, then it is best for it to retain the same
value from one fetchmany() call to the next."
fetchall(),"Fetches all (remaining) rows of a query result, returning a list.  Note that
the cursor’s arraysize attribute can affect the performance of this operation.
An empty list is returned when no rows are available."
close(),"Close the cursor now (rather than whenever __del__ is called).
The cursor will be unusable from this point forward; a ProgrammingError
exception will be raised if any operation is attempted with the cursor."
keys(),"This method returns a list of column names. Immediately after a query,
it is the first member of each tuple in Cursor.description."
"zlib.adler32(data[, value])","Computes an Adler-32 checksum of data.  (An Adler-32 checksum is almost as
reliable as a CRC32 but can be computed much more quickly.)  The result
is an unsigned 32-bit integer.  If value is present, it is used as
the starting value of the checksum; otherwise, a default value of 1
is used.  Passing in value allows computing a running checksum over the
concatenation of several inputs.  The algorithm is not cryptographically
strong, and should not be used for authentication or digital signatures.  Since
the algorithm is designed for use as a checksum algorithm, it is not suitable
for use as a general hash algorithm.

Changed in version 3.0: Always returns an unsigned value.
To generate the same numeric value across all Python versions and
platforms, use adler32(data) & 0xffffffff."
"zlib.compress(data, level=-1)","Compresses the bytes in data, returning a bytes object containing compressed data.
level is an integer from 0 to 9 or -1 controlling the level of compression;
1 (Z_BEST_SPEED) is fastest and produces the least compression, 9 (Z_BEST_COMPRESSION)
is slowest and produces the most.  0 (Z_NO_COMPRESSION) is no compression.
The default value is -1 (Z_DEFAULT_COMPRESSION).  Z_DEFAULT_COMPRESSION represents a default
compromise between speed and compression (currently equivalent to level 6).
Raises the error exception if any error occurs.

Changed in version 3.6: level can now be used as a keyword parameter."
"zlib.crc32(data[, value])","Computes a CRC (Cyclic Redundancy Check) checksum of data. The
result is an unsigned 32-bit integer. If value is present, it is used
as the starting value of the checksum; otherwise, a default value of 0
is used.  Passing in value allows computing a running checksum over the
concatenation of several inputs.  The algorithm is not cryptographically
strong, and should not be used for authentication or digital signatures.  Since
the algorithm is designed for use as a checksum algorithm, it is not suitable
for use as a general hash algorithm.

Changed in version 3.0: Always returns an unsigned value.
To generate the same numeric value across all Python versions and
platforms, use crc32(data) & 0xffffffff."
"zlib.decompressobj(wbits=MAX_WBITS[, zdict])","Returns a decompression object, to be used for decompressing data streams that
won’t fit into memory at once.
The wbits parameter controls the size of the history buffer (or the
“window size”), and what header and trailer format is expected.  It has
the same meaning as described for decompress().
The zdict parameter specifies a predefined compression dictionary. If
provided, this must be the same dictionary as was used by the compressor that
produced the data that is to be decompressed.

Note
If zdict is a mutable object (such as a bytearray), you must not
modify its contents between the call to decompressobj() and the first
call to the decompressor’s decompress() method.


Changed in version 3.3: Added the zdict parameter."
Compress.compress(data),"Compress data, returning a bytes object containing compressed data for at least
part of the data in data.  This data should be concatenated to the output
produced by any preceding calls to the compress() method.  Some input may
be kept in internal buffers for later processing."
Compress.flush([mode]),"All pending input is processed, and a bytes object containing the remaining compressed
output is returned.  mode can be selected from the constants
Z_NO_FLUSH, Z_PARTIAL_FLUSH, Z_SYNC_FLUSH,
Z_FULL_FLUSH, Z_BLOCK (zlib 1.2.3.4), or Z_FINISH,
defaulting to Z_FINISH.  Except Z_FINISH, all constants
allow compressing further bytestrings of data, while Z_FINISH finishes the
compressed stream and prevents compressing any more data.  After calling flush()
with mode set to Z_FINISH, the compress() method cannot be called again;
the only realistic action is to delete the object."
Compress.copy(),"Returns a copy of the compression object.  This can be used to efficiently
compress a set of data that share a common initial prefix."
"Decompress.decompress(data, max_length=0)","Decompress data, returning a bytes object containing the uncompressed data
corresponding to at least part of the data in string.  This data should be
concatenated to the output produced by any preceding calls to the
decompress() method.  Some of the input data may be preserved in internal
buffers for later processing.
If the optional parameter max_length is non-zero then the return value will be
no longer than max_length. This may mean that not all of the compressed input
can be processed; and unconsumed data will be stored in the attribute
unconsumed_tail. This bytestring must be passed to a subsequent call to
decompress() if decompression is to continue.  If max_length is zero
then the whole input is decompressed, and unconsumed_tail is empty.

Changed in version 3.6: max_length can be used as a keyword argument."
Decompress.flush([length]),"All pending input is processed, and a bytes object containing the remaining
uncompressed output is returned.  After calling flush(), the
decompress() method cannot be called again; the only realistic action is
to delete the object.
The optional parameter length sets the initial size of the output buffer."
Decompress.copy(),"Returns a copy of the decompression object.  This can be used to save the state
of the decompressor midway through the data stream in order to speed up random
seeks into the stream at a future point."
"gzip.open(filename, mode='rb', compresslevel=9, encoding=None, errors=None, newline=None)","Open a gzip-compressed file in binary or text mode, returning a file
object.
The filename argument can be an actual filename (a str or
bytes object), or an existing file object to read from or write to.
The mode argument can be any of 'r', 'rb', 'a', 'ab',
'w', 'wb', 'x' or 'xb' for binary mode, or 'rt',
'at', 'wt', or 'xt' for text mode. The default is 'rb'.
The compresslevel argument is an integer from 0 to 9, as for the
GzipFile constructor.
For binary mode, this function is equivalent to the GzipFile
constructor: GzipFile(filename, mode, compresslevel). In this case, the
encoding, errors and newline arguments must not be provided.
For text mode, a GzipFile object is created, and wrapped in an
io.TextIOWrapper instance with the specified encoding, error
handling behavior, and line ending(s).

Changed in version 3.3: Added support for filename being a file object, support for text mode,
and the encoding, errors and newline arguments.


Changed in version 3.4: Added support for the 'x', 'xb' and 'xt' modes.


Changed in version 3.6: Accepts a path-like object."
"gzip.compress(data, compresslevel=9, *, mtime=None)","Compress the data, returning a bytes object containing
the compressed data.  compresslevel and mtime have the same meaning as in
the GzipFile constructor above.

New in version 3.2.


Changed in version 3.8: Added the mtime parameter for reproducible output."
gzip.decompress(data),"Decompress the data, returning a bytes object containing the
uncompressed data.

New in version 3.2."
peek(n),"Read n uncompressed bytes without advancing the file position.
At most one single read on the compressed stream is done to satisfy
the call.  The number of bytes returned may be more or less than
requested.

Note
While calling peek() does not change the file position of
the GzipFile, it may change the position of the underlying
file object (e.g. if the GzipFile was constructed with the
fileobj parameter).


New in version 3.2."
"bz2.open(filename, mode='r', compresslevel=9, encoding=None, errors=None, newline=None)","Open a bzip2-compressed file in binary or text mode, returning a file
object.
As with the constructor for BZ2File, the filename argument can be
an actual filename (a str or bytes object), or an existing
file object to read from or write to.
The mode argument can be any of 'r', 'rb', 'w', 'wb',
'x', 'xb', 'a' or 'ab' for binary mode, or 'rt',
'wt', 'xt', or 'at' for text mode. The default is 'rb'.
The compresslevel argument is an integer from 1 to 9, as for the
BZ2File constructor.
For binary mode, this function is equivalent to the BZ2File
constructor: BZ2File(filename, mode, compresslevel=compresslevel). In
this case, the encoding, errors and newline arguments must not be
provided.
For text mode, a BZ2File object is created, and wrapped in an
io.TextIOWrapper instance with the specified encoding, error
handling behavior, and line ending(s).

New in version 3.3.


Changed in version 3.4: The 'x' (exclusive creation) mode was added.


Changed in version 3.6: Accepts a path-like object."
"bz2.compress(data, compresslevel=9)","Compress data, a bytes-like object.
compresslevel, if given, must be an integer between 1 and 9. The
default is 9.
For incremental compression, use a BZ2Compressor instead."
bz2.decompress(data),"Decompress data, a bytes-like object.
If data is the concatenation of multiple compressed streams, decompress
all of the streams.
For incremental decompression, use a BZ2Decompressor instead.

Changed in version 3.3: Support for multi-stream inputs was added."
peek([n]),"Return buffered data without advancing the file position. At least one
byte of data will be returned (unless at EOF). The exact number of bytes
returned is unspecified.

Note
While calling peek() does not change the file position of
the BZ2File, it may change the position of the underlying file
object (e.g. if the BZ2File was constructed by passing a file
object for filename).


New in version 3.3."
compress(data),"Provide data to the compressor object. Returns a chunk of compressed data
if possible, or an empty byte string otherwise.
When you have finished providing data to the compressor, call the
flush() method to finish the compression process."
flush(),"Finish the compression process. Returns the compressed data left in
internal buffers.
The compressor object may not be used after this method has been called."
"decompress(data, max_length=-1)","Decompress data (a bytes-like object), returning
uncompressed data as bytes. Some of data may be buffered
internally, for use in later calls to decompress(). The
returned data should be concatenated with the output of any
previous calls to decompress().
If max_length is nonnegative, returns at most max_length
bytes of decompressed data. If this limit is reached and further
output can be produced, the needs_input attribute will
be set to False. In this case, the next call to
decompress() may provide data as b'' to obtain
more of the output.
If all of the input data was decompressed and returned (either
because this was less than max_length bytes, or because
max_length was negative), the needs_input attribute
will be set to True.
Attempting to decompress data after the end of stream is reached
raises an EOFError.  Any data found after the end of the
stream is ignored and saved in the unused_data attribute.

Changed in version 3.5: Added the max_length parameter."
"lzma.open(filename, mode=""rb"", *, format=None, check=-1, preset=None, filters=None, encoding=None, errors=None, newline=None)","Open an LZMA-compressed file in binary or text mode, returning a file
object.
The filename argument can be either an actual file name (given as a
str, bytes or path-like object), in
which case the named file is opened, or it can be an existing file object
to read from or write to.
The mode argument can be any of ""r"", ""rb"", ""w"", ""wb"",
""x"", ""xb"", ""a"" or ""ab"" for binary mode, or ""rt"",
""wt"", ""xt"", or ""at"" for text mode. The default is ""rb"".
When opening a file for reading, the format and filters arguments have
the same meanings as for LZMADecompressor. In this case, the check
and preset arguments should not be used.
When opening a file for writing, the format, check, preset and
filters arguments have the same meanings as for LZMACompressor.
For binary mode, this function is equivalent to the LZMAFile
constructor: LZMAFile(filename, mode, ...). In this case, the encoding,
errors and newline arguments must not be provided.
For text mode, a LZMAFile object is created, and wrapped in an
io.TextIOWrapper instance with the specified encoding, error
handling behavior, and line ending(s).

Changed in version 3.4: Added support for the ""x"", ""xb"" and ""xt"" modes.


Changed in version 3.6: Accepts a path-like object."
"lzma.compress(data, format=FORMAT_XZ, check=-1, preset=None, filters=None)","Compress data (a bytes object), returning the compressed data as a
bytes object.
See LZMACompressor above for a description of the format, check,
preset and filters arguments."
"lzma.decompress(data, format=FORMAT_AUTO, memlimit=None, filters=None)","Decompress data (a bytes object), returning the uncompressed data
as a bytes object.
If data is the concatenation of multiple distinct compressed streams,
decompress all of these streams, and return the concatenation of the results.
See LZMADecompressor above for a description of the format,
memlimit and filters arguments."
lzma.is_check_supported(check),"Return True if the given integrity check is supported on this system.
CHECK_NONE and CHECK_CRC32 are always supported.
CHECK_CRC64 and CHECK_SHA256 may be unavailable if you are
using a version of liblzma that was compiled with a limited
feature set."
peek(size=-1),"Return buffered data without advancing the file position. At least one
byte of data will be returned, unless EOF has been reached. The exact
number of bytes returned is unspecified (the size argument is ignored).

Note
While calling peek() does not change the file position of
the LZMAFile, it may change the position of the underlying
file object (e.g. if the LZMAFile was constructed by passing a
file object for filename)."
compress(data),"Compress data (a bytes object), returning a bytes
object containing compressed data for at least part of the input. Some of
data may be buffered internally, for use in later calls to
compress() and flush(). The returned data should be
concatenated with the output of any previous calls to compress()."
flush(),"Finish the compression process, returning a bytes object
containing any data stored in the compressor’s internal buffers.
The compressor cannot be used after this method has been called."
"decompress(data, max_length=-1)","Decompress data (a bytes-like object), returning
uncompressed data as bytes. Some of data may be buffered
internally, for use in later calls to decompress(). The
returned data should be concatenated with the output of any
previous calls to decompress().
If max_length is nonnegative, returns at most max_length
bytes of decompressed data. If this limit is reached and further
output can be produced, the needs_input attribute will
be set to False. In this case, the next call to
decompress() may provide data as b'' to obtain
more of the output.
If all of the input data was decompressed and returned (either
because this was less than max_length bytes, or because
max_length was negative), the needs_input attribute
will be set to True.
Attempting to decompress data after the end of stream is reached
raises an EOFError.  Any data found after the end of the
stream is ignored and saved in the unused_data attribute.

Changed in version 3.5: Added the max_length parameter."
zipfile.is_zipfile(filename),"Returns True if filename is a valid ZIP file based on its magic number,
otherwise returns False.  filename may be a file or file-like object too.

Changed in version 3.1: Support for file and file-like objects."
ZipFile.close(),"Close the archive file.  You must call close() before exiting your program
or essential records will not be written."
ZipFile.getinfo(name),"Return a ZipInfo object with information about the archive member
name.  Calling getinfo() for a name not currently contained in the
archive will raise a KeyError."
ZipFile.infolist(),"Return a list containing a ZipInfo object for each member of the
archive.  The objects are in the same order as their entries in the actual ZIP
file on disk if an existing archive was opened."
ZipFile.namelist(),Return a list of archive members by name.
"ZipFile.open(name, mode='r', pwd=None, *, force_zip64=False)","Access a member of the archive as a binary file-like object.  name
can be either the name of a file within the archive or a ZipInfo
object.  The mode parameter, if included, must be 'r' (the default)
or 'w'.  pwd is the password used to decrypt encrypted ZIP files.
open() is also a context manager and therefore supports the
with statement:
with ZipFile('spam.zip') as myzip:
    with myzip.open('eggs.txt') as myfile:
        print(myfile.read())


With mode 'r' the file-like object
(ZipExtFile) is read-only and provides the following methods:
read(), readline(),
readlines(), seek(),
tell(), __iter__(), __next__().
These objects can operate independently of the ZipFile.
With mode='w', a writable file handle is returned, which supports the
write() method.  While a writable file handle is open,
attempting to read or write other files in the ZIP file will raise a
ValueError.
When writing a file, if the file size is not known in advance but may exceed
2 GiB, pass force_zip64=True to ensure that the header format is
capable of supporting large files.  If the file size is known in advance,
construct a ZipInfo object with file_size set, and
use that as the name parameter.

Note
The open(), read() and extract() methods can take a filename
or a ZipInfo object.  You will appreciate this when trying to read a
ZIP file that contains members with duplicate names.


Changed in version 3.6: Removed support of mode='U'.  Use io.TextIOWrapper for reading
compressed text files in universal newlines mode.


Changed in version 3.6: open() can now be used to write files into the archive with the
mode='w' option.


Changed in version 3.6: Calling open() on a closed ZipFile will raise a ValueError.
Previously, a RuntimeError was raised."
"ZipFile.extract(member, path=None, pwd=None)","Extract a member from the archive to the current working directory; member
must be its full name or a ZipInfo object.  Its file information is
extracted as accurately as possible.  path specifies a different directory
to extract to.  member can be a filename or a ZipInfo object.
pwd is the password used for encrypted files.
Returns the normalized path created (a directory or new file).

Note
If a member filename is an absolute path, a drive/UNC sharepoint and
leading (back)slashes will be stripped, e.g.: ///foo/bar becomes
foo/bar on Unix, and C:\foo\bar becomes foo\bar on Windows.
And all "".."" components in a member filename will be removed, e.g.:
../../foo../../ba..r becomes foo../ba..r.  On Windows illegal
characters (:, <, >, |, "", ?, and *)
replaced by underscore (_).


Changed in version 3.6: Calling extract() on a closed ZipFile will raise a
ValueError.  Previously, a RuntimeError was raised.


Changed in version 3.6.2: The path parameter accepts a path-like object."
"ZipFile.extractall(path=None, members=None, pwd=None)","Extract all members from the archive to the current working directory.  path
specifies a different directory to extract to.  members is optional and must
be a subset of the list returned by namelist().  pwd is the password
used for encrypted files.

Warning
Never extract archives from untrusted sources without prior inspection.
It is possible that files are created outside of path, e.g. members
that have absolute filenames starting with ""/"" or filenames with two
dots "".."".  This module attempts to prevent that.
See extract() note.


Changed in version 3.6: Calling extractall() on a closed ZipFile will raise a
ValueError.  Previously, a RuntimeError was raised.


Changed in version 3.6.2: The path parameter accepts a path-like object."
ZipFile.printdir(),Print a table of contents for the archive to sys.stdout.
ZipFile.setpassword(pwd),Set pwd as default password to extract encrypted files.
"ZipFile.read(name, pwd=None)","Return the bytes of the file name in the archive.  name is the name of the
file in the archive, or a ZipInfo object.  The archive must be open for
read or append. pwd is the password used for encrypted  files and, if specified,
it will override the default password set with setpassword().  Calling
read() on a ZipFile that uses a compression method other than
ZIP_STORED, ZIP_DEFLATED, ZIP_BZIP2 or
ZIP_LZMA will raise a NotImplementedError. An error will also
be raised if the corresponding compression module is not available.

Changed in version 3.6: Calling read() on a closed ZipFile will raise a ValueError.
Previously, a RuntimeError was raised."
ZipFile.testzip(),"Read all the files in the archive and check their CRC’s and file headers.
Return the name of the first bad file, or else return None.

Changed in version 3.6: Calling testzip() on a closed ZipFile will raise a
ValueError.  Previously, a RuntimeError was raised."
"ZipFile.write(filename, arcname=None, compress_type=None, compresslevel=None)","Write the file named filename to the archive, giving it the archive name
arcname (by default, this will be the same as filename, but without a drive
letter and with leading path separators removed).  If given, compress_type
overrides the value given for the compression parameter to the constructor for
the new entry. Similarly, compresslevel will override the constructor if
given.
The archive must be open with mode 'w', 'x' or 'a'.

Note
Archive names should be relative to the archive root, that is, they should not
start with a path separator.


Note
If arcname (or filename, if arcname is  not given) contains a null
byte, the name of the file in the archive will be truncated at the null byte.


Changed in version 3.6: Calling write() on a ZipFile created with mode 'r' or
a closed ZipFile will raise a ValueError.  Previously,
a RuntimeError was raised."
"ZipFile.writestr(zinfo_or_arcname, data, compress_type=None, compresslevel=None)","Write a file into the archive.  The contents is data, which may be either
a str or a bytes instance; if it is a str,
it is encoded as UTF-8 first.  zinfo_or_arcname is either the file
name it will be given in the archive, or a ZipInfo instance.  If it’s
an instance, at least the filename, date, and time must be given.  If it’s a
name, the date and time is set to the current date and time.
The archive must be opened with mode 'w', 'x' or 'a'.
If given, compress_type overrides the value given for the compression
parameter to the constructor for the new entry, or in the zinfo_or_arcname
(if that is a ZipInfo instance). Similarly, compresslevel will
override the constructor if given.

Note
When passing a ZipInfo instance as the zinfo_or_arcname parameter,
the compression method used will be that specified in the compress_type
member of the given ZipInfo instance.  By default, the
ZipInfo constructor sets this member to ZIP_STORED.


Changed in version 3.2: The compress_type argument.


Changed in version 3.6: Calling writestr() on a ZipFile created with mode 'r' or
a closed ZipFile will raise a ValueError.  Previously,
a RuntimeError was raised."
"Path.open(*, **)","Invoke ZipFile.open() on the current path. Accepts
the same arguments as ZipFile.open()."
Path.iterdir(),Enumerate the children of the current directory.
Path.is_dir(),Return True if the current context references a directory.
Path.is_file(),Return True if the current context references a file.
Path.exists(),"Return True if the current context references a file or
directory in the zip file."
"Path.read_text(*, **)","Read the current file as unicode text. Positional and
keyword arguments are passed through to
io.TextIOWrapper (except buffer, which is
implied by the context)."
Path.read_bytes(),Read the current file as bytes.
"writepy(pathname, basename='', filterfunc=None)","Search for files *.py and add the corresponding file to the
archive.
If the optimize parameter to PyZipFile was not given or -1,
the corresponding file is a *.pyc file, compiling if necessary.
If the optimize parameter to PyZipFile was 0, 1 or
2, only files with that optimization level (see compile()) are
added to the archive, compiling if necessary.
If pathname is a file, the filename must end with .py, and
just the (corresponding *.pyc) file is added at the top level
(no path information).  If pathname is a file that does not end with
.py, a RuntimeError will be raised.  If it is a directory,
and the directory is not a package directory, then all the files
*.pyc are added at the top level.  If the directory is a
package directory, then all *.pyc are added under the package
name as a file path, and if any subdirectories are package directories,
all of these are added recursively in sorted order.
basename is intended for internal use only.
filterfunc, if given, must be a function taking a single string
argument.  It will be passed each path (including each individual full
file path) before it is added to the archive.  If filterfunc returns a
false value, the path will not be added, and if it is a directory its
contents will be ignored.  For example, if our test files are all either
in test directories or start with the string test_, we can use a
filterfunc to exclude them:
>>> zf = PyZipFile('myprog.zip')
>>> def notests(s):
...     fn = os.path.basename(s)
...     return (not (fn == 'test' or fn.startswith('test_')))
>>> zf.writepy('myprog', filterfunc=notests)


The writepy() method makes archives with file names like
this:
string.pyc                   # Top level name
test/__init__.pyc            # Package directory
test/testall.pyc             # Module test.testall
test/bogus/__init__.pyc      # Subpackage directory
test/bogus/myfile.pyc        # Submodule test.bogus.myfile



New in version 3.4: The filterfunc parameter.


Changed in version 3.6.2: The pathname parameter accepts a path-like object.


Changed in version 3.7: Recursion sorts directory entries."
"classmethod ZipInfo.from_file(filename, arcname=None, *, strict_timestamps=True)","Construct a ZipInfo instance for a file on the filesystem, in
preparation for adding it to a zip file.
filename should be the path to a file or directory on the filesystem.
If arcname is specified, it is used as the name within the archive.
If arcname is not specified, the name will be the same as filename, but
with any drive letter and leading path separators removed.
The strict_timestamps argument, when set to False, allows to
zip files older than 1980-01-01 at the cost of setting the
timestamp to 1980-01-01.
Similar behavior occurs with files newer than 2107-12-31,
the timestamp is also set to the limit.

New in version 3.6.


Changed in version 3.6.2: The filename parameter accepts a path-like object.


New in version 3.8: The strict_timestamps keyword-only argument"
ZipInfo.is_dir(),"Return True if this archive member is a directory.
This uses the entry’s name: directories should always end with /.

New in version 3.6."
"tarfile.open(name=None, mode='r', fileobj=None, bufsize=10240, **kwargs)","Return a TarFile object for the pathname name. For detailed
information on TarFile objects and the keyword arguments that are
allowed, see TarFile Objects.
mode has to be a string of the form 'filemode[:compression]', it defaults
to 'r'. Here is a full list of mode combinations:






mode
action



'r' or 'r:*'
Open for reading with transparent
compression (recommended).

'r:'
Open for reading exclusively without
compression.

'r:gz'
Open for reading with gzip compression.

'r:bz2'
Open for reading with bzip2 compression.

'r:xz'
Open for reading with lzma compression.

'x' or
'x:'
Create a tarfile exclusively without
compression.
Raise an FileExistsError exception
if it already exists.

'x:gz'
Create a tarfile with gzip compression.
Raise an FileExistsError exception
if it already exists.

'x:bz2'
Create a tarfile with bzip2 compression.
Raise an FileExistsError exception
if it already exists.

'x:xz'
Create a tarfile with lzma compression.
Raise an FileExistsError exception
if it already exists.

'a' or 'a:'
Open for appending with no compression. The
file is created if it does not exist.

'w' or 'w:'
Open for uncompressed writing.

'w:gz'
Open for gzip compressed writing.

'w:bz2'
Open for bzip2 compressed writing.

'w:xz'
Open for lzma compressed writing.



Note that 'a:gz', 'a:bz2' or 'a:xz' is not possible. If mode
is not suitable to open a certain (compressed) file for reading,
ReadError is raised. Use mode 'r' to avoid this.  If a
compression method is not supported, CompressionError is raised.
If fileobj is specified, it is used as an alternative to a file object
opened in binary mode for name. It is supposed to be at position 0.
For modes 'w:gz', 'r:gz', 'w:bz2', 'r:bz2', 'x:gz',
'x:bz2', tarfile.open() accepts the keyword argument
compresslevel (default 9) to specify the compression level of the file.
For special purposes, there is a second format for mode:
'filemode|[compression]'.  tarfile.open() will return a TarFile
object that processes its data as a stream of blocks.  No random seeking will
be done on the file. If given, fileobj may be any object that has a
read() or write() method (depending on the mode). bufsize
specifies the blocksize and defaults to 20 * 512 bytes. Use this variant
in combination with e.g. sys.stdin, a socket file object or a tape
device. However, such a TarFile object is limited in that it does
not allow random access, see Examples.  The currently
possible modes:






Mode
Action



'r|*'
Open a stream of tar blocks for reading
with transparent compression.

'r|'
Open a stream of uncompressed tar blocks
for reading.

'r|gz'
Open a gzip compressed stream for
reading.

'r|bz2'
Open a bzip2 compressed stream for
reading.

'r|xz'
Open an lzma compressed stream for
reading.

'w|'
Open an uncompressed stream for writing.

'w|gz'
Open a gzip compressed stream for
writing.

'w|bz2'
Open a bzip2 compressed stream for
writing.

'w|xz'
Open an lzma compressed stream for
writing.




Changed in version 3.5: The 'x' (exclusive creation) mode was added.


Changed in version 3.6: The name parameter accepts a path-like object."
tarfile.is_tarfile(name),"Return True if name is a tar archive file, that the tarfile
module can read."
classmethod TarFile.open(...),"Alternative constructor. The tarfile.open() function is actually a
shortcut to this classmethod."
TarFile.getmember(name),"Return a TarInfo object for member name. If name can not be found
in the archive, KeyError is raised.

Note
If a member occurs more than once in the archive, its last occurrence is assumed
to be the most up-to-date version."
TarFile.getmembers(),"Return the members of the archive as a list of TarInfo objects. The
list has the same order as the members in the archive."
TarFile.getnames(),"Return the members as a list of their names. It has the same order as the list
returned by getmembers()."
"TarFile.list(verbose=True, *, members=None)","Print a table of contents to sys.stdout. If verbose is False,
only the names of the members are printed. If it is True, output
similar to that of ls -l is produced. If optional members is
given, it must be a subset of the list returned by getmembers().

Changed in version 3.5: Added the members parameter."
TarFile.next(),"Return the next member of the archive as a TarInfo object, when
TarFile is opened for reading. Return None if there is no more
available."
"TarFile.extractall(path=""."", members=None, *, numeric_owner=False)","Extract all members from the archive to the current working directory or
directory path. If optional members is given, it must be a subset of the
list returned by getmembers(). Directory information like owner,
modification time and permissions are set after all members have been extracted.
This is done to work around two problems: A directory’s modification time is
reset each time a file is created in it. And, if a directory’s permissions do
not allow writing, extracting files to it will fail.
If numeric_owner is True, the uid and gid numbers from the tarfile
are used to set the owner/group for the extracted files. Otherwise, the named
values from the tarfile are used.

Warning
Never extract archives from untrusted sources without prior inspection.
It is possible that files are created outside of path, e.g. members
that have absolute filenames starting with ""/"" or filenames with two
dots "".."".


Changed in version 3.5: Added the numeric_owner parameter.


Changed in version 3.6: The path parameter accepts a path-like object."
"TarFile.extract(member, path="""", set_attrs=True, *, numeric_owner=False)","Extract a member from the archive to the current working directory, using its
full name. Its file information is extracted as accurately as possible. member
may be a filename or a TarInfo object. You can specify a different
directory using path. path may be a path-like object.
File attributes (owner, mtime, mode) are set unless set_attrs is false.
If numeric_owner is True, the uid and gid numbers from the tarfile
are used to set the owner/group for the extracted files. Otherwise, the named
values from the tarfile are used.

Note
The extract() method does not take care of several extraction issues.
In most cases you should consider using the extractall() method.


Warning
See the warning for extractall().


Changed in version 3.2: Added the set_attrs parameter.


Changed in version 3.5: Added the numeric_owner parameter.


Changed in version 3.6: The path parameter accepts a path-like object."
TarFile.extractfile(member),"Extract a member from the archive as a file object. member may be a filename
or a TarInfo object. If member is a regular file or a link, an
io.BufferedReader object is returned. Otherwise, None is
returned.

Changed in version 3.3: Return an io.BufferedReader object."
"TarFile.add(name, arcname=None, recursive=True, *, filter=None)","Add the file name to the archive. name may be any type of file
(directory, fifo, symbolic link, etc.). If given, arcname specifies an
alternative name for the file in the archive. Directories are added
recursively by default. This can be avoided by setting recursive to
False. Recursion adds entries in sorted order.
If filter is given, it
should be a function that takes a TarInfo object argument and
returns the changed TarInfo object. If it instead returns
None the TarInfo object will be excluded from the
archive. See Examples for an example.

Changed in version 3.2: Added the filter parameter.


Changed in version 3.7: Recursion adds entries in sorted order."
"TarFile.addfile(tarinfo, fileobj=None)","Add the TarInfo object tarinfo to the archive. If fileobj is given,
it should be a binary file, and
tarinfo.size bytes are read from it and added to the archive.  You can
create TarInfo objects directly, or by using gettarinfo()."
"TarFile.gettarinfo(name=None, arcname=None, fileobj=None)","Create a TarInfo object from the result of os.stat() or
equivalent on an existing file.  The file is either named by name, or
specified as a file object fileobj with a file descriptor.
name may be a path-like object.  If
given, arcname specifies an alternative name for the file in the
archive, otherwise, the name is taken from fileobj’s
name attribute, or the name argument.  The name
should be a text string.
You can modify
some of the TarInfo’s attributes before you add it using addfile().
If the file object is not an ordinary file object positioned at the
beginning of the file, attributes such as size may need
modifying.  This is the case for objects such as GzipFile.
The name may also be modified, in which case arcname
could be a dummy string.

Changed in version 3.6: The name parameter accepts a path-like object."
TarFile.close(),"Close the TarFile. In write mode, two finishing zero blocks are
appended to the archive."
"classmethod TarInfo.frombuf(buf, encoding, errors)","Create and return a TarInfo object from string buffer buf.
Raises HeaderError if the buffer is invalid."
classmethod TarInfo.fromtarfile(tarfile),"Read the next member from the TarFile object tarfile and return it as
a TarInfo object."
"TarInfo.tobuf(format=DEFAULT_FORMAT, encoding=ENCODING, errors='surrogateescape')","Create a string buffer from a TarInfo object. For information on the
arguments see the constructor of the TarFile class.

Changed in version 3.2: Use 'surrogateescape' as the default for the errors argument."
TarInfo.isfile(),Return True if the Tarinfo object is a regular file.
TarInfo.isreg(),Same as isfile().
TarInfo.isdir(),Return True if it is a directory.
TarInfo.issym(),Return True if it is a symbolic link.
TarInfo.islnk(),Return True if it is a hard link.
TarInfo.ischr(),Return True if it is a character device.
TarInfo.isblk(),Return True if it is a block device.
TarInfo.isfifo(),Return True if it is a FIFO.
TarInfo.isdev(),"Return True if it is one of character device, block device or FIFO."
"csv.reader(csvfile, dialect='excel', **fmtparams)","Return a reader object which will iterate over lines in the given csvfile.
csvfile can be any object which supports the iterator protocol and returns a
string each time its __next__() method is called — file objects and list objects are both suitable.   If csvfile is a file object,
it should be opened with newline=''. 1  An optional
dialect parameter can be given which is used to define a set of parameters
specific to a particular CSV dialect.  It may be an instance of a subclass of
the Dialect class or one of the strings returned by the
list_dialects() function.  The other optional fmtparams keyword arguments
can be given to override individual formatting parameters in the current
dialect.  For full details about the dialect and formatting parameters, see
section Dialects and Formatting Parameters.
Each row read from the csv file is returned as a list of strings.  No
automatic data type conversion is performed unless the QUOTE_NONNUMERIC format
option is specified (in which case unquoted fields are transformed into floats).
A short usage example:
>>> import csv
>>> with open('eggs.csv', newline='') as csvfile:
...     spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')
...     for row in spamreader:
...         print(', '.join(row))
Spam, Spam, Spam, Spam, Spam, Baked Beans
Spam, Lovely Spam, Wonderful Spam"
"csv.writer(csvfile, dialect='excel', **fmtparams)","Return a writer object responsible for converting the user’s data into delimited
strings on the given file-like object.  csvfile can be any object with a
write() method.  If csvfile is a file object, it should be opened with
newline='' 1.  An optional dialect
parameter can be given which is used to define a set of parameters specific to a
particular CSV dialect.  It may be an instance of a subclass of the
Dialect class or one of the strings returned by the
list_dialects() function.  The other optional fmtparams keyword arguments
can be given to override individual formatting parameters in the current
dialect.  For full details about the dialect and formatting parameters, see
section Dialects and Formatting Parameters. To make it
as easy as possible to interface with modules which implement the DB API, the
value None is written as the empty string.  While this isn’t a
reversible transformation, it makes it easier to dump SQL NULL data values to
CSV files without preprocessing the data returned from a cursor.fetch* call.
All other non-string data are stringified with str() before being written.
A short usage example:
import csv
with open('eggs.csv', 'w', newline='') as csvfile:
    spamwriter = csv.writer(csvfile, delimiter=' ',
                            quotechar='|', quoting=csv.QUOTE_MINIMAL)
    spamwriter.writerow(['Spam'] * 5 + ['Baked Beans'])
    spamwriter.writerow(['Spam', 'Lovely Spam', 'Wonderful Spam'])"
"csv.register_dialect(name[, dialect[, **fmtparams]])","Associate dialect with name.  name must be a string. The
dialect can be specified either by passing a sub-class of Dialect, or
by fmtparams keyword arguments, or both, with keyword arguments overriding
parameters of the dialect. For full details about the dialect and formatting
parameters, see section Dialects and Formatting Parameters."
csv.unregister_dialect(name),"Delete the dialect associated with name from the dialect registry.  An
Error is raised if name is not a registered dialect name."
csv.get_dialect(name),"Return the dialect associated with name.  An Error is raised if
name is not a registered dialect name.  This function returns an immutable
Dialect."
csv.list_dialects(),Return the names of all registered dialects.
csv.field_size_limit([new_limit]),"Returns the current maximum field size allowed by the parser. If new_limit is
given, this becomes the new limit."
"sniff(sample, delimiters=None)","Analyze the given sample and return a Dialect subclass
reflecting the parameters found.  If the optional delimiters parameter
is given, it is interpreted as a string containing possible valid
delimiter characters."
has_header(sample),"Analyze the sample text (presumed to be in CSV format) and return
True if the first row appears to be a series of column headers."
csvreader.__next__(),"Return the next row of the reader’s iterable object as a list (if the object
was returned from reader()) or a dict (if it is a DictReader
instance), parsed according to the current dialect.  Usually you should call
this as next(reader)."
csvwriter.writerow(row),"Write the row parameter to the writer’s file object, formatted according to
the current dialect. Return the return value of the call to the write method
of the underlying file object.

Changed in version 3.5: Added support of arbitrary iterables."
csvwriter.writerows(rows),"Write all elements in rows (an iterable of row objects as described
above) to the writer’s file object, formatted according to the current
dialect."
DictWriter.writeheader(),"Write a row with the field names (as specified in the constructor) to
the writer’s file object, formatted according to the current dialect. Return
the return value of the csvwriter.writerow() call used internally.

New in version 3.2.


Changed in version 3.8: writeheader() now also returns the value returned by
the csvwriter.writerow() method it uses internally."
ConfigParser.optionxform(option),"This method transforms option names on every read, get, or set
operation.  The default converts the name to lowercase.  This also
means that when a configuration file gets written, all keys will be
lowercase.  Override this method if that’s unsuitable.
For example:
>>> config = """"""
... [Section1]
... Key = Value
...
... [Section2]
... AnotherKey = Value
... """"""
>>> typical = configparser.ConfigParser()
>>> typical.read_string(config)
>>> list(typical['Section1'].keys())
['key']
>>> list(typical['Section2'].keys())
['anotherkey']
>>> custom = configparser.RawConfigParser()
>>> custom.optionxform = lambda option: option
>>> custom.read_string(config)
>>> list(custom['Section1'].keys())
['Key']
>>> list(custom['Section2'].keys())
['AnotherKey']



Note
The optionxform function transforms option names to a canonical form.
This should be an idempotent function: if the name is already in
canonical form, it should be returned unchanged."
defaults(),Return a dictionary containing the instance-wide defaults.
sections(),"Return a list of the sections available; the default section is not
included in the list."
add_section(section),"Add a section named section to the instance.  If a section by the given
name already exists, DuplicateSectionError is raised.  If the
default section name is passed, ValueError is raised.  The name
of the section must be a string; if not, TypeError is raised.

Changed in version 3.2: Non-string section names raise TypeError."
has_section(section),"Indicates whether the named section is present in the configuration.
The default section is not acknowledged."
options(section),Return a list of options available in the specified section.
"has_option(section, option)","If the given section exists, and contains the given option, return
True; otherwise return False.  If the specified
section is None or an empty string, DEFAULT is assumed."
"read(filenames, encoding=None)","Attempt to read and parse an iterable of filenames, returning a list of
filenames which were successfully parsed.
If filenames is a string, a bytes object or a
path-like object, it is treated as
a single filename.  If a file named in filenames cannot be opened, that
file will be ignored.  This is designed so that you can specify an
iterable of potential configuration file locations (for example, the
current directory, the user’s home directory, and some system-wide
directory), and all existing configuration files in the iterable will be
read.
If none of the named files exist, the ConfigParser
instance will contain an empty dataset.  An application which requires
initial values to be loaded from a file should load the required file or
files using read_file() before calling read() for any
optional files:
import configparser, os

config = configparser.ConfigParser()
config.read_file(open('defaults.cfg'))
config.read(['site.cfg', os.path.expanduser('~/.myapp.cfg')],
            encoding='cp1250')



New in version 3.2: The encoding parameter.  Previously, all files were read using the
default encoding for open().


New in version 3.6.1: The filenames parameter accepts a path-like object.


New in version 3.7: The filenames parameter accepts a bytes object."
"read_file(f, source=None)","Read and parse configuration data from f which must be an iterable
yielding Unicode strings (for example files opened in text mode).
Optional argument source specifies the name of the file being read.  If
not given and f has a name attribute, that is used for
source; the default is '<???>'.

New in version 3.2: Replaces readfp()."
"read_string(string, source='<string>')","Parse configuration data from a string.
Optional argument source specifies a context-specific name of the
string passed.  If not given, '<string>' is used.  This should
commonly be a filesystem path or a URL.

New in version 3.2."
"read_dict(dictionary, source='<dict>')","Load configuration from any object that provides a dict-like items()
method.  Keys are section names, values are dictionaries with keys and
values that should be present in the section.  If the used dictionary
type preserves order, sections and their keys will be added in order.
Values are automatically converted to strings.
Optional argument source specifies a context-specific name of the
dictionary passed.  If not given, <dict> is used.
This method can be used to copy state between parsers.

New in version 3.2."
"get(section, option, *, raw=False, vars=None[, fallback])","Get an option value for the named section.  If vars is provided, it
must be a dictionary.  The option is looked up in vars (if provided),
section, and in DEFAULTSECT in that order.  If the key is not found
and fallback is provided, it is used as a fallback value.  None can
be provided as a fallback value.
All the '%' interpolations are expanded in the return values, unless
the raw argument is true.  Values for interpolation keys are looked up
in the same manner as the option.

Changed in version 3.2: Arguments raw, vars and fallback are keyword only to protect
users from trying to use the third argument as the fallback fallback
(especially when using the mapping protocol)."
"getint(section, option, *, raw=False, vars=None[, fallback])","A convenience method which coerces the option in the specified section
to an integer.  See get() for explanation of raw, vars and
fallback."
"getfloat(section, option, *, raw=False, vars=None[, fallback])","A convenience method which coerces the option in the specified section
to a floating point number.  See get() for explanation of raw,
vars and fallback."
"getboolean(section, option, *, raw=False, vars=None[, fallback])","A convenience method which coerces the option in the specified section
to a Boolean value.  Note that the accepted values for the option are
'1', 'yes', 'true', and 'on', which cause this method to
return True, and '0', 'no', 'false', and 'off', which
cause it to return False.  These string values are checked in a
case-insensitive manner.  Any other value will cause it to raise
ValueError.  See get() for explanation of raw, vars and
fallback."
"items(raw=False, vars=None)","When section is not given, return a list of section_name,
section_proxy pairs, including DEFAULTSECT.
Otherwise, return a list of name, value pairs for the options in the
given section.  Optional arguments have the same meaning as for the
get() method.

Changed in version 3.8: Items present in vars no longer appear in the result.  The previous
behaviour mixed actual parser options with variables provided for
interpolation."
"set(section, option, value)","If the given section exists, set the given option to the specified value;
otherwise raise NoSectionError.  option and value must be
strings; if not, TypeError is raised."
"write(fileobject, space_around_delimiters=True)","Write a representation of the configuration to the specified file
object, which must be opened in text mode (accepting strings).  This
representation can be parsed by a future read() call.  If
space_around_delimiters is true, delimiters between
keys and values are surrounded by spaces."
"remove_option(section, option)","Remove the specified option from the specified section.  If the
section does not exist, raise NoSectionError.  If the option
existed to be removed, return True; otherwise return
False."
remove_section(section),"Remove the specified section from the configuration.  If the section in
fact existed, return True.  Otherwise return False."
optionxform(option,"Transforms the option name option as found in an input file or as passed
in by client code to the form that should be used in the internal
structures.  The default implementation returns a lower-case version of
option; subclasses may override this or client code can set an attribute
of this name on instances to affect this behavior.
You don’t need to subclass the parser to use this method, you can also
set it on an instance, to a function that takes a string argument and
returns a string.  Setting it to str, for example, would make option
names case sensitive:
cfgparser = ConfigParser()
cfgparser.optionxform = str


Note that when reading configuration files, whitespace around the option
names is stripped before optionxform() is called."
"readfp(fp, filename=None)","Deprecated since version 3.2: Use read_file() instead.


Changed in version 3.2: readfp() now iterates on fp instead of calling fp.readline().

For existing code calling readfp() with arguments which don’t
support iteration, the following generator may be used as a wrapper
around the file-like object:
def readline_generator(fp):
    line = fp.readline()
    while line:
        yield line
        line = fp.readline()


Instead of parser.readfp(fp) use
parser.read_file(readline_generator(fp))."
add_section(section),"Add a section named section to the instance.  If a section by the given
name already exists, DuplicateSectionError is raised.  If the
default section name is passed, ValueError is raised.
Type of section is not checked which lets users create non-string named
sections.  This behaviour is unsupported and may cause internal errors."
"set(section, option, value)","If the given section exists, set the given option to the specified value;
otherwise raise NoSectionError.  While it is possible to use
RawConfigParser (or ConfigParser with raw parameters
set to true) for internal storage of non-string values, full
functionality (including interpolation and output to files) can only be
achieved using string values.
This method lets users assign non-string values to keys internally.  This
behaviour is unsupported and will cause errors when attempting to write
to a file or get it in non-raw mode.  Use the mapping protocol API
which does not allow such assignments to take place."
netrc.authenticators(host),"Return a 3-tuple (login, account, password) of authenticators for host.
If the netrc file did not contain an entry for the given host, return the tuple
associated with the ‘default’ entry.  If neither matching host nor default entry
is available, return None."
netrc.__repr__(),"Dump the class data as a string in the format of a netrc file. (This discards
comments and may reorder the entries.)"
Packer.get_buffer(),Returns the current pack buffer as a string.
Packer.reset(),Resets the pack buffer to the empty string.
Packer.pack_float(value),Packs the single-precision floating point number value.
Packer.pack_double(value),Packs the double-precision floating point number value.
"Packer.pack_fstring(n, s)","Packs a fixed length string, s.  n is the length of the string but it is
not packed into the data buffer.  The string is padded with null bytes if
necessary to guaranteed 4 byte alignment."
"Packer.pack_fopaque(n, data)","Packs a fixed length opaque data stream, similarly to pack_fstring()."
Packer.pack_string(s),"Packs a variable length string, s.  The length of the string is first packed
as an unsigned integer, then the string data is packed with
pack_fstring()."
Packer.pack_opaque(data),"Packs a variable length opaque data string, similarly to pack_string()."
Packer.pack_bytes(bytes),"Packs a variable length byte stream, similarly to pack_string()."
"Packer.pack_list(list, pack_item)","Packs a list of homogeneous items.  This method is useful for lists with an
indeterminate size; i.e. the size is not available until the entire list has
been walked.  For each item in the list, an unsigned integer 1 is packed
first, followed by the data value from the list.  pack_item is the function
that is called to pack the individual item.  At the end of the list, an unsigned
integer 0 is packed.
For example, to pack a list of integers, the code might appear like this:
import xdrlib
p = xdrlib.Packer()
p.pack_list([1, 2, 3], p.pack_int)"
"Packer.pack_farray(n, array, pack_item)","Packs a fixed length list (array) of homogeneous items.  n is the length of
the list; it is not packed into the buffer, but a ValueError exception
is raised if len(array) is not equal to n.  As above, pack_item is the
function used to pack each element."
"Packer.pack_array(list, pack_item)","Packs a variable length list of homogeneous items.  First, the length of the
list is packed as an unsigned integer, then each element is packed as in
pack_farray() above."
Unpacker.reset(data),Resets the string buffer with the given data.
Unpacker.get_position(),Returns the current unpack position in the data buffer.
Unpacker.set_position(position),"Sets the data buffer unpack position to position.  You should be careful about
using get_position() and set_position()."
Unpacker.get_buffer(),Returns the current unpack data buffer as a string.
Unpacker.done(),"Indicates unpack completion.  Raises an Error exception if all of the
data has not been unpacked."
Unpacker.unpack_float(),Unpacks a single-precision floating point number.
Unpacker.unpack_double(),"Unpacks a double-precision floating point number, similarly to
unpack_float()."
Unpacker.unpack_fstring(n),"Unpacks and returns a fixed length string.  n is the number of characters
expected.  Padding with null bytes to guaranteed 4 byte alignment is assumed."
Unpacker.unpack_fopaque(n),"Unpacks and returns a fixed length opaque data stream, similarly to
unpack_fstring()."
Unpacker.unpack_string(),"Unpacks and returns a variable length string.  The length of the string is first
unpacked as an unsigned integer, then the string data is unpacked with
unpack_fstring()."
Unpacker.unpack_opaque(),"Unpacks and returns a variable length opaque data string, similarly to
unpack_string()."
Unpacker.unpack_bytes(),"Unpacks and returns a variable length byte stream, similarly to
unpack_string()."
Unpacker.unpack_list(unpack_item),"Unpacks and returns a list of homogeneous items.  The list is unpacked one
element at a time by first unpacking an unsigned integer flag.  If the flag is
1, then the item is unpacked and appended to the list.  A flag of 0
indicates the end of the list.  unpack_item is the function that is called to
unpack the items."
"Unpacker.unpack_farray(n, unpack_item)","Unpacks and returns (as a list) a fixed length array of homogeneous items.  n
is number of list elements to expect in the buffer. As above, unpack_item is
the function used to unpack each element."
Unpacker.unpack_array(unpack_item),"Unpacks and returns a variable length list of homogeneous items. First, the
length of the list is unpacked as an unsigned integer, then each element is
unpacked as in unpack_farray() above."
"plistlib.load(fp, *, fmt=None, use_builtin_types=True, dict_type=dict)","Read a plist file. fp should be a readable and binary file object.
Return the unpacked root object (which usually is a
dictionary).
The fmt is the format of the file and the following values are valid:

None: Autodetect the file format
FMT_XML: XML file format
FMT_BINARY: Binary plist format

If use_builtin_types is true (the default) binary data will be returned
as instances of bytes, otherwise it is returned as instances of
Data.
The dict_type is the type used for dictionaries that are read from the
plist file.
XML data for the FMT_XML format is parsed using the Expat parser
from xml.parsers.expat – see its documentation for possible
exceptions on ill-formed XML.  Unknown elements will simply be ignored
by the plist parser.
The parser for the binary format raises InvalidFileException
when the file cannot be parsed.

New in version 3.4."
"plistlib.loads(data, *, fmt=None, use_builtin_types=True, dict_type=dict)","Load a plist from a bytes object. See load() for an explanation of
the keyword arguments.

New in version 3.4."
"plistlib.dump(value, fp, *, fmt=FMT_XML, sort_keys=True, skipkeys=False)","Write value to a plist file. Fp should be a writable, binary
file object.
The fmt argument specifies the format of the plist file and can be
one of the following values:

FMT_XML: XML formatted plist file
FMT_BINARY: Binary formatted plist file

When sort_keys is true (the default) the keys for dictionaries will be
written to the plist in sorted order, otherwise they will be written in
the iteration order of the dictionary.
When skipkeys is false (the default) the function raises TypeError
when a key of a dictionary is not a string, otherwise such keys are skipped.
A TypeError will be raised if the object is of an unsupported type or
a container that contains objects of unsupported types.
An OverflowError will be raised for integer values that cannot
be represented in (binary) plist files.

New in version 3.4."
"plistlib.dumps(value, *, fmt=FMT_XML, sort_keys=True, skipkeys=False)","Return value as a plist-formatted bytes object. See
the documentation for dump() for an explanation of the keyword
arguments of this function.

New in version 3.4."
plistlib.readPlist(pathOrFile),"Read a plist file. pathOrFile may be either a file name or a (readable
and binary) file object. Returns the unpacked root object (which usually
is a dictionary).
This function calls load() to do the actual work, see the documentation
of that function for an explanation of the keyword arguments.

Deprecated since version 3.4: Use load() instead.


Changed in version 3.7: Dict values in the result are now normal dicts.  You no longer can use
attribute access to access items of these dictionaries."
"plistlib.writePlist(rootObject, pathOrFile)","Write rootObject to an XML plist file. pathOrFile may be either a file name
or a (writable and binary) file object

Deprecated since version 3.4: Use dump() instead."
plistlib.readPlistFromBytes(data),"Read a plist data from a bytes object.  Return the root object.
See load() for a description of the keyword arguments.

Deprecated since version 3.4: Use loads() instead.


Changed in version 3.7: Dict values in the result are now normal dicts.  You no longer can use
attribute access to access items of these dictionaries."
plistlib.writePlistToBytes(rootObject),"Return rootObject as an XML plist-formatted bytes object.

Deprecated since version 3.4: Use dumps() instead."
"hashlib.new(name[, data])","Is a generic constructor that takes the string name of the desired
algorithm as its first parameter.  It also exists to allow access to the
above listed hashes as well as any other algorithms that your OpenSSL
library may offer.  The named constructors are much faster than new()
and should be preferred."
"hashlib.pbkdf2_hmac(hash_name, password, salt, iterations, dklen=None)","The function provides PKCS#5 password-based key derivation function 2. It
uses HMAC as pseudorandom function.
The string hash_name is the desired name of the hash digest algorithm for
HMAC, e.g. ‘sha1’ or ‘sha256’. password and salt are interpreted as
buffers of bytes. Applications and libraries should limit password to
a sensible length (e.g. 1024). salt should be about 16 or more bytes from
a proper source, e.g. os.urandom().
The number of iterations should be chosen based on the hash algorithm and
computing power. As of 2013, at least 100,000 iterations of SHA-256 are
suggested.
dklen is the length of the derived key. If dklen is None then the
digest size of the hash algorithm hash_name is used, e.g. 64 for SHA-512.
>>> import hashlib
>>> dk = hashlib.pbkdf2_hmac('sha256', b'password', b'salt', 100000)
>>> dk.hex()
'0394a2ede332c9a13eb82e9b24631604c31df978b4e2f0fbd2c549944f9d79a5'



New in version 3.4.


Note
A fast implementation of pbkdf2_hmac is available with OpenSSL.  The
Python implementation uses an inline version of hmac. It is about
three times slower and doesn’t release the GIL."
"hashlib.scrypt(password, *, salt, n, r, p, maxmem=0, dklen=64)","The function provides scrypt password-based key derivation function as
defined in RFC 7914.
password and salt must be bytes-like objects.  Applications and libraries should limit password
to a sensible length (e.g. 1024).  salt should be about 16 or more
bytes from a proper source, e.g. os.urandom().
n is the CPU/Memory cost factor, r the block size, p parallelization
factor and maxmem limits memory (OpenSSL 1.1.0 defaults to 32 MiB).
dklen is the length of the derived key.
Availability: OpenSSL 1.1+.

New in version 3.6."
"hashlib.blake2b(data=b'', *, digest_size=64, key=b'', salt=b'', person=b'', fanout=1, depth=1, leaf_size=0, node_offset=0, node_depth=0, inner_size=0, last_node=False)",
"hashlib.blake2s(data=b'', *, digest_size=32, key=b'', salt=b'', person=b'', fanout=1, depth=1, leaf_size=0, node_offset=0, node_depth=0, inner_size=0, last_node=False)",
hash.update(data),"Update the hash object with the bytes-like object.
Repeated calls are equivalent to a single call with the
concatenation of all the arguments: m.update(a); m.update(b) is
equivalent to m.update(a+b).

Changed in version 3.1: The Python GIL is released to allow other threads to run while hash
updates on data larger than 2047 bytes is taking place when using hash
algorithms supplied by OpenSSL."
hash.digest(),"Return the digest of the data passed to the update() method so far.
This is a bytes object of size digest_size which may contain bytes in
the whole range from 0 to 255."
hash.hexdigest(),"Like digest() except the digest is returned as a string object of
double length, containing only hexadecimal digits.  This may be used to
exchange the value safely in email or other non-binary environments."
hash.copy(),"Return a copy (“clone”) of the hash object.  This can be used to efficiently
compute the digests of data sharing a common initial substring."
shake.digest(length),"Return the digest of the data passed to the update() method so far.
This is a bytes object of size length which may contain bytes in
the whole range from 0 to 255."
shake.hexdigest(length),"Like digest() except the digest is returned as a string object of
double length, containing only hexadecimal digits.  This may be used to
exchange the value safely in email or other non-binary environments."
"hmac.new(key, msg=None, digestmod='')","Return a new hmac object.  key is a bytes or bytearray object giving the
secret key.  If msg is present, the method call update(msg) is made.
digestmod is the digest name, digest constructor or module for the HMAC
object to use.  It may be any name suitable to hashlib.new().
Despite its argument position, it is required.

Changed in version 3.4: Parameter key can be a bytes or bytearray object.
Parameter msg can be of any type supported by hashlib.
Parameter digestmod can be the name of a hash algorithm.


Deprecated since version 3.4, will be removed in version 3.8: MD5 as implicit default digest for digestmod is deprecated.
The digestmod parameter is now required.  Pass it as a keyword
argument to avoid awkwardness when you do not have an initial msg."
"hmac.digest(key, msg, digest)","Return digest of msg for given secret key and digest. The
function is equivalent to HMAC(key, msg, digest).digest(), but
uses an optimized C or inline implementation, which is faster for messages
that fit into memory. The parameters key, msg, and digest have
the same meaning as in new().
CPython implementation detail, the optimized C implementation is only used
when digest is a string and name of a digest algorithm, which is
supported by OpenSSL.

New in version 3.7."
"hmac.compare_digest(a, b)","Return a == b.  This function uses an approach designed to prevent
timing analysis by avoiding content-based short circuiting behaviour,
making it appropriate for cryptography.  a and b must both be of the
same type: either str (ASCII only, as e.g. returned by
HMAC.hexdigest()), or a bytes-like object.

Note
If a and b are of different lengths, or if an error occurs,
a timing attack could theoretically reveal information about the
types and lengths of a and b—but not their values.


New in version 3.3."
HMAC.update(msg),"Update the hmac object with msg.  Repeated calls are equivalent to a
single call with the concatenation of all the arguments:
m.update(a); m.update(b) is equivalent to m.update(a + b).

Changed in version 3.4: Parameter msg can be of any type supported by hashlib."
HMAC.digest(),"Return the digest of the bytes passed to the update() method so far.
This bytes object will be the same length as the digest_size of the digest
given to the constructor.  It may contain non-ASCII bytes, including NUL
bytes.

Warning
When comparing the output of digest() to an externally-supplied
digest during a verification routine, it is recommended to use the
compare_digest() function instead of the == operator
to reduce the vulnerability to timing attacks."
HMAC.hexdigest(),"Like digest() except the digest is returned as a string twice the
length containing only hexadecimal digits.  This may be used to exchange the
value safely in email or other non-binary environments.

Warning
When comparing the output of hexdigest() to an externally-supplied
digest during a verification routine, it is recommended to use the
compare_digest() function instead of the == operator
to reduce the vulnerability to timing attacks."
HMAC.copy(),"Return a copy (“clone”) of the hmac object.  This can be used to efficiently
compute the digests of strings that share a common initial substring."
secrets.choice(sequence),Return a randomly-chosen element from a non-empty sequence.
secrets.randbelow(n),"Return a random int in the range [0, n)."
secrets.randbits(k),Return an int with k random bits.
secrets.token_bytes([nbytes=None]),"Return a random byte string containing nbytes number of bytes.
If nbytes is None or not supplied, a reasonable default is
used.
>>> token_bytes(16)  
b'\xebr\x17D*t\xae\xd4\xe3S\xb6\xe2\xebP1\x8b'"
secrets.token_hex([nbytes=None]),"Return a random text string, in hexadecimal.  The string has nbytes
random bytes, each byte converted to two hex digits.  If nbytes is
None or not supplied, a reasonable default is used.
>>> token_hex(16)  
'f9bf78b9a18ce6d46a0cd2b0b86df9da'"
secrets.token_urlsafe([nbytes=None]),"Return a random URL-safe text string, containing nbytes random
bytes.  The text is Base64 encoded, so on average each byte results
in approximately 1.3 characters.  If nbytes is None or not
supplied, a reasonable default is used.
>>> token_urlsafe(16)  
'Drmhze6EPcv0fN_81Bj-nA'"
"secrets.compare_digest(a, b)","Return True if strings a and b are equal, otherwise False,
in such a way as to reduce the risk of
timing attacks.
See hmac.compare_digest() for additional details."
os.ctermid(),"Return the filename corresponding to the controlling terminal of the process.
Availability: Unix."
os.chdir(path,These functions are described in Files and Directories.
os.fsencode(filename),"Encode path-like filename to the filesystem
encoding with 'surrogateescape' error handler, or 'strict' on
Windows; return bytes unchanged.
fsdecode() is the reverse function.

New in version 3.2.


Changed in version 3.6: Support added to accept objects implementing the os.PathLike
interface."
os.fsdecode(filename),"Decode the path-like filename from the
filesystem encoding with 'surrogateescape' error handler, or 'strict'
on Windows; return str unchanged.
fsencode() is the reverse function.

New in version 3.2.


Changed in version 3.6: Support added to accept objects implementing the os.PathLike
interface."
os.fspath(path),"Return the file system representation of the path.
If str or bytes is passed in, it is returned unchanged.
Otherwise __fspath__() is called and its value is
returned as long as it is a str or bytes object.
In all other cases, TypeError is raised.

New in version 3.6."
"os.getenv(key, default=None)","Return the value of the environment variable key if it exists, or
default if it doesn’t. key, default and the result are str.
On Unix, keys and values are decoded with sys.getfilesystemencoding()
and 'surrogateescape' error handler. Use os.getenvb() if you
would like to use a different encoding.
Availability: most flavors of Unix, Windows."
"os.getenvb(key, default=None)","Return the value of the environment variable key if it exists, or
default if it doesn’t. key, default and the result are bytes.
getenvb() is only available if supports_bytes_environ
is True.
Availability: most flavors of Unix.

New in version 3.2."
os.get_exec_path(env=None),"Returns the list of directories that will be searched for a named
executable, similar to a shell, when launching a process.
env, when specified, should be an environment variable dictionary
to lookup the PATH in.
By default, when env is None, environ is used.

New in version 3.2."
os.getegid(),"Return the effective group id of the current process.  This corresponds to the
“set id” bit on the file being executed in the current process.
Availability: Unix."
os.geteuid(),"Return the current process’s effective user id.
Availability: Unix."
os.getgid(),"Return the real group id of the current process.
Availability: Unix."
"os.getgrouplist(user, group)","Return list of group ids that user belongs to. If group is not in the
list, it is included; typically, group is specified as the group ID
field from the password record for user.
Availability: Unix.

New in version 3.3."
os.getgroups(),"Return list of supplemental group ids associated with the current process.
Availability: Unix.

Note
On Mac OS X, getgroups() behavior differs somewhat from
other Unix platforms. If the Python interpreter was built with a
deployment target of 10.5 or earlier, getgroups() returns
the list of effective group ids associated with the current user process;
this list is limited to a system-defined number of entries, typically 16,
and may be modified by calls to setgroups() if suitably privileged.
If built with a deployment target greater than 10.5,
getgroups() returns the current group access list for the user
associated with the effective user id of the process; the group access
list may change over the lifetime of the process, it is not affected by
calls to setgroups(), and its length is not limited to 16.  The
deployment target value, MACOSX_DEPLOYMENT_TARGET, can be
obtained with sysconfig.get_config_var()."
os.getlogin(),"Return the name of the user logged in on the controlling terminal of the
process.  For most purposes, it is more useful to use
getpass.getuser() since the latter checks the environment variables
LOGNAME or USERNAME to find out who the user is, and
falls back to pwd.getpwuid(os.getuid())[0] to get the login name of the
current real user id.
Availability: Unix, Windows."
os.getpgid(pid),"Return the process group id of the process with process id pid. If pid is 0,
the process group id of the current process is returned.
Availability: Unix."
os.getpgrp(),"Return the id of the current process group.
Availability: Unix."
os.getpid(),Return the current process id.
os.getppid(),"Return the parent’s process id.  When the parent process has exited, on Unix
the id returned is the one of the init process (1), on Windows it is still
the same id, which may be already reused by another process.
Availability: Unix, Windows.

Changed in version 3.2: Added support for Windows."
"os.getpriority(which, who)","Get program scheduling priority.  The value which is one of
PRIO_PROCESS, PRIO_PGRP, or PRIO_USER, and who
is interpreted relative to which (a process identifier for
PRIO_PROCESS, process group identifier for PRIO_PGRP, and a
user ID for PRIO_USER).  A zero value for who denotes
(respectively) the calling process, the process group of the calling process,
or the real user ID of the calling process.
Availability: Unix.

New in version 3.3."
os.getresuid(),"Return a tuple (ruid, euid, suid) denoting the current process’s
real, effective, and saved user ids.
Availability: Unix.

New in version 3.2."
os.getresgid(),"Return a tuple (rgid, egid, sgid) denoting the current process’s
real, effective, and saved group ids.
Availability: Unix.

New in version 3.2."
os.getuid(),"Return the current process’s real user id.
Availability: Unix."
"os.initgroups(username, gid)","Call the system initgroups() to initialize the group access list with all of
the groups of which the specified username is a member, plus the specified
group id.
Availability: Unix.

New in version 3.2."
"os.putenv(key, value)","Set the environment variable named key to the string value.  Such
changes to the environment affect subprocesses started with os.system(),
popen() or fork() and execv().
Availability: most flavors of Unix, Windows.

Note
On some platforms, including FreeBSD and Mac OS X, setting environ may
cause memory leaks. Refer to the system documentation for putenv.

When putenv() is supported, assignments to items in os.environ are
automatically translated into corresponding calls to putenv(); however,
calls to putenv() don’t update os.environ, so it is actually
preferable to assign to items of os.environ.
Raises an auditing event os.putenv with arguments key, value."
os.setegid(egid),"Set the current process’s effective group id.
Availability: Unix."
os.seteuid(euid),"Set the current process’s effective user id.
Availability: Unix."
os.setgid(gid),"Set the current process’ group id.
Availability: Unix."
os.setgroups(groups),"Set the list of supplemental group ids associated with the current process to
groups. groups must be a sequence, and each element must be an integer
identifying a group. This operation is typically available only to the superuser.
Availability: Unix.

Note
On Mac OS X, the length of groups may not exceed the
system-defined maximum number of effective group ids, typically 16.
See the documentation for getgroups() for cases where it may not
return the same group list set by calling setgroups()."
os.setpgrp(),"Call the system call setpgrp() or setpgrp(0, 0) depending on
which version is implemented (if any).  See the Unix manual for the semantics.
Availability: Unix."
"os.setpgid(pid, pgrp)","Call the system call setpgid() to set the process group id of the
process with id pid to the process group with id pgrp.  See the Unix manual
for the semantics.
Availability: Unix."
"os.setpriority(which, who, priority)","Set program scheduling priority. The value which is one of
PRIO_PROCESS, PRIO_PGRP, or PRIO_USER, and who
is interpreted relative to which (a process identifier for
PRIO_PROCESS, process group identifier for PRIO_PGRP, and a
user ID for PRIO_USER). A zero value for who denotes
(respectively) the calling process, the process group of the calling process,
or the real user ID of the calling process.
priority is a value in the range -20 to 19. The default priority is 0;
lower priorities cause more favorable scheduling.
Availability: Unix.

New in version 3.3."
"os.setregid(rgid, egid)","Set the current process’s real and effective group ids.
Availability: Unix."
"os.setresgid(rgid, egid, sgid)","Set the current process’s real, effective, and saved group ids.
Availability: Unix.

New in version 3.2."
"os.setresuid(ruid, euid, suid)","Set the current process’s real, effective, and saved user ids.
Availability: Unix.

New in version 3.2."
"os.setreuid(ruid, euid)","Set the current process’s real and effective user ids.
Availability: Unix."
os.getsid(pid),"Call the system call getsid().  See the Unix manual for the semantics.
Availability: Unix."
os.setsid(),"Call the system call setsid().  See the Unix manual for the semantics.
Availability: Unix."
os.setuid(uid),"Set the current process’s user id.
Availability: Unix."
os.strerror(code),"Return the error message corresponding to the error code in code.
On platforms where strerror() returns NULL when given an unknown
error number, ValueError is raised."
os.umask(mask),Set the current numeric umask and return the previous umask.
os.uname(),"Returns information identifying the current operating system.
The return value is an object with five attributes:

sysname - operating system name
nodename - name of machine on network (implementation-defined)
release - operating system release
version - operating system version
machine - hardware identifier

For backwards compatibility, this object is also iterable, behaving
like a five-tuple containing sysname, nodename,
release, version, and machine
in that order.
Some systems truncate nodename to 8 characters or to the
leading component; a better way to get the hostname is
socket.gethostname()  or even
socket.gethostbyaddr(socket.gethostname()).
Availability: recent flavors of Unix.

Changed in version 3.3: Return type changed from a tuple to a tuple-like object
with named attributes."
os.unsetenv(key),"Unset (delete) the environment variable named key. Such changes to the
environment affect subprocesses started with os.system(), popen() or
fork() and execv().
When unsetenv() is supported, deletion of items in os.environ is
automatically translated into a corresponding call to unsetenv(); however,
calls to unsetenv() don’t update os.environ, so it is actually
preferable to delete items of os.environ.
Raises an auditing event os.unsetenv with argument key.
Availability: most flavors of Unix."
"os.fdopen(fd, *args, **kwargs)","Return an open file object connected to the file descriptor fd.  This is an
alias of the open() built-in function and accepts the same arguments.
The only difference is that the first argument of fdopen() must always
be an integer."
os.close(fd),"Close file descriptor fd.

Note
This function is intended for low-level I/O and must be applied to a file
descriptor as returned by os.open() or pipe().  To close a “file
object” returned by the built-in function open() or by popen() or
fdopen(), use its close() method."
"os.closerange(fd_low, fd_high)","Close all file descriptors from fd_low (inclusive) to fd_high (exclusive),
ignoring errors. Equivalent to (but much faster than):
for fd in range(fd_low, fd_high):
    try:
        os.close(fd)
    except OSError:
        pass"
"os.copy_file_range(src, dst, count, offset_src=None, offset_dst=None)","Copy count bytes from file descriptor src, starting from offset
offset_src, to file descriptor dst, starting from offset offset_dst.
If offset_src is None, then src is read from the current position;
respectively for offset_dst. The files pointed by src and dst
must reside in the same filesystem, otherwise an OSError is
raised with errno set to errno.EXDEV.
This copy is done without the additional cost of transferring data
from the kernel to user space and then back into the kernel. Additionally,
some filesystems could implement extra optimizations. The copy is done as if
both files are opened as binary.
The return value is the amount of bytes copied. This could be less than the
amount requested.
Availability: Linux kernel >= 4.5 or glibc >= 2.27.

New in version 3.8."
os.device_encoding(fd),"Return a string describing the encoding of the device associated with fd
if it is connected to a terminal; else return None."
os.dup(fd),"Return a duplicate of file descriptor fd. The new file descriptor is
non-inheritable.
On Windows, when duplicating a standard stream (0: stdin, 1: stdout,
2: stderr), the new file descriptor is inheritable.

Changed in version 3.4: The new file descriptor is now non-inheritable."
"os.dup2(fd, fd2, inheritable=True)","Duplicate file descriptor fd to fd2, closing the latter first if
necessary. Return fd2. The new file descriptor is inheritable by default or non-inheritable if inheritable
is False.

Changed in version 3.4: Add the optional inheritable parameter.


Changed in version 3.7: Return fd2 on success. Previously, None was always returned."
"os.fchmod(fd, mode)","Change the mode of the file given by fd to the numeric mode.  See the
docs for chmod() for possible values of mode.  As of Python 3.3, this
is equivalent to os.chmod(fd, mode).
Raises an auditing event os.chmod with arguments path, mode, dir_fd.
Availability: Unix."
"os.fchown(fd, uid, gid)","Change the owner and group id of the file given by fd to the numeric uid
and gid.  To leave one of the ids unchanged, set it to -1.  See
chown().  As of Python 3.3, this is equivalent to os.chown(fd, uid,
gid).
Raises an auditing event os.chown with arguments path, uid, gid, dir_fd.
Availability: Unix."
os.fdatasync(fd),"Force write of file with filedescriptor fd to disk. Does not force update of
metadata.
Availability: Unix.

Note
This function is not available on MacOS."
"os.fpathconf(fd, name)","Return system configuration information relevant to an open file. name
specifies the configuration value to retrieve; it may be a string which is the
name of a defined system value; these names are specified in a number of
standards (POSIX.1, Unix 95, Unix 98, and others).  Some platforms define
additional names as well.  The names known to the host operating system are
given in the pathconf_names dictionary.  For configuration variables not
included in that mapping, passing an integer for name is also accepted.
If name is a string and is not known, ValueError is raised.  If a
specific value for name is not supported by the host system, even if it is
included in pathconf_names, an OSError is raised with
errno.EINVAL for the error number.
As of Python 3.3, this is equivalent to os.pathconf(fd, name).
Availability: Unix."
os.fstat(fd),"Get the status of the file descriptor fd. Return a stat_result
object.
As of Python 3.3, this is equivalent to os.stat(fd).

See also
The stat() function."
os.fstatvfs(fd),"Return information about the filesystem containing the file associated with
file descriptor fd, like statvfs().  As of Python 3.3, this is
equivalent to os.statvfs(fd).
Availability: Unix."
os.fsync(fd),"Force write of file with filedescriptor fd to disk.  On Unix, this calls the
native fsync() function; on Windows, the MS _commit() function.
If you’re starting with a buffered Python file object f, first do
f.flush(), and then do os.fsync(f.fileno()), to ensure that all internal
buffers associated with f are written to disk.
Availability: Unix, Windows."
"os.ftruncate(fd, length)","Truncate the file corresponding to file descriptor fd, so that it is at
most length bytes in size.  As of Python 3.3, this is equivalent to
os.truncate(fd, length).
Raises an auditing event os.truncate with arguments fd, length.
Availability: Unix, Windows.

Changed in version 3.5: Added support for Windows"
os.get_blocking(fd),"Get the blocking mode of the file descriptor: False if the
O_NONBLOCK flag is set, True if the flag is cleared.
See also set_blocking() and socket.socket.setblocking().
Availability: Unix.

New in version 3.5."
os.isatty(fd),"Return True if the file descriptor fd is open and connected to a
tty(-like) device, else False."
"os.lockf(fd, cmd, len)","Apply, test or remove a POSIX lock on an open file descriptor.
fd is an open file descriptor.
cmd specifies the command to use - one of F_LOCK, F_TLOCK,
F_ULOCK or F_TEST.
len specifies the section of the file to lock.
Raises an auditing event os.lockf with arguments fd, cmd, len.
Availability: Unix.

New in version 3.3."
"os.lseek(fd, pos, how)","Set the current position of file descriptor fd to position pos, modified
by how: SEEK_SET or 0 to set the position relative to the
beginning of the file; SEEK_CUR or 1 to set it relative to the
current position; SEEK_END or 2 to set it relative to the end of
the file. Return the new cursor position in bytes, starting from the beginning."
"os.open(path, flags, mode=0o777, *, dir_fd=None)","Open the file path and set various flags according to flags and possibly
its mode according to mode.  When computing mode, the current umask value
is first masked out.  Return the file descriptor for the newly opened file.
The new file descriptor is non-inheritable.
For a description of the flag and mode values, see the C run-time documentation;
flag constants (like O_RDONLY and O_WRONLY) are defined in
the os module.  In particular, on Windows adding
O_BINARY is needed to open files in binary mode.
This function can support paths relative to directory descriptors with the dir_fd parameter.
Raises an auditing event open with arguments path, mode, flags.

Changed in version 3.4: The new file descriptor is now non-inheritable.


Note
This function is intended for low-level I/O.  For normal usage, use the
built-in function open(), which returns a file object with
read() and write() methods (and many more).  To
wrap a file descriptor in a file object, use fdopen().


New in version 3.3: The dir_fd argument.


Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an
exception, the function now retries the system call instead of raising an
InterruptedError exception (see PEP 475 for the rationale).


Changed in version 3.6: Accepts a path-like object."
os.openpty(),"Open a new pseudo-terminal pair. Return a pair of file descriptors
(master, slave) for the pty and the tty, respectively. The new file
descriptors are non-inheritable. For a (slightly) more
portable approach, use the pty module.
Availability: some flavors of Unix.

Changed in version 3.4: The new file descriptors are now non-inheritable."
os.pipe(),"Create a pipe.  Return a pair of file descriptors (r, w) usable for
reading and writing, respectively. The new file descriptor is
non-inheritable.
Availability: Unix, Windows.

Changed in version 3.4: The new file descriptors are now non-inheritable."
os.pipe2(flags),"Create a pipe with flags set atomically.
flags can be constructed by ORing together one or more of these values:
O_NONBLOCK, O_CLOEXEC.
Return a pair of file descriptors (r, w) usable for reading and writing,
respectively.
Availability: some flavors of Unix.

New in version 3.3."
"os.posix_fallocate(fd, offset, len)","Ensures that enough disk space is allocated for the file specified by fd
starting from offset and continuing for len bytes.
Availability: Unix.

New in version 3.3."
"os.posix_fadvise(fd, offset, len, advice)","Announces an intention to access data in a specific pattern thus allowing
the kernel to make optimizations.
The advice applies to the region of the file specified by fd starting at
offset and continuing for len bytes.
advice is one of POSIX_FADV_NORMAL, POSIX_FADV_SEQUENTIAL,
POSIX_FADV_RANDOM, POSIX_FADV_NOREUSE,
POSIX_FADV_WILLNEED or POSIX_FADV_DONTNEED.
Availability: Unix.

New in version 3.3."
"os.pread(fd, n, offset)","Read at most n bytes from file descriptor fd at a position of offset,
leaving the file offset unchanged.
Return a bytestring containing the bytes read. If the end of the file
referred to by fd has been reached, an empty bytes object is returned.
Availability: Unix.

New in version 3.3."
"os.preadv(fd, buffers, offset, flags=0)","Read from a file descriptor fd at a position of offset into mutable
bytes-like objects buffers, leaving the file
offset unchanged.  Transfer data into each buffer until it is full and then
move on to the next buffer in the sequence to hold the rest of the data.
The flags argument contains a bitwise OR of zero or more of the following
flags:

RWF_HIPRI
RWF_NOWAIT

Return the total number of bytes actually read which can be less than the
total capacity of all the objects.
The operating system may set a limit (sysconf() value
'SC_IOV_MAX') on the number of buffers that can be used.
Combine the functionality of os.readv() and os.pread().
Availability: Linux 2.6.30 and newer, FreeBSD 6.0 and newer,
OpenBSD 2.7 and newer. Using flags requires Linux 4.6 or newer.

New in version 3.7."
"os.pwrite(fd, str, offset)","Write the bytestring in str to file descriptor fd at position of
offset, leaving the file offset unchanged.
Return the number of bytes actually written.
Availability: Unix.

New in version 3.3."
"os.pwritev(fd, buffers, offset, flags=0)","Write the buffers contents to file descriptor fd at a offset offset,
leaving the file offset unchanged.  buffers must be a sequence of
bytes-like objects. Buffers are processed in
array order. Entire contents of the first buffer is written before
proceeding to the second, and so on.
The flags argument contains a bitwise OR of zero or more of the following
flags:

RWF_DSYNC
RWF_SYNC

Return the total number of bytes actually written.
The operating system may set a limit (sysconf() value
'SC_IOV_MAX') on the number of buffers that can be used.
Combine the functionality of os.writev() and os.pwrite().
Availability: Linux 2.6.30 and newer, FreeBSD 6.0 and newer,
OpenBSD 2.7 and newer. Using flags requires Linux 4.7 or newer.

New in version 3.7."
"os.read(fd, n)","Read at most n bytes from file descriptor fd.
Return a bytestring containing the bytes read. If the end of the file
referred to by fd has been reached, an empty bytes object is returned.

Note
This function is intended for low-level I/O and must be applied to a file
descriptor as returned by os.open() or pipe().  To read a
“file object” returned by the built-in function open() or by
popen() or fdopen(), or sys.stdin, use its
read() or readline() methods.


Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an
exception, the function now retries the system call instead of raising an
InterruptedError exception (see PEP 475 for the rationale)."
"os.sendfile(out, in, offset, count)","Copy count bytes from file descriptor in to file descriptor out
starting at offset.
Return the number of bytes sent. When EOF is reached return 0.
The first function notation is supported by all platforms that define
sendfile().
On Linux, if offset is given as None, the bytes are read from the
current position of in and the position of in is updated.
The second case may be used on Mac OS X and FreeBSD where headers and
trailers are arbitrary sequences of buffers that are written before and
after the data from in is written. It returns the same as the first case.
On Mac OS X and FreeBSD, a value of 0 for count specifies to send until
the end of in is reached.
All platforms support sockets as out file descriptor, and some platforms
allow other types (e.g. regular file, pipe) as well.
Cross-platform applications should not use headers, trailers and flags
arguments.
Availability: Unix.

Note
For a higher-level wrapper of sendfile(), see
socket.socket.sendfile().


New in version 3.3."
"os.set_blocking(fd, blocking)","Set the blocking mode of the specified file descriptor. Set the
O_NONBLOCK flag if blocking is False, clear the flag otherwise.
See also get_blocking() and socket.socket.setblocking().
Availability: Unix.

New in version 3.5."
"os.readv(fd, buffers)","Read from a file descriptor fd into a number of mutable bytes-like
objects buffers. Transfer data into each buffer until
it is full and then move on to the next buffer in the sequence to hold the
rest of the data.
Return the total number of bytes actually read which can be less than the
total capacity of all the objects.
The operating system may set a limit (sysconf() value
'SC_IOV_MAX') on the number of buffers that can be used.
Availability: Unix.

New in version 3.3."
os.tcgetpgrp(fd),"Return the process group associated with the terminal given by fd (an open
file descriptor as returned by os.open()).
Availability: Unix."
"os.tcsetpgrp(fd, pg)","Set the process group associated with the terminal given by fd (an open file
descriptor as returned by os.open()) to pg.
Availability: Unix."
os.ttyname(fd),"Return a string which specifies the terminal device associated with
file descriptor fd.  If fd is not associated with a terminal device, an
exception is raised.
Availability: Unix."
"os.write(fd, str)","Write the bytestring in str to file descriptor fd.
Return the number of bytes actually written.

Note
This function is intended for low-level I/O and must be applied to a file
descriptor as returned by os.open() or pipe().  To write a “file
object” returned by the built-in function open() or by popen() or
fdopen(), or sys.stdout or sys.stderr, use its
write() method.


Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an
exception, the function now retries the system call instead of raising an
InterruptedError exception (see PEP 475 for the rationale)."
"os.writev(fd, buffers)","Write the contents of buffers to file descriptor fd. buffers must be
a sequence of bytes-like objects. Buffers are
processed in array order. Entire contents of the first buffer is written
before proceeding to the second, and so on.
Returns the total number of bytes actually written.
The operating system may set a limit (sysconf() value
'SC_IOV_MAX') on the number of buffers that can be used.
Availability: Unix.

New in version 3.3."
os.get_terminal_size(fd=STDOUT_FILENO),"Return the size of the terminal window as (columns, lines),
tuple of type terminal_size.
The optional argument fd (default STDOUT_FILENO, or standard
output) specifies which file descriptor should be queried.
If the file descriptor is not connected to a terminal, an OSError
is raised.
shutil.get_terminal_size() is the high-level function which
should normally be used, os.get_terminal_size is the low-level
implementation.
Availability: Unix, Windows."
os.get_inheritable(fd),Get the “inheritable” flag of the specified file descriptor (a boolean).
"os.set_inheritable(fd, inheritable)",Set the “inheritable” flag of the specified file descriptor.
os.get_handle_inheritable(handle),"Get the “inheritable” flag of the specified handle (a boolean).
Availability: Windows."
"os.set_handle_inheritable(handle, inheritable)","Set the “inheritable” flag of the specified handle.
Availability: Windows."
"os.access(path, mode, *, dir_fd=None, effective_ids=False, follow_symlinks=True)","Use the real uid/gid to test for access to path.  Note that most operations
will use the effective uid/gid, therefore this routine can be used in a
suid/sgid environment to test if the invoking user has the specified access to
path.  mode should be F_OK to test the existence of path, or it
can be the inclusive OR of one or more of R_OK, W_OK, and
X_OK to test permissions.  Return True if access is allowed,
False if not. See the Unix man page access(2) for more
information.
This function can support specifying paths relative to directory
descriptors and not following symlinks.
If effective_ids is True, access() will perform its access
checks using the effective uid/gid instead of the real uid/gid.
effective_ids may not be supported on your platform; you can check whether
or not it is available using os.supports_effective_ids.  If it is
unavailable, using it will raise a NotImplementedError.

Note
Using access() to check if a user is authorized to e.g. open a file
before actually doing so using open() creates a security hole,
because the user might exploit the short time interval between checking
and opening the file to manipulate it. It’s preferable to use EAFP
techniques. For example:
if os.access(""myfile"", os.R_OK):
    with open(""myfile"") as fp:
        return fp.read()
return ""some default data""


is better written as:
try:
    fp = open(""myfile"")
except PermissionError:
    return ""some default data""
else:
    with fp:
        return fp.read()




Note
I/O operations may fail even when access() indicates that they would
succeed, particularly for operations on network filesystems which may have
permissions semantics beyond the usual POSIX permission-bit model.


Changed in version 3.3: Added the dir_fd, effective_ids, and follow_symlinks parameters.


Changed in version 3.6: Accepts a path-like object."
os.chdir(path),"Change the current working directory to path.
This function can support specifying a file descriptor.  The
descriptor must refer to an opened directory, not an open file.
This function can raise OSError and subclasses such as
FileNotFoundError, PermissionError, and NotADirectoryError.
Raises an auditing event os.chdir with argument path.

New in version 3.3: Added support for specifying path as a file descriptor
on some platforms.


Changed in version 3.6: Accepts a path-like object."
"os.chflags(path, flags, *, follow_symlinks=True)","Set the flags of path to the numeric flags. flags may take a combination
(bitwise OR) of the following values (as defined in the stat module):

stat.UF_NODUMP
stat.UF_IMMUTABLE
stat.UF_APPEND
stat.UF_OPAQUE
stat.UF_NOUNLINK
stat.UF_COMPRESSED
stat.UF_HIDDEN
stat.SF_ARCHIVED
stat.SF_IMMUTABLE
stat.SF_APPEND
stat.SF_NOUNLINK
stat.SF_SNAPSHOT

This function can support not following symlinks.
Raises an auditing event os.chflags with arguments path, flags.
Availability: Unix.

New in version 3.3: The follow_symlinks argument.


Changed in version 3.6: Accepts a path-like object."
"os.chmod(path, mode, *, dir_fd=None, follow_symlinks=True)","Change the mode of path to the numeric mode. mode may take one of the
following values (as defined in the stat module) or bitwise ORed
combinations of them:

stat.S_ISUID
stat.S_ISGID
stat.S_ENFMT
stat.S_ISVTX
stat.S_IREAD
stat.S_IWRITE
stat.S_IEXEC
stat.S_IRWXU
stat.S_IRUSR
stat.S_IWUSR
stat.S_IXUSR
stat.S_IRWXG
stat.S_IRGRP
stat.S_IWGRP
stat.S_IXGRP
stat.S_IRWXO
stat.S_IROTH
stat.S_IWOTH
stat.S_IXOTH

This function can support specifying a file descriptor,
paths relative to directory descriptors and not
following symlinks.

Note
Although Windows supports chmod(), you can only set the file’s
read-only flag with it (via the stat.S_IWRITE and stat.S_IREAD
constants or a corresponding integer value).  All other bits are ignored.

Raises an auditing event os.chmod with arguments path, mode, dir_fd.

New in version 3.3: Added support for specifying path as an open file descriptor,
and the dir_fd and follow_symlinks arguments.


Changed in version 3.6: Accepts a path-like object."
"os.chown(path, uid, gid, *, dir_fd=None, follow_symlinks=True)","Change the owner and group id of path to the numeric uid and gid.  To
leave one of the ids unchanged, set it to -1.
This function can support specifying a file descriptor,
paths relative to directory descriptors and not
following symlinks.
See shutil.chown() for a higher-level function that accepts names in
addition to numeric ids.
Raises an auditing event os.chown with arguments path, uid, gid, dir_fd.
Availability: Unix.

New in version 3.3: Added support for specifying path as an open file descriptor,
and the dir_fd and follow_symlinks arguments.


Changed in version 3.6: Supports a path-like object."
os.chroot(path),"Change the root directory of the current process to path.
Availability: Unix.

Changed in version 3.6: Accepts a path-like object."
os.fchdir(fd),"Change the current working directory to the directory represented by the file
descriptor fd.  The descriptor must refer to an opened directory, not an
open file.  As of Python 3.3, this is equivalent to os.chdir(fd).
Raises an auditing event os.chdir with argument path.
Availability: Unix."
os.getcwd(),Return a string representing the current working directory.
os.getcwdb(),"Return a bytestring representing the current working directory.

Changed in version 3.8: The function now uses the UTF-8 encoding on Windows, rather than the ANSI
code page: see PEP 529 for the rationale. The function is no longer
deprecated on Windows."
"os.lchflags(path, flags)","Set the flags of path to the numeric flags, like chflags(), but do
not follow symbolic links.  As of Python 3.3, this is equivalent to
os.chflags(path, flags, follow_symlinks=False).
Raises an auditing event os.chflags with arguments path, flags.
Availability: Unix.

Changed in version 3.6: Accepts a path-like object."
"os.lchmod(path, mode)","Change the mode of path to the numeric mode. If path is a symlink, this
affects the symlink rather than the target.  See the docs for chmod()
for possible values of mode.  As of Python 3.3, this is equivalent to
os.chmod(path, mode, follow_symlinks=False).
Raises an auditing event os.chmod with arguments path, mode, dir_fd.
Availability: Unix.

Changed in version 3.6: Accepts a path-like object."
"os.lchown(path, uid, gid)","Change the owner and group id of path to the numeric uid and gid.  This
function will not follow symbolic links.  As of Python 3.3, this is equivalent
to os.chown(path, uid, gid, follow_symlinks=False).
Raises an auditing event os.chown with arguments path, uid, gid, dir_fd.
Availability: Unix.

Changed in version 3.6: Accepts a path-like object."
"os.link(src, dst, *, src_dir_fd=None, dst_dir_fd=None, follow_symlinks=True)","Create a hard link pointing to src named dst.
This function can support specifying src_dir_fd and/or dst_dir_fd to
supply paths relative to directory descriptors, and not
following symlinks.
Raises an auditing event os.link with arguments src, dst, src_dir_fd, dst_dir_fd.
Availability: Unix, Windows.

Changed in version 3.2: Added Windows support.


New in version 3.3: Added the src_dir_fd, dst_dir_fd, and follow_symlinks arguments.


Changed in version 3.6: Accepts a path-like object for src and dst."
os.listdir(path='.'),"Return a list containing the names of the entries in the directory given by
path.  The list is in arbitrary order, and does not include the special
entries '.' and '..' even if they are present in the directory.
path may be a path-like object.  If path is of type bytes
(directly or indirectly through the PathLike interface),
the filenames returned will also be of type bytes;
in all other circumstances, they will be of type str.
This function can also support specifying a file descriptor; the file descriptor must refer to a directory.
Raises an auditing event os.listdir with argument path.

Note
To encode str filenames to bytes, use fsencode().


See also
The scandir() function returns directory entries along with
file attribute information, giving better performance for many
common use cases.


Changed in version 3.2: The path parameter became optional.


New in version 3.3: Added support for specifying path as an open file descriptor.


Changed in version 3.6: Accepts a path-like object."
"os.lstat(path, *, dir_fd=None)","Perform the equivalent of an lstat() system call on the given path.
Similar to stat(), but does not follow symbolic links. Return a
stat_result object.
On platforms that do not support symbolic links, this is an alias for
stat().
As of Python 3.3, this is equivalent to os.stat(path, dir_fd=dir_fd,
follow_symlinks=False).
This function can also support paths relative to directory descriptors.

See also
The stat() function.


Changed in version 3.2: Added support for Windows 6.0 (Vista) symbolic links.


Changed in version 3.3: Added the dir_fd parameter.


Changed in version 3.6: Accepts a path-like object for src and dst.


Changed in version 3.8: On Windows, now opens reparse points that represent another path
(name surrogates), including symbolic links and directory junctions.
Other kinds of reparse points are resolved by the operating system as
for stat()."
"os.mkdir(path, mode=0o777, *, dir_fd=None)","Create a directory named path with numeric mode mode.
If the directory already exists, FileExistsError is raised.
On some systems, mode is ignored.  Where it is used, the current umask
value is first masked out.  If bits other than the last 9 (i.e. the last 3
digits of the octal representation of the mode) are set, their meaning is
platform-dependent.  On some platforms, they are ignored and you should call
chmod() explicitly to set them.
This function can also support paths relative to directory descriptors.
It is also possible to create temporary directories; see the
tempfile module’s tempfile.mkdtemp() function.
Raises an auditing event os.mkdir with arguments path, mode, dir_fd.

New in version 3.3: The dir_fd argument.


Changed in version 3.6: Accepts a path-like object."
"os.makedirs(name, mode=0o777, exist_ok=False)","Recursive directory creation function.  Like mkdir(), but makes all
intermediate-level directories needed to contain the leaf directory.
The mode parameter is passed to mkdir() for creating the leaf
directory; see the mkdir() description for how it
is interpreted.  To set the file permission bits of any newly-created parent
directories you can set the umask before invoking makedirs().  The
file permission bits of existing parent directories are not changed.
If exist_ok is False (the default), an FileExistsError is
raised if the target directory already exists.

Note
makedirs() will become confused if the path elements to create
include pardir (eg. “..” on UNIX systems).

This function handles UNC paths correctly.
Raises an auditing event os.mkdir with arguments path, mode, dir_fd.

New in version 3.2: The exist_ok parameter.


Changed in version 3.4.1: Before Python 3.4.1, if exist_ok was True and the directory existed,
makedirs() would still raise an error if mode did not match the
mode of the existing directory. Since this behavior was impossible to
implement safely, it was removed in Python 3.4.1. See bpo-21082.


Changed in version 3.6: Accepts a path-like object.


Changed in version 3.7: The mode argument no longer affects the file permission bits of
newly-created intermediate-level directories."
"os.mkfifo(path, mode=0o666, *, dir_fd=None)","Create a FIFO (a named pipe) named path with numeric mode mode.
The current umask value is first masked out from the mode.
This function can also support paths relative to directory descriptors.
FIFOs are pipes that can be accessed like regular files.  FIFOs exist until they
are deleted (for example with os.unlink()). Generally, FIFOs are used as
rendezvous between “client” and “server” type processes: the server opens the
FIFO for reading, and the client opens it for writing.  Note that mkfifo()
doesn’t open the FIFO — it just creates the rendezvous point.
Availability: Unix.

New in version 3.3: The dir_fd argument.


Changed in version 3.6: Accepts a path-like object."
"os.mknod(path, mode=0o600, device=0, *, dir_fd=None)","Create a filesystem node (file, device special file or named pipe) named
path. mode specifies both the permissions to use and the type of node
to be created, being combined (bitwise OR) with one of stat.S_IFREG,
stat.S_IFCHR, stat.S_IFBLK, and stat.S_IFIFO (those constants are
available in stat).  For stat.S_IFCHR and stat.S_IFBLK,
device defines the newly created device special file (probably using
os.makedev()), otherwise it is ignored.
This function can also support paths relative to directory descriptors.
Availability: Unix.

New in version 3.3: The dir_fd argument.


Changed in version 3.6: Accepts a path-like object."
os.major(device),"Extract the device major number from a raw device number (usually the
st_dev or st_rdev field from stat)."
os.minor(device),"Extract the device minor number from a raw device number (usually the
st_dev or st_rdev field from stat)."
"os.makedev(major, minor)",Compose a raw device number from the major and minor device numbers.
"os.pathconf(path, name)","Return system configuration information relevant to a named file. name
specifies the configuration value to retrieve; it may be a string which is the
name of a defined system value; these names are specified in a number of
standards (POSIX.1, Unix 95, Unix 98, and others).  Some platforms define
additional names as well.  The names known to the host operating system are
given in the pathconf_names dictionary.  For configuration variables not
included in that mapping, passing an integer for name is also accepted.
If name is a string and is not known, ValueError is raised.  If a
specific value for name is not supported by the host system, even if it is
included in pathconf_names, an OSError is raised with
errno.EINVAL for the error number.
This function can support specifying a file descriptor.
Availability: Unix.

Changed in version 3.6: Accepts a path-like object."
"os.readlink(path, *, dir_fd=None)","Return a string representing the path to which the symbolic link points.  The
result may be either an absolute or relative pathname; if it is relative, it
may be converted to an absolute pathname using
os.path.join(os.path.dirname(path), result).
If the path is a string object (directly or indirectly through a
PathLike interface), the result will also be a string object,
and the call may raise a UnicodeDecodeError. If the path is a bytes
object (direct or indirectly), the result will be a bytes object.
This function can also support paths relative to directory descriptors.
When trying to resolve a path that may contain links, use
realpath() to properly handle recursion and platform
differences.
Availability: Unix, Windows.

Changed in version 3.2: Added support for Windows 6.0 (Vista) symbolic links.


New in version 3.3: The dir_fd argument.


Changed in version 3.6: Accepts a path-like object on Unix.


Changed in version 3.8: Accepts a path-like object and a bytes object on Windows.


Changed in version 3.8: Added support for directory junctions, and changed to return the
substitution path (which typically includes \\?\ prefix) rather
than the optional “print name” field that was previously returned."
"os.remove(path, *, dir_fd=None)","Remove (delete) the file path.  If path is a directory, an
IsADirectoryError is raised.  Use rmdir() to remove directories.
This function can support paths relative to directory descriptors.
On Windows, attempting to remove a file that is in use causes an exception to
be raised; on Unix, the directory entry is removed but the storage allocated
to the file is not made available until the original file is no longer in use.
This function is semantically identical to unlink().
Raises an auditing event os.remove with arguments path, dir_fd.

New in version 3.3: The dir_fd argument.


Changed in version 3.6: Accepts a path-like object."
os.removedirs(name),"Remove directories recursively.  Works like rmdir() except that, if the
leaf directory is successfully removed, removedirs()  tries to
successively remove every parent directory mentioned in  path until an error
is raised (which is ignored, because it generally means that a parent directory
is not empty). For example, os.removedirs('foo/bar/baz') will first remove
the directory 'foo/bar/baz', and then remove 'foo/bar' and 'foo' if
they are empty. Raises OSError if the leaf directory could not be
successfully removed.
Raises an auditing event os.remove with arguments path, dir_fd.

Changed in version 3.6: Accepts a path-like object."
"os.rename(src, dst, *, src_dir_fd=None, dst_dir_fd=None)","Rename the file or directory src to dst. If dst exists, the operation
will fail with an OSError subclass in a number of cases:
On Windows, if dst exists a FileExistsError is always raised.
On Unix, if src is a file and dst is a directory or vice-versa, an
IsADirectoryError or a NotADirectoryError will be raised
respectively.  If both are directories and dst is empty, dst will be
silently replaced.  If dst is a non-empty directory, an OSError
is raised. If both are files, dst it will be replaced silently if the user
has permission.  The operation may fail on some Unix flavors if src and
dst are on different filesystems.  If successful, the renaming will be an
atomic operation (this is a POSIX requirement).
This function can support specifying src_dir_fd and/or dst_dir_fd to
supply paths relative to directory descriptors.
If you want cross-platform overwriting of the destination, use replace().
Raises an auditing event os.rename with arguments src, dst, src_dir_fd, dst_dir_fd.

New in version 3.3: The src_dir_fd and dst_dir_fd arguments.


Changed in version 3.6: Accepts a path-like object for src and dst."
"os.renames(old, new)","Recursive directory or file renaming function. Works like rename(), except
creation of any intermediate directories needed to make the new pathname good is
attempted first. After the rename, directories corresponding to rightmost path
segments of the old name will be pruned away using removedirs().

Note
This function can fail with the new directory structure made if you lack
permissions needed to remove the leaf directory or file.

Raises an auditing event os.rename with arguments src, dst, src_dir_fd, dst_dir_fd.

Changed in version 3.6: Accepts a path-like object for old and new."
"os.replace(src, dst, *, src_dir_fd=None, dst_dir_fd=None)","Rename the file or directory src to dst.  If dst is a directory,
OSError will be raised.  If dst exists and is a file, it will
be replaced silently if the user has permission.  The operation may fail
if src and dst are on different filesystems.  If successful,
the renaming will be an atomic operation (this is a POSIX requirement).
This function can support specifying src_dir_fd and/or dst_dir_fd to
supply paths relative to directory descriptors.
Raises an auditing event os.rename with arguments src, dst, src_dir_fd, dst_dir_fd.

New in version 3.3.


Changed in version 3.6: Accepts a path-like object for src and dst."
"os.rmdir(path, *, dir_fd=None)","Remove (delete) the directory path.  If the directory does not exist or is
not empty, an FileNotFoundError or an OSError is raised
respectively.  In order to remove whole directory trees,
shutil.rmtree() can be used.
This function can support paths relative to directory descriptors.
Raises an auditing event os.rmdir with arguments path, dir_fd.

New in version 3.3: The dir_fd parameter.


Changed in version 3.6: Accepts a path-like object."
os.scandir(path='.'),"Return an iterator of os.DirEntry objects corresponding to the
entries in the directory given by path. The entries are yielded in
arbitrary order, and the special entries '.' and '..' are not
included.
Using scandir() instead of listdir() can significantly
increase the performance of code that also needs file type or file
attribute information, because os.DirEntry objects expose this
information if the operating system provides it when scanning a directory.
All os.DirEntry methods may perform a system call, but
is_dir() and is_file() usually only
require a system call for symbolic links; os.DirEntry.stat()
always requires a system call on Unix but only requires one for
symbolic links on Windows.
path may be a path-like object.  If path is of type bytes
(directly or indirectly through the PathLike interface),
the type of the name and path
attributes of each os.DirEntry will be bytes; in all other
circumstances, they will be of type str.
This function can also support specifying a file descriptor; the file descriptor must refer to a directory.
Raises an auditing event os.scandir with argument path.
The scandir() iterator supports the context manager protocol
and has the following method:


scandir.close()¶
Close the iterator and free acquired resources.
This is called automatically when the iterator is exhausted or garbage
collected, or when an error happens during iterating.  However it
is advisable to call it explicitly or use the with
statement.

New in version 3.6.


The following example shows a simple use of scandir() to display all
the files (excluding directories) in the given path that don’t start with
'.'. The entry.is_file() call will generally not make an additional
system call:
with os.scandir(path) as it:
    for entry in it:
        if not entry.name.startswith('.') and entry.is_file():
            print(entry.name)



Note
On Unix-based systems, scandir() uses the system’s
opendir()
and
readdir()
functions. On Windows, it uses the Win32
FindFirstFileW
and
FindNextFileW
functions.


New in version 3.5.


New in version 3.6: Added support for the context manager protocol and the
close() method.  If a scandir() iterator is neither
exhausted nor explicitly closed a ResourceWarning will be emitted
in its destructor.
The function accepts a path-like object.


Changed in version 3.7: Added support for file descriptors on Unix."
"os.stat(path, *, dir_fd=None, follow_symlinks=True)","Get the status of a file or a file descriptor. Perform the equivalent of a
stat() system call on the given path. path may be specified as
either a string or bytes – directly or indirectly through the PathLike
interface – or as an open file descriptor. Return a stat_result
object.
This function normally follows symlinks; to stat a symlink add the argument
follow_symlinks=False, or use lstat().
This function can support specifying a file descriptor and
not following symlinks.
On Windows, passing follow_symlinks=False will disable following all
name-surrogate reparse points, which includes symlinks and directory
junctions. Other types of reparse points that do not resemble links or that
the operating system is unable to follow will be opened directly. When
following a chain of multiple links, this may result in the original link
being returned instead of the non-link that prevented full traversal. To
obtain stat results for the final path in this case, use the
os.path.realpath() function to resolve the path name as far as
possible and call lstat() on the result. This does not apply to
dangling symlinks or junction points, which will raise the usual exceptions.
Example:
>>> import os
>>> statinfo = os.stat('somefile.txt')
>>> statinfo
os.stat_result(st_mode=33188, st_ino=7876932, st_dev=234881026,
st_nlink=1, st_uid=501, st_gid=501, st_size=264, st_atime=1297230295,
st_mtime=1297230027, st_ctime=1297230027)
>>> statinfo.st_size
264



See also
fstat() and lstat() functions.


New in version 3.3: Added the dir_fd and follow_symlinks arguments, specifying a file
descriptor instead of a path.


Changed in version 3.6: Accepts a path-like object.


Changed in version 3.8: On Windows, all reparse points that can be resolved by the operating
system are now followed, and passing follow_symlinks=False
disables following all name surrogate reparse points. If the operating
system reaches a reparse point that it is not able to follow, stat now
returns the information for the original path as if
follow_symlinks=False had been specified instead of raising an error."
os.statvfs(path),"Perform a statvfs() system call on the given path.  The return value is
an object whose attributes describe the filesystem on the given path, and
correspond to the members of the statvfs structure, namely:
f_bsize, f_frsize, f_blocks, f_bfree,
f_bavail, f_files, f_ffree, f_favail,
f_flag, f_namemax, f_fsid.
Two module-level constants are defined for the f_flag attribute’s
bit-flags: if ST_RDONLY is set, the filesystem is mounted
read-only, and if ST_NOSUID is set, the semantics of
setuid/setgid bits are disabled or not supported.
Additional module-level constants are defined for GNU/glibc based systems.
These are ST_NODEV (disallow access to device special files),
ST_NOEXEC (disallow program execution), ST_SYNCHRONOUS
(writes are synced at once), ST_MANDLOCK (allow mandatory locks on an FS),
ST_WRITE (write on file/directory/symlink), ST_APPEND
(append-only file), ST_IMMUTABLE (immutable file), ST_NOATIME
(do not update access times), ST_NODIRATIME (do not update directory access
times), ST_RELATIME (update atime relative to mtime/ctime).
This function can support specifying a file descriptor.
Availability: Unix.

Changed in version 3.2: The ST_RDONLY and ST_NOSUID constants were added.


New in version 3.3: Added support for specifying path as an open file descriptor.


Changed in version 3.4: The ST_NODEV, ST_NOEXEC, ST_SYNCHRONOUS,
ST_MANDLOCK, ST_WRITE, ST_APPEND,
ST_IMMUTABLE, ST_NOATIME, ST_NODIRATIME,
and ST_RELATIME constants were added.


Changed in version 3.6: Accepts a path-like object.


New in version 3.7: Added f_fsid."
"os.symlink(src, dst, target_is_directory=False, *, dir_fd=None)","Create a symbolic link pointing to src named dst.
On Windows, a symlink represents either a file or a directory, and does not
morph to the target dynamically.  If the target is present, the type of the
symlink will be created to match. Otherwise, the symlink will be created
as a directory if target_is_directory is True or a file symlink (the
default) otherwise.  On non-Windows platforms, target_is_directory is ignored.
This function can support paths relative to directory descriptors.

Note
On newer versions of Windows 10, unprivileged accounts can create symlinks
if Developer Mode is enabled. When Developer Mode is not available/enabled,
the SeCreateSymbolicLinkPrivilege privilege is required, or the process
must be run as an administrator.
OSError is raised when the function is called by an unprivileged
user.

Raises an auditing event os.symlink with arguments src, dst, dir_fd.
Availability: Unix, Windows.

Changed in version 3.2: Added support for Windows 6.0 (Vista) symbolic links.


New in version 3.3: Added the dir_fd argument, and now allow target_is_directory
on non-Windows platforms.


Changed in version 3.6: Accepts a path-like object for src and dst.


Changed in version 3.8: Added support for unelevated symlinks on Windows with Developer Mode."
os.sync(),"Force write of everything to disk.
Availability: Unix.

New in version 3.3."
"os.truncate(path, length)","Truncate the file corresponding to path, so that it is at most
length bytes in size.
This function can support specifying a file descriptor.
Raises an auditing event os.truncate with arguments path, length.
Availability: Unix, Windows.

New in version 3.3.


Changed in version 3.5: Added support for Windows


Changed in version 3.6: Accepts a path-like object."
"os.unlink(path, *, dir_fd=None)","Remove (delete) the file path.  This function is semantically
identical to remove(); the unlink name is its
traditional Unix name.  Please see the documentation for
remove() for further information.
Raises an auditing event os.remove with arguments path, dir_fd.

New in version 3.3: The dir_fd parameter.


Changed in version 3.6: Accepts a path-like object."
"os.utime(path, times=None, *, [ns, ]dir_fd=None, follow_symlinks=True)","Set the access and modified times of the file specified by path.
utime() takes two optional parameters, times and ns.
These specify the times set on path and are used as follows:

If ns is specified,
it must be a 2-tuple of the form (atime_ns, mtime_ns)
where each member is an int expressing nanoseconds.
If times is not None,
it must be a 2-tuple of the form (atime, mtime)
where each member is an int or float expressing seconds.
If times is None and ns is unspecified,
this is equivalent to specifying ns=(atime_ns, mtime_ns)
where both times are the current time.

It is an error to specify tuples for both times and ns.
Note that the exact times you set here may not be returned by a subsequent
stat() call, depending on the resolution with which your operating
system records access and modification times; see stat(). The best
way to preserve exact times is to use the st_atime_ns and st_mtime_ns
fields from the os.stat() result object with the ns parameter to
utime.
This function can support specifying a file descriptor,
paths relative to directory descriptors and not
following symlinks.
Raises an auditing event os.utime with arguments path, times, ns, dir_fd.

New in version 3.3: Added support for specifying path as an open file descriptor,
and the dir_fd, follow_symlinks, and ns parameters.


Changed in version 3.6: Accepts a path-like object."
"os.walk(top, topdown=True, onerror=None, followlinks=False)","Generate the file names in a directory tree by walking the tree
either top-down or bottom-up. For each directory in the tree rooted at directory
top (including top itself), it yields a 3-tuple (dirpath, dirnames,
filenames).
dirpath is a string, the path to the directory.  dirnames is a list of the
names of the subdirectories in dirpath (excluding '.' and '..').
filenames is a list of the names of the non-directory files in dirpath.
Note that the names in the lists contain no path components.  To get a full path
(which begins with top) to a file or directory in dirpath, do
os.path.join(dirpath, name).
If optional argument topdown is True or not specified, the triple for a
directory is generated before the triples for any of its subdirectories
(directories are generated top-down).  If topdown is False, the triple
for a directory is generated after the triples for all of its subdirectories
(directories are generated bottom-up). No matter the value of topdown, the
list of subdirectories is retrieved before the tuples for the directory and
its subdirectories are generated.
When topdown is True, the caller can modify the dirnames list in-place
(perhaps using del or slice assignment), and walk() will only
recurse into the subdirectories whose names remain in dirnames; this can be
used to prune the search, impose a specific order of visiting, or even to inform
walk() about directories the caller creates or renames before it resumes
walk() again.  Modifying dirnames when topdown is False has
no effect on the behavior of the walk, because in bottom-up mode the directories
in dirnames are generated before dirpath itself is generated.
By default, errors from the scandir() call are ignored.  If optional
argument onerror is specified, it should be a function; it will be called with
one argument, an OSError instance.  It can report the error to continue
with the walk, or raise the exception to abort the walk.  Note that the filename
is available as the filename attribute of the exception object.
By default, walk() will not walk down into symbolic links that resolve to
directories. Set followlinks to True to visit directories pointed to by
symlinks, on systems that support them.

Note
Be aware that setting followlinks to True can lead to infinite
recursion if a link points to a parent directory of itself. walk()
does not keep track of the directories it visited already.


Note
If you pass a relative pathname, don’t change the current working directory
between resumptions of walk().  walk() never changes the current
directory, and assumes that its caller doesn’t either.

This example displays the number of bytes taken by non-directory files in each
directory under the starting directory, except that it doesn’t look under any
CVS subdirectory:
import os
from os.path import join, getsize
for root, dirs, files in os.walk('python/Lib/email'):
    print(root, ""consumes"", end="" "")
    print(sum(getsize(join(root, name)) for name in files), end="" "")
    print(""bytes in"", len(files), ""non-directory files"")
    if 'CVS' in dirs:
        dirs.remove('CVS')  # don't visit CVS directories


In the next example (simple implementation of shutil.rmtree()),
walking the tree bottom-up is essential, rmdir() doesn’t allow
deleting a directory before the directory is empty:
# Delete everything reachable from the directory named in ""top"",
# assuming there are no symbolic links.
# CAUTION:  This is dangerous!  For example, if top == '/', it
# could delete all your disk files.
import os
for root, dirs, files in os.walk(top, topdown=False):
    for name in files:
        os.remove(os.path.join(root, name))
    for name in dirs:
        os.rmdir(os.path.join(root, name))



Changed in version 3.5: This function now calls os.scandir() instead of os.listdir(),
making it faster by reducing the number of calls to os.stat().


Changed in version 3.6: Accepts a path-like object."
"os.fwalk(top='.', topdown=True, onerror=None, *, follow_symlinks=False, dir_fd=None)","This behaves exactly like walk(), except that it yields a 4-tuple
(dirpath, dirnames, filenames, dirfd), and it supports dir_fd.
dirpath, dirnames and filenames are identical to walk() output,
and dirfd is a file descriptor referring to the directory dirpath.
This function always supports paths relative to directory descriptors and not following symlinks.  Note however
that, unlike other functions, the fwalk() default value for
follow_symlinks is False.

Note
Since fwalk() yields file descriptors, those are only valid until
the next iteration step, so you should duplicate them (e.g. with
dup()) if you want to keep them longer.

This example displays the number of bytes taken by non-directory files in each
directory under the starting directory, except that it doesn’t look under any
CVS subdirectory:
import os
for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):
    print(root, ""consumes"", end="""")
    print(sum([os.stat(name, dir_fd=rootfd).st_size for name in files]),
          end="""")
    print(""bytes in"", len(files), ""non-directory files"")
    if 'CVS' in dirs:
        dirs.remove('CVS')  # don't visit CVS directories


In the next example, walking the tree bottom-up is essential:
rmdir() doesn’t allow deleting a directory before the directory is
empty:
# Delete everything reachable from the directory named in ""top"",
# assuming there are no symbolic links.
# CAUTION:  This is dangerous!  For example, if top == '/', it
# could delete all your disk files.
import os
for root, dirs, files, rootfd in os.fwalk(top, topdown=False):
    for name in files:
        os.unlink(name, dir_fd=rootfd)
    for name in dirs:
        os.rmdir(name, dir_fd=rootfd)


Availability: Unix.

New in version 3.3.


Changed in version 3.6: Accepts a path-like object.


Changed in version 3.7: Added support for bytes paths."
"os.memfd_create(name[, flags=os.MFD_CLOEXEC])","Create an anonymous file and return a file descriptor that refers to it.
flags must be one of the os.MFD_* constants available on the system
(or a bitwise ORed combination of them).  By default, the new file
descriptor is non-inheritable.
The name supplied in name is used as a filename and will be displayed as
the target of the corresponding symbolic link in the directory
/proc/self/fd/. The displayed name is always prefixed with memfd:
and serves only for debugging purposes. Names do not affect the behavior of
the file descriptor, and as such multiple files can have the same name
without any side effects.
Availability: Linux 3.17 or newer with glibc 2.27 or newer.

New in version 3.8."
"os.getxattr(path, attribute, *, follow_symlinks=True)","Return the value of the extended filesystem attribute attribute for
path. attribute can be bytes or str (directly or indirectly through the
PathLike interface). If it is str, it is encoded with the filesystem
encoding.
This function can support specifying a file descriptor and
not following symlinks.
Raises an auditing event os.getxattr with arguments path, attribute.

Changed in version 3.6: Accepts a path-like object for path and attribute."
"os.listxattr(path=None, *, follow_symlinks=True)","Return a list of the extended filesystem attributes on path.  The
attributes in the list are represented as strings decoded with the filesystem
encoding.  If path is None, listxattr() will examine the current
directory.
This function can support specifying a file descriptor and
not following symlinks.
Raises an auditing event os.listxattr with argument path.

Changed in version 3.6: Accepts a path-like object."
"os.removexattr(path, attribute, *, follow_symlinks=True)","Removes the extended filesystem attribute attribute from path.
attribute should be bytes or str (directly or indirectly through the
PathLike interface). If it is a string, it is encoded
with the filesystem encoding.
This function can support specifying a file descriptor and
not following symlinks.
Raises an auditing event os.removexattr with arguments path, attribute.

Changed in version 3.6: Accepts a path-like object for path and attribute."
"os.setxattr(path, attribute, value, flags=0, *, follow_symlinks=True)","Set the extended filesystem attribute attribute on path to value.
attribute must be a bytes or str with no embedded NULs (directly or
indirectly through the PathLike interface). If it is a str,
it is encoded with the filesystem encoding.  flags may be
XATTR_REPLACE or XATTR_CREATE. If XATTR_REPLACE is
given and the attribute does not exist, EEXISTS will be raised.
If XATTR_CREATE is given and the attribute already exists, the
attribute will not be created and ENODATA will be raised.
This function can support specifying a file descriptor and
not following symlinks.

Note
A bug in Linux kernel versions less than 2.6.39 caused the flags argument
to be ignored on some filesystems.

Raises an auditing event os.setxattr with arguments path, attribute, value, flags.

Changed in version 3.6: Accepts a path-like object for path and attribute."
os.abort(),"Generate a SIGABRT signal to the current process.  On Unix, the default
behavior is to produce a core dump; on Windows, the process immediately returns
an exit code of 3.  Be aware that calling this function will not call the
Python signal handler registered for SIGABRT with
signal.signal()."
os.add_dll_directory(path),"Add a path to the DLL search path.
This search path is used when resolving dependencies for imported
extension modules (the module itself is resolved through sys.path),
and also by ctypes.
Remove the directory by calling close() on the returned object
or using it in a with statement.
See the Microsoft documentation
for more information about how DLLs are loaded.
Raises an auditing event os.add_dll_directory with argument path.
Availability: Windows.

New in version 3.8: Previous versions of CPython would resolve DLLs using the default
behavior for the current process. This led to inconsistencies,
such as only sometimes searching PATH or the current
working directory, and OS functions such as AddDllDirectory
having no effect.
In 3.8, the two primary ways DLLs are loaded now explicitly
override the process-wide behavior to ensure consistency. See the
porting notes for information on
updating libraries."
"os.execl(path, arg0, arg1, ...)","These functions all execute a new program, replacing the current process; they
do not return.  On Unix, the new executable is loaded into the current process,
and will have the same process id as the caller.  Errors will be reported as
OSError exceptions.
The current process is replaced immediately. Open file objects and
descriptors are not flushed, so if there may be data buffered
on these open files, you should flush them using
sys.stdout.flush() or os.fsync() before calling an
exec* function.
The “l” and “v” variants of the exec* functions differ in how
command-line arguments are passed.  The “l” variants are perhaps the easiest
to work with if the number of parameters is fixed when the code is written; the
individual parameters simply become additional parameters to the execl*()
functions.  The “v” variants are good when the number of parameters is
variable, with the arguments being passed in a list or tuple as the args
parameter.  In either case, the arguments to the child process should start with
the name of the command being run, but this is not enforced.
The variants which include a “p” near the end (execlp(),
execlpe(), execvp(), and execvpe()) will use the
PATH environment variable to locate the program file.  When the
environment is being replaced (using one of the exec*e variants,
discussed in the next paragraph), the new environment is used as the source of
the PATH variable. The other variants, execl(), execle(),
execv(), and execve(), will not use the PATH variable to
locate the executable; path must contain an appropriate absolute or relative
path.
For execle(), execlpe(), execve(), and execvpe() (note
that these all end in “e”), the env parameter must be a mapping which is
used to define the environment variables for the new process (these are used
instead of the current process’ environment); the functions execl(),
execlp(), execv(), and execvp() all cause the new process to
inherit the environment of the current process.
For execve() on some platforms, path may also be specified as an open
file descriptor.  This functionality may not be supported on your platform;
you can check whether or not it is available using os.supports_fd.
If it is unavailable, using it will raise a NotImplementedError.
Raises an auditing event os.exec with arguments path, args, env.
Availability: Unix, Windows.

New in version 3.3: Added support for specifying path as an open file descriptor
for execve().


Changed in version 3.6: Accepts a path-like object."
os._exit(n),"Exit the process with status n, without calling cleanup handlers, flushing
stdio buffers, etc.

Note
The standard way to exit is sys.exit(n).  _exit() should
normally only be used in the child process after a fork()."
os.fork(),"Fork a child process.  Return 0 in the child and the child’s process id in the
parent.  If an error occurs OSError is raised.
Note that some platforms including FreeBSD <= 6.3 and Cygwin have
known issues when using fork() from a thread.
Raises an auditing event os.fork with no arguments.

Changed in version 3.8: Calling fork() in a subinterpreter is no longer supported
(RuntimeError is raised).


Warning
See ssl for applications that use the SSL module with fork().

Availability: Unix."
os.forkpty(),"Fork a child process, using a new pseudo-terminal as the child’s controlling
terminal. Return a pair of (pid, fd), where pid is 0 in the child, the
new child’s process id in the parent, and fd is the file descriptor of the
master end of the pseudo-terminal.  For a more portable approach, use the
pty module.  If an error occurs OSError is raised.
Raises an auditing event os.forkpty with no arguments.

Changed in version 3.8: Calling forkpty() in a subinterpreter is no longer supported
(RuntimeError is raised).

Availability: some flavors of Unix."
"os.kill(pid, sig)","Send signal sig to the process pid.  Constants for the specific signals
available on the host platform are defined in the signal module.
Windows: The signal.CTRL_C_EVENT and
signal.CTRL_BREAK_EVENT signals are special signals which can
only be sent to console processes which share a common console window,
e.g., some subprocesses. Any other value for sig will cause the process
to be unconditionally killed by the TerminateProcess API, and the exit code
will be set to sig. The Windows version of kill() additionally takes
process handles to be killed.
See also signal.pthread_kill().
Raises an auditing event os.kill with arguments pid, sig.

New in version 3.2: Windows support."
"os.killpg(pgid, sig)","Send the signal sig to the process group pgid.
Raises an auditing event os.killpg with arguments pgid, sig.
Availability: Unix."
os.nice(increment),"Add increment to the process’s “niceness”.  Return the new niceness.
Availability: Unix."
os.plock(op),"Lock program segments into memory.  The value of op (defined in
<sys/lock.h>) determines which segments are locked.
Availability: Unix."
"os.popen(cmd, mode='r', buffering=-1)","Open a pipe to or from command cmd.
The return value is an open file object
connected to the pipe, which can be read or written depending on whether mode
is 'r' (default) or 'w'. The buffering argument has the same meaning as
the corresponding argument to the built-in open() function. The
returned file object reads or writes text strings rather than bytes.
The close method returns None if the subprocess exited
successfully, or the subprocess’s return code if there was an
error. On POSIX systems, if the return code is positive it
represents the return value of the process left-shifted by one
byte.  If the return code is negative, the process was terminated
by the signal given by the negated value of the return code.  (For
example, the return value might be - signal.SIGKILL if the
subprocess was killed.)  On Windows systems, the return value
contains the signed integer return code from the child process.
This is implemented using subprocess.Popen; see that class’s
documentation for more powerful ways to manage and communicate with
subprocesses."
"os.posix_spawn(path, argv, env, *, file_actions=None, setpgroup=None, resetids=False, setsid=False, setsigmask=(), setsigdef=(), scheduler=None)","Wraps the posix_spawn() C library API for use from Python.
Most users should use subprocess.run() instead of posix_spawn().
The positional-only arguments path, args, and env are similar to
execve().
The path parameter is the path to the executable file.The path should
contain a directory.Use posix_spawnp() to pass an executable file
without directory.
The file_actions argument may be a sequence of tuples describing actions
to take on specific file descriptors in the child process between the C
library implementation’s fork() and exec() steps.
The first item in each tuple must be one of the three type indicator
listed below describing the remaining tuple elements:


os.POSIX_SPAWN_OPEN¶
(os.POSIX_SPAWN_OPEN, fd, path, flags, mode)
Performs os.dup2(os.open(path, flags, mode), fd).



os.POSIX_SPAWN_CLOSE¶
(os.POSIX_SPAWN_CLOSE, fd)
Performs os.close(fd).



os.POSIX_SPAWN_DUP2¶
(os.POSIX_SPAWN_DUP2, fd, new_fd)
Performs os.dup2(fd, new_fd).

These tuples correspond to the C library
posix_spawn_file_actions_addopen(),
posix_spawn_file_actions_addclose(), and
posix_spawn_file_actions_adddup2() API calls used to prepare
for the posix_spawn() call itself.
The setpgroup argument will set the process group of the child to the value
specified. If the value specified is 0, the child’s process group ID will be
made the same as its process ID. If the value of setpgroup is not set, the
child will inherit the parent’s process group ID. This argument corresponds
to the C library POSIX_SPAWN_SETPGROUP flag.
If the resetids argument is True it will reset the effective UID and
GID of the child to the real UID and GID of the parent process. If the
argument is False, then the child retains the effective UID and GID of
the parent. In either case, if the set-user-ID and set-group-ID permission
bits are enabled on the executable file, their effect will override the
setting of the effective UID and GID. This argument corresponds to the C
library POSIX_SPAWN_RESETIDS flag.
If the setsid argument is True, it will create a new session ID
for posix_spawn. setsid requires POSIX_SPAWN_SETSID
or POSIX_SPAWN_SETSID_NP flag. Otherwise, NotImplementedError
is raised.
The setsigmask argument will set the signal mask to the signal set
specified. If the parameter is not used, then the child inherits the
parent’s signal mask. This argument corresponds to the C library
POSIX_SPAWN_SETSIGMASK flag.
The sigdef argument will reset the disposition of all signals in the set
specified. This argument corresponds to the C library
POSIX_SPAWN_SETSIGDEF flag.
The scheduler argument must be a tuple containing the (optional) scheduler
policy and an instance of sched_param with the scheduler parameters.
A value of None in the place of the scheduler policy indicates that is
not being provided. This argument is a combination of the C library
POSIX_SPAWN_SETSCHEDPARAM and POSIX_SPAWN_SETSCHEDULER
flags.
Raises an auditing event os.posix_spawn with arguments path, argv, env.

New in version 3.8.

Availability: Unix."
"os.posix_spawnp(path, argv, env, *, file_actions=None, setpgroup=None, resetids=False, setsid=False, setsigmask=(), setsigdef=(), scheduler=None)","Wraps the posix_spawnp() C library API for use from Python.
Similar to posix_spawn() except that the system searches
for the executable file in the list of directories specified by the
PATH environment variable (in the same way as for execvp(3)).
Raises an auditing event os.posix_spawn with arguments path, argv, env.

New in version 3.8.

Availability: See posix_spawn() documentation."
"os.register_at_fork(*, before=None, after_in_parent=None, after_in_child=None)","Register callables to be executed when a new child process is forked
using os.fork() or similar process cloning APIs.
The parameters are optional and keyword-only.
Each specifies a different call point.

before is a function called before forking a child process.
after_in_parent is a function called from the parent process
after forking a child process.
after_in_child is a function called from the child process.

These calls are only made if control is expected to return to the
Python interpreter.  A typical subprocess launch will not
trigger them as the child is not going to re-enter the interpreter.
Functions registered for execution before forking are called in
reverse registration order.  Functions registered for execution
after forking (either in the parent or in the child) are called
in registration order.
Note that fork() calls made by third-party C code may not
call those functions, unless it explicitly calls PyOS_BeforeFork(),
PyOS_AfterFork_Parent() and PyOS_AfterFork_Child().
There is no way to unregister a function.
Availability: Unix.

New in version 3.7."
"os.spawnl(mode, path, ...)","Execute the program path in a new process.
(Note that the subprocess module provides more powerful facilities for
spawning new processes and retrieving their results; using that module is
preferable to using these functions.  Check especially the
Replacing Older Functions with the subprocess Module section.)
If mode is P_NOWAIT, this function returns the process id of the new
process; if mode is P_WAIT, returns the process’s exit code if it
exits normally, or -signal, where signal is the signal that killed the
process.  On Windows, the process id will actually be the process handle, so can
be used with the waitpid() function.
Note on VxWorks, this function doesn’t return -signal when the new process is
killed. Instead it raises OSError exception.
The “l” and “v” variants of the spawn* functions differ in how
command-line arguments are passed.  The “l” variants are perhaps the easiest
to work with if the number of parameters is fixed when the code is written; the
individual parameters simply become additional parameters to the
spawnl*() functions.  The “v” variants are good when the number of
parameters is variable, with the arguments being passed in a list or tuple as
the args parameter.  In either case, the arguments to the child process must
start with the name of the command being run.
The variants which include a second “p” near the end (spawnlp(),
spawnlpe(), spawnvp(), and spawnvpe()) will use the
PATH environment variable to locate the program file.  When the
environment is being replaced (using one of the spawn*e variants,
discussed in the next paragraph), the new environment is used as the source of
the PATH variable.  The other variants, spawnl(),
spawnle(), spawnv(), and spawnve(), will not use the
PATH variable to locate the executable; path must contain an
appropriate absolute or relative path.
For spawnle(), spawnlpe(), spawnve(), and spawnvpe()
(note that these all end in “e”), the env parameter must be a mapping
which is used to define the environment variables for the new process (they are
used instead of the current process’ environment); the functions
spawnl(), spawnlp(), spawnv(), and spawnvp() all cause
the new process to inherit the environment of the current process.  Note that
keys and values in the env dictionary must be strings; invalid keys or
values will cause the function to fail, with a return value of 127.
As an example, the following calls to spawnlp() and spawnvpe() are
equivalent:
import os
os.spawnlp(os.P_WAIT, 'cp', 'cp', 'index.html', '/dev/null')

L = ['cp', 'index.html', '/dev/null']
os.spawnvpe(os.P_WAIT, 'cp', L, os.environ)


Raises an auditing event os.spawn with arguments mode, path, args, env.
Availability: Unix, Windows.  spawnlp(), spawnlpe(), spawnvp()
and spawnvpe() are not available on Windows.  spawnle() and
spawnve() are not thread-safe on Windows; we advise you to use the
subprocess module instead.

Changed in version 3.6: Accepts a path-like object."
"os.startfile(path[, operation])","Start a file with its associated application.
When operation is not specified or 'open', this acts like double-clicking
the file in Windows Explorer, or giving the file name as an argument to the
start command from the interactive command shell: the file is opened
with whatever application (if any) its extension is associated.
When another operation is given, it must be a “command verb” that specifies
what should be done with the file. Common verbs documented by Microsoft are
'print' and  'edit' (to be used on files) as well as 'explore' and
'find' (to be used on directories).
startfile() returns as soon as the associated application is launched.
There is no option to wait for the application to close, and no way to retrieve
the application’s exit status.  The path parameter is relative to the current
directory.  If you want to use an absolute path, make sure the first character
is not a slash ('/'); the underlying Win32 ShellExecute() function
doesn’t work if it is.  Use the os.path.normpath() function to ensure that
the path is properly encoded for Win32.
To reduce interpreter startup overhead, the Win32 ShellExecute()
function is not resolved until this function is first called.  If the function
cannot be resolved, NotImplementedError will be raised.
Raises an auditing event os.startfile with arguments path, operation.
Availability: Windows."
os.system(command),"Execute the command (a string) in a subshell.  This is implemented by calling
the Standard C function system(), and has the same limitations.
Changes to sys.stdin, etc. are not reflected in the environment of
the executed command. If command generates any output, it will be sent to
the interpreter standard output stream.
On Unix, the return value is the exit status of the process encoded in the
format specified for wait().  Note that POSIX does not specify the
meaning of the return value of the C system() function, so the return
value of the Python function is system-dependent.
On Windows, the return value is that returned by the system shell after
running command.  The shell is given by the Windows environment variable
COMSPEC: it is usually cmd.exe, which returns the exit
status of the command run; on systems using a non-native shell, consult your
shell documentation.
The subprocess module provides more powerful facilities for spawning
new processes and retrieving their results; using that module is preferable
to using this function.  See the Replacing Older Functions with the subprocess Module section in
the subprocess documentation for some helpful recipes.
Raises an auditing event os.system with argument command.
Availability: Unix, Windows."
os.times(),"Returns the current global process times.
The return value is an object with five attributes:

user - user time
system - system time
children_user - user time of all child processes
children_system - system time of all child processes
elapsed - elapsed real time since a fixed point in the past

For backwards compatibility, this object also behaves like a five-tuple
containing user, system, children_user,
children_system, and elapsed in that order.
See the Unix manual page
times(2) and times(3) manual page on Unix or the GetProcessTimes MSDN
on Windows. On Windows, only user and system are known; the other attributes are zero.
Availability: Unix, Windows.

Changed in version 3.3: Return type changed from a tuple to a tuple-like object
with named attributes."
os.wait(),"Wait for completion of a child process, and return a tuple containing its pid
and exit status indication: a 16-bit number, whose low byte is the signal number
that killed the process, and whose high byte is the exit status (if the signal
number is zero); the high bit of the low byte is set if a core file was
produced.
Availability: Unix."
"os.waitid(idtype, id, options)","Wait for the completion of one or more child processes.
idtype can be P_PID, P_PGID or P_ALL.
id specifies the pid to wait on.
options is constructed from the ORing of one or more of WEXITED,
WSTOPPED or WCONTINUED and additionally may be ORed with
WNOHANG or WNOWAIT. The return value is an object
representing the data contained in the siginfo_t structure, namely:
si_pid, si_uid, si_signo, si_status,
si_code or None if WNOHANG is specified and there are no
children in a waitable state.
Availability: Unix.

New in version 3.3."
"os.waitpid(pid, options)","The details of this function differ on Unix and Windows.
On Unix: Wait for completion of a child process given by process id pid, and
return a tuple containing its process id and exit status indication (encoded as
for wait()).  The semantics of the call are affected by the value of the
integer options, which should be 0 for normal operation.
If pid is greater than 0, waitpid() requests status information for
that specific process.  If pid is 0, the request is for the status of any
child in the process group of the current process.  If pid is -1, the
request pertains to any child of the current process.  If pid is less than
-1, status is requested for any process in the process group -pid (the
absolute value of pid).
An OSError is raised with the value of errno when the syscall
returns -1.
On Windows: Wait for completion of a process given by process handle pid, and
return a tuple containing pid, and its exit status shifted left by 8 bits
(shifting makes cross-platform use of the function easier). A pid less than or
equal to 0 has no special meaning on Windows, and raises an exception. The
value of integer options has no effect. pid can refer to any process whose
id is known, not necessarily a child process. The spawn*
functions called with P_NOWAIT return suitable process handles.

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an
exception, the function now retries the system call instead of raising an
InterruptedError exception (see PEP 475 for the rationale)."
os.wait3(options),"Similar to waitpid(), except no process id argument is given and a
3-element tuple containing the child’s process id, exit status indication,
and resource usage information is returned.  Refer to
resource.getrusage() for details on resource usage
information.  The option argument is the same as that provided to
waitpid() and wait4().
Availability: Unix."
"os.wait4(pid, options)","Similar to waitpid(), except a 3-element tuple, containing the child’s
process id, exit status indication, and resource usage information is returned.
Refer to resource.getrusage() for details on
resource usage information.  The arguments to wait4() are the same
as those provided to waitpid().
Availability: Unix."
os.WCOREDUMP(status),"Return True if a core dump was generated for the process, otherwise
return False.
Availability: Unix."
os.WIFCONTINUED(status),"Return True if the process has been continued from a job control stop,
otherwise return False.
Availability: Unix."
os.WIFSTOPPED(status),"Return True if the process has been stopped, otherwise return
False.
Availability: Unix."
os.WIFSIGNALED(status),"Return True if the process exited due to a signal, otherwise return
False.
Availability: Unix."
os.WIFEXITED(status),"Return True if the process exited using the exit(2) system call,
otherwise return False.
Availability: Unix."
os.WEXITSTATUS(status),"If WIFEXITED(status) is true, return the integer parameter to the
exit(2) system call.  Otherwise, the return value is meaningless.
Availability: Unix."
os.WSTOPSIG(status),"Return the signal which caused the process to stop.
Availability: Unix."
os.WTERMSIG(status),"Return the signal which caused the process to exit.
Availability: Unix."
os.sched_get_priority_min(policy),"Get the minimum priority value for policy. policy is one of the
scheduling policy constants above."
os.sched_get_priority_max(policy),"Get the maximum priority value for policy. policy is one of the
scheduling policy constants above."
"os.sched_setscheduler(pid, policy, param)","Set the scheduling policy for the process with PID pid. A pid of 0 means
the calling process. policy is one of the scheduling policy constants
above. param is a sched_param instance."
os.sched_getscheduler(pid),"Return the scheduling policy for the process with PID pid. A pid of 0
means the calling process. The result is one of the scheduling policy
constants above."
"os.sched_setparam(pid, param)","Set a scheduling parameters for the process with PID pid. A pid of 0 means
the calling process. param is a sched_param instance."
os.sched_getparam(pid),"Return the scheduling parameters as a sched_param instance for the
process with PID pid. A pid of 0 means the calling process."
os.sched_rr_get_interval(pid),"Return the round-robin quantum in seconds for the process with PID pid. A
pid of 0 means the calling process."
os.sched_yield(),Voluntarily relinquish the CPU.
"os.sched_setaffinity(pid, mask)","Restrict the process with PID pid (or the current process if zero) to a
set of CPUs.  mask is an iterable of integers representing the set of
CPUs to which the process should be restricted."
os.sched_getaffinity(pid),"Return the set of CPUs the process with PID pid (or the current process
if zero) is restricted to."
os.confstr(name),"Return string-valued system configuration values. name specifies the
configuration value to retrieve; it may be a string which is the name of a
defined system value; these names are specified in a number of standards (POSIX,
Unix 95, Unix 98, and others).  Some platforms define additional names as well.
The names known to the host operating system are given as the keys of the
confstr_names dictionary.  For configuration variables not included in that
mapping, passing an integer for name is also accepted.
If the configuration value specified by name isn’t defined, None is
returned.
If name is a string and is not known, ValueError is raised.  If a
specific value for name is not supported by the host system, even if it is
included in confstr_names, an OSError is raised with
errno.EINVAL for the error number.
Availability: Unix."
os.cpu_count(),"Return the number of CPUs in the system. Returns None if undetermined.
This number is not equivalent to the number of CPUs the current process can
use.  The number of usable CPUs can be obtained with
len(os.sched_getaffinity(0))

New in version 3.4."
os.getloadavg(),"Return the number of processes in the system run queue averaged over the last
1, 5, and 15 minutes or raises OSError if the load average was
unobtainable.
Availability: Unix."
os.sysconf(name),"Return integer-valued system configuration values. If the configuration value
specified by name isn’t defined, -1 is returned.  The comments regarding
the name parameter for confstr() apply here as well; the dictionary that
provides information on the known names is given by sysconf_names.
Availability: Unix."
"os.getrandom(size, flags=0)","Get up to size random bytes. The function can return less bytes than
requested.
These bytes can be used to seed user-space random number generators or for
cryptographic purposes.
getrandom() relies on entropy gathered from device drivers and other
sources of environmental noise. Unnecessarily reading large quantities of
data will have a negative impact on  other users  of the /dev/random and
/dev/urandom devices.
The flags argument is a bit mask that can contain zero or more of the
following values ORed together: os.GRND_RANDOM and
GRND_NONBLOCK.
See also the Linux getrandom() manual page.
Availability: Linux 3.17 and newer.

New in version 3.6."
os.urandom(size),"Return a string of size random bytes suitable for cryptographic use.
This function returns random bytes from an OS-specific randomness source.  The
returned data should be unpredictable enough for cryptographic applications,
though its exact quality depends on the OS implementation.
On Linux, if the getrandom() syscall is available, it is used in
blocking mode: block until the system urandom entropy pool is initialized
(128 bits of entropy are collected by the kernel). See the PEP 524 for
the rationale. On Linux, the getrandom() function can be used to get
random bytes in non-blocking mode (using the GRND_NONBLOCK flag) or
to poll until the system urandom entropy pool is initialized.
On a Unix-like system, random bytes are read from the /dev/urandom
device. If the /dev/urandom device is not available or not readable, the
NotImplementedError exception is raised.
On Windows, it will use CryptGenRandom().

See also
The secrets module provides higher level functions. For an
easy-to-use interface to the random number generator provided by your
platform, please see random.SystemRandom.


Changed in version 3.6.0: On Linux, getrandom() is now used in blocking mode to increase the
security.


Changed in version 3.5.2: On Linux, if the getrandom() syscall blocks (the urandom entropy pool
is not initialized yet), fall back on reading /dev/urandom.


Changed in version 3.5: On Linux 3.17 and newer, the getrandom() syscall is now used
when available.  On OpenBSD 5.6 and newer, the C getentropy()
function is now used. These functions avoid the usage of an internal file
descriptor."
abstractmethod __fspath__(),"Return the file system path representation of the object.
The method should only return a str or bytes object,
with the preference being for str."
scandir.close(),"Close the iterator and free acquired resources.
This is called automatically when the iterator is exhausted or garbage
collected, or when an error happens during iterating.  However it
is advisable to call it explicitly or use the with
statement.

New in version 3.6."
inode(),"Return the inode number of the entry.
The result is cached on the os.DirEntry object. Use
os.stat(entry.path, follow_symlinks=False).st_ino to fetch up-to-date
information.
On the first, uncached call, a system call is required on Windows but
not on Unix."
"is_dir(*, follow_symlinks=True)","Return True if this entry is a directory or a symbolic link pointing
to a directory; return False if the entry is or points to any other
kind of file, or if it doesn’t exist anymore.
If follow_symlinks is False, return True only if this entry
is a directory (without following symlinks); return False if the
entry is any other kind of file or if it doesn’t exist anymore.
The result is cached on the os.DirEntry object, with a separate cache
for follow_symlinks True and False. Call os.stat() along
with stat.S_ISDIR() to fetch up-to-date information.
On the first, uncached call, no system call is required in most cases.
Specifically, for non-symlinks, neither Windows or Unix require a system
call, except on certain Unix file systems, such as network file systems,
that return dirent.d_type == DT_UNKNOWN. If the entry is a symlink,
a system call will be required to follow the symlink unless
follow_symlinks is False.
This method can raise OSError, such as PermissionError,
but FileNotFoundError is caught and not raised."
"is_file(*, follow_symlinks=True)","Return True if this entry is a file or a symbolic link pointing to a
file; return False if the entry is or points to a directory or other
non-file entry, or if it doesn’t exist anymore.
If follow_symlinks is False, return True only if this entry
is a file (without following symlinks); return False if the entry is
a directory or other non-file entry, or if it doesn’t exist anymore.
The result is cached on the os.DirEntry object. Caching, system calls
made, and exceptions raised are as per is_dir()."
is_symlink(),"Return True if this entry is a symbolic link (even if broken);
return False if the entry points to a directory or any kind of file,
or if it doesn’t exist anymore.
The result is cached on the os.DirEntry object. Call
os.path.islink() to fetch up-to-date information.
On the first, uncached call, no system call is required in most cases.
Specifically, neither Windows or Unix require a system call, except on
certain Unix file systems, such as network file systems, that return
dirent.d_type == DT_UNKNOWN.
This method can raise OSError, such as PermissionError,
but FileNotFoundError is caught and not raised."
"stat(*, follow_symlinks=True)","Return a stat_result object for this entry. This method
follows symbolic links by default; to stat a symbolic link add the
follow_symlinks=False argument.
On Unix, this method always requires a system call. On Windows, it
only requires a system call if follow_symlinks is True and the
entry is a reparse point (for example, a symbolic link or directory
junction).
On Windows, the st_ino, st_dev and st_nlink attributes of the
stat_result are always set to zero. Call os.stat() to
get these attributes.
The result is cached on the os.DirEntry object, with a separate cache
for follow_symlinks True and False. Call os.stat() to
fetch up-to-date information."
"io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)","This is an alias for the builtin open() function.
This function raises an auditing event open with
arguments path, mode and flags. The mode and flags
arguments may have been modified or inferred from the original call."
io.open_code(path),"Opens the provided file with mode 'rb'. This function should be used
when the intent is to treat the contents as executable code.
path should be an absolute path.
The behavior of this function may be overridden by an earlier call to the
PyFile_SetOpenCodeHook(), however, it should always be considered
interchangeable with open(path, 'rb'). Overriding the behavior is
intended for additional validation or preprocessing of the file.

New in version 3.8."
close(),"Flush and close this stream. This method has no effect if the file is
already closed. Once the file is closed, any operation on the file
(e.g. reading or writing) will raise a ValueError.
As a convenience, it is allowed to call this method more than once;
only the first call, however, will have an effect."
fileno(),"Return the underlying file descriptor (an integer) of the stream if it
exists.  An OSError is raised if the IO object does not use a file
descriptor."
flush(),"Flush the write buffers of the stream if applicable.  This does nothing
for read-only and non-blocking streams."
isatty(),"Return True if the stream is interactive (i.e., connected to
a terminal/tty device)."
readable(),"Return True if the stream can be read from.  If False, read()
will raise OSError."
readline(size=-1),"Read and return one line from the stream.  If size is specified, at
most size bytes will be read.
The line terminator is always b'\n' for binary files; for text files,
the newline argument to open() can be used to select the line
terminator(s) recognized."
readlines(hint=-1),"Read and return a list of lines from the stream.  hint can be specified
to control the number of lines read: no more lines will be read if the
total size (in bytes/characters) of all lines so far exceeds hint.
Note that it’s already possible to iterate on file objects using for
line in file: ... without calling file.readlines()."
"seek(offset, whence=SEEK_SET)","Change the stream position to the given byte offset.  offset is
interpreted relative to the position indicated by whence.  The default
value for whence is SEEK_SET.  Values for whence are:

SEEK_SET or 0 – start of the stream (the default);
offset should be zero or positive
SEEK_CUR or 1 – current stream position; offset may
be negative
SEEK_END or 2 – end of the stream; offset is usually
negative

Return the new absolute position.

New in version 3.1: The SEEK_* constants.


New in version 3.3: Some operating systems could support additional values, like
os.SEEK_HOLE or os.SEEK_DATA. The valid values
for a file could depend on it being open in text or binary mode."
seekable(),"Return True if the stream supports random access.  If False,
seek(), tell() and truncate() will raise OSError."
tell(),Return the current stream position.
truncate(size=None),"Resize the stream to the given size in bytes (or the current position
if size is not specified).  The current stream position isn’t changed.
This resizing can extend or reduce the current file size.  In case of
extension, the contents of the new file area depend on the platform
(on most systems, additional bytes are zero-filled).  The new file size
is returned.

Changed in version 3.5: Windows will now zero-fill files when extending."
writable(),"Return True if the stream supports writing.  If False,
write() and truncate() will raise OSError."
writelines(lines),"Write a list of lines to the stream.  Line separators are not added, so it
is usual for each of the lines provided to have a line separator at the
end."
__del__(),"Prepare for object destruction. IOBase provides a default
implementation of this method that calls the instance’s
close() method."
read(size=-1),"Read up to size bytes from the object and return them.  As a convenience,
if size is unspecified or -1, all bytes until EOF are returned.
Otherwise, only one system call is ever made.  Fewer than size bytes may
be returned if the operating system call returns fewer than size bytes.
If 0 bytes are returned, and size was not 0, this indicates end of file.
If the object is in non-blocking mode and no bytes are available,
None is returned.
The default implementation defers to readall() and
readinto()."
readall(),"Read and return all the bytes from the stream until EOF, using multiple
calls to the stream if necessary."
readinto(b),"Read bytes into a pre-allocated, writable
bytes-like object b, and return the
number of bytes read.  For example, b might be a bytearray.
If the object is in non-blocking mode and no bytes
are available, None is returned."
write(b),"Write the given bytes-like object, b, to the
underlying raw stream, and return the number of
bytes written.  This can be less than the length of b in
bytes, depending on specifics of the underlying raw
stream, and especially if it is in non-blocking mode.  None is
returned if the raw stream is set not to block and no single byte could
be readily written to it.  The caller may release or mutate b after
this method returns, so the implementation should only access b
during the method call."
detach(),"Separate the underlying raw stream from the buffer and return it.
After the raw stream has been detached, the buffer is in an unusable
state.
Some buffers, like BytesIO, do not have the concept of a single
raw stream to return from this method.  They raise
UnsupportedOperation.

New in version 3.1."
read(size=-1),"Read and return up to size bytes.  If the argument is omitted, None,
or negative, data is read and returned until EOF is reached.  An empty
bytes object is returned if the stream is already at EOF.
If the argument is positive, and the underlying raw stream is not
interactive, multiple raw reads may be issued to satisfy the byte count
(unless EOF is reached first).  But for interactive raw streams, at most
one raw read will be issued, and a short result does not imply that EOF is
imminent.
A BlockingIOError is raised if the underlying raw stream is in
non blocking-mode, and has no data available at the moment."
read1([size]),"Read and return up to size bytes, with at most one call to the
underlying raw stream’s read() (or
readinto()) method.  This can be useful if you are
implementing your own buffering on top of a BufferedIOBase
object.
If size is -1 (the default), an arbitrary number of bytes are
returned (more than zero unless EOF is reached)."
readinto(b),"Read bytes into a pre-allocated, writable
bytes-like object b and return the number of bytes read.
For example, b might be a bytearray.
Like read(), multiple reads may be issued to the underlying raw
stream, unless the latter is interactive.
A BlockingIOError is raised if the underlying raw stream is in non
blocking-mode, and has no data available at the moment."
readinto1(b),"Read bytes into a pre-allocated, writable
bytes-like object b, using at most one call to
the underlying raw stream’s read() (or
readinto()) method. Return the number of bytes read.
A BlockingIOError is raised if the underlying raw stream is in non
blocking-mode, and has no data available at the moment.

New in version 3.5."
write(b),"Write the given bytes-like object, b, and return the number
of bytes written (always equal to the length of b in bytes, since if
the write fails an OSError will be raised).  Depending on the
actual implementation, these bytes may be readily written to the
underlying stream, or held in a buffer for performance and latency
reasons.
When in non-blocking mode, a BlockingIOError is raised if the
data needed to be written to the raw stream but it couldn’t accept
all the data without blocking.
The caller may release or mutate b after this method returns,
so the implementation should only access b during the method call."
getbuffer(),"Return a readable and writable view over the contents of the buffer
without copying them.  Also, mutating the view will transparently
update the contents of the buffer:
>>> b = io.BytesIO(b""abcdef"")
>>> view = b.getbuffer()
>>> view[2:4] = b""56""
>>> b.getvalue()
b'ab56ef'



Note
As long as the view exists, the BytesIO object cannot be
resized or closed.


New in version 3.2."
getvalue(),Return bytes containing the entire contents of the buffer.
read1([size]),"In BytesIO, this is the same as read().

Changed in version 3.7: The size argument is now optional."
readinto1(b),"In BytesIO, this is the same as readinto().

New in version 3.5."
peek([size]),"Return bytes from the stream without advancing the position.  At most one
single read on the raw stream is done to satisfy the call. The number of
bytes returned may be less or more than requested."
read([size]),"Read and return size bytes, or if size is not given or negative, until
EOF or if the read call would block in non-blocking mode."
read1([size]),"Read and return up to size bytes with only one call on the raw stream.
If at least one byte is buffered, only buffered bytes are returned.
Otherwise, one raw stream read call is made.

Changed in version 3.7: The size argument is now optional."
flush(),"Force bytes held in the buffer into the raw stream.  A
BlockingIOError should be raised if the raw stream blocks."
write(b),"Write the bytes-like object, b, and return the
number of bytes written.  When in non-blocking mode, a
BlockingIOError is raised if the buffer needs to be written out but
the raw stream blocks."
detach(),"Separate the underlying binary buffer from the TextIOBase and
return it.
After the underlying buffer has been detached, the TextIOBase is
in an unusable state.
Some TextIOBase implementations, like StringIO, may not
have the concept of an underlying buffer and calling this method will
raise UnsupportedOperation.

New in version 3.1."
read(size=-1),"Read and return at most size characters from the stream as a single
str.  If size is negative or None, reads until EOF."
readline(size=-1),"Read until newline or EOF and return a single str.  If the stream is
already at EOF, an empty string is returned.
If size is specified, at most size characters will be read."
"seek(offset, whence=SEEK_SET)","Change the stream position to the given offset.  Behaviour depends on
the whence parameter.  The default value for whence is
SEEK_SET.

SEEK_SET or 0: seek from the start of the stream
(the default); offset must either be a number returned by
TextIOBase.tell(), or zero.  Any other offset value
produces undefined behaviour.
SEEK_CUR or 1: “seek” to the current position;
offset must be zero, which is a no-operation (all other values
are unsupported).
SEEK_END or 2: seek to the end of the stream;
offset must be zero (all other values are unsupported).

Return the new absolute position as an opaque number.

New in version 3.1: The SEEK_* constants."
tell(),"Return the current stream position as an opaque number.  The number
does not usually represent a number of bytes in the underlying
binary storage."
write(s),"Write the string s to the stream and return the number of characters
written."
"reconfigure(*[, encoding][, errors][, newline][,                      line_buffering][, write_through])","Reconfigure this text stream using new settings for encoding,
errors, newline, line_buffering and write_through.
Parameters not specified keep current settings, except
errors='strict' is used when encoding is specified but
errors is not specified.
It is not possible to change the encoding or newline if some data
has already been read from the stream. On the other hand, changing
encoding after write is possible.
This method does an implicit stream flush before setting the
new parameters.

New in version 3.7."
getvalue(),"Return a str containing the entire contents of the buffer.
Newlines are decoded as if by read(), although
the stream position is not changed."
time.asctime([t]),"Convert a tuple or struct_time representing a time as returned by
gmtime() or localtime() to a string of the following
form: 'Sun Jun 20 23:21:05 1993'. The day field is two characters long
and is space padded if the day is a single digit,
e.g.: 'Wed Jun  9 04:26:40 1993'.
If t is not provided, the current time as returned by localtime()
is used. Locale information is not used by asctime().

Note
Unlike the C function of the same name, asctime() does not add a
trailing newline."
time.pthread_getcpuclockid(thread_id),"Return the clk_id of the thread-specific CPU-time clock for the specified thread_id.
Use threading.get_ident() or the ident
attribute of threading.Thread objects to get a suitable value
for thread_id.

Warning
Passing an invalid or expired thread_id may result in
undefined behavior, such as segmentation fault.

Availability: Unix (see the man page for pthread_getcpuclockid(3) for
further information).

New in version 3.7."
time.clock_getres(clk_id),"Return the resolution (precision) of the specified clock clk_id.  Refer to
Clock ID Constants for a list of accepted values for clk_id.
Availability: Unix.

New in version 3.3."
"time.clock_settime(clk_id, time: float)","Set the time of the specified clock clk_id.  Currently,
CLOCK_REALTIME is the only accepted value for clk_id.
Availability: Unix.

New in version 3.3."
"time.clock_settime_ns(clk_id, time: int)","Similar to clock_settime() but set time with nanoseconds.
Availability: Unix.

New in version 3.7."
time.ctime([secs]),"Convert a time expressed in seconds since the epoch to a string of a form:
'Sun Jun 20 23:21:05 1993' representing local time. The day field
is two characters long and is space padded if the day is a single digit,
e.g.: 'Wed Jun  9 04:26:40 1993'.
If secs is not provided or None, the current time as
returned by time() is used. ctime(secs) is equivalent to
asctime(localtime(secs)). Locale information is not used by
ctime()."
time.get_clock_info(name),"Get information on the specified clock as a namespace object.
Supported clock names and the corresponding functions to read their value
are:

'monotonic': time.monotonic()
'perf_counter': time.perf_counter()
'process_time': time.process_time()
'thread_time': time.thread_time()
'time': time.time()

The result has the following attributes:

adjustable: True if the clock can be changed automatically (e.g. by
a NTP daemon) or manually by the system administrator, False otherwise
implementation: The name of the underlying C function used to get
the clock value.  Refer to Clock ID Constants for possible values.
monotonic: True if the clock cannot go backward,
False otherwise
resolution: The resolution of the clock in seconds (float)


New in version 3.3."
time.gmtime([secs]),"Convert a time expressed in seconds since the epoch to a struct_time in
UTC in which the dst flag is always zero.  If secs is not provided or
None, the current time as returned by time() is used.  Fractions
of a second are ignored.  See above for a description of the
struct_time object. See calendar.timegm() for the inverse of this
function."
time.localtime([secs]),"Like gmtime() but converts to local time.  If secs is not provided or
None, the current time as returned by time() is used.  The dst
flag is set to 1 when DST applies to the given time."
time.mktime(t),"This is the inverse function of localtime().  Its argument is the
struct_time or full 9-tuple (since the dst flag is needed; use -1
as the dst flag if it is unknown) which expresses the time in local time, not
UTC.  It returns a floating point number, for compatibility with time().
If the input value cannot be represented as a valid time, either
OverflowError or ValueError will be raised (which depends on
whether the invalid value is caught by Python or the underlying C libraries).
The earliest date for which it can generate a time is platform-dependent."
time.sleep(secs),"Suspend execution of the calling thread for the given number of seconds.
The argument may be a floating point number to indicate a more precise sleep
time. The actual suspension time may be less than that requested because any
caught signal will terminate the sleep() following execution of that
signal’s catching routine.  Also, the suspension time may be longer than
requested by an arbitrary amount because of the scheduling of other activity
in the system.

Changed in version 3.5: The function now sleeps at least secs even if the sleep is interrupted
by a signal, except if the signal handler raises an exception (see
PEP 475 for the rationale)."
"time.strftime(format[, t])","Convert a tuple or struct_time representing a time as returned by
gmtime() or localtime() to a string as specified by the format
argument.  If t is not provided, the current time as returned by
localtime() is used.  format must be a string.  ValueError is
raised if any field in t is outside of the allowed range.
0 is a legal argument for any position in the time tuple; if it is normally
illegal the value is forced to a correct one.
The following directives can be embedded in the format string. They are shown
without the optional field width and precision specification, and are replaced
by the indicated characters in the strftime() result:







Directive
Meaning
Notes



%a
Locale’s abbreviated weekday name.


%A
Locale’s full weekday name.


%b
Locale’s abbreviated month name.


%B
Locale’s full month name.


%c
Locale’s appropriate date and time
representation.


%d
Day of the month as a decimal number [01,31].


%H
Hour (24-hour clock) as a decimal number
[00,23].


%I
Hour (12-hour clock) as a decimal number
[01,12].


%j
Day of the year as a decimal number [001,366].


%m
Month as a decimal number [01,12].


%M
Minute as a decimal number [00,59].


%p
Locale’s equivalent of either AM or PM.
(1)

%S
Second as a decimal number [00,61].
(2)

%U
Week number of the year (Sunday as the first
day of the week) as a decimal number [00,53].
All days in a new year preceding the first
Sunday are considered to be in week 0.
(3)

%w
Weekday as a decimal number [0(Sunday),6].


%W
Week number of the year (Monday as the first
day of the week) as a decimal number [00,53].
All days in a new year preceding the first
Monday are considered to be in week 0.
(3)

%x
Locale’s appropriate date representation.


%X
Locale’s appropriate time representation.


%y
Year without century as a decimal number
[00,99].


%Y
Year with century as a decimal number.


%z
Time zone offset indicating a positive or
negative time difference from UTC/GMT of the
form +HHMM or -HHMM, where H represents decimal
hour digits and M represents decimal minute
digits [-23:59, +23:59].


%Z
Time zone name (no characters if no time zone
exists).


%%
A literal '%' character.




Notes:

When used with the strptime() function, the %p directive only affects
the output hour field if the %I directive is used to parse the hour.
The range really is 0 to 61; value 60 is valid in
timestamps representing leap seconds and value 61 is supported
for historical reasons.
When used with the strptime() function, %U and %W are only used in
calculations when the day of the week and the year are specified.

Here is an example, a format for dates compatible with that specified  in the
RFC 2822 Internet email standard.  1
>>> from time import gmtime, strftime
>>> strftime(""%a, %d %b %Y %H:%M:%S +0000"", gmtime())
'Thu, 28 Jun 2001 14:17:15 +0000'


Additional directives may be supported on certain platforms, but only the
ones listed here have a meaning standardized by ANSI C.  To see the full set
of format codes supported on your platform, consult the strftime(3)
documentation.
On some platforms, an optional field width and precision specification can
immediately follow the initial '%' of a directive in the following order;
this is also not portable. The field width is normally 2 except for %j where
it is 3."
"time.strptime(string[, format])","Parse a string representing a time according to a format.  The return value
is a struct_time as returned by gmtime() or
localtime().
The format parameter uses the same directives as those used by
strftime(); it defaults to ""%a %b %d %H:%M:%S %Y"" which matches the
formatting returned by ctime(). If string cannot be parsed according
to format, or if it has excess data after parsing, ValueError is
raised. The default values used to fill in any missing data when more
accurate values cannot be inferred are (1900, 1, 1, 0, 0, 0, 0, 1, -1).
Both string and format must be strings.
For example:
>>> import time
>>> time.strptime(""30 Nov 00"", ""%d %b %y"")   
time.struct_time(tm_year=2000, tm_mon=11, tm_mday=30, tm_hour=0, tm_min=0,
                 tm_sec=0, tm_wday=3, tm_yday=335, tm_isdst=-1)


Support for the %Z directive is based on the values contained in tzname
and whether daylight is true.  Because of this, it is platform-specific
except for recognizing UTC and GMT which are always known (and are considered to
be non-daylight savings timezones).
Only the directives specified in the documentation are supported.  Because
strftime() is implemented per platform it can sometimes offer more
directives than those listed.  But strptime() is independent of any platform
and thus does not necessarily support all directives available that are not
documented as supported."
time.tzset(),"Reset the time conversion rules used by the library routines. The environment
variable TZ specifies how this is done. It will also set the variables
tzname (from the TZ environment variable), timezone (non-DST
seconds West of UTC), altzone (DST seconds west of UTC) and daylight
(to 0 if this timezone does not have any daylight saving time rules, or to
nonzero if there is a time, past, present or future when daylight saving time
applies).
Availability: Unix.

Note
Although in many cases, changing the TZ environment variable may
affect the output of functions like localtime() without calling
tzset(), this behavior should not be relied on.
The TZ environment variable should contain no whitespace.

The standard format of the TZ environment variable is (whitespace
added for clarity):
std offset [dst [offset [,start[/time], end[/time]]]]


Where the components are:

std and dstThree or more alphanumerics giving the timezone abbreviations. These will be
propagated into time.tzname

offsetThe offset has the form: ± hh[:mm[:ss]]. This indicates the value
added the local time to arrive at UTC.  If preceded by a ‘-‘, the timezone
is east of the Prime Meridian; otherwise, it is west. If no offset follows
dst, summer time is assumed to be one hour ahead of standard time.

start[/time], end[/time]Indicates when to change to and back from DST. The format of the
start and end dates are one of the following:

JnThe Julian day n (1 <= n <= 365). Leap days are not counted, so in
all years February 28 is day 59 and March 1 is day 60.

nThe zero-based Julian day (0 <= n <= 365). Leap days are counted, and
it is possible to refer to February 29.

Mm.n.dThe d’th day (0 <= d <= 6) of week n of month m of the year (1
<= n <= 5, 1 <= m <= 12, where week 5 means “the last d day in
month m” which may occur in either the fourth or the fifth
week). Week 1 is the first week in which the d’th day occurs. Day
zero is a Sunday.


time has the same format as offset except that no leading sign
(‘-‘ or ‘+’) is allowed. The default, if time is not given, is 02:00:00.


>>> os.environ['TZ'] = 'EST+05EDT,M4.1.0,M10.5.0'
>>> time.tzset()
>>> time.strftime('%X %x %Z')
'02:07:36 05/08/03 EDT'
>>> os.environ['TZ'] = 'AEST-10AEDT-11,M10.5.0,M3.5.0'
>>> time.tzset()
>>> time.strftime('%X %x %Z')
'16:08:12 05/08/03 AEST'


On many Unix systems (including *BSD, Linux, Solaris, and Darwin), it is more
convenient to use the system’s zoneinfo (tzfile(5))  database to
specify the timezone rules. To do this, set the  TZ environment
variable to the path of the required timezone  datafile, relative to the root of
the systems ‘zoneinfo’ timezone database, usually located at
/usr/share/zoneinfo. For example,  'US/Eastern',
'Australia/Melbourne', 'Egypt' or  'Europe/Amsterdam'.
>>> os.environ['TZ'] = 'US/Eastern'
>>> time.tzset()
>>> time.tzname
('EST', 'EDT')
>>> os.environ['TZ'] = 'Egypt'
>>> time.tzset()
>>> time.tzname
('EET', 'EEST')"
"ArgumentParser.add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest])","Define how a single command-line argument should be parsed.  Each parameter
has its own more detailed description below, but in short they are:

name or flags - Either a name or a list of option strings, e.g. foo
or -f, --foo.
action - The basic type of action to be taken when this argument is
encountered at the command line.
nargs - The number of command-line arguments that should be consumed.
const - A constant value required by some action and nargs selections.
default - The value produced if the argument is absent from the
command line.
type - The type to which the command-line argument should be converted.
choices - A container of the allowable values for the argument.
required - Whether or not the command-line option may be omitted
(optionals only).
help - A brief description of what the argument does.
metavar - A name for the argument in usage messages.
dest - The name of the attribute to be added to the object returned by
parse_args()."
"ArgumentParser.parse_args(args=None, namespace=None)","Convert argument strings to objects and assign them as attributes of the
namespace.  Return the populated namespace.
Previous calls to add_argument() determine exactly what objects are
created and how they are assigned. See the documentation for
add_argument() for details.

args - List of strings to parse.  The default is taken from
sys.argv.
namespace - An object to take the attributes.  The default is a new empty
Namespace object."
"ArgumentParser.add_subparsers([title][, description][, prog][, parser_class][, action][, option_string][, dest][, required][, help][, metavar])","Many programs split up their functionality into a number of sub-commands,
for example, the svn program can invoke sub-commands like svn
checkout, svn update, and svn commit.  Splitting up functionality
this way can be a particularly good idea when a program performs several
different functions which require different kinds of command-line arguments.
ArgumentParser supports the creation of such sub-commands with the
add_subparsers() method.  The add_subparsers() method is normally
called with no arguments and returns a special action object.  This object
has a single method, add_parser(), which takes a
command name and any ArgumentParser constructor arguments, and
returns an ArgumentParser object that can be modified as usual.
Description of parameters:

title - title for the sub-parser group in help output; by default
“subcommands” if description is provided, otherwise uses title for
positional arguments
description - description for the sub-parser group in help output, by
default None
prog - usage information that will be displayed with sub-command help,
by default the name of the program and any positional arguments before the
subparser argument
parser_class - class which will be used to create sub-parser instances, by
default the class of the current parser (e.g. ArgumentParser)
action - the basic type of action to be taken when this argument is
encountered at the command line
dest - name of the attribute under which sub-command name will be
stored; by default None and no value is stored
required - Whether or not a subcommand must be provided, by default
False (added in 3.7)
help - help for sub-parser group in help output, by default None
metavar - string presenting available sub-commands in help; by default it
is None and presents sub-commands in form {cmd1, cmd2, ..}

Some example usage:
>>> # create the top-level parser
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('--foo', action='store_true', help='foo help')
>>> subparsers = parser.add_subparsers(help='sub-command help')
>>>
>>> # create the parser for the ""a"" command
>>> parser_a = subparsers.add_parser('a', help='a help')
>>> parser_a.add_argument('bar', type=int, help='bar help')
>>>
>>> # create the parser for the ""b"" command
>>> parser_b = subparsers.add_parser('b', help='b help')
>>> parser_b.add_argument('--baz', choices='XYZ', help='baz help')
>>>
>>> # parse some argument lists
>>> parser.parse_args(['a', '12'])
Namespace(bar=12, foo=False)
>>> parser.parse_args(['--foo', 'b', '--baz', 'Z'])
Namespace(baz='Z', foo=True)


Note that the object returned by parse_args() will only contain
attributes for the main parser and the subparser that was selected by the
command line (and not any other subparsers).  So in the example above, when
the a command is specified, only the foo and bar attributes are
present, and when the b command is specified, only the foo and
baz attributes are present.
Similarly, when a help message is requested from a subparser, only the help
for that particular parser will be printed.  The help message will not
include parent parser or sibling parser messages.  (A help message for each
subparser command, however, can be given by supplying the help= argument
to add_parser() as above.)
>>> parser.parse_args(['--help'])
usage: PROG [-h] [--foo] {a,b} ...

positional arguments:
  {a,b}   sub-command help
    a     a help
    b     b help

optional arguments:
  -h, --help  show this help message and exit
  --foo   foo help

>>> parser.parse_args(['a', '--help'])
usage: PROG a [-h] bar

positional arguments:
  bar     bar help

optional arguments:
  -h, --help  show this help message and exit

>>> parser.parse_args(['b', '--help'])
usage: PROG b [-h] [--baz {X,Y,Z}]

optional arguments:
  -h, --help     show this help message and exit
  --baz {X,Y,Z}  baz help


The add_subparsers() method also supports title and description
keyword arguments.  When either is present, the subparser’s commands will
appear in their own group in the help output.  For example:
>>> parser = argparse.ArgumentParser()
>>> subparsers = parser.add_subparsers(title='subcommands',
...                                    description='valid subcommands',
...                                    help='additional help')
>>> subparsers.add_parser('foo')
>>> subparsers.add_parser('bar')
>>> parser.parse_args(['-h'])
usage:  [-h] {foo,bar} ...

optional arguments:
  -h, --help  show this help message and exit

subcommands:
  valid subcommands

  {foo,bar}   additional help


Furthermore, add_parser supports an additional aliases argument,
which allows multiple strings to refer to the same subparser. This example,
like svn, aliases co as a shorthand for checkout:
>>> parser = argparse.ArgumentParser()
>>> subparsers = parser.add_subparsers()
>>> checkout = subparsers.add_parser('checkout', aliases=['co'])
>>> checkout.add_argument('foo')
>>> parser.parse_args(['co', 'bar'])
Namespace(foo='bar')


One particularly effective way of handling sub-commands is to combine the use
of the add_subparsers() method with calls to set_defaults() so
that each subparser knows which Python function it should execute.  For
example:
>>> # sub-command functions
>>> def foo(args):
...     print(args.x * args.y)
...
>>> def bar(args):
...     print('((%s))' % args.z)
...
>>> # create the top-level parser
>>> parser = argparse.ArgumentParser()
>>> subparsers = parser.add_subparsers()
>>>
>>> # create the parser for the ""foo"" command
>>> parser_foo = subparsers.add_parser('foo')
>>> parser_foo.add_argument('-x', type=int, default=1)
>>> parser_foo.add_argument('y', type=float)
>>> parser_foo.set_defaults(func=foo)
>>>
>>> # create the parser for the ""bar"" command
>>> parser_bar = subparsers.add_parser('bar')
>>> parser_bar.add_argument('z')
>>> parser_bar.set_defaults(func=bar)
>>>
>>> # parse the args and call whatever function was selected
>>> args = parser.parse_args('foo 1 -x 2'.split())
>>> args.func(args)
2.0
>>>
>>> # parse the args and call whatever function was selected
>>> args = parser.parse_args('bar XYZYX'.split())
>>> args.func(args)
((XYZYX))


This way, you can let parse_args() do the job of calling the
appropriate function after argument parsing is complete.  Associating
functions with actions like this is typically the easiest way to handle the
different actions for each of your subparsers.  However, if it is necessary
to check the name of the subparser that was invoked, the dest keyword
argument to the add_subparsers() call will work:
>>> parser = argparse.ArgumentParser()
>>> subparsers = parser.add_subparsers(dest='subparser_name')
>>> subparser1 = subparsers.add_parser('1')
>>> subparser1.add_argument('-x')
>>> subparser2 = subparsers.add_parser('2')
>>> subparser2.add_argument('y')
>>> parser.parse_args(['2', 'frobble'])
Namespace(subparser_name='2', y='frobble')



Changed in version 3.7: New required keyword argument."
"ArgumentParser.add_argument_group(title=None, description=None)","By default, ArgumentParser groups command-line arguments into
“positional arguments” and “optional arguments” when displaying help
messages. When there is a better conceptual grouping of arguments than this
default one, appropriate groups can be created using the
add_argument_group() method:
>>> parser = argparse.ArgumentParser(prog='PROG', add_help=False)
>>> group = parser.add_argument_group('group')
>>> group.add_argument('--foo', help='foo help')
>>> group.add_argument('bar', help='bar help')
>>> parser.print_help()
usage: PROG [--foo FOO] bar

group:
  bar    bar help
  --foo FOO  foo help


The add_argument_group() method returns an argument group object which
has an add_argument() method just like a regular
ArgumentParser.  When an argument is added to the group, the parser
treats it just like a normal argument, but displays the argument in a
separate group for help messages.  The add_argument_group() method
accepts title and description arguments which can be used to
customize this display:
>>> parser = argparse.ArgumentParser(prog='PROG', add_help=False)
>>> group1 = parser.add_argument_group('group1', 'group1 description')
>>> group1.add_argument('foo', help='foo help')
>>> group2 = parser.add_argument_group('group2', 'group2 description')
>>> group2.add_argument('--bar', help='bar help')
>>> parser.print_help()
usage: PROG [--bar BAR] foo

group1:
  group1 description

  foo    foo help

group2:
  group2 description

  --bar BAR  bar help


Note that any arguments not in your user-defined groups will end up back
in the usual “positional arguments” and “optional arguments” sections."
ArgumentParser.add_mutually_exclusive_group(required=False),"Create a mutually exclusive group. argparse will make sure that only
one of the arguments in the mutually exclusive group was present on the
command line:
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> group = parser.add_mutually_exclusive_group()
>>> group.add_argument('--foo', action='store_true')
>>> group.add_argument('--bar', action='store_false')
>>> parser.parse_args(['--foo'])
Namespace(bar=True, foo=True)
>>> parser.parse_args(['--bar'])
Namespace(bar=False, foo=False)
>>> parser.parse_args(['--foo', '--bar'])
usage: PROG [-h] [--foo | --bar]
PROG: error: argument --bar: not allowed with argument --foo


The add_mutually_exclusive_group() method also accepts a required
argument, to indicate that at least one of the mutually exclusive arguments
is required:
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> group = parser.add_mutually_exclusive_group(required=True)
>>> group.add_argument('--foo', action='store_true')
>>> group.add_argument('--bar', action='store_false')
>>> parser.parse_args([])
usage: PROG [-h] (--foo | --bar)
PROG: error: one of the arguments --foo --bar is required


Note that currently mutually exclusive argument groups do not support the
title and description arguments of
add_argument_group()."
ArgumentParser.set_defaults(**kwargs),"Most of the time, the attributes of the object returned by parse_args()
will be fully determined by inspecting the command-line arguments and the argument
actions.  set_defaults() allows some additional
attributes that are determined without any inspection of the command line to
be added:
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('foo', type=int)
>>> parser.set_defaults(bar=42, baz='badger')
>>> parser.parse_args(['736'])
Namespace(bar=42, baz='badger', foo=736)


Note that parser-level defaults always override argument-level defaults:
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', default='bar')
>>> parser.set_defaults(foo='spam')
>>> parser.parse_args([])
Namespace(foo='spam')


Parser-level defaults can be particularly useful when working with multiple
parsers.  See the add_subparsers() method for an
example of this type."
ArgumentParser.get_default(dest),"Get the default value for a namespace attribute, as set by either
add_argument() or by
set_defaults():
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', default='badger')
>>> parser.get_default('foo')
'badger'"
ArgumentParser.print_usage(file=None),"Print a brief description of how the ArgumentParser should be
invoked on the command line.  If file is None, sys.stdout is
assumed."
ArgumentParser.print_help(file=None),"Print a help message, including the program usage and information about the
arguments registered with the ArgumentParser.  If file is
None, sys.stdout is assumed."
ArgumentParser.format_usage(),"Return a string containing a brief description of how the
ArgumentParser should be invoked on the command line."
ArgumentParser.format_help(),"Return a string containing a help message, including the program usage and
information about the arguments registered with the ArgumentParser."
"ArgumentParser.parse_known_args(args=None, namespace=None)",
ArgumentParser.convert_arg_line_to_args(arg_line),"Arguments that are read from a file (see the fromfile_prefix_chars
keyword argument to the ArgumentParser constructor) are read one
argument per line. convert_arg_line_to_args() can be overridden for
fancier reading.
This method takes a single argument arg_line which is a string read from
the argument file.  It returns a list of arguments parsed from this string.
The method is called once per line read from the argument file, in order.
A useful override of this method is one that treats each space-separated word
as an argument.  The following example demonstrates how to do this:
class MyArgumentParser(argparse.ArgumentParser):
    def convert_arg_line_to_args(self, arg_line):
        return arg_line.split()"
"ArgumentParser.exit(status=0, message=None)","This method terminates the program, exiting with the specified status
and, if given, it prints a message before that. The user can override
this method to handle these steps differently:
class ErrorCatchingArgumentParser(argparse.ArgumentParser):
    def exit(self, status=0, message=None):
        if status:
            raise Exception(f'Exiting because of an error: {message}')
        exit(status)"
ArgumentParser.error(message),"This method prints a usage message including the message to the
standard error and terminates the program with a status code of 2."
"ArgumentParser.parse_intermixed_args(args=None, namespace=None)",
"ArgumentParser.parse_known_intermixed_args(args=None, namespace=None)",
"getopt.getopt(args, shortopts, longopts=[])","Parses command line options and parameter list.  args is the argument list to
be parsed, without the leading reference to the running program. Typically, this
means sys.argv[1:]. shortopts is the string of option letters that the
script wants to recognize, with options that require an argument followed by a
colon (':'; i.e., the same format that Unix getopt() uses).

Note
Unlike GNU getopt(), after a non-option argument, all further
arguments are considered also non-options. This is similar to the way
non-GNU Unix systems work.

longopts, if specified, must be a list of strings with the names of the
long options which should be supported.  The leading '--' characters
should not be included in the option name.  Long options which require an
argument should be followed by an equal sign ('=').  Optional arguments
are not supported.  To accept only long options, shortopts should be an
empty string.  Long options on the command line can be recognized so long as
they provide a prefix of the option name that matches exactly one of the
accepted options.  For example, if longopts is ['foo', 'frob'], the
option --fo will match as --foo, but --f will
not match uniquely, so GetoptError will be raised.
The return value consists of two elements: the first is a list of (option,
value) pairs; the second is the list of program arguments left after the
option list was stripped (this is a trailing slice of args).  Each
option-and-value pair returned has the option as its first element, prefixed
with a hyphen for short options (e.g., '-x') or two hyphens for long
options (e.g., '--long-option'), and the option argument as its
second element, or an empty string if the option has no argument.  The
options occur in the list in the same order in which they were found, thus
allowing multiple occurrences.  Long and short options may be mixed."
"getopt.gnu_getopt(args, shortopts, longopts=[])","This function works like getopt(), except that GNU style scanning mode is
used by default. This means that option and non-option arguments may be
intermixed. The getopt() function stops processing options as soon as a
non-option argument is encountered.
If the first character of the option string is '+', or if the environment
variable POSIXLY_CORRECT is set, then option processing stops as
soon as a non-option argument is encountered."
logging.getLogger(name=None),"Return a logger with the specified name or, if name is None, return a
logger which is the root logger of the hierarchy. If specified, the name is
typically a dot-separated hierarchical name like ‘a’, ‘a.b’ or ‘a.b.c.d’.
Choice of these names is entirely up to the developer who is using logging.
All calls to this function with a given name return the same logger instance.
This means that logger instances never need to be passed between different parts
of an application."
logging.getLoggerClass(),"Return either the standard Logger class, or the last class passed to
setLoggerClass(). This function may be called from within a new class
definition, to ensure that installing a customized Logger class will
not undo customizations already applied by other code. For example:
class MyLogger(logging.getLoggerClass()):
    # ... override behaviour here"
logging.getLogRecordFactory(),"Return a callable which is used to create a LogRecord.

New in version 3.2: This function has been provided, along with setLogRecordFactory(),
to allow developers more control over how the LogRecord
representing a logging event is constructed.

See setLogRecordFactory() for more information about the how the
factory is called."
"logging.debug(msg, *args, **kwargs)","Logs a message with level DEBUG on the root logger. The msg is the
message format string, and the args are the arguments which are merged into
msg using the string formatting operator. (Note that this means that you can
use keywords in the format string, together with a single dictionary argument.)
There are three keyword arguments in kwargs which are inspected: exc_info
which, if it does not evaluate as false, causes exception information to be
added to the logging message. If an exception tuple (in the format returned by
sys.exc_info()) or an exception instance is provided, it is used;
otherwise, sys.exc_info() is called to get the exception information.
The second optional keyword argument is stack_info, which defaults to
False. If true, stack information is added to the logging
message, including the actual logging call. Note that this is not the same
stack information as that displayed through specifying exc_info: The
former is stack frames from the bottom of the stack up to the logging call
in the current thread, whereas the latter is information about stack frames
which have been unwound, following an exception, while searching for
exception handlers.
You can specify stack_info independently of exc_info, e.g. to just show
how you got to a certain point in your code, even when no exceptions were
raised. The stack frames are printed following a header line which says:
Stack (most recent call last):


This mimics the Traceback (most recent call last): which is used when
displaying exception frames.
The third optional keyword argument is extra which can be used to pass a
dictionary which is used to populate the __dict__ of the LogRecord created for
the logging event with user-defined attributes. These custom attributes can then
be used as you like. For example, they could be incorporated into logged
messages. For example:
FORMAT = '%(asctime)-15s %(clientip)s %(user)-8s %(message)s'
logging.basicConfig(format=FORMAT)
d = {'clientip': '192.168.0.1', 'user': 'fbloggs'}
logging.warning('Protocol problem: %s', 'connection reset', extra=d)


would print something like:
2006-02-08 22:20:02,165 192.168.0.1 fbloggs  Protocol problem: connection reset


The keys in the dictionary passed in extra should not clash with the keys used
by the logging system. (See the Formatter documentation for more
information on which keys are used by the logging system.)
If you choose to use these attributes in logged messages, you need to exercise
some care. In the above example, for instance, the Formatter has been
set up with a format string which expects ‘clientip’ and ‘user’ in the attribute
dictionary of the LogRecord. If these are missing, the message will not be
logged because a string formatting exception will occur. So in this case, you
always need to pass the extra dictionary with these keys.
While this might be annoying, this feature is intended for use in specialized
circumstances, such as multi-threaded servers where the same code executes in
many contexts, and interesting conditions which arise are dependent on this
context (such as remote client IP address and authenticated user name, in the
above example). In such circumstances, it is likely that specialized
Formatters would be used with particular Handlers.

Changed in version 3.2: The stack_info parameter was added."
"logging.info(msg, *args, **kwargs)","Logs a message with level INFO on the root logger. The arguments are
interpreted as for debug()."
"logging.warning(msg, *args, **kwargs)","Logs a message with level WARNING on the root logger. The arguments
are interpreted as for debug().

Note
There is an obsolete function warn which is functionally
identical to warning. As warn is deprecated, please do not use
it - use warning instead."
"logging.error(msg, *args, **kwargs)","Logs a message with level ERROR on the root logger. The arguments are
interpreted as for debug()."
"logging.critical(msg, *args, **kwargs)","Logs a message with level CRITICAL on the root logger. The arguments
are interpreted as for debug()."
"logging.exception(msg, *args, **kwargs)","Logs a message with level ERROR on the root logger. The arguments are
interpreted as for debug(). Exception info is added to the logging
message. This function should only be called from an exception handler."
"logging.log(level, msg, *args, **kwargs)","Logs a message with level level on the root logger. The other arguments are
interpreted as for debug().

Note
The above module-level convenience functions, which delegate to the
root logger, call basicConfig() to ensure that at least one handler
is available. Because of this, they should not be used in threads,
in versions of Python earlier than 2.7.1 and 3.2, unless at least one
handler has been added to the root logger before the threads are
started. In earlier versions of Python, due to a thread safety shortcoming
in basicConfig(), this can (under rare circumstances) lead to
handlers being added multiple times to the root logger, which can in turn
lead to multiple messages for the same event."
logging.disable(level=CRITICAL),"Provides an overriding level level for all loggers which takes precedence over
the logger’s own level. When the need arises to temporarily throttle logging
output down across the whole application, this function can be useful. Its
effect is to disable all logging calls of severity level and below, so that
if you call it with a value of INFO, then all INFO and DEBUG events would be
discarded, whereas those of severity WARNING and above would be processed
according to the logger’s effective level. If
logging.disable(logging.NOTSET) is called, it effectively removes this
overriding level, so that logging output again depends on the effective
levels of individual loggers.
Note that if you have defined any custom logging level higher than
CRITICAL (this is not recommended), you won’t be able to rely on the
default value for the level parameter, but will have to explicitly supply a
suitable value.

Changed in version 3.7: The level parameter was defaulted to level CRITICAL. See Issue
#28524 for more information about this change."
"logging.addLevelName(level, levelName)","Associates level level with text levelName in an internal dictionary, which is
used to map numeric levels to a textual representation, for example when a
Formatter formats a message. This function can also be used to define
your own levels. The only constraints are that all levels used must be
registered using this function, levels should be positive integers and they
should increase in increasing order of severity.

Note
If you are thinking of defining your own levels, please see the
section on Custom Levels."
logging.getLevelName(level),"Returns the textual representation of logging level level. If the level is one
of the predefined levels CRITICAL, ERROR, WARNING,
INFO or DEBUG then you get the corresponding string. If you
have associated levels with names using addLevelName() then the name you
have associated with level is returned. If a numeric value corresponding to one
of the defined levels is passed in, the corresponding string representation is
returned. Otherwise, the string ‘Level %s’ % level is returned.

Note
Levels are internally integers (as they need to be compared in the
logging logic). This function is used to convert between an integer level
and the level name displayed in the formatted log output by means of the
%(levelname)s format specifier (see LogRecord attributes).


Changed in version 3.4: In Python versions earlier than 3.4, this function could also be passed a
text level, and would return the corresponding numeric value of the level.
This undocumented behaviour was considered a mistake, and was removed in
Python 3.4, but reinstated in 3.4.2 due to retain backward compatibility."
logging.makeLogRecord(attrdict),"Creates and returns a new LogRecord instance whose attributes are
defined by attrdict. This function is useful for taking a pickled
LogRecord attribute dictionary, sent over a socket, and reconstituting
it as a LogRecord instance at the receiving end."
logging.basicConfig(**kwargs),"Does basic configuration for the logging system by creating a
StreamHandler with a default Formatter and adding it to the
root logger. The functions debug(), info(), warning(),
error() and critical() will call basicConfig() automatically
if no handlers are defined for the root logger.
This function does nothing if the root logger already has handlers
configured, unless the keyword argument force is set to True.

Note
This function should be called from the main thread
before other threads are started. In versions of Python prior to
2.7.1 and 3.2, if this function is called from multiple threads,
it is possible (in rare circumstances) that a handler will be added
to the root logger more than once, leading to unexpected results
such as messages being duplicated in the log.

The following keyword arguments are supported.






Format
Description



filename
Specifies that a FileHandler be created,
using the specified filename, rather than a
StreamHandler.

filemode
If filename is specified, open the file
in this mode. Defaults
to 'a'.

format
Use the specified format string for the
handler.

datefmt
Use the specified date/time format, as
accepted by time.strftime().

style
If format is specified, use this style
for the format string. One of '%',
'{' or '$' for printf-style,
str.format() or
string.Template respectively.
Defaults to '%'.

level
Set the root logger level to the specified
level.

stream
Use the specified stream to initialize the
StreamHandler. Note that this argument is
incompatible with filename - if both
are present, a ValueError is raised.

handlers
If specified, this should be an iterable of
already created handlers to add to the root
logger. Any handlers which don’t already
have a formatter set will be assigned the
default formatter created in this function.
Note that this argument is incompatible
with filename or stream - if both
are present, a ValueError is raised.

force
If this keyword argument is specified as
true, any existing handlers attached to the
root logger are removed and closed, before
carrying out the configuration as specified
by the other arguments.




Changed in version 3.2: The style argument was added.


Changed in version 3.3: The handlers argument was added. Additional checks were added to
catch situations where incompatible arguments are specified (e.g.
handlers together with stream or filename, or stream
together with filename).


Changed in version 3.8: The force argument was added."
logging.shutdown(),"Informs the logging system to perform an orderly shutdown by flushing and
closing all handlers. This should be called at application exit and no
further use of the logging system should be made after this call.
When the logging module is imported, it registers this function as an exit
handler (see atexit), so normally there’s no need to do that
manually."
logging.setLoggerClass(klass),"Tells the logging system to use the class klass when instantiating a logger.
The class should define __init__() such that only a name argument is
required, and the __init__() should call Logger.__init__(). This
function is typically called before any loggers are instantiated by applications
which need to use custom logger behavior. After this call, as at any other
time, do not instantiate loggers directly using the subclass: continue to use
the logging.getLogger() API to get your loggers."
logging.setLogRecordFactory(factory),"Set a callable which is used to create a LogRecord.

Parameters
factory – The factory callable to be used to instantiate a log record.



New in version 3.2: This function has been provided, along with getLogRecordFactory(), to
allow developers more control over how the LogRecord representing
a logging event is constructed.

The factory has the following signature:
factory(name, level, fn, lno, msg, args, exc_info, func=None, sinfo=None, **kwargs)


name
The logger name.

level
The logging level (numeric).

fn
The full pathname of the file where the logging call was made.

lno
The line number in the file where the logging call was made.

msg
The logging message.

args
The arguments for the logging message.

exc_info
An exception tuple, or None.

func
The name of the function or method which invoked the logging
call.

sinfo
A stack traceback such as is provided by
traceback.print_stack(), showing the call hierarchy.

kwargs
Additional keyword arguments."
logging.captureWarnings(capture),"This function is used to turn the capture of warnings by logging on and
off.
If capture is True, warnings issued by the warnings module will
be redirected to the logging system. Specifically, a warning will be
formatted using warnings.formatwarning() and the resulting string
logged to a logger named 'py.warnings' with a severity of WARNING.
If capture is False, the redirection of warnings to the logging system
will stop, and warnings will be redirected to their original destinations
(i.e. those in effect before captureWarnings(True) was called)."
setLevel(level),"Sets the threshold for this logger to level. Logging messages which are less
severe than level will be ignored; logging messages which have severity level
or higher will be emitted by whichever handler or handlers service this logger,
unless a handler’s level has been set to a higher severity level than level.
When a logger is created, the level is set to NOTSET (which causes
all messages to be processed when the logger is the root logger, or delegation
to the parent when the logger is a non-root logger). Note that the root logger
is created with level WARNING.
The term ‘delegation to the parent’ means that if a logger has a level of
NOTSET, its chain of ancestor loggers is traversed until either an ancestor with
a level other than NOTSET is found, or the root is reached.
If an ancestor is found with a level other than NOTSET, then that ancestor’s
level is treated as the effective level of the logger where the ancestor search
began, and is used to determine how a logging event is handled.
If the root is reached, and it has a level of NOTSET, then all messages will be
processed. Otherwise, the root’s level will be used as the effective level.
See Logging Levels for a list of levels.

Changed in version 3.2: The level parameter now accepts a string representation of the
level such as ‘INFO’ as an alternative to the integer constants
such as INFO. Note, however, that levels are internally stored
as integers, and methods such as e.g. getEffectiveLevel() and
isEnabledFor() will return/expect to be passed integers."
isEnabledFor(level),"Indicates if a message of severity level would be processed by this logger.
This method checks first the module-level level set by
logging.disable(level) and then the logger’s effective level as determined
by getEffectiveLevel()."
getEffectiveLevel(),"Indicates the effective level for this logger. If a value other than
NOTSET has been set using setLevel(), it is returned. Otherwise,
the hierarchy is traversed towards the root until a value other than
NOTSET is found, and that value is returned. The value returned is
an integer, typically one of logging.DEBUG, logging.INFO
etc."
getChild(suffix),"Returns a logger which is a descendant to this logger, as determined by the suffix.
Thus, logging.getLogger('abc').getChild('def.ghi') would return the same
logger as would be returned by logging.getLogger('abc.def.ghi'). This is a
convenience method, useful when the parent logger is named using e.g. __name__
rather than a literal string.

New in version 3.2."
"debug(msg, *args, **kwargs)","Logs a message with level DEBUG on this logger. The msg is the
message format string, and the args are the arguments which are merged into
msg using the string formatting operator. (Note that this means that you can
use keywords in the format string, together with a single dictionary argument.)
There are four keyword arguments in kwargs which are inspected:
exc_info, stack_info, stacklevel and extra.
If exc_info does not evaluate as false, it causes exception information to be
added to the logging message. If an exception tuple (in the format returned by
sys.exc_info()) or an exception instance is provided, it is used;
otherwise, sys.exc_info() is called to get the exception information.
The second optional keyword argument is stack_info, which defaults to
False. If true, stack information is added to the logging
message, including the actual logging call. Note that this is not the same
stack information as that displayed through specifying exc_info: The
former is stack frames from the bottom of the stack up to the logging call
in the current thread, whereas the latter is information about stack frames
which have been unwound, following an exception, while searching for
exception handlers.
You can specify stack_info independently of exc_info, e.g. to just show
how you got to a certain point in your code, even when no exceptions were
raised. The stack frames are printed following a header line which says:
Stack (most recent call last):


This mimics the Traceback (most recent call last): which is used when
displaying exception frames.
The third optional keyword argument is stacklevel, which defaults to 1.
If greater than 1, the corresponding number of stack frames are skipped
when computing the line number and function name set in the LogRecord
created for the logging event. This can be used in logging helpers so that
the function name, filename and line number recorded are not the information
for the helper function/method, but rather its caller. The name of this
parameter mirrors the equivalent one in the warnings module.
The fourth keyword argument is extra which can be used to pass a
dictionary which is used to populate the __dict__ of the LogRecord
created for the logging event with user-defined attributes. These custom
attributes can then be used as you like. For example, they could be
incorporated into logged messages. For example:
FORMAT = '%(asctime)-15s %(clientip)s %(user)-8s %(message)s'
logging.basicConfig(format=FORMAT)
d = {'clientip': '192.168.0.1', 'user': 'fbloggs'}
logger = logging.getLogger('tcpserver')
logger.warning('Protocol problem: %s', 'connection reset', extra=d)


would print something like
2006-02-08 22:20:02,165 192.168.0.1 fbloggs  Protocol problem: connection reset


The keys in the dictionary passed in extra should not clash with the keys used
by the logging system. (See the Formatter documentation for more
information on which keys are used by the logging system.)
If you choose to use these attributes in logged messages, you need to exercise
some care. In the above example, for instance, the Formatter has been
set up with a format string which expects ‘clientip’ and ‘user’ in the attribute
dictionary of the LogRecord. If these are missing, the message will
not be logged because a string formatting exception will occur. So in this case,
you always need to pass the extra dictionary with these keys.
While this might be annoying, this feature is intended for use in specialized
circumstances, such as multi-threaded servers where the same code executes in
many contexts, and interesting conditions which arise are dependent on this
context (such as remote client IP address and authenticated user name, in the
above example). In such circumstances, it is likely that specialized
Formatters would be used with particular Handlers.

Changed in version 3.2: The stack_info parameter was added.


Changed in version 3.5: The exc_info parameter can now accept exception instances.


Changed in version 3.8: The stacklevel parameter was added."
"info(msg, *args, **kwargs)","Logs a message with level INFO on this logger. The arguments are
interpreted as for debug()."
"warning(msg, *args, **kwargs)","Logs a message with level WARNING on this logger. The arguments are
interpreted as for debug().

Note
There is an obsolete method warn which is functionally
identical to warning. As warn is deprecated, please do not use
it - use warning instead."
"error(msg, *args, **kwargs)","Logs a message with level ERROR on this logger. The arguments are
interpreted as for debug()."
"critical(msg, *args, **kwargs)","Logs a message with level CRITICAL on this logger. The arguments are
interpreted as for debug()."
"log(level, msg, *args, **kwargs)","Logs a message with integer level level on this logger. The other arguments are
interpreted as for debug()."
"exception(msg, *args, **kwargs)","Logs a message with level ERROR on this logger. The arguments are
interpreted as for debug(). Exception info is added to the logging
message. This method should only be called from an exception handler."
addFilter(filter),Adds the specified filter filter to this logger.
removeFilter(filter),Removes the specified filter filter from this logger.
filter(record),"Apply this logger’s filters to the record and return True if the
record is to be processed. The filters are consulted in turn, until one of
them returns a false value. If none of them return a false value, the record
will be processed (passed to handlers). If one returns a false value, no
further processing of the record occurs."
addHandler(hdlr),Adds the specified handler hdlr to this logger.
removeHandler(hdlr),Removes the specified handler hdlr from this logger.
"findCaller(stack_info=False, stacklevel=1)","Finds the caller’s source filename and line number. Returns the filename, line
number, function name and stack information as a 4-element tuple. The stack
information is returned as None unless stack_info is True.
The stacklevel parameter is passed from code calling the debug()
and other APIs. If greater than 1, the excess is used to skip stack frames
before determining the values to be returned. This will generally be useful
when calling logging APIs from helper/wrapper code, so that the information
in the event log refers not to the helper/wrapper code, but to the code that
calls it."
handle(record),"Handles a record by passing it to all handlers associated with this logger and
its ancestors (until a false value of propagate is found). This method is used
for unpickled records received from a socket, as well as those created locally.
Logger-level filtering is applied using filter()."
"makeRecord(name, level, fn, lno, msg, args, exc_info, func=None, extra=None, sinfo=None)","This is a factory method which can be overridden in subclasses to create
specialized LogRecord instances."
hasHandlers(),"Checks to see if this logger has any handlers configured. This is done by
looking for handlers in this logger and its parents in the logger hierarchy.
Returns True if a handler was found, else False. The method stops searching
up the hierarchy whenever a logger with the ‘propagate’ attribute set to
false is found - that will be the last logger which is checked for the
existence of handlers.

New in version 3.2."
__init__(level=NOTSET),"Initializes the Handler instance by setting its level, setting the list
of filters to the empty list and creating a lock (using createLock()) for
serializing access to an I/O mechanism."
createLock(),"Initializes a thread lock which can be used to serialize access to underlying
I/O functionality which may not be threadsafe."
acquire(),Acquires the thread lock created with createLock().
release(),Releases the thread lock acquired with acquire().
setLevel(level),"Sets the threshold for this handler to level. Logging messages which are
less severe than level will be ignored. When a handler is created, the
level is set to NOTSET (which causes all messages to be
processed).
See Logging Levels for a list of levels.

Changed in version 3.2: The level parameter now accepts a string representation of the
level such as ‘INFO’ as an alternative to the integer constants
such as INFO."
setFormatter(fmt),Sets the Formatter for this handler to fmt.
addFilter(filter),Adds the specified filter filter to this handler.
removeFilter(filter),Removes the specified filter filter from this handler.
filter(record),"Apply this handler’s filters to the record and return True if the
record is to be processed. The filters are consulted in turn, until one of
them returns a false value. If none of them return a false value, the record
will be emitted. If one returns a false value, the handler will not emit the
record."
flush(),"Ensure all logging output has been flushed. This version does nothing and is
intended to be implemented by subclasses."
close(),"Tidy up any resources used by the handler. This version does no output but
removes the handler from an internal list of handlers which is closed when
shutdown() is called. Subclasses should ensure that this gets called
from overridden close() methods."
handle(record),"Conditionally emits the specified logging record, depending on filters which may
have been added to the handler. Wraps the actual emission of the record with
acquisition/release of the I/O thread lock."
handleError(record),"This method should be called from handlers when an exception is encountered
during an emit() call. If the module-level attribute
raiseExceptions is False, exceptions get silently ignored. This is
what is mostly wanted for a logging system - most users will not care about
errors in the logging system, they are more interested in application
errors. You could, however, replace this with a custom handler if you wish.
The specified record is the one which was being processed when the exception
occurred. (The default value of raiseExceptions is True, as that is
more useful during development)."
format(record),"Do formatting for a record - if a formatter is set, use it. Otherwise, use the
default formatter for the module."
emit(record),"Do whatever it takes to actually log the specified logging record. This version
is intended to be implemented by subclasses and so raises a
NotImplementedError."
format(record),"The record’s attribute dictionary is used as the operand to a string
formatting operation. Returns the resulting string. Before formatting the
dictionary, a couple of preparatory steps are carried out. The message
attribute of the record is computed using msg % args. If the
formatting string contains '(asctime)', formatTime() is called
to format the event time. If there is exception information, it is
formatted using formatException() and appended to the message. Note
that the formatted exception information is cached in attribute
exc_text. This is useful because the exception information can be
pickled and sent across the wire, but you should be careful if you have
more than one Formatter subclass which customizes the formatting
of exception information. In this case, you will have to clear the cached
value after a formatter has done its formatting, so that the next
formatter to handle the event doesn’t use the cached value but
recalculates it afresh.
If stack information is available, it’s appended after the exception
information, using formatStack() to transform it if necessary."
"formatTime(record, datefmt=None)","This method should be called from format() by a formatter which
wants to make use of a formatted time. This method can be overridden in
formatters to provide for any specific requirement, but the basic behavior
is as follows: if datefmt (a string) is specified, it is used with
time.strftime() to format the creation time of the
record. Otherwise, the format ‘%Y-%m-%d %H:%M:%S,uuu’ is used, where the
uuu part is a millisecond value and the other letters are as per the
time.strftime() documentation.  An example time in this format is
2003-01-23 00:29:50,411.  The resulting string is returned.
This function uses a user-configurable function to convert the creation
time to a tuple. By default, time.localtime() is used; to change
this for a particular formatter instance, set the converter attribute
to a function with the same signature as time.localtime() or
time.gmtime(). To change it for all formatters, for example if you
want all logging times to be shown in GMT, set the converter
attribute in the Formatter class.

Changed in version 3.3: Previously, the default format was hard-coded as in this example:
2010-09-06 22:38:15,292 where the part before the comma is
handled by a strptime format string ('%Y-%m-%d %H:%M:%S'), and the
part after the comma is a millisecond value. Because strptime does not
have a format placeholder for milliseconds, the millisecond value is
appended using another format string, '%s,%03d' — and both of these
format strings have been hardcoded into this method. With the change,
these strings are defined as class-level attributes which can be
overridden at the instance level when desired. The names of the
attributes are default_time_format (for the strptime format string)
and default_msec_format (for appending the millisecond value)."
formatException(exc_info),"Formats the specified exception information (a standard exception tuple as
returned by sys.exc_info()) as a string. This default implementation
just uses traceback.print_exception(). The resulting string is
returned."
formatStack(stack_info),"Formats the specified stack information (a string as returned by
traceback.print_stack(), but with the last newline removed) as a
string. This default implementation just returns the input value."
filter(record),"Is the specified record to be logged? Returns zero for no, nonzero for
yes. If deemed appropriate, the record may be modified in-place by this
method."
getMessage(),"Returns the message for this LogRecord instance after merging any
user-supplied arguments with the message. If the user-supplied message
argument to the logging call is not a string, str() is called on it to
convert it to a string. This allows use of user-defined classes as
messages, whose __str__ method can return the actual format string to
be used."
"process(msg, kwargs)","Modifies the message and/or keyword arguments passed to a logging call in
order to insert contextual information. This implementation takes the object
passed as extra to the constructor and adds it to kwargs using key
‘extra’. The return value is a (msg, kwargs) tuple which has the
(possibly modified) versions of the arguments passed in."
logging.config.dictConfig(config),"Takes the logging configuration from a dictionary.  The contents of
this dictionary are described in Configuration dictionary schema
below.
If an error is encountered during configuration, this function will
raise a ValueError, TypeError, AttributeError
or ImportError with a suitably descriptive message.  The
following is a (possibly incomplete) list of conditions which will
raise an error:

A level which is not a string or which is a string not
corresponding to an actual logging level.
A propagate value which is not a boolean.
An id which does not have a corresponding destination.
A non-existent handler id found during an incremental call.
An invalid logger name.
Inability to resolve to an internal or external object.

Parsing is performed by the DictConfigurator class, whose
constructor is passed the dictionary used for configuration, and
has a configure() method.  The logging.config module
has a callable attribute dictConfigClass
which is initially set to DictConfigurator.
You can replace the value of dictConfigClass with a
suitable implementation of your own.
dictConfig() calls dictConfigClass passing
the specified dictionary, and then calls the configure() method on
the returned object to put the configuration into effect:
def dictConfig(config):
    dictConfigClass(config).configure()


For example, a subclass of DictConfigurator could call
DictConfigurator.__init__() in its own __init__(), then
set up custom prefixes which would be usable in the subsequent
configure() call. dictConfigClass would be bound to
this new subclass, and then dictConfig() could be called exactly as
in the default, uncustomized state.


New in version 3.2."
"logging.config.fileConfig(fname, defaults=None, disable_existing_loggers=True)","Reads the logging configuration from a configparser-format file. The
format of the file should be as described in
Configuration file format.
This function can be called several times from an application, allowing an
end user to select from various pre-canned configurations (if the developer
provides a mechanism to present the choices and load the chosen
configuration).

Parameters

fname – A filename, or a file-like object, or an instance derived
from RawConfigParser. If a
RawConfigParser-derived instance is passed, it is used as
is. Otherwise, a Configparser is
instantiated, and the configuration read by it from the
object passed in fname. If that has a readline()
method, it is assumed to be a file-like object and read using
read_file(); otherwise,
it is assumed to be a filename and passed to
read().
defaults – Defaults to be passed to the ConfigParser can be specified
in this argument.
disable_existing_loggers – If specified as False, loggers which
exist when this call is made are left
enabled. The default is True because this
enables old behaviour in a
backward-compatible way. This behaviour is to
disable any existing non-root loggers unless
they or their ancestors are explicitly named
in the logging configuration.




Changed in version 3.4: An instance of a subclass of RawConfigParser is
now accepted as a value for fname. This facilitates:

Use of a configuration file where logging configuration is just part
of the overall application configuration.
Use of a configuration read from a file, and then modified by the using
application (e.g. based on command-line parameters or other aspects
of the runtime environment) before being passed to fileConfig."
"logging.config.listen(port=DEFAULT_LOGGING_CONFIG_PORT, verify=None)","Starts up a socket server on the specified port, and listens for new
configurations. If no port is specified, the module’s default
DEFAULT_LOGGING_CONFIG_PORT is used. Logging configurations will be
sent as a file suitable for processing by dictConfig() or
fileConfig(). Returns a Thread instance on which
you can call start() to start the server, and which
you can join() when appropriate. To stop the server,
call stopListening().
The verify argument, if specified, should be a callable which should
verify whether bytes received across the socket are valid and should be
processed. This could be done by encrypting and/or signing what is sent
across the socket, such that the verify callable can perform
signature verification and/or decryption. The verify callable is called
with a single argument - the bytes received across the socket - and should
return the bytes to be processed, or None to indicate that the bytes should
be discarded. The returned bytes could be the same as the passed in bytes
(e.g. when only verification is done), or they could be completely different
(perhaps if decryption were performed).
To send a configuration to the socket, read in the configuration file and
send it to the socket as a sequence of bytes preceded by a four-byte length
string packed in binary using struct.pack('>L', n).

Note
Because portions of the configuration are passed through
eval(), use of this function may open its users to a security risk.
While the function only binds to a socket on localhost, and so does
not accept connections from remote machines, there are scenarios where
untrusted code could be run under the account of the process which calls
listen(). Specifically, if the process calling listen() runs
on a multi-user machine where users cannot trust each other, then a
malicious user could arrange to run essentially arbitrary code in a
victim user’s process, simply by connecting to the victim’s
listen() socket and sending a configuration which runs whatever
code the attacker wants to have executed in the victim’s process. This is
especially easy to do if the default port is used, but not hard even if a
different port is used). To avoid the risk of this happening, use the
verify argument to listen() to prevent unrecognised
configurations from being applied.


Changed in version 3.4: The verify argument was added.


Note
If you want to send configurations to the listener which don’t
disable existing loggers, you will need to use a JSON format for
the configuration, which will use dictConfig() for configuration.
This method allows you to specify disable_existing_loggers as
False in the configuration you send."
logging.config.stopListening(),"Stops the listening server which was created with a call to listen().
This is typically called before calling join() on the return value from
listen()."
emit(record),"If a formatter is specified, it is used to format the record. The record
is then written to the stream with a terminator. If exception information
is present, it is formatted using traceback.print_exception() and
appended to the stream."
flush(),"Flushes the stream by calling its flush() method. Note that the
close() method is inherited from Handler and so
does no output, so an explicit flush() call may be needed at times."
setStream(stream),"Sets the instance’s stream to the specified value, if it is different.
The old stream is flushed before the new stream is set.

Parameters
stream – The stream that the handler should use.

Returns
the old stream, if the stream was changed, or None if it wasn’t."
close(),Closes the file.
emit(record),Outputs the record to the file.
emit(record),This method does nothing.
handle(record),This method does nothing.
createLock(),"This method returns None for the lock, since there is no
underlying I/O to which access needs to be serialized."
reopenIfNeeded(),"Checks to see if the file has changed.  If it has, the existing stream is
flushed and closed and the file opened again, typically as a precursor to
outputting the record to the file.

New in version 3.6."
emit(record),"Outputs the record to the file, but first calls reopenIfNeeded() to
reopen the file if it has changed."
rotation_filename(default_name),"Modify the filename of a log file when rotating.
This is provided so that a custom filename can be provided.
The default implementation calls the ‘namer’ attribute of the handler,
if it’s callable, passing the default name to it. If the attribute isn’t
callable (the default is None), the name is returned unchanged.

Parameters
default_name – The default name for the log file.



New in version 3.3."
"rotate(source, dest)","When rotating, rotate the current log.
The default implementation calls the ‘rotator’ attribute of the handler,
if it’s callable, passing the source and dest arguments to it. If the
attribute isn’t callable (the default is None), the source is simply
renamed to the destination.

Parameters

source – The source filename. This is normally the base
filename, e.g. ‘test.log’.
dest – The destination filename. This is normally
what the source is rotated to, e.g. ‘test.log.1’.




New in version 3.3."
doRollover(),"Does a rollover, as described above."
emit(record),"Outputs the record to the file, catering for rollover as described
previously."
doRollover(),"Does a rollover, as described above."
emit(record),"Outputs the record to the file, catering for rollover as described above."
close(),Closes the socket.
emit(),"Pickles the record’s attribute dictionary and writes it to the socket in
binary format. If there is an error with the socket, silently drops the
packet. If the connection was previously lost, re-establishes the
connection. To unpickle the record at the receiving end into a
LogRecord, use the makeLogRecord()
function."
handleError(),"Handles an error which has occurred during emit(). The most likely
cause is a lost connection. Closes the socket so that we can retry on the
next event."
makeSocket(),"This is a factory method which allows subclasses to define the precise
type of socket they want. The default implementation creates a TCP socket
(socket.SOCK_STREAM)."
makePickle(record),"Pickles the record’s attribute dictionary in binary format with a length
prefix, and returns it ready for transmission across the socket. The
details of this operation are equivalent to:
data = pickle.dumps(record_attr_dict, 1)
datalen = struct.pack('>L', len(data))
return datalen + data


Note that pickles aren’t completely secure. If you are concerned about
security, you may want to override this method to implement a more secure
mechanism. For example, you can sign pickles using HMAC and then verify
them on the receiving end, or alternatively you can disable unpickling of
global objects on the receiving end."
send(packet),"Send a pickled byte-string packet to the socket. The format of the sent
byte-string is as described in the documentation for
makePickle().
This function allows for partial sends, which can happen when the network
is busy."
createSocket(),"Tries to create a socket; on failure, uses an exponential back-off
algorithm.  On initial failure, the handler will drop the message it was
trying to send.  When subsequent messages are handled by the same
instance, it will not try connecting until some time has passed.  The
default parameters are such that the initial delay is one second, and if
after that delay the connection still can’t be made, the handler will
double the delay each time up to a maximum of 30 seconds.
This behaviour is controlled by the following handler attributes:

retryStart (initial delay, defaulting to 1.0 seconds).
retryFactor (multiplier, defaulting to 2.0).
retryMax (maximum delay, defaulting to 30.0 seconds).

This means that if the remote listener starts up after the handler has
been used, you could lose messages (since the handler won’t even attempt
a connection until the delay has elapsed, but just silently drop messages
during the delay period)."
emit(),"Pickles the record’s attribute dictionary and writes it to the socket in
binary format. If there is an error with the socket, silently drops the
packet. To unpickle the record at the receiving end into a
LogRecord, use the makeLogRecord()
function."
makeSocket(),"The factory method of SocketHandler is here overridden to create
a UDP socket (socket.SOCK_DGRAM)."
send(s),"Send a pickled byte-string to a socket. The format of the sent byte-string
is as described in the documentation for SocketHandler.makePickle()."
close(),Closes the socket to the remote host.
emit(record),"The record is formatted, and then sent to the syslog server. If exception
information is present, it is not sent to the server.

Changed in version 3.2.1: (See: bpo-12168.) In earlier versions, the message sent to the
syslog daemons was always terminated with a NUL byte, because early
versions of these daemons expected a NUL terminated message - even
though it’s not in the relevant specification (RFC 5424). More recent
versions of these daemons don’t expect the NUL byte but strip it off
if it’s there, and even more recent daemons (which adhere more closely
to RFC 5424) pass the NUL byte on as part of the message.
To enable easier handling of syslog messages in the face of all these
differing daemon behaviours, the appending of the NUL byte has been
made configurable, through the use of a class-level attribute,
append_nul. This defaults to True (preserving the existing
behaviour) but can be set to False on a SysLogHandler instance
in order for that instance to not append the NUL terminator.


Changed in version 3.3: (See: bpo-12419.) In earlier versions, there was no facility for
an “ident” or “tag” prefix to identify the source of the message. This
can now be specified using a class-level attribute, defaulting to
"""" to preserve existing behaviour, but which can be overridden on
a SysLogHandler instance in order for that instance to prepend
the ident to every message handled. Note that the provided ident must
be text, not bytes, and is prepended to the message exactly as is."
"encodePriority(facility, priority)","Encodes the facility and priority into an integer. You can pass in strings
or integers - if strings are passed, internal mapping dictionaries are
used to convert them to integers.
The symbolic LOG_ values are defined in SysLogHandler and
mirror the values defined in the sys/syslog.h header file.
Priorities






Name (string)
Symbolic value



alert
LOG_ALERT

crit or critical
LOG_CRIT

debug
LOG_DEBUG

emerg or panic
LOG_EMERG

err or error
LOG_ERR

info
LOG_INFO

notice
LOG_NOTICE

warn or warning
LOG_WARNING



Facilities






Name (string)
Symbolic value



auth
LOG_AUTH

authpriv
LOG_AUTHPRIV

cron
LOG_CRON

daemon
LOG_DAEMON

ftp
LOG_FTP

kern
LOG_KERN

lpr
LOG_LPR

mail
LOG_MAIL

news
LOG_NEWS

syslog
LOG_SYSLOG

user
LOG_USER

uucp
LOG_UUCP

local0
LOG_LOCAL0

local1
LOG_LOCAL1

local2
LOG_LOCAL2

local3
LOG_LOCAL3

local4
LOG_LOCAL4

local5
LOG_LOCAL5

local6
LOG_LOCAL6

local7
LOG_LOCAL7"
mapPriority(levelname),"Maps a logging level name to a syslog priority name.
You may need to override this if you are using custom levels, or
if the default algorithm is not suitable for your needs. The
default algorithm maps DEBUG, INFO, WARNING, ERROR and
CRITICAL to the equivalent syslog names, and all other level
names to ‘warning’."
close(),"At this point, you can remove the application name from the registry as a
source of event log entries. However, if you do this, you will not be able
to see the events as you intended in the Event Log Viewer - it needs to be
able to access the registry to get the .dll name. The current version does
not do this."
emit(record),"Determines the message ID, event category and event type, and then logs
the message in the NT event log."
getEventCategory(record),"Returns the event category for the record. Override this if you want to
specify your own categories. This version returns 0."
getEventType(record),"Returns the event type for the record. Override this if you want to
specify your own types. This version does a mapping using the handler’s
typemap attribute, which is set up in __init__() to a dictionary
which contains mappings for DEBUG, INFO,
WARNING, ERROR and CRITICAL. If you are using
your own levels, you will either need to override this method or place a
suitable dictionary in the handler’s typemap attribute."
getMessageID(record),"Returns the message ID for the record. If you are using your own messages,
you could do this by having the msg passed to the logger being an ID
rather than a format string. Then, in here, you could use a dictionary
lookup to get the message ID. This version returns 1, which is the base
message ID in win32service.pyd."
emit(record),Formats the record and sends it to the specified addressees.
getSubject(record),"If you want to specify a subject line which is record-dependent, override
this method."
emit(record),"Append the record to the buffer. If shouldFlush() returns true,
call flush() to process the buffer."
flush(),"You can override this to implement custom flushing behavior. This version
just zaps the buffer to empty."
shouldFlush(record),"Return True if the buffer is up to capacity. This method can be
overridden to implement custom flushing strategies."
close(),"Calls flush(), sets the target to None and clears the
buffer."
flush(),"For a MemoryHandler, flushing means just sending the buffered
records to the target, if there is one. The buffer is also cleared when
this happens. Override if you want different behavior."
setTarget(target),Sets the target handler for this handler.
shouldFlush(record),Checks for buffer full or a record at the flushLevel or higher.
mapLogRecord(record),"Provides a dictionary, based on record, which is to be URL-encoded
and sent to the web server. The default implementation just returns
record.__dict__. This method can be overridden if e.g. only a
subset of LogRecord is to be sent to the web server, or
if more specific customization of what’s sent to the server is required."
emit(record),"Sends the record to the Web server as a URL-encoded dictionary. The
mapLogRecord() method is used to convert the record to the
dictionary to be sent."
emit(record),"Enqueues the result of preparing the LogRecord. Should an exception
occur (e.g. because a bounded queue has filled up), the
handleError() method is called to handle the
error. This can result in the record silently being dropped (if
logging.raiseExceptions is False) or a message printed to
sys.stderr (if logging.raiseExceptions is True)."
prepare(record),"Prepares a record for queuing. The object returned by this
method is enqueued.
The base implementation formats the record to merge the message,
arguments, and exception information, if present.  It also
removes unpickleable items from the record in-place.
You might want to override this method if you want to convert
the record to a dict or JSON string, or send a modified copy
of the record while leaving the original intact."
enqueue(record),"Enqueues the record on the queue using put_nowait(); you may
want to override this if you want to use blocking behaviour, or a
timeout, or a customized queue implementation."
dequeue(block),"Dequeues a record and return it, optionally blocking.
The base implementation uses get(). You may want to override this
method if you want to use timeouts or work with custom queue
implementations."
prepare(record),"Prepare a record for handling.
This implementation just returns the passed-in record. You may want to
override this method if you need to do any custom marshalling or
manipulation of the record before passing it to the handlers."
handle(record),"Handle a record.
This just loops through the handlers offering them the record
to handle. The actual object passed to the handlers is that which
is returned from prepare()."
start(),"Starts the listener.
This starts up a background thread to monitor the queue for
LogRecords to process."
stop(),"Stops the listener.
This asks the thread to terminate, and then waits for it to do so.
Note that if you don’t call this before your application exits, there
may be some records still left on the queue, which won’t be processed."
enqueue_sentinel(),"Writes a sentinel to the queue to tell the listener to quit. This
implementation uses put_nowait().  You may want to override this
method if you want to use timeouts or work with custom queue
implementations.

New in version 3.3."
"getpass.getpass(prompt='Password: ', stream=None)","Prompt the user for a password without echoing.  The user is prompted using
the string prompt, which defaults to 'Password: '.  On Unix, the
prompt is written to the file-like object stream using the replace error
handler if needed.  stream defaults to the controlling terminal
(/dev/tty) or if that is unavailable to sys.stderr (this
argument is ignored on Windows).
If echo free input is unavailable getpass() falls back to printing
a warning message to stream and reading from sys.stdin and
issuing a GetPassWarning.

Note
If you call getpass from within IDLE, the input may be done in the
terminal you launched IDLE from rather than the idle window itself."
getpass.getuser(),"Return the “login name” of the user.
This function checks the environment variables LOGNAME,
USER, LNAME and USERNAME, in order, and
returns the value of the first one which is set to a non-empty string.  If
none are set, the login name from the password database is returned on
systems which support the pwd module, otherwise, an exception is
raised.
In general, this function should be preferred over os.getlogin()."
curses.baudrate(),"Return the output speed of the terminal in bits per second.  On software
terminal emulators it will have a fixed high value. Included for historical
reasons; in former times, it was used to  write output loops for time delays and
occasionally to change interfaces depending on the line speed."
curses.beep(),Emit a short attention sound.
curses.can_change_color(),"Return True or False, depending on whether the programmer can change the colors
displayed by the terminal."
curses.cbreak(),"Enter cbreak mode.  In cbreak mode (sometimes called “rare” mode) normal tty
line buffering is turned off and characters are available to be read one by one.
However, unlike raw mode, special characters (interrupt, quit, suspend, and flow
control) retain their effects on the tty driver and calling program.  Calling
first raw() then cbreak() leaves the terminal in cbreak mode."
curses.color_content(color_number),"Return the intensity of the red, green, and blue (RGB) components in the color
color_number, which must be between 0 and COLORS.  Return a 3-tuple,
containing the R,G,B values for the given color, which will be between
0 (no component) and 1000 (maximum amount of component)."
curses.color_pair(color_number),"Return the attribute value for displaying text in the specified color.  This
attribute value can be combined with A_STANDOUT, A_REVERSE,
and the other A_* attributes.  pair_number() is the counterpart
to this function."
curses.curs_set(visibility),"Set the cursor state.  visibility can be set to 0, 1, or 2, for invisible,
normal, or very visible.  If the terminal supports the visibility requested, return the
previous cursor state; otherwise raise an exception.  On many
terminals, the “visible” mode is an underline cursor and the “very visible” mode
is a block cursor."
curses.def_prog_mode(),"Save the current terminal mode as the “program” mode, the mode when the running
program is using curses.  (Its counterpart is the “shell” mode, for when the
program is not in curses.)  Subsequent calls to reset_prog_mode() will
restore this mode."
curses.def_shell_mode(),"Save the current terminal mode as the “shell” mode, the mode when the running
program is not using curses.  (Its counterpart is the “program” mode, when the
program is using curses capabilities.) Subsequent calls to
reset_shell_mode() will restore this mode."
curses.delay_output(ms),Insert an ms millisecond pause in output.
curses.doupdate(),"Update the physical screen.  The curses library keeps two data structures, one
representing the current physical screen contents and a virtual screen
representing the desired next state.  The doupdate() ground updates the
physical screen to match the virtual screen.
The virtual screen may be updated by a noutrefresh() call after write
operations such as addstr() have been performed on a window.  The normal
refresh() call is simply noutrefresh() followed by doupdate();
if you have to update multiple windows, you can speed performance and perhaps
reduce screen flicker by issuing noutrefresh() calls on all windows,
followed by a single doupdate()."
curses.echo(),"Enter echo mode.  In echo mode, each character input is echoed to the screen as
it is entered."
curses.endwin(),"De-initialize the library, and return terminal to normal status."
curses.erasechar(),"Return the user’s current erase character as a one-byte bytes object.  Under Unix operating systems this
is a property of the controlling tty of the curses program, and is not set by
the curses library itself."
curses.filter(),"The filter() routine, if used, must be called before initscr() is
called.  The effect is that, during those calls, LINES is set to 1; the
capabilities clear, cup, cud, cud1, cuu1, cuu, vpa are disabled; and the home
string is set to the value of cr. The effect is that the cursor is confined to
the current line, and so are screen updates.  This may be used for enabling
character-at-a-time  line editing without touching the rest of the screen."
curses.flash(),"Flash the screen.  That is, change it to reverse-video and then change it back
in a short interval.  Some people prefer such as ‘visible bell’ to the audible
attention signal produced by beep()."
curses.flushinp(),"Flush all input buffers.  This throws away any  typeahead  that  has been typed
by the user and has not yet been processed by the program."
curses.getmouse(),"After getch() returns KEY_MOUSE to signal a mouse event, this
method should be call to retrieve the queued mouse event, represented as a
5-tuple (id, x, y, z, bstate). id is an ID value used to distinguish
multiple devices, and x, y, z are the event’s coordinates.  (z is
currently unused.)  bstate is an integer value whose bits will be set to
indicate the type of event, and will be the bitwise OR of one or more of the
following constants, where n is the button number from 1 to 4:
BUTTONn_PRESSED, BUTTONn_RELEASED, BUTTONn_CLICKED,
BUTTONn_DOUBLE_CLICKED, BUTTONn_TRIPLE_CLICKED,
BUTTON_SHIFT, BUTTON_CTRL, BUTTON_ALT."
curses.getsyx(),"Return the current coordinates of the virtual screen cursor as a tuple
(y, x).  If leaveok is currently True, then return (-1, -1)."
curses.getwin(file),"Read window related data stored in the file by an earlier putwin() call.
The routine then creates and initializes a new window using that data, returning
the new window object."
curses.has_colors(),"Return True if the terminal can display colors; otherwise, return False."
curses.has_ic(),"Return True if the terminal has insert- and delete-character capabilities.
This function is included for historical reasons only, as all modern software
terminal emulators have such capabilities."
curses.has_il(),"Return True if the terminal has insert- and delete-line capabilities, or can
simulate  them  using scrolling regions. This function is included for
historical reasons only, as all modern software terminal emulators have such
capabilities."
curses.has_key(ch),"Take a key value ch, and return True if the current terminal type recognizes
a key with that value."
curses.halfdelay(tenths),"Used for half-delay mode, which is similar to cbreak mode in that characters
typed by the user are immediately available to the program. However, after
blocking for tenths tenths of seconds, raise an exception if nothing has
been typed.  The value of tenths must be a number between 1 and 255.  Use
nocbreak() to leave half-delay mode."
"curses.init_color(color_number, r, g, b)","Change the definition of a color, taking the number of the color to be changed
followed by three RGB values (for the amounts of red, green, and blue
components).  The value of color_number must be between 0 and
COLORS.  Each of r, g, b, must be a value between 0 and
1000.  When init_color() is used, all occurrences of that color on the
screen immediately change to the new definition.  This function is a no-op on
most terminals; it is active only if can_change_color() returns True."
"curses.init_pair(pair_number, fg, bg)","Change the definition of a color-pair.  It takes three arguments: the number of
the color-pair to be changed, the foreground color number, and the background
color number.  The value of pair_number must be between 1 and
COLOR_PAIRS - 1 (the 0 color pair is wired to white on black and cannot
be changed).  The value of fg and bg arguments must be between 0 and
COLORS.  If the color-pair was previously initialized, the screen is
refreshed and all occurrences of that color-pair are changed to the new
definition."
curses.initscr(),"Initialize the library. Return a window object
which represents the whole screen.

Note
If there is an error opening the terminal, the underlying curses library may
cause the interpreter to exit."
"curses.is_term_resized(nlines, ncols)","Return True if resize_term() would modify the window structure,
False otherwise."
curses.isendwin(),"Return True if endwin() has been called (that is, the  curses library has
been deinitialized)."
curses.keyname(k),"Return the name of the key numbered k as a bytes object.  The name of a key generating printable
ASCII character is the key’s character.  The name of a control-key combination
is a two-byte bytes object consisting of a caret (b'^') followed by the corresponding
printable ASCII character.  The name of an alt-key combination (128–255) is a
bytes object consisting of the prefix b'M-' followed by the name of the corresponding
ASCII character."
curses.killchar(),"Return the user’s current line kill character as a one-byte bytes object. Under Unix operating systems
this is a property of the controlling tty of the curses program, and is not set
by the curses library itself."
curses.longname(),"Return a bytes object containing the terminfo long name field describing the current
terminal.  The maximum length of a verbose description is 128 characters.  It is
defined only after the call to initscr()."
curses.meta(flag),"If flag is True, allow 8-bit characters to be input.  If
flag is False,  allow only 7-bit chars."
curses.mouseinterval(interval),"Set the maximum time in milliseconds that can elapse between press and release
events in order for them to be recognized as a click, and return the previous
interval value.  The default value is 200 msec, or one fifth of a second."
curses.mousemask(mousemask),"Set the mouse events to be reported, and return a tuple (availmask,
oldmask).   availmask indicates which of the specified mouse events can be
reported; on complete failure it returns 0.  oldmask is the previous value of
the given window’s mouse event mask.  If this function is never called, no mouse
events are ever reported."
curses.napms(ms),Sleep for ms milliseconds.
"curses.newpad(nlines, ncols)","Create and return a pointer to a new pad data structure with the given number
of lines and columns.  Return a pad as a window object.
A pad is like a window, except that it is not restricted by the screen size, and
is not necessarily associated with a particular part of the screen.  Pads can be
used when a large window is needed, and only a part of the window will be on the
screen at one time.  Automatic refreshes of pads (such as from scrolling or
echoing of input) do not occur.  The refresh() and noutrefresh()
methods of a pad require 6 arguments to specify the part of the pad to be
displayed and the location on the screen to be used for the display. The
arguments are pminrow, pmincol, sminrow, smincol, smaxrow, smaxcol; the p
arguments refer to the upper left corner of the pad region to be displayed and
the s arguments define a clipping box on the screen within which the pad region
is to be displayed."
"curses.newwin(nlines, ncols)","Return a new window, whose left-upper corner
is at  (begin_y, begin_x), and whose height/width is  nlines/ncols.
By default, the window will extend from the  specified position to the lower
right corner of the screen."
curses.nl(),"Enter newline mode.  This mode translates the return key into newline on input,
and translates newline into return and line-feed on output. Newline mode is
initially on."
curses.nocbreak(),Leave cbreak mode.  Return to normal “cooked” mode with line buffering.
curses.noecho(),Leave echo mode.  Echoing of input characters is turned off.
curses.nonl(),"Leave newline mode.  Disable translation of return into newline on input, and
disable low-level translation of newline into newline/return on output (but this
does not change the behavior of addch('\n'), which always does the
equivalent of return and line feed on the virtual screen).  With translation
off, curses can sometimes speed up vertical motion a little; also, it will be
able to detect the return key on input."
curses.noqiflush(),"When the noqiflush() routine is used, normal flush of input and output queues
associated with the INTR, QUIT and SUSP characters will not be done.  You may
want to call noqiflush() in a signal handler if you want output to
continue as though the interrupt had not occurred, after the handler exits."
curses.noraw(),Leave raw mode. Return to normal “cooked” mode with line buffering.
curses.pair_content(pair_number),"Return a tuple (fg, bg) containing the colors for the requested color pair.
The value of pair_number must be between 1 and COLOR_PAIRS - 1."
curses.pair_number(attr),"Return the number of the color-pair set by the attribute value attr.
color_pair() is the counterpart to this function."
curses.putp(str),"Equivalent to tputs(str, 1, putchar); emit the value of a specified
terminfo capability for the current terminal.  Note that the output of putp()
always goes to standard output."
curses.qiflush([flag]),"If flag is False, the effect is the same as calling noqiflush(). If
flag is True, or no argument is provided, the queues will be flushed when
these control characters are read."
curses.raw(),"Enter raw mode.  In raw mode, normal line buffering and  processing of
interrupt, quit, suspend, and flow control keys are turned off; characters are
presented to curses input functions one by one."
curses.reset_prog_mode(),"Restore the  terminal  to “program” mode, as previously saved  by
def_prog_mode()."
curses.reset_shell_mode(),"Restore the  terminal  to “shell” mode, as previously saved  by
def_shell_mode()."
curses.resetty(),"Restore the state of the terminal modes to what it was at the last call to
savetty()."
"curses.resize_term(nlines, ncols)","Backend function used by resizeterm(), performing most of the work;
when resizing the windows, resize_term() blank-fills the areas that are
extended.  The calling application should fill in these areas with
appropriate data.  The resize_term() function attempts to resize all
windows.  However, due to the calling convention of pads, it is not possible
to resize these without additional interaction with the application."
"curses.resizeterm(nlines, ncols)","Resize the standard and current windows to the specified dimensions, and
adjusts other bookkeeping data used by the curses library that record the
window dimensions (in particular the SIGWINCH handler)."
curses.savetty(),"Save the current state of the terminal modes in a buffer, usable by
resetty()."
"curses.setsyx(y, x)","Set the virtual screen cursor to y, x. If y and x are both -1, then
leaveok is set True."
"curses.setupterm(term=None, fd=-1)","Initialize the terminal.  term is a string giving
the terminal name, or None; if omitted or None, the value of the
TERM environment variable will be used.  fd is the
file descriptor to which any initialization sequences will be sent; if not
supplied or -1, the file descriptor for sys.stdout will be used."
curses.start_color(),"Must be called if the programmer wants to use colors, and before any other color
manipulation routine is called.  It is good practice to call this routine right
after initscr().
start_color() initializes eight basic colors (black, red,  green, yellow,
blue, magenta, cyan, and white), and two global variables in the curses
module, COLORS and COLOR_PAIRS, containing the maximum number
of colors and color-pairs the terminal can support.  It also restores the colors
on the terminal to the values they had when the terminal was just turned on."
curses.termattrs(),"Return a logical OR of all video attributes supported by the terminal.  This
information is useful when a curses program needs complete control over the
appearance of the screen."
curses.termname(),"Return the value of the environment variable TERM, as a bytes object,
truncated to 14 characters."
curses.tigetflag(capname),"Return the value of the Boolean capability corresponding to the terminfo
capability name capname as an integer.  Return the value -1 if capname is not a
Boolean capability, or 0 if it is canceled or absent from the terminal
description."
curses.tigetnum(capname),"Return the value of the numeric capability corresponding to the terminfo
capability name capname as an integer.  Return the value -2 if capname is not a
numeric capability, or -1 if it is canceled or absent from the terminal
description."
curses.tigetstr(capname),"Return the value of the string capability corresponding to the terminfo
capability name capname as a bytes object.  Return None if capname
is not a terminfo “string capability”, or is canceled or absent from the
terminal description."
"curses.tparm(str[, ...])","Instantiate the bytes object str with the supplied parameters, where str should
be a parameterized string obtained from the terminfo database.  E.g.
tparm(tigetstr(""cup""), 5, 3) could result in b'\033[6;4H', the exact
result depending on terminal type."
curses.typeahead(fd),"Specify that the file descriptor fd be used for typeahead checking.  If fd
is -1, then no typeahead checking is done.
The curses library does “line-breakout optimization” by looking for typeahead
periodically while updating the screen.  If input is found, and it is coming
from a tty, the current update is postponed until refresh or doupdate is called
again, allowing faster response to commands typed in advance. This function
allows specifying a different file descriptor for typeahead checking."
curses.unctrl(ch),"Return a bytes object which is a printable representation of the character ch.
Control characters are represented as a caret followed by the character, for
example as b'^C'. Printing characters are left as they are."
curses.ungetch(ch),"Push ch so the next getch() will return it.

Note
Only one ch can be pushed before getch() is called."
curses.update_lines_cols(),"Update LINES and COLS. Useful for detecting manual screen resize.

New in version 3.5."
curses.unget_wch(ch),"Push ch so the next get_wch() will return it.

Note
Only one ch can be pushed before get_wch() is called.


New in version 3.3."
"curses.ungetmouse(id, x, y, z, bstate)","Push a KEY_MOUSE event onto the input queue, associating the given
state data with it."
curses.use_env(flag),"If used, this function should be called before initscr() or newterm are
called.  When flag is False, the values of lines and columns specified in the
terminfo database will be used, even if environment variables LINES
and COLUMNS (used by default) are set, or if curses is running in a
window (in which case default behavior would be to use the window size if
LINES and COLUMNS are not set)."
curses.use_default_colors(),"Allow use of default values for colors on terminals supporting this feature. Use
this to support transparency in your application.  The default color is assigned
to the color number -1. After calling this function,  init_pair(x,
curses.COLOR_RED, -1) initializes, for instance, color pair x to a red
foreground color on the default background."
"curses.wrapper(func, ...)","Initialize curses and call another callable object, func, which should be the
rest of your curses-using application.  If the application raises an exception,
this function will restore the terminal to a sane state before re-raising the
exception and generating a traceback.  The callable object func is then passed
the main window ‘stdscr’ as its first argument, followed by any other arguments
passed to wrapper().  Before calling func, wrapper() turns on
cbreak mode, turns off echo, enables the terminal keypad, and initializes colors
if the terminal has color support.  On exit (whether normally or by exception)
it restores cooked mode, turns on echo, and disables the terminal keypad."
"curses.textpad.rectangle(win, uly, ulx, lry, lrx)","Draw a rectangle.  The first argument must be a window object; the remaining
arguments are coordinates relative to that window.  The second and third
arguments are the y and x coordinates of the upper left hand corner of the
rectangle to be drawn; the fourth and fifth arguments are the y and x
coordinates of the lower right hand corner. The rectangle will be drawn using
VT100/IBM PC forms characters on terminals that make this possible (including
xterm and most other software terminal emulators).  Otherwise it will be drawn
with ASCII  dashes, vertical bars, and plus signs."
"window.addch(ch[, attr])","Paint character ch at (y, x) with attributes attr, overwriting any
character previously painter at that location.  By default, the character
position and attributes are the current settings for the window object.

Note
Writing outside the window, subwindow, or pad raises a curses.error.
Attempting to write to the lower right corner of a window, subwindow,
or pad will cause an exception to be raised after the character is printed."
"window.addnstr(str, n[, attr])","Paint at most n characters of the character string str at
(y, x) with attributes
attr, overwriting anything previously on the display."
"window.addstr(str[, attr])","Paint the character string str at (y, x) with attributes
attr, overwriting anything previously on the display.

Note

Writing outside the window, subwindow, or pad raises curses.error.
Attempting to write to the lower right corner of a window, subwindow,
or pad will cause an exception to be raised after the string is printed.
A bug in ncurses, the backend
for this Python module, can cause SegFaults when resizing windows. This
is fixed in ncurses-6.1-20190511.  If you are stuck with an earlier
ncurses, you can avoid triggering this if you do not call addstr()
with a str that has embedded newlines.  Instead, call addstr()
separately for each line."
window.attroff(attr),"Remove attribute attr from the “background” set applied to all writes to the
current window."
window.attron(attr),"Add attribute attr from the “background” set applied to all writes to the
current window."
window.attrset(attr),"Set the “background” set of attributes to attr.  This set is initially
0 (no attributes)."
"window.bkgd(ch[, attr])","Set the background property of the window to the character ch, with
attributes attr.  The change is then applied to every character position in
that window:

The attribute of every character in the window  is changed to the new
background attribute.
Wherever  the  former background character appears, it is changed to the new
background character."
"window.bkgdset(ch[, attr])","Set the window’s background.  A window’s background consists of a character and
any combination of attributes.  The attribute part of the background is combined
(OR’ed) with all non-blank characters that are written into the window.  Both
the character and attribute parts of the background are combined with the blank
characters.  The background becomes a property of the character and moves with
the character through any scrolling and insert/delete line/character operations."
"window.border([ls[, rs[, ts[, bs[, tl[, tr[, bl[, br]]]]]]]])","Draw a border around the edges of the window. Each parameter specifies  the
character to use for a specific part of the border; see the table below for more
details.

Note
A 0 value for any parameter will cause the default character to be used for
that parameter.  Keyword parameters can not be used.  The defaults are listed
in this table:








Parameter
Description
Default value



ls
Left side
ACS_VLINE

rs
Right side
ACS_VLINE

ts
Top
ACS_HLINE

bs
Bottom
ACS_HLINE

tl
Upper-left corner
ACS_ULCORNER

tr
Upper-right corner
ACS_URCORNER

bl
Bottom-left corner
ACS_LLCORNER

br
Bottom-right corner
ACS_LRCORNER"
"window.box([vertch, horch])","Similar to border(), but both ls and rs are vertch and both ts and
bs are horch.  The default corner characters are always used by this function."
window.chgat(attr),"Set the attributes of num characters at the current cursor position, or at
position (y, x) if supplied. If num is not given or is -1,
the attribute will be set on all the characters to the end of the line.  This
function moves cursor to position (y, x) if supplied. The changed line
will be touched using the touchline() method so that the contents will
be redisplayed by the next window refresh."
window.clear(),"Like erase(), but also cause the whole window to be repainted upon next
call to refresh()."
window.clearok(flag),"If flag is True, the next call to refresh() will clear the window
completely."
window.clrtobot(),"Erase from cursor to the end of the window: all lines below the cursor are
deleted, and then the equivalent of clrtoeol() is performed."
window.clrtoeol(),Erase from cursor to the end of the line.
window.cursyncup(),"Update the current cursor position of all the ancestors of the window to
reflect the current cursor position of the window."
"window.delch([y, x])","Delete any character at (y, x)."
window.deleteln(),Delete the line under the cursor. All following lines are moved up by one line.
"window.derwin(begin_y, begin_x)","An abbreviation for “derive window”, derwin() is the same as calling
subwin(), except that begin_y and begin_x are relative to the origin
of the window, rather than relative to the entire screen.  Return a window
object for the derived window."
"window.echochar(ch[, attr])","Add character ch with attribute attr, and immediately  call refresh()
on the window."
"window.enclose(y, x)","Test whether the given pair of screen-relative character-cell coordinates are
enclosed by the given window, returning True or False.  It is useful for
determining what subset of the screen windows enclose the location of a mouse
event."
window.erase(),Clear the window.
window.getbegyx(),"Return a tuple (y, x) of co-ordinates of upper-left corner."
window.getbkgd(),Return the given window’s current background character/attribute pair.
"window.getch([y, x])","Get a character. Note that the integer returned does not have to be in ASCII
range: function keys, keypad keys and so on are represented by numbers higher
than 255.  In no-delay mode, return -1 if there is no input, otherwise
wait until a key is pressed."
"window.get_wch([y, x])","Get a wide character. Return a character for most keys, or an integer for
function keys, keypad keys, and other special keys.
In no-delay mode, raise an exception if there is no input.

New in version 3.3."
"window.getkey([y, x])","Get a character, returning a string instead of an integer, as getch()
does. Function keys, keypad keys and other special keys return a multibyte
string containing the key name.  In no-delay mode, raise an exception if
there is no input."
window.getmaxyx(),"Return a tuple (y, x) of the height and width of the window."
window.getparyx(),"Return the beginning coordinates of this window relative to its parent window
as a tuple (y, x).  Return (-1, -1) if this window has no
parent."
window.getstr(),"Read a bytes object from the user, with primitive line editing capacity."
window.getyx(),"Return a tuple (y, x) of current cursor position  relative to the window’s
upper-left corner."
"window.hline(ch, n)","Display a horizontal line starting at (y, x) with length n consisting of
the character ch."
window.idcok(flag),"If flag is False, curses no longer considers using the hardware insert/delete
character feature of the terminal; if flag is True, use of character insertion
and deletion is enabled.  When curses is first initialized, use of character
insert/delete is enabled by default."
window.idlok(flag),"If flag is True, curses will try and use hardware line
editing facilities. Otherwise, line insertion/deletion are disabled."
window.immedok(flag),"If flag is True, any change in the window image automatically causes the
window to be refreshed; you no longer have to call refresh() yourself.
However, it may degrade performance considerably, due to repeated calls to
wrefresh.  This option is disabled by default."
"window.inch([y, x])","Return the character at the given position in the window. The bottom 8 bits are
the character proper, and upper bits are the attributes."
"window.insch(ch[, attr])","Paint character ch at (y, x) with attributes attr, moving the line from
position x right by one character."
window.insdelln(nlines),"Insert nlines lines into the specified window above the current line.  The
nlines bottom lines are lost.  For negative nlines, delete nlines lines
starting with the one under the cursor, and move the remaining lines up.  The
bottom nlines lines are cleared.  The current cursor position remains the
same."
window.insertln(),"Insert a blank line under the cursor. All following lines are moved down by one
line."
"window.insnstr(str, n[, attr])","Insert a character string (as many characters as will fit on the line) before
the character under the cursor, up to n characters.   If n is zero or
negative, the entire string is inserted. All characters to the right of the
cursor are shifted right, with the rightmost characters on the line being lost.
The cursor position does not change (after moving to y, x, if specified)."
"window.insstr(str[, attr])","Insert a character string (as many characters as will fit on the line) before
the character under the cursor.  All characters to the right of the cursor are
shifted right, with the rightmost characters on the line being lost.  The cursor
position does not change (after moving to y, x, if specified)."
window.instr([n]),"Return a bytes object of characters, extracted from the window starting at the
current cursor position, or at y, x if specified. Attributes are stripped
from the characters.  If n is specified, instr() returns a string
at most n characters long (exclusive of the trailing NUL)."
window.is_linetouched(line),"Return True if the specified line was modified since the last call to
refresh(); otherwise return False.  Raise a curses.error
exception if line is not valid for the given window."
window.is_wintouched(),"Return True if the specified window was modified since the last call to
refresh(); otherwise return False."
window.keypad(flag),"If flag is True, escape sequences generated by some keys (keypad,  function keys)
will be interpreted by curses. If flag is False, escape sequences will be
left as is in the input stream."
window.leaveok(flag),"If flag is True, cursor is left where it is on update, instead of being at “cursor
position.”  This reduces cursor movement where possible. If possible the cursor
will be made invisible.
If flag is False, cursor will always be at “cursor position” after an update."
"window.move(new_y, new_x)","Move cursor to (new_y, new_x)."
"window.mvderwin(y, x)","Move the window inside its parent window.  The screen-relative parameters of
the window are not changed.  This routine is used to display different parts of
the parent window at the same physical position on the screen."
"window.mvwin(new_y, new_x)","Move the window so its upper-left corner is at (new_y, new_x)."
window.nodelay(flag),"If flag is True, getch() will be non-blocking."
window.notimeout(flag),"If flag is True, escape sequences will not be timed out.
If flag is False, after a few milliseconds, an escape sequence will not be
interpreted, and will be left in the input stream as is."
window.noutrefresh(),"Mark for refresh but wait.  This function updates the data structure
representing the desired state of the window, but does not force an update of
the physical screen.  To accomplish that, call  doupdate()."
"window.overlay(destwin[, sminrow, smincol, dminrow, dmincol, dmaxrow, dmaxcol])","Overlay the window on top of destwin. The windows need not be the same size,
only the overlapping region is copied. This copy is non-destructive, which means
that the current background character does not overwrite the old contents of
destwin.
To get fine-grained control over the copied region, the second form of
overlay() can be used. sminrow and smincol are the upper-left
coordinates of the source window, and the other variables mark a rectangle in
the destination window."
"window.overwrite(destwin[, sminrow, smincol, dminrow, dmincol, dmaxrow, dmaxcol])","Overwrite the window on top of destwin. The windows need not be the same size,
in which case only the overlapping region is copied. This copy is destructive,
which means that the current background character overwrites the old contents of
destwin.
To get fine-grained control over the copied region, the second form of
overwrite() can be used. sminrow and smincol are the upper-left
coordinates of the source window, the other variables mark a rectangle in the
destination window."
window.putwin(file),"Write all data associated with the window into the provided file object.  This
information can be later retrieved using the getwin() function."
"window.redrawln(beg, num)","Indicate that the num screen lines, starting at line beg, are corrupted and
should be completely redrawn on the next refresh() call."
window.redrawwin(),"Touch the entire window, causing it to be completely redrawn on the next
refresh() call."
"window.refresh([pminrow, pmincol, sminrow, smincol, smaxrow, smaxcol])","Update the display immediately (sync actual screen with previous
drawing/deleting methods).
The 6 optional arguments can only be specified when the window is a pad created
with newpad().  The additional parameters are needed to indicate what part
of the pad and screen are involved. pminrow and pmincol specify the upper
left-hand corner of the rectangle to be displayed in the pad.  sminrow,
smincol, smaxrow, and smaxcol specify the edges of the rectangle to be
displayed on the screen.  The lower right-hand corner of the rectangle to be
displayed in the pad is calculated from the screen coordinates, since the
rectangles must be the same size.  Both rectangles must be entirely contained
within their respective structures.  Negative values of pminrow, pmincol,
sminrow, or smincol are treated as if they were zero."
"window.resize(nlines, ncols)","Reallocate storage for a curses window to adjust its dimensions to the
specified values.  If either dimension is larger than the current values, the
window’s data is filled with blanks that have the current background
rendition (as set by bkgdset()) merged into them."
window.scroll([lines=1]),Scroll the screen or scrolling region upward by lines lines.
window.scrollok(flag),"Control what happens when the cursor of a window is moved off the edge of the
window or scrolling region, either as a result of a newline action on the bottom
line, or typing the last character of the last line.  If flag is False, the
cursor is left on the bottom line.  If flag is True, the window is scrolled up
one line.  Note that in order to get the physical scrolling effect on the
terminal, it is also necessary to call idlok()."
"window.setscrreg(top, bottom)","Set the scrolling region from line top to line bottom. All scrolling actions
will take place in this region."
window.standend(),"Turn off the standout attribute.  On some terminals this has the side effect of
turning off all attributes."
window.standout(),Turn on attribute A_STANDOUT.
"window.subpad(begin_y, begin_x)","Return a sub-window, whose upper-left corner is at (begin_y, begin_x), and
whose width/height is ncols/nlines."
"window.subwin(begin_y, begin_x)","Return a sub-window, whose upper-left corner is at (begin_y, begin_x), and
whose width/height is ncols/nlines.
By default, the sub-window will extend from the specified position to the lower
right corner of the window."
window.syncdown(),"Touch each location in the window that has been touched in any of its ancestor
windows.  This routine is called by refresh(), so it should almost never
be necessary to call it manually."
window.syncok(flag),"If flag is True, then syncup() is called automatically
whenever there is a change in the window."
window.syncup(),"Touch all locations in ancestors of the window that have been changed in  the
window."
window.timeout(delay),"Set blocking or non-blocking read behavior for the window.  If delay is
negative, blocking read is used (which will wait indefinitely for input).  If
delay is zero, then non-blocking read is used, and getch() will
return -1 if no input is waiting.  If delay is positive, then
getch() will block for delay milliseconds, and return -1 if there is
still no input at the end of that time."
"window.touchline(start, count[, changed])","Pretend count lines have been changed, starting with line start.  If
changed is supplied, it specifies whether the affected lines are marked as
having been changed (changed=True) or unchanged (changed=False)."
window.touchwin(),"Pretend the whole window has been changed, for purposes of drawing
optimizations."
window.untouchwin(),"Mark all lines in  the  window  as unchanged since the last call to
refresh()."
"window.vline(ch, n)","Display a vertical line starting at (y, x) with length n consisting of the
character ch."
edit([validator]),"This is the entry point you will normally use.  It accepts editing
keystrokes until one of the termination keystrokes is entered.  If
validator is supplied, it must be a function.  It will be called for
each keystroke entered with the keystroke as a parameter; command dispatch
is done on the result. This method returns the window contents as a
string; whether blanks in the window are included is affected by the
stripspaces attribute."
do_command(ch),"Process a single command keystroke.  Here are the supported special
keystrokes:






Keystroke
Action



Control-A
Go to left edge of window.

Control-B
Cursor left, wrapping to previous line if
appropriate.

Control-D
Delete character under cursor.

Control-E
Go to right edge (stripspaces off) or end
of line (stripspaces on).

Control-F
Cursor right, wrapping to next line when
appropriate.

Control-G
Terminate, returning the window contents.

Control-H
Delete character backward.

Control-J
Terminate if the window is 1 line,
otherwise insert newline.

Control-K
If line is blank, delete it, otherwise
clear to end of line.

Control-L
Refresh screen.

Control-N
Cursor down; move down one line.

Control-O
Insert a blank line at cursor location.

Control-P
Cursor up; move up one line.



Move operations do nothing if the cursor is at an edge where the movement
is not possible.  The following synonyms are supported where possible:






Constant
Keystroke



KEY_LEFT
Control-B

KEY_RIGHT
Control-F

KEY_UP
Control-P

KEY_DOWN
Control-N

KEY_BACKSPACE
Control-h



All other keystrokes are treated as a command to insert the given
character and move right (with line wrapping)."
gather(),"Return the window contents as a string; whether blanks in the
window are included is affected by the stripspaces member."
curses.baudrate(),"Return the output speed of the terminal in bits per second.  On software
terminal emulators it will have a fixed high value. Included for historical
reasons; in former times, it was used to  write output loops for time delays and
occasionally to change interfaces depending on the line speed."
curses.beep(),Emit a short attention sound.
curses.can_change_color(),"Return True or False, depending on whether the programmer can change the colors
displayed by the terminal."
curses.cbreak(),"Enter cbreak mode.  In cbreak mode (sometimes called “rare” mode) normal tty
line buffering is turned off and characters are available to be read one by one.
However, unlike raw mode, special characters (interrupt, quit, suspend, and flow
control) retain their effects on the tty driver and calling program.  Calling
first raw() then cbreak() leaves the terminal in cbreak mode."
curses.color_content(color_number),"Return the intensity of the red, green, and blue (RGB) components in the color
color_number, which must be between 0 and COLORS.  Return a 3-tuple,
containing the R,G,B values for the given color, which will be between
0 (no component) and 1000 (maximum amount of component)."
curses.color_pair(color_number),"Return the attribute value for displaying text in the specified color.  This
attribute value can be combined with A_STANDOUT, A_REVERSE,
and the other A_* attributes.  pair_number() is the counterpart
to this function."
curses.curs_set(visibility),"Set the cursor state.  visibility can be set to 0, 1, or 2, for invisible,
normal, or very visible.  If the terminal supports the visibility requested, return the
previous cursor state; otherwise raise an exception.  On many
terminals, the “visible” mode is an underline cursor and the “very visible” mode
is a block cursor."
curses.def_prog_mode(),"Save the current terminal mode as the “program” mode, the mode when the running
program is using curses.  (Its counterpart is the “shell” mode, for when the
program is not in curses.)  Subsequent calls to reset_prog_mode() will
restore this mode."
curses.def_shell_mode(),"Save the current terminal mode as the “shell” mode, the mode when the running
program is not using curses.  (Its counterpart is the “program” mode, when the
program is using curses capabilities.) Subsequent calls to
reset_shell_mode() will restore this mode."
curses.delay_output(ms),Insert an ms millisecond pause in output.
curses.doupdate(),"Update the physical screen.  The curses library keeps two data structures, one
representing the current physical screen contents and a virtual screen
representing the desired next state.  The doupdate() ground updates the
physical screen to match the virtual screen.
The virtual screen may be updated by a noutrefresh() call after write
operations such as addstr() have been performed on a window.  The normal
refresh() call is simply noutrefresh() followed by doupdate();
if you have to update multiple windows, you can speed performance and perhaps
reduce screen flicker by issuing noutrefresh() calls on all windows,
followed by a single doupdate()."
curses.echo(),"Enter echo mode.  In echo mode, each character input is echoed to the screen as
it is entered."
curses.endwin(),"De-initialize the library, and return terminal to normal status."
curses.erasechar(),"Return the user’s current erase character as a one-byte bytes object.  Under Unix operating systems this
is a property of the controlling tty of the curses program, and is not set by
the curses library itself."
curses.filter(),"The filter() routine, if used, must be called before initscr() is
called.  The effect is that, during those calls, LINES is set to 1; the
capabilities clear, cup, cud, cud1, cuu1, cuu, vpa are disabled; and the home
string is set to the value of cr. The effect is that the cursor is confined to
the current line, and so are screen updates.  This may be used for enabling
character-at-a-time  line editing without touching the rest of the screen."
curses.flash(),"Flash the screen.  That is, change it to reverse-video and then change it back
in a short interval.  Some people prefer such as ‘visible bell’ to the audible
attention signal produced by beep()."
curses.flushinp(),"Flush all input buffers.  This throws away any  typeahead  that  has been typed
by the user and has not yet been processed by the program."
curses.getmouse(),"After getch() returns KEY_MOUSE to signal a mouse event, this
method should be call to retrieve the queued mouse event, represented as a
5-tuple (id, x, y, z, bstate). id is an ID value used to distinguish
multiple devices, and x, y, z are the event’s coordinates.  (z is
currently unused.)  bstate is an integer value whose bits will be set to
indicate the type of event, and will be the bitwise OR of one or more of the
following constants, where n is the button number from 1 to 4:
BUTTONn_PRESSED, BUTTONn_RELEASED, BUTTONn_CLICKED,
BUTTONn_DOUBLE_CLICKED, BUTTONn_TRIPLE_CLICKED,
BUTTON_SHIFT, BUTTON_CTRL, BUTTON_ALT."
curses.getsyx(),"Return the current coordinates of the virtual screen cursor as a tuple
(y, x).  If leaveok is currently True, then return (-1, -1)."
curses.getwin(file),"Read window related data stored in the file by an earlier putwin() call.
The routine then creates and initializes a new window using that data, returning
the new window object."
curses.has_colors(),"Return True if the terminal can display colors; otherwise, return False."
curses.has_ic(),"Return True if the terminal has insert- and delete-character capabilities.
This function is included for historical reasons only, as all modern software
terminal emulators have such capabilities."
curses.has_il(),"Return True if the terminal has insert- and delete-line capabilities, or can
simulate  them  using scrolling regions. This function is included for
historical reasons only, as all modern software terminal emulators have such
capabilities."
curses.has_key(ch),"Take a key value ch, and return True if the current terminal type recognizes
a key with that value."
curses.halfdelay(tenths),"Used for half-delay mode, which is similar to cbreak mode in that characters
typed by the user are immediately available to the program. However, after
blocking for tenths tenths of seconds, raise an exception if nothing has
been typed.  The value of tenths must be a number between 1 and 255.  Use
nocbreak() to leave half-delay mode."
"curses.init_color(color_number, r, g, b)","Change the definition of a color, taking the number of the color to be changed
followed by three RGB values (for the amounts of red, green, and blue
components).  The value of color_number must be between 0 and
COLORS.  Each of r, g, b, must be a value between 0 and
1000.  When init_color() is used, all occurrences of that color on the
screen immediately change to the new definition.  This function is a no-op on
most terminals; it is active only if can_change_color() returns True."
"curses.init_pair(pair_number, fg, bg)","Change the definition of a color-pair.  It takes three arguments: the number of
the color-pair to be changed, the foreground color number, and the background
color number.  The value of pair_number must be between 1 and
COLOR_PAIRS - 1 (the 0 color pair is wired to white on black and cannot
be changed).  The value of fg and bg arguments must be between 0 and
COLORS.  If the color-pair was previously initialized, the screen is
refreshed and all occurrences of that color-pair are changed to the new
definition."
curses.initscr(),"Initialize the library. Return a window object
which represents the whole screen.

Note
If there is an error opening the terminal, the underlying curses library may
cause the interpreter to exit."
"curses.is_term_resized(nlines, ncols)","Return True if resize_term() would modify the window structure,
False otherwise."
curses.isendwin(),"Return True if endwin() has been called (that is, the  curses library has
been deinitialized)."
curses.keyname(k),"Return the name of the key numbered k as a bytes object.  The name of a key generating printable
ASCII character is the key’s character.  The name of a control-key combination
is a two-byte bytes object consisting of a caret (b'^') followed by the corresponding
printable ASCII character.  The name of an alt-key combination (128–255) is a
bytes object consisting of the prefix b'M-' followed by the name of the corresponding
ASCII character."
curses.killchar(),"Return the user’s current line kill character as a one-byte bytes object. Under Unix operating systems
this is a property of the controlling tty of the curses program, and is not set
by the curses library itself."
curses.longname(),"Return a bytes object containing the terminfo long name field describing the current
terminal.  The maximum length of a verbose description is 128 characters.  It is
defined only after the call to initscr()."
curses.meta(flag),"If flag is True, allow 8-bit characters to be input.  If
flag is False,  allow only 7-bit chars."
curses.mouseinterval(interval),"Set the maximum time in milliseconds that can elapse between press and release
events in order for them to be recognized as a click, and return the previous
interval value.  The default value is 200 msec, or one fifth of a second."
curses.mousemask(mousemask),"Set the mouse events to be reported, and return a tuple (availmask,
oldmask).   availmask indicates which of the specified mouse events can be
reported; on complete failure it returns 0.  oldmask is the previous value of
the given window’s mouse event mask.  If this function is never called, no mouse
events are ever reported."
curses.napms(ms),Sleep for ms milliseconds.
"curses.newpad(nlines, ncols)","Create and return a pointer to a new pad data structure with the given number
of lines and columns.  Return a pad as a window object.
A pad is like a window, except that it is not restricted by the screen size, and
is not necessarily associated with a particular part of the screen.  Pads can be
used when a large window is needed, and only a part of the window will be on the
screen at one time.  Automatic refreshes of pads (such as from scrolling or
echoing of input) do not occur.  The refresh() and noutrefresh()
methods of a pad require 6 arguments to specify the part of the pad to be
displayed and the location on the screen to be used for the display. The
arguments are pminrow, pmincol, sminrow, smincol, smaxrow, smaxcol; the p
arguments refer to the upper left corner of the pad region to be displayed and
the s arguments define a clipping box on the screen within which the pad region
is to be displayed."
"curses.newwin(nlines, ncols)","Return a new window, whose left-upper corner
is at  (begin_y, begin_x), and whose height/width is  nlines/ncols.
By default, the window will extend from the  specified position to the lower
right corner of the screen."
curses.nl(),"Enter newline mode.  This mode translates the return key into newline on input,
and translates newline into return and line-feed on output. Newline mode is
initially on."
curses.nocbreak(),Leave cbreak mode.  Return to normal “cooked” mode with line buffering.
curses.noecho(),Leave echo mode.  Echoing of input characters is turned off.
curses.nonl(),"Leave newline mode.  Disable translation of return into newline on input, and
disable low-level translation of newline into newline/return on output (but this
does not change the behavior of addch('\n'), which always does the
equivalent of return and line feed on the virtual screen).  With translation
off, curses can sometimes speed up vertical motion a little; also, it will be
able to detect the return key on input."
curses.noqiflush(),"When the noqiflush() routine is used, normal flush of input and output queues
associated with the INTR, QUIT and SUSP characters will not be done.  You may
want to call noqiflush() in a signal handler if you want output to
continue as though the interrupt had not occurred, after the handler exits."
curses.noraw(),Leave raw mode. Return to normal “cooked” mode with line buffering.
curses.pair_content(pair_number),"Return a tuple (fg, bg) containing the colors for the requested color pair.
The value of pair_number must be between 1 and COLOR_PAIRS - 1."
curses.pair_number(attr),"Return the number of the color-pair set by the attribute value attr.
color_pair() is the counterpart to this function."
curses.putp(str),"Equivalent to tputs(str, 1, putchar); emit the value of a specified
terminfo capability for the current terminal.  Note that the output of putp()
always goes to standard output."
curses.qiflush([flag]),"If flag is False, the effect is the same as calling noqiflush(). If
flag is True, or no argument is provided, the queues will be flushed when
these control characters are read."
curses.raw(),"Enter raw mode.  In raw mode, normal line buffering and  processing of
interrupt, quit, suspend, and flow control keys are turned off; characters are
presented to curses input functions one by one."
curses.reset_prog_mode(),"Restore the  terminal  to “program” mode, as previously saved  by
def_prog_mode()."
curses.reset_shell_mode(),"Restore the  terminal  to “shell” mode, as previously saved  by
def_shell_mode()."
curses.resetty(),"Restore the state of the terminal modes to what it was at the last call to
savetty()."
"curses.resize_term(nlines, ncols)","Backend function used by resizeterm(), performing most of the work;
when resizing the windows, resize_term() blank-fills the areas that are
extended.  The calling application should fill in these areas with
appropriate data.  The resize_term() function attempts to resize all
windows.  However, due to the calling convention of pads, it is not possible
to resize these without additional interaction with the application."
"curses.resizeterm(nlines, ncols)","Resize the standard and current windows to the specified dimensions, and
adjusts other bookkeeping data used by the curses library that record the
window dimensions (in particular the SIGWINCH handler)."
curses.savetty(),"Save the current state of the terminal modes in a buffer, usable by
resetty()."
"curses.setsyx(y, x)","Set the virtual screen cursor to y, x. If y and x are both -1, then
leaveok is set True."
"curses.setupterm(term=None, fd=-1)","Initialize the terminal.  term is a string giving
the terminal name, or None; if omitted or None, the value of the
TERM environment variable will be used.  fd is the
file descriptor to which any initialization sequences will be sent; if not
supplied or -1, the file descriptor for sys.stdout will be used."
curses.start_color(),"Must be called if the programmer wants to use colors, and before any other color
manipulation routine is called.  It is good practice to call this routine right
after initscr().
start_color() initializes eight basic colors (black, red,  green, yellow,
blue, magenta, cyan, and white), and two global variables in the curses
module, COLORS and COLOR_PAIRS, containing the maximum number
of colors and color-pairs the terminal can support.  It also restores the colors
on the terminal to the values they had when the terminal was just turned on."
curses.termattrs(),"Return a logical OR of all video attributes supported by the terminal.  This
information is useful when a curses program needs complete control over the
appearance of the screen."
curses.termname(),"Return the value of the environment variable TERM, as a bytes object,
truncated to 14 characters."
curses.tigetflag(capname),"Return the value of the Boolean capability corresponding to the terminfo
capability name capname as an integer.  Return the value -1 if capname is not a
Boolean capability, or 0 if it is canceled or absent from the terminal
description."
curses.tigetnum(capname),"Return the value of the numeric capability corresponding to the terminfo
capability name capname as an integer.  Return the value -2 if capname is not a
numeric capability, or -1 if it is canceled or absent from the terminal
description."
curses.tigetstr(capname),"Return the value of the string capability corresponding to the terminfo
capability name capname as a bytes object.  Return None if capname
is not a terminfo “string capability”, or is canceled or absent from the
terminal description."
"curses.tparm(str[, ...])","Instantiate the bytes object str with the supplied parameters, where str should
be a parameterized string obtained from the terminfo database.  E.g.
tparm(tigetstr(""cup""), 5, 3) could result in b'\033[6;4H', the exact
result depending on terminal type."
curses.typeahead(fd),"Specify that the file descriptor fd be used for typeahead checking.  If fd
is -1, then no typeahead checking is done.
The curses library does “line-breakout optimization” by looking for typeahead
periodically while updating the screen.  If input is found, and it is coming
from a tty, the current update is postponed until refresh or doupdate is called
again, allowing faster response to commands typed in advance. This function
allows specifying a different file descriptor for typeahead checking."
curses.unctrl(ch),"Return a bytes object which is a printable representation of the character ch.
Control characters are represented as a caret followed by the character, for
example as b'^C'. Printing characters are left as they are."
curses.ungetch(ch),"Push ch so the next getch() will return it.

Note
Only one ch can be pushed before getch() is called."
curses.update_lines_cols(),"Update LINES and COLS. Useful for detecting manual screen resize.

New in version 3.5."
curses.unget_wch(ch),"Push ch so the next get_wch() will return it.

Note
Only one ch can be pushed before get_wch() is called.


New in version 3.3."
"curses.ungetmouse(id, x, y, z, bstate)","Push a KEY_MOUSE event onto the input queue, associating the given
state data with it."
curses.use_env(flag),"If used, this function should be called before initscr() or newterm are
called.  When flag is False, the values of lines and columns specified in the
terminfo database will be used, even if environment variables LINES
and COLUMNS (used by default) are set, or if curses is running in a
window (in which case default behavior would be to use the window size if
LINES and COLUMNS are not set)."
curses.use_default_colors(),"Allow use of default values for colors on terminals supporting this feature. Use
this to support transparency in your application.  The default color is assigned
to the color number -1. After calling this function,  init_pair(x,
curses.COLOR_RED, -1) initializes, for instance, color pair x to a red
foreground color on the default background."
"curses.wrapper(func, ...)","Initialize curses and call another callable object, func, which should be the
rest of your curses-using application.  If the application raises an exception,
this function will restore the terminal to a sane state before re-raising the
exception and generating a traceback.  The callable object func is then passed
the main window ‘stdscr’ as its first argument, followed by any other arguments
passed to wrapper().  Before calling func, wrapper() turns on
cbreak mode, turns off echo, enables the terminal keypad, and initializes colors
if the terminal has color support.  On exit (whether normally or by exception)
it restores cooked mode, turns on echo, and disables the terminal keypad."
"curses.textpad.rectangle(win, uly, ulx, lry, lrx)","Draw a rectangle.  The first argument must be a window object; the remaining
arguments are coordinates relative to that window.  The second and third
arguments are the y and x coordinates of the upper left hand corner of the
rectangle to be drawn; the fourth and fifth arguments are the y and x
coordinates of the lower right hand corner. The rectangle will be drawn using
VT100/IBM PC forms characters on terminals that make this possible (including
xterm and most other software terminal emulators).  Otherwise it will be drawn
with ASCII  dashes, vertical bars, and plus signs."
"window.addch(ch[, attr])","Paint character ch at (y, x) with attributes attr, overwriting any
character previously painter at that location.  By default, the character
position and attributes are the current settings for the window object.

Note
Writing outside the window, subwindow, or pad raises a curses.error.
Attempting to write to the lower right corner of a window, subwindow,
or pad will cause an exception to be raised after the character is printed."
"window.addnstr(str, n[, attr])","Paint at most n characters of the character string str at
(y, x) with attributes
attr, overwriting anything previously on the display."
"window.addstr(str[, attr])","Paint the character string str at (y, x) with attributes
attr, overwriting anything previously on the display.

Note

Writing outside the window, subwindow, or pad raises curses.error.
Attempting to write to the lower right corner of a window, subwindow,
or pad will cause an exception to be raised after the string is printed.
A bug in ncurses, the backend
for this Python module, can cause SegFaults when resizing windows. This
is fixed in ncurses-6.1-20190511.  If you are stuck with an earlier
ncurses, you can avoid triggering this if you do not call addstr()
with a str that has embedded newlines.  Instead, call addstr()
separately for each line."
window.attroff(attr),"Remove attribute attr from the “background” set applied to all writes to the
current window."
window.attron(attr),"Add attribute attr from the “background” set applied to all writes to the
current window."
window.attrset(attr),"Set the “background” set of attributes to attr.  This set is initially
0 (no attributes)."
"window.bkgd(ch[, attr])","Set the background property of the window to the character ch, with
attributes attr.  The change is then applied to every character position in
that window:

The attribute of every character in the window  is changed to the new
background attribute.
Wherever  the  former background character appears, it is changed to the new
background character."
"window.bkgdset(ch[, attr])","Set the window’s background.  A window’s background consists of a character and
any combination of attributes.  The attribute part of the background is combined
(OR’ed) with all non-blank characters that are written into the window.  Both
the character and attribute parts of the background are combined with the blank
characters.  The background becomes a property of the character and moves with
the character through any scrolling and insert/delete line/character operations."
"window.border([ls[, rs[, ts[, bs[, tl[, tr[, bl[, br]]]]]]]])","Draw a border around the edges of the window. Each parameter specifies  the
character to use for a specific part of the border; see the table below for more
details.

Note
A 0 value for any parameter will cause the default character to be used for
that parameter.  Keyword parameters can not be used.  The defaults are listed
in this table:








Parameter
Description
Default value



ls
Left side
ACS_VLINE

rs
Right side
ACS_VLINE

ts
Top
ACS_HLINE

bs
Bottom
ACS_HLINE

tl
Upper-left corner
ACS_ULCORNER

tr
Upper-right corner
ACS_URCORNER

bl
Bottom-left corner
ACS_LLCORNER

br
Bottom-right corner
ACS_LRCORNER"
"window.box([vertch, horch])","Similar to border(), but both ls and rs are vertch and both ts and
bs are horch.  The default corner characters are always used by this function."
window.chgat(attr),"Set the attributes of num characters at the current cursor position, or at
position (y, x) if supplied. If num is not given or is -1,
the attribute will be set on all the characters to the end of the line.  This
function moves cursor to position (y, x) if supplied. The changed line
will be touched using the touchline() method so that the contents will
be redisplayed by the next window refresh."
window.clear(),"Like erase(), but also cause the whole window to be repainted upon next
call to refresh()."
window.clearok(flag),"If flag is True, the next call to refresh() will clear the window
completely."
window.clrtobot(),"Erase from cursor to the end of the window: all lines below the cursor are
deleted, and then the equivalent of clrtoeol() is performed."
window.clrtoeol(),Erase from cursor to the end of the line.
window.cursyncup(),"Update the current cursor position of all the ancestors of the window to
reflect the current cursor position of the window."
"window.delch([y, x])","Delete any character at (y, x)."
window.deleteln(),Delete the line under the cursor. All following lines are moved up by one line.
"window.derwin(begin_y, begin_x)","An abbreviation for “derive window”, derwin() is the same as calling
subwin(), except that begin_y and begin_x are relative to the origin
of the window, rather than relative to the entire screen.  Return a window
object for the derived window."
"window.echochar(ch[, attr])","Add character ch with attribute attr, and immediately  call refresh()
on the window."
"window.enclose(y, x)","Test whether the given pair of screen-relative character-cell coordinates are
enclosed by the given window, returning True or False.  It is useful for
determining what subset of the screen windows enclose the location of a mouse
event."
window.erase(),Clear the window.
window.getbegyx(),"Return a tuple (y, x) of co-ordinates of upper-left corner."
window.getbkgd(),Return the given window’s current background character/attribute pair.
"window.getch([y, x])","Get a character. Note that the integer returned does not have to be in ASCII
range: function keys, keypad keys and so on are represented by numbers higher
than 255.  In no-delay mode, return -1 if there is no input, otherwise
wait until a key is pressed."
"window.get_wch([y, x])","Get a wide character. Return a character for most keys, or an integer for
function keys, keypad keys, and other special keys.
In no-delay mode, raise an exception if there is no input.

New in version 3.3."
"window.getkey([y, x])","Get a character, returning a string instead of an integer, as getch()
does. Function keys, keypad keys and other special keys return a multibyte
string containing the key name.  In no-delay mode, raise an exception if
there is no input."
window.getmaxyx(),"Return a tuple (y, x) of the height and width of the window."
window.getparyx(),"Return the beginning coordinates of this window relative to its parent window
as a tuple (y, x).  Return (-1, -1) if this window has no
parent."
window.getstr(),"Read a bytes object from the user, with primitive line editing capacity."
window.getyx(),"Return a tuple (y, x) of current cursor position  relative to the window’s
upper-left corner."
"window.hline(ch, n)","Display a horizontal line starting at (y, x) with length n consisting of
the character ch."
window.idcok(flag),"If flag is False, curses no longer considers using the hardware insert/delete
character feature of the terminal; if flag is True, use of character insertion
and deletion is enabled.  When curses is first initialized, use of character
insert/delete is enabled by default."
window.idlok(flag),"If flag is True, curses will try and use hardware line
editing facilities. Otherwise, line insertion/deletion are disabled."
window.immedok(flag),"If flag is True, any change in the window image automatically causes the
window to be refreshed; you no longer have to call refresh() yourself.
However, it may degrade performance considerably, due to repeated calls to
wrefresh.  This option is disabled by default."
"window.inch([y, x])","Return the character at the given position in the window. The bottom 8 bits are
the character proper, and upper bits are the attributes."
"window.insch(ch[, attr])","Paint character ch at (y, x) with attributes attr, moving the line from
position x right by one character."
window.insdelln(nlines),"Insert nlines lines into the specified window above the current line.  The
nlines bottom lines are lost.  For negative nlines, delete nlines lines
starting with the one under the cursor, and move the remaining lines up.  The
bottom nlines lines are cleared.  The current cursor position remains the
same."
window.insertln(),"Insert a blank line under the cursor. All following lines are moved down by one
line."
"window.insnstr(str, n[, attr])","Insert a character string (as many characters as will fit on the line) before
the character under the cursor, up to n characters.   If n is zero or
negative, the entire string is inserted. All characters to the right of the
cursor are shifted right, with the rightmost characters on the line being lost.
The cursor position does not change (after moving to y, x, if specified)."
"window.insstr(str[, attr])","Insert a character string (as many characters as will fit on the line) before
the character under the cursor.  All characters to the right of the cursor are
shifted right, with the rightmost characters on the line being lost.  The cursor
position does not change (after moving to y, x, if specified)."
window.instr([n]),"Return a bytes object of characters, extracted from the window starting at the
current cursor position, or at y, x if specified. Attributes are stripped
from the characters.  If n is specified, instr() returns a string
at most n characters long (exclusive of the trailing NUL)."
window.is_linetouched(line),"Return True if the specified line was modified since the last call to
refresh(); otherwise return False.  Raise a curses.error
exception if line is not valid for the given window."
window.is_wintouched(),"Return True if the specified window was modified since the last call to
refresh(); otherwise return False."
window.keypad(flag),"If flag is True, escape sequences generated by some keys (keypad,  function keys)
will be interpreted by curses. If flag is False, escape sequences will be
left as is in the input stream."
window.leaveok(flag),"If flag is True, cursor is left where it is on update, instead of being at “cursor
position.”  This reduces cursor movement where possible. If possible the cursor
will be made invisible.
If flag is False, cursor will always be at “cursor position” after an update."
"window.move(new_y, new_x)","Move cursor to (new_y, new_x)."
"window.mvderwin(y, x)","Move the window inside its parent window.  The screen-relative parameters of
the window are not changed.  This routine is used to display different parts of
the parent window at the same physical position on the screen."
"window.mvwin(new_y, new_x)","Move the window so its upper-left corner is at (new_y, new_x)."
window.nodelay(flag),"If flag is True, getch() will be non-blocking."
window.notimeout(flag),"If flag is True, escape sequences will not be timed out.
If flag is False, after a few milliseconds, an escape sequence will not be
interpreted, and will be left in the input stream as is."
window.noutrefresh(),"Mark for refresh but wait.  This function updates the data structure
representing the desired state of the window, but does not force an update of
the physical screen.  To accomplish that, call  doupdate()."
"window.overlay(destwin[, sminrow, smincol, dminrow, dmincol, dmaxrow, dmaxcol])","Overlay the window on top of destwin. The windows need not be the same size,
only the overlapping region is copied. This copy is non-destructive, which means
that the current background character does not overwrite the old contents of
destwin.
To get fine-grained control over the copied region, the second form of
overlay() can be used. sminrow and smincol are the upper-left
coordinates of the source window, and the other variables mark a rectangle in
the destination window."
"window.overwrite(destwin[, sminrow, smincol, dminrow, dmincol, dmaxrow, dmaxcol])","Overwrite the window on top of destwin. The windows need not be the same size,
in which case only the overlapping region is copied. This copy is destructive,
which means that the current background character overwrites the old contents of
destwin.
To get fine-grained control over the copied region, the second form of
overwrite() can be used. sminrow and smincol are the upper-left
coordinates of the source window, the other variables mark a rectangle in the
destination window."
window.putwin(file),"Write all data associated with the window into the provided file object.  This
information can be later retrieved using the getwin() function."
"window.redrawln(beg, num)","Indicate that the num screen lines, starting at line beg, are corrupted and
should be completely redrawn on the next refresh() call."
window.redrawwin(),"Touch the entire window, causing it to be completely redrawn on the next
refresh() call."
"window.refresh([pminrow, pmincol, sminrow, smincol, smaxrow, smaxcol])","Update the display immediately (sync actual screen with previous
drawing/deleting methods).
The 6 optional arguments can only be specified when the window is a pad created
with newpad().  The additional parameters are needed to indicate what part
of the pad and screen are involved. pminrow and pmincol specify the upper
left-hand corner of the rectangle to be displayed in the pad.  sminrow,
smincol, smaxrow, and smaxcol specify the edges of the rectangle to be
displayed on the screen.  The lower right-hand corner of the rectangle to be
displayed in the pad is calculated from the screen coordinates, since the
rectangles must be the same size.  Both rectangles must be entirely contained
within their respective structures.  Negative values of pminrow, pmincol,
sminrow, or smincol are treated as if they were zero."
"window.resize(nlines, ncols)","Reallocate storage for a curses window to adjust its dimensions to the
specified values.  If either dimension is larger than the current values, the
window’s data is filled with blanks that have the current background
rendition (as set by bkgdset()) merged into them."
window.scroll([lines=1]),Scroll the screen or scrolling region upward by lines lines.
window.scrollok(flag),"Control what happens when the cursor of a window is moved off the edge of the
window or scrolling region, either as a result of a newline action on the bottom
line, or typing the last character of the last line.  If flag is False, the
cursor is left on the bottom line.  If flag is True, the window is scrolled up
one line.  Note that in order to get the physical scrolling effect on the
terminal, it is also necessary to call idlok()."
"window.setscrreg(top, bottom)","Set the scrolling region from line top to line bottom. All scrolling actions
will take place in this region."
window.standend(),"Turn off the standout attribute.  On some terminals this has the side effect of
turning off all attributes."
window.standout(),Turn on attribute A_STANDOUT.
"window.subpad(begin_y, begin_x)","Return a sub-window, whose upper-left corner is at (begin_y, begin_x), and
whose width/height is ncols/nlines."
"window.subwin(begin_y, begin_x)","Return a sub-window, whose upper-left corner is at (begin_y, begin_x), and
whose width/height is ncols/nlines.
By default, the sub-window will extend from the specified position to the lower
right corner of the window."
window.syncdown(),"Touch each location in the window that has been touched in any of its ancestor
windows.  This routine is called by refresh(), so it should almost never
be necessary to call it manually."
window.syncok(flag),"If flag is True, then syncup() is called automatically
whenever there is a change in the window."
window.syncup(),"Touch all locations in ancestors of the window that have been changed in  the
window."
window.timeout(delay),"Set blocking or non-blocking read behavior for the window.  If delay is
negative, blocking read is used (which will wait indefinitely for input).  If
delay is zero, then non-blocking read is used, and getch() will
return -1 if no input is waiting.  If delay is positive, then
getch() will block for delay milliseconds, and return -1 if there is
still no input at the end of that time."
"window.touchline(start, count[, changed])","Pretend count lines have been changed, starting with line start.  If
changed is supplied, it specifies whether the affected lines are marked as
having been changed (changed=True) or unchanged (changed=False)."
window.touchwin(),"Pretend the whole window has been changed, for purposes of drawing
optimizations."
window.untouchwin(),"Mark all lines in  the  window  as unchanged since the last call to
refresh()."
"window.vline(ch, n)","Display a vertical line starting at (y, x) with length n consisting of the
character ch."
edit([validator]),"This is the entry point you will normally use.  It accepts editing
keystrokes until one of the termination keystrokes is entered.  If
validator is supplied, it must be a function.  It will be called for
each keystroke entered with the keystroke as a parameter; command dispatch
is done on the result. This method returns the window contents as a
string; whether blanks in the window are included is affected by the
stripspaces attribute."
do_command(ch),"Process a single command keystroke.  Here are the supported special
keystrokes:






Keystroke
Action



Control-A
Go to left edge of window.

Control-B
Cursor left, wrapping to previous line if
appropriate.

Control-D
Delete character under cursor.

Control-E
Go to right edge (stripspaces off) or end
of line (stripspaces on).

Control-F
Cursor right, wrapping to next line when
appropriate.

Control-G
Terminate, returning the window contents.

Control-H
Delete character backward.

Control-J
Terminate if the window is 1 line,
otherwise insert newline.

Control-K
If line is blank, delete it, otherwise
clear to end of line.

Control-L
Refresh screen.

Control-N
Cursor down; move down one line.

Control-O
Insert a blank line at cursor location.

Control-P
Cursor up; move up one line.



Move operations do nothing if the cursor is at an edge where the movement
is not possible.  The following synonyms are supported where possible:






Constant
Keystroke



KEY_LEFT
Control-B

KEY_RIGHT
Control-F

KEY_UP
Control-P

KEY_DOWN
Control-N

KEY_BACKSPACE
Control-h



All other keystrokes are treated as a command to insert the given
character and move right (with line wrapping)."
gather(),"Return the window contents as a string; whether blanks in the
window are included is affected by the stripspaces member."
curses.ascii.isalnum(c),"Checks for an ASCII alphanumeric character; it is equivalent to isalpha(c) or
isdigit(c)."
curses.ascii.isalpha(c),"Checks for an ASCII alphabetic character; it is equivalent to isupper(c) or
islower(c)."
curses.ascii.isascii(c),Checks for a character value that fits in the 7-bit ASCII set.
curses.ascii.isblank(c),Checks for an ASCII whitespace character; space or horizontal tab.
curses.ascii.iscntrl(c),Checks for an ASCII control character (in the range 0x00 to 0x1f or 0x7f).
curses.ascii.isdigit(c),"Checks for an ASCII decimal digit, '0' through '9'.  This is equivalent
to c in string.digits."
curses.ascii.isgraph(c),Checks for ASCII any printable character except space.
curses.ascii.islower(c),Checks for an ASCII lower-case character.
curses.ascii.isprint(c),Checks for any ASCII printable character including space.
curses.ascii.ispunct(c),"Checks for any printable ASCII character which is not a space or an alphanumeric
character."
curses.ascii.isspace(c),"Checks for ASCII white-space characters; space, line feed, carriage return, form
feed, horizontal tab, vertical tab."
curses.ascii.isupper(c),Checks for an ASCII uppercase letter.
curses.ascii.isxdigit(c),"Checks for an ASCII hexadecimal digit.  This is equivalent to c in
string.hexdigits."
curses.ascii.isctrl(c),Checks for an ASCII control character (ordinal values 0 to 31).
curses.ascii.ismeta(c),Checks for a non-ASCII character (ordinal values 0x80 and above).
curses.ascii.ascii(c),Return the ASCII value corresponding to the low 7 bits of c.
curses.ascii.ctrl(c),"Return the control character corresponding to the given character (the character
bit value is bitwise-anded with 0x1f)."
curses.ascii.alt(c),"Return the 8-bit character corresponding to the given ASCII character (the
character bit value is bitwise-ored with 0x80)."
curses.ascii.unctrl(c),"Return a string representation of the ASCII character c.  If c is printable,
this string is the character itself.  If the character is a control character
(0x00–0x1f) the string consists of a caret ('^') followed by the
corresponding uppercase letter. If the character is an ASCII delete (0x7f) the
string is '^?'.  If the character has its meta bit (0x80) set, the meta bit
is stripped, the preceding rules applied, and '!' prepended to the result."
curses.panel.bottom_panel(),Returns the bottom panel in the panel stack.
curses.panel.new_panel(win),"Returns a panel object, associating it with the given window win. Be aware
that you need to keep the returned panel object referenced explicitly.  If you
don’t, the panel object is garbage collected and removed from the panel stack."
curses.panel.top_panel(),Returns the top panel in the panel stack.
curses.panel.update_panels(),"Updates the virtual screen after changes in the panel stack. This does not call
curses.doupdate(), so you’ll have to do this yourself."
Panel.above(),Returns the panel above the current panel.
Panel.below(),Returns the panel below the current panel.
Panel.bottom(),Push the panel to the bottom of the stack.
Panel.hidden(),"Returns True if the panel is hidden (not visible), False otherwise."
Panel.hide(),"Hide the panel. This does not delete the object, it just makes the window on
screen invisible."
"Panel.move(y, x)","Move the panel to the screen coordinates (y, x)."
Panel.replace(win),Change the window associated with the panel to the window win.
Panel.set_userptr(obj),"Set the panel’s user pointer to obj. This is used to associate an arbitrary
piece of data with the panel, and can be any Python object."
Panel.show(),Display the panel (which might have been hidden).
Panel.top(),Push panel to the top of the stack.
Panel.userptr(),Returns the user pointer for the panel.  This might be any Python object.
Panel.window(),Returns the window object associated with the panel.
"platform.architecture(executable=sys.executable, bits='', linkage='')","Queries the given executable (defaults to the Python interpreter binary) for
various architecture information.
Returns a tuple (bits, linkage) which contain information about the bit
architecture and the linkage format used for the executable. Both values are
returned as strings.
Values that cannot be determined are returned as given by the parameter presets.
If bits is given as '', the sizeof(pointer) (or
sizeof(long) on Python version < 1.5.2) is used as indicator for the
supported pointer size.
The function relies on the system’s file command to do the actual work.
This is available on most if not all Unix  platforms and some non-Unix platforms
and then only if the executable points to the Python interpreter.  Reasonable
defaults are used when the above needs are not met.

Note
On Mac OS X (and perhaps other platforms), executable files may be
universal files containing multiple architectures.
To get at the “64-bitness” of the current interpreter, it is more
reliable to query the sys.maxsize attribute:
is_64bits = sys.maxsize > 2**32"
platform.machine(),"Returns the machine type, e.g. 'i386'. An empty string is returned if the
value cannot be determined."
platform.node(),"Returns the computer’s network name (may not be fully qualified!). An empty
string is returned if the value cannot be determined."
"platform.platform(aliased=0, terse=0)","Returns a single string identifying the underlying platform with as much useful
information as possible.
The output is intended to be human readable rather than machine parseable. It
may look different on different platforms and this is intended.
If aliased is true, the function will use aliases for various platforms that
report system names which differ from their common names, for example SunOS will
be reported as Solaris.  The system_alias() function is used to implement
this.
Setting terse to true causes the function to return only the absolute minimum
information needed to identify the platform.

Changed in version 3.8: On macOS, the function now uses mac_ver(), if it returns a
non-empty release string, to get the macOS version rather than the darwin
version."
platform.processor(),"Returns the (real) processor name, e.g. 'amdk6'.
An empty string is returned if the value cannot be determined. Note that many
platforms do not provide this information or simply return the same value as for
machine().  NetBSD does this."
platform.python_build(),"Returns a tuple (buildno, builddate) stating the Python build number and
date as strings."
platform.python_compiler(),Returns a string identifying the compiler used for compiling Python.
platform.python_branch(),Returns a string identifying the Python implementation SCM branch.
platform.python_implementation(),"Returns a string identifying the Python implementation. Possible return values
are: ‘CPython’, ‘IronPython’, ‘Jython’, ‘PyPy’."
platform.python_revision(),Returns a string identifying the Python implementation SCM revision.
platform.python_version(),"Returns the Python version as string 'major.minor.patchlevel'.
Note that unlike the Python sys.version, the returned value will always
include the patchlevel (it defaults to 0)."
platform.python_version_tuple(),"Returns the Python version as tuple (major, minor, patchlevel) of strings.
Note that unlike the Python sys.version, the returned value will always
include the patchlevel (it defaults to '0')."
platform.release(),"Returns the system’s release, e.g. '2.2.0' or 'NT' An empty string is
returned if the value cannot be determined."
platform.system(),"Returns the system/OS name, such as 'Linux', 'Darwin', 'Java',
'Windows'. An empty string is returned if the value cannot be determined."
"platform.system_alias(system, release, version)","Returns (system, release, version) aliased to common marketing names used
for some systems.  It also does some reordering of the information in some cases
where it would otherwise cause confusion."
platform.version(),"Returns the system’s release version, e.g. '#3 on degas'. An empty string is
returned if the value cannot be determined."
platform.uname(),"Fairly portable uname interface. Returns a namedtuple()
containing six attributes: system, node, release,
version, machine, and processor.
Note that this adds a sixth attribute (processor) not present
in the os.uname() result.  Also, the attribute names are different
for the first two attributes; os.uname() names them
sysname and nodename.
Entries which cannot be determined are set to ''.

Changed in version 3.3: Result changed from a tuple to a namedtuple."
"platform.java_ver(release='', vendor='', vminfo=('', '', ''), osinfo=('', '', ''))","Version interface for Jython.
Returns a tuple (release, vendor, vminfo, osinfo) with vminfo being a
tuple (vm_name, vm_release, vm_vendor) and osinfo being a tuple
(os_name, os_version, os_arch). Values which cannot be determined are set to
the defaults given as parameters (which all default to '')."
"platform.win32_ver(release='', version='', csd='', ptype='')","Get additional version information from the Windows Registry and return a tuple
(release, version, csd, ptype) referring to OS release, version number,
CSD level (service pack) and OS type (multi/single processor).
As a hint: ptype is 'Uniprocessor Free' on single processor NT machines
and 'Multiprocessor Free' on multi processor machines. The ‘Free’ refers
to the OS version being free of debugging code. It could also state ‘Checked’
which means the OS version uses debugging code, i.e. code that checks arguments,
ranges, etc.

Note
This function works best with Mark Hammond’s
win32all package installed, but also on Python 2.3 and
later (support for this was added in Python 2.6). It obviously
only runs on Win32 compatible platforms."
platform.win32_edition(),"Returns a string representing the current Windows edition.  Possible
values include but are not limited to 'Enterprise', 'IoTUAP',
'ServerStandard', and 'nanoserver'.

New in version 3.8."
platform.win32_is_iot(),"Return True if the Windows edition returned by win32_edition()
is recognized as an IoT edition.

New in version 3.8."
"platform.mac_ver(release='', versioninfo=('', '', ''), machine='')","Get Mac OS version information and return it as tuple (release, versioninfo,
machine) with versioninfo being a tuple (version, dev_stage,
non_release_version).
Entries which cannot be determined are set to ''.  All tuple entries are
strings."
"platform.libc_ver(executable=sys.executable, lib='', version='', chunksize=16384)","Tries to determine the libc version against which the file executable (defaults
to the Python interpreter) is linked.  Returns a tuple of strings (lib,
version) which default to the given parameters in case the lookup fails.
Note that this function has intimate knowledge of how different libc versions
add symbols to the executable is probably only usable for executables compiled
using gcc.
The file is read and scanned in chunks of chunksize bytes."
"callable(result, func, arguments","result is what the foreign function returns, as specified by the
restype attribute.
func is the foreign function object itself, this allows reusing the
same callable object to check or post process the results of several
functions.
arguments is a tuple containing the parameters originally passed to
the function call, this allows specializing the behavior on the
arguments used."
"ctypes.CFUNCTYPE(restype, *argtypes, use_errno=False, use_last_error=False)","The returned function prototype creates functions that use the standard C
calling convention.  The function will release the GIL during the call.  If
use_errno is set to true, the ctypes private copy of the system
errno variable is exchanged with the real errno value before
and after the call; use_last_error does the same for the Windows error
code."
"ctypes.WINFUNCTYPE(restype, *argtypes, use_errno=False, use_last_error=False)","Windows only: The returned function prototype creates functions that use the
stdcall calling convention, except on Windows CE where
WINFUNCTYPE() is the same as CFUNCTYPE().  The function will
release the GIL during the call.  use_errno and use_last_error have the
same meaning as above."
"ctypes.PYFUNCTYPE(restype, *argtypes)","The returned function prototype creates functions that use the Python calling
convention.  The function will not release the GIL during the call."
prototype(address,Returns a foreign function at the specified address which must be an integer.
prototype(callable,Create a C callable function (a callback function) from a Python callable.
"prototype(func_spec[, paramflags]","Returns a foreign function exported by a shared library. func_spec must
be a 2-tuple (name_or_ordinal, library). The first item is the name of
the exported function as string, or the ordinal of the exported function
as small integer.  The second item is the shared library instance."
"prototype(vtbl_index, name[, paramflags[, iid]]","Returns a foreign function that will call a COM method. vtbl_index is
the index into the virtual function table, a small non-negative
integer. name is name of the COM method. iid is an optional pointer to
the interface identifier which is used in extended error reporting.
COM methods use a special calling convention: They require a pointer to
the COM interface as first argument, in addition to those parameters that
are specified in the argtypes tuple."
ctypes.addressof(obj),"Returns the address of the memory buffer as integer.  obj must be an
instance of a ctypes type.
Raises an auditing event ctypes.addressof with argument obj."
ctypes.alignment(obj_or_type),"Returns the alignment requirements of a ctypes type. obj_or_type must be a
ctypes type or instance."
"ctypes.byref(obj[, offset])","Returns a light-weight pointer to obj, which must be an instance of a
ctypes type.  offset defaults to zero, and must be an integer that will be
added to the internal pointer value.
byref(obj, offset) corresponds to this C code:
(((char *)&obj) + offset)


The returned object can only be used as a foreign function call parameter.
It behaves similar to pointer(obj), but the construction is a lot faster."
"ctypes.cast(obj, type)","This function is similar to the cast operator in C. It returns a new instance
of type which points to the same memory block as obj.  type must be a
pointer type, and obj must be an object that can be interpreted as a
pointer."
"ctypes.create_string_buffer(init_or_size, size=None)","This function creates a mutable character buffer. The returned object is a
ctypes array of c_char.
init_or_size must be an integer which specifies the size of the array, or a
bytes object which will be used to initialize the array items.
If a bytes object is specified as first argument, the buffer is made one item
larger than its length so that the last element in the array is a NUL
termination character. An integer can be passed as second argument which allows
specifying the size of the array if the length of the bytes should not be used.
Raises an auditing event ctypes.create_string_buffer with arguments init, size."
"ctypes.create_unicode_buffer(init_or_size, size=None)","This function creates a mutable unicode character buffer. The returned object is
a ctypes array of c_wchar.
init_or_size must be an integer which specifies the size of the array, or a
string which will be used to initialize the array items.
If a string is specified as first argument, the buffer is made one item
larger than the length of the string so that the last element in the array is a
NUL termination character. An integer can be passed as second argument which
allows specifying the size of the array if the length of the string should not
be used.
Raises an auditing event ctypes.create_unicode_buffer with arguments init, size."
ctypes.DllCanUnloadNow(),"Windows only: This function is a hook which allows implementing in-process
COM servers with ctypes.  It is called from the DllCanUnloadNow function that
the _ctypes extension dll exports."
ctypes.DllGetClassObject(),"Windows only: This function is a hook which allows implementing in-process
COM servers with ctypes.  It is called from the DllGetClassObject function
that the _ctypes extension dll exports."
ctypes.util.find_library(name),"Try to find a library and return a pathname.  name is the library name
without any prefix like lib, suffix like .so, .dylib or version
number (this is the form used for the posix linker option -l).  If
no library can be found, returns None.
The exact functionality is system dependent."
ctypes.util.find_msvcrt(),"Windows only: return the filename of the VC runtime library used by Python,
and by the extension modules.  If the name of the library cannot be
determined, None is returned.
If you need to free memory, for example, allocated by an extension module
with a call to the free(void *), it is important that you use the
function in the same library that allocated the memory."
ctypes.FormatError([code]),"Windows only: Returns a textual description of the error code code.  If no
error code is specified, the last error code is used by calling the Windows
api function GetLastError."
ctypes.GetLastError(),"Windows only: Returns the last error code set by Windows in the calling thread.
This function calls the Windows GetLastError() function directly,
it does not return the ctypes-private copy of the error code."
ctypes.get_errno(),"Returns the current value of the ctypes-private copy of the system
errno variable in the calling thread.
Raises an auditing event ctypes.get_errno with no arguments."
ctypes.get_last_error(),"Windows only: returns the current value of the ctypes-private copy of the system
LastError variable in the calling thread.
Raises an auditing event ctypes.get_last_error with no arguments."
"ctypes.memmove(dst, src, count)","Same as the standard C memmove library function: copies count bytes from
src to dst. dst and src must be integers or ctypes instances that can
be converted to pointers."
"ctypes.memset(dst, c, count)","Same as the standard C memset library function: fills the memory block at
address dst with count bytes of value c. dst must be an integer
specifying an address, or a ctypes instance."
ctypes.POINTER(type),"This factory function creates and returns a new ctypes pointer type. Pointer
types are cached and reused internally, so calling this function repeatedly is
cheap. type must be a ctypes type."
ctypes.pointer(obj),"This function creates a new pointer instance, pointing to obj. The returned
object is of the type POINTER(type(obj)).
Note: If you just want to pass a pointer to an object to a foreign function
call, you should use byref(obj) which is much faster."
"ctypes.resize(obj, size)","This function resizes the internal memory buffer of obj, which must be an
instance of a ctypes type.  It is not possible to make the buffer smaller
than the native size of the objects type, as given by sizeof(type(obj)),
but it is possible to enlarge the buffer."
ctypes.set_errno(value),"Set the current value of the ctypes-private copy of the system errno
variable in the calling thread to value and return the previous value.
Raises an auditing event ctypes.set_errno with argument errno."
ctypes.set_last_error(value),"Windows only: set the current value of the ctypes-private copy of the system
LastError variable in the calling thread to value and return the
previous value.
Raises an auditing event ctypes.set_last_error with argument error."
ctypes.sizeof(obj_or_type),"Returns the size in bytes of a ctypes type or instance memory buffer.
Does the same as the C sizeof operator."
"ctypes.string_at(address, size=-1)","This function returns the C string starting at memory address address as a bytes
object. If size is specified, it is used as size, otherwise the string is assumed
to be zero-terminated.
Raises an auditing event ctypes.string_at with arguments address, size."
"ctypes.WinError(code=None, descr=None)","Windows only: this function is probably the worst-named thing in ctypes. It
creates an instance of OSError.  If code is not specified,
GetLastError is called to determine the error code. If descr is not
specified, FormatError() is called to get a textual description of the
error.

Changed in version 3.3: An instance of WindowsError used to be created."
"ctypes.wstring_at(address, size=-1)","This function returns the wide character string starting at memory address
address as a string.  If size is specified, it is used as the number of
characters of the string, otherwise the string is assumed to be
zero-terminated.
Raises an auditing event ctypes.wstring_at with arguments address, size."
LoadLibrary(name),"Load a shared library into the process and return it.  This method always
returns a new instance of the library."
"from_buffer(source[, offset])","This method returns a ctypes instance that shares the buffer of the
source object.  The source object must support the writeable buffer
interface.  The optional offset parameter specifies an offset into the
source buffer in bytes; the default is zero.  If the source buffer is not
large enough a ValueError is raised.
Raises an auditing event ctypes.cdata/buffer with arguments pointer, size, offset."
"from_buffer_copy(source[, offset])","This method creates a ctypes instance, copying the buffer from the
source object buffer which must be readable.  The optional offset
parameter specifies an offset into the source buffer in bytes; the default
is zero.  If the source buffer is not large enough a ValueError is
raised.
Raises an auditing event ctypes.cdata/buffer with arguments pointer, size, offset."
from_address(address),"This method returns a ctypes type instance using the memory specified by
address which must be an integer.
This method, and others that indirectly call this method, raises an
auditing event ctypes.cdata with argument
address."
from_param(obj),"This method adapts obj to a ctypes type.  It is called with the actual
object used in a foreign function call when the type is present in the
foreign function’s argtypes tuple; it must return an object that
can be used as a function call parameter.
All ctypes data types have a default implementation of this classmethod
that normally returns obj if that is an instance of the type.  Some
types accept other objects as well."
"in_dll(library, name)","This method returns a ctypes type instance exported by a shared
library. name is the name of the symbol that exports the data, library
is the loaded shared library."
threading.active_count(),"Return the number of Thread objects currently alive.  The returned
count is equal to the length of the list returned by enumerate()."
threading.current_thread(),"Return the current Thread object, corresponding to the caller’s thread
of control.  If the caller’s thread of control was not created through the
threading module, a dummy thread object with limited functionality is
returned."
"threading.excepthook(args, /)","Handle uncaught exception raised by Thread.run().
The args argument has the following attributes:

exc_type: Exception type.
exc_value: Exception value, can be None.
exc_traceback: Exception traceback, can be None.
thread: Thread which raised the exception, can be None.

If exc_type is SystemExit, the exception is silently ignored.
Otherwise, the exception is printed out on sys.stderr.
If  this function raises an exception, sys.excepthook() is called to
handle it.
threading.excepthook() can be overridden to control how uncaught
exceptions raised by Thread.run() are handled.
Storing exc_value using a custom hook can create a reference cycle. It
should be cleared explicitly to break the reference cycle when the
exception is no longer needed.
Storing thread using a custom hook can resurrect it if it is set to an
object which is being finalized. Avoid storing thread after the custom
hook completes to avoid resurrecting objects.

See also
sys.excepthook() handles uncaught exceptions.


New in version 3.8."
threading.get_ident(),"Return the ‘thread identifier’ of the current thread.  This is a nonzero
integer.  Its value has no direct meaning; it is intended as a magic cookie
to be used e.g. to index a dictionary of thread-specific data.  Thread
identifiers may be recycled when a thread exits and another thread is
created.

New in version 3.3."
threading.get_native_id(),"Return the native integral Thread ID of the current thread assigned by the kernel.
This is a non-negative integer.
Its value may be used to uniquely identify this particular thread system-wide
(until the thread terminates, after which the value may be recycled by the OS).
Availability: Windows, FreeBSD, Linux, macOS, OpenBSD, NetBSD, AIX.

New in version 3.8."
threading.enumerate(),"Return a list of all Thread objects currently alive.  The list
includes daemonic threads, dummy thread objects created by
current_thread(), and the main thread.  It excludes terminated threads
and threads that have not yet been started."
threading.main_thread(),"Return the main Thread object.  In normal conditions, the
main thread is the thread from which the Python interpreter was
started.

New in version 3.4."
threading.settrace(func),"Set a trace function for all threads started from the threading module.
The func will be passed to  sys.settrace() for each thread, before its
run() method is called."
threading.setprofile(func),"Set a profile function for all threads started from the threading module.
The func will be passed to  sys.setprofile() for each thread, before its
run() method is called."
threading.stack_size([size]),"Return the thread stack size used when creating new threads.  The optional
size argument specifies the stack size to be used for subsequently created
threads, and must be 0 (use platform or configured default) or a positive
integer value of at least 32,768 (32 KiB). If size is not specified,
0 is used.  If changing the thread stack size is
unsupported, a RuntimeError is raised.  If the specified stack size is
invalid, a ValueError is raised and the stack size is unmodified.  32 KiB
is currently the minimum supported stack size value to guarantee sufficient
stack space for the interpreter itself.  Note that some platforms may have
particular restrictions on values for the stack size, such as requiring a
minimum stack size > 32 KiB or requiring allocation in multiples of the system
memory page size - platform documentation should be referred to for more
information (4 KiB pages are common; using multiples of 4096 for the stack size is
the suggested approach in the absence of more specific information).
Availability: Windows, systems with POSIX threads."
start(),"Start the thread’s activity.
It must be called at most once per thread object.  It arranges for the
object’s run() method to be invoked in a separate thread
of control.
This method will raise a RuntimeError if called more than once
on the same thread object."
run(),"Method representing the thread’s activity.
You may override this method in a subclass.  The standard run()
method invokes the callable object passed to the object’s constructor as
the target argument, if any, with positional and keyword arguments taken
from the args and kwargs arguments, respectively."
join(timeout=None),"Wait until the thread terminates. This blocks the calling thread until
the thread whose join() method is called terminates – either
normally or through an unhandled exception – or until the optional
timeout occurs.
When the timeout argument is present and not None, it should be a
floating point number specifying a timeout for the operation in seconds
(or fractions thereof). As join() always returns None,
you must call is_alive() after join() to
decide whether a timeout happened – if the thread is still alive, the
join() call timed out.
When the timeout argument is not present or None, the operation will
block until the thread terminates.
A thread can be join()ed many times.
join() raises a RuntimeError if an attempt is made
to join the current thread as that would cause a deadlock. It is also
an error to join() a thread before it has been started
and attempts to do so raise the same exception."
getName(),"Old getter/setter API for name; use it directly as a
property instead."
is_alive(),"Return whether the thread is alive.
This method returns True just before the run() method
starts until just after the run() method terminates.  The
module function enumerate() returns a list of all alive threads."
isDaemon(),"Old getter/setter API for daemon; use it directly as a
property instead."
"acquire(blocking=True, timeout=-1)","Acquire a lock, blocking or non-blocking.
When invoked with the blocking argument set to True (the default),
block until the lock is unlocked, then set it to locked and return True.
When invoked with the blocking argument set to False, do not block.
If a call with blocking set to True would block, return False
immediately; otherwise, set the lock to locked and return True.
When invoked with the floating-point timeout argument set to a positive
value, block for at most the number of seconds specified by timeout
and as long as the lock cannot be acquired.  A timeout argument of -1
specifies an unbounded wait.  It is forbidden to specify a timeout
when blocking is false.
The return value is True if the lock is acquired successfully,
False if not (for example if the timeout expired).

Changed in version 3.2: The timeout parameter is new.


Changed in version 3.2: Lock acquisition can now be interrupted by signals on POSIX if the
underlying threading implementation supports it."
release(),"Release a lock.  This can be called from any thread, not only the thread
which has acquired the lock.
When the lock is locked, reset it to unlocked, and return.  If any other threads
are blocked waiting for the lock to become unlocked, allow exactly one of them
to proceed.
When invoked on an unlocked lock, a RuntimeError is raised.
There is no return value."
locked(),Return true if the lock is acquired.
"acquire(blocking=True, timeout=-1)","Acquire a lock, blocking or non-blocking.
When invoked without arguments: if this thread already owns the lock, increment
the recursion level by one, and return immediately.  Otherwise, if another
thread owns the lock, block until the lock is unlocked.  Once the lock is
unlocked (not owned by any thread), then grab ownership, set the recursion level
to one, and return.  If more than one thread is blocked waiting until the lock
is unlocked, only one at a time will be able to grab ownership of the lock.
There is no return value in this case.
When invoked with the blocking argument set to true, do the same thing as when
called without arguments, and return True.
When invoked with the blocking argument set to false, do not block.  If a call
without an argument would block, return False immediately; otherwise, do the
same thing as when called without arguments, and return True.
When invoked with the floating-point timeout argument set to a positive
value, block for at most the number of seconds specified by timeout
and as long as the lock cannot be acquired.  Return True if the lock has
been acquired, false if the timeout has elapsed.

Changed in version 3.2: The timeout parameter is new."
release(),"Release a lock, decrementing the recursion level.  If after the decrement it is
zero, reset the lock to unlocked (not owned by any thread), and if any other
threads are blocked waiting for the lock to become unlocked, allow exactly one
of them to proceed.  If after the decrement the recursion level is still
nonzero, the lock remains locked and owned by the calling thread.
Only call this method when the calling thread owns the lock. A
RuntimeError is raised if this method is called when the lock is
unlocked.
There is no return value."
acquire(*args),"Acquire the underlying lock. This method calls the corresponding method on
the underlying lock; the return value is whatever that method returns."
release(),"Release the underlying lock. This method calls the corresponding method on
the underlying lock; there is no return value."
wait(timeout=None),"Wait until notified or until a timeout occurs. If the calling thread has
not acquired the lock when this method is called, a RuntimeError is
raised.
This method releases the underlying lock, and then blocks until it is
awakened by a notify() or notify_all() call for the same
condition variable in another thread, or until the optional timeout
occurs.  Once awakened or timed out, it re-acquires the lock and returns.
When the timeout argument is present and not None, it should be a
floating point number specifying a timeout for the operation in seconds
(or fractions thereof).
When the underlying lock is an RLock, it is not released using
its release() method, since this may not actually unlock the lock
when it was acquired multiple times recursively.  Instead, an internal
interface of the RLock class is used, which really unlocks it
even when it has been recursively acquired several times. Another internal
interface is then used to restore the recursion level when the lock is
reacquired.
The return value is True unless a given timeout expired, in which
case it is False.

Changed in version 3.2: Previously, the method always returned None."
"wait_for(predicate, timeout=None)","Wait until a condition evaluates to true.  predicate should be a
callable which result will be interpreted as a boolean value.
A timeout may be provided giving the maximum time to wait.
This utility method may call wait() repeatedly until the predicate
is satisfied, or until a timeout occurs. The return value is
the last return value of the predicate and will evaluate to
False if the method timed out.
Ignoring the timeout feature, calling this method is roughly equivalent to
writing:
while not predicate():
    cv.wait()


Therefore, the same rules apply as with wait(): The lock must be
held when called and is re-acquired on return.  The predicate is evaluated
with the lock held.

New in version 3.2."
notify(n=1),"By default, wake up one thread waiting on this condition, if any.  If the
calling thread has not acquired the lock when this method is called, a
RuntimeError is raised.
This method wakes up at most n of the threads waiting for the condition
variable; it is a no-op if no threads are waiting.
The current implementation wakes up exactly n threads, if at least n
threads are waiting.  However, it’s not safe to rely on this behavior.
A future, optimized implementation may occasionally wake up more than
n threads.
Note: an awakened thread does not actually return from its wait()
call until it can reacquire the lock.  Since notify() does not
release the lock, its caller should."
notify_all(),"Wake up all threads waiting on this condition.  This method acts like
notify(), but wakes up all waiting threads instead of one. If the
calling thread has not acquired the lock when this method is called, a
RuntimeError is raised."
"acquire(blocking=True, timeout=None)","Acquire a semaphore.
When invoked without arguments:

If the internal counter is larger than zero on entry, decrement it by
one and return True immediately.
If the internal counter is zero on entry, block until awoken by a call to
release().  Once awoken (and the counter is greater
than 0), decrement the counter by 1 and return True.  Exactly one
thread will be awoken by each call to release().  The
order in which threads are awoken should not be relied on.

When invoked with blocking set to false, do not block.  If a call
without an argument would block, return False immediately; otherwise, do
the same thing as when called without arguments, and return True.
When invoked with a timeout other than None, it will block for at
most timeout seconds.  If acquire does not complete successfully in
that interval, return False.  Return True otherwise.

Changed in version 3.2: The timeout parameter is new."
release(),"Release a semaphore, incrementing the internal counter by one.  When it
was zero on entry and another thread is waiting for it to become larger
than zero again, wake up that thread."
is_set(),Return True if and only if the internal flag is true.
set(),"Set the internal flag to true. All threads waiting for it to become true
are awakened. Threads that call wait() once the flag is true will
not block at all."
clear(),"Reset the internal flag to false. Subsequently, threads calling
wait() will block until set() is called to set the internal
flag to true again."
wait(timeout=None),"Block until the internal flag is true.  If the internal flag is true on
entry, return immediately.  Otherwise, block until another thread calls
set() to set the flag to true, or until the optional timeout occurs.
When the timeout argument is present and not None, it should be a
floating point number specifying a timeout for the operation in seconds
(or fractions thereof).
This method returns True if and only if the internal flag has been set to
true, either before the wait call or after the wait starts, so it will
always return True except if a timeout is given and the operation
times out.

Changed in version 3.1: Previously, the method always returned None."
cancel(),"Stop the timer, and cancel the execution of the timer’s action.  This will
only work if the timer is still in its waiting stage."
wait(timeout=None),"Pass the barrier.  When all the threads party to the barrier have called
this function, they are all released simultaneously.  If a timeout is
provided, it is used in preference to any that was supplied to the class
constructor.
The return value is an integer in the range 0 to parties – 1, different
for each thread.  This can be used to select a thread to do some special
housekeeping, e.g.:
i = barrier.wait()
if i == 0:
    # Only one thread needs to print this
    print(""passed the barrier"")


If an action was provided to the constructor, one of the threads will
have called it prior to being released.  Should this call raise an error,
the barrier is put into the broken state.
If the call times out, the barrier is put into the broken state.
This method may raise a BrokenBarrierError exception if the
barrier is broken or reset while a thread is waiting."
reset(),"Return the barrier to the default, empty state.  Any threads waiting on it
will receive the BrokenBarrierError exception.
Note that using this function may require some external
synchronization if there are other threads whose state is unknown.  If a
barrier is broken it may be better to just leave it and create a new one."
abort(),"Put the barrier into a broken state.  This causes any active or future
calls to wait() to fail with the BrokenBarrierError.  Use
this for example if one of the threads needs to abort, to avoid deadlocking the
application.
It may be preferable to simply create the barrier with a sensible
timeout value to automatically guard against one of the threads going
awry."
multiprocessing.Pipe([duplex]),"Returns a pair (conn1, conn2) of
Connection objects representing the
ends of a pipe.
If duplex is True (the default) then the pipe is bidirectional.  If
duplex is False then the pipe is unidirectional: conn1 can only be
used for receiving messages and conn2 can only be used for sending
messages."
multiprocessing.active_children(),"Return list of all live children of the current process.
Calling this has the side effect of “joining” any processes which have
already finished."
multiprocessing.cpu_count(),"Return the number of CPUs in the system.
This number is not equivalent to the number of CPUs the current process can
use.  The number of usable CPUs can be obtained with
len(os.sched_getaffinity(0))
May raise NotImplementedError.

See also
os.cpu_count()"
multiprocessing.current_process(),"Return the Process object corresponding to the current process.
An analogue of threading.current_thread()."
multiprocessing.parent_process(),"Return the Process object corresponding to the parent process of
the current_process(). For the main process, parent_process will
be None.

New in version 3.8."
multiprocessing.freeze_support(),"Add support for when a program which uses multiprocessing has been
frozen to produce a Windows executable.  (Has been tested with py2exe,
PyInstaller and cx_Freeze.)
One needs to call this function straight after the if __name__ ==
'__main__' line of the main module.  For example:
from multiprocessing import Process, freeze_support

def f():
    print('hello world!')

if __name__ == '__main__':
    freeze_support()
    Process(target=f).start()


If the freeze_support() line is omitted then trying to run the frozen
executable will raise RuntimeError.
Calling freeze_support() has no effect when invoked on any operating
system other than Windows.  In addition, if the module is being run
normally by the Python interpreter on Windows (the program has not been
frozen), then freeze_support() has no effect."
multiprocessing.get_all_start_methods(),"Returns a list of the supported start methods, the first of which
is the default.  The possible start methods are 'fork',
'spawn' and 'forkserver'.  On Windows only 'spawn' is
available.  On Unix 'fork' and 'spawn' are always
supported, with 'fork' being the default.

New in version 3.4."
multiprocessing.get_context(method=None),"Return a context object which has the same attributes as the
multiprocessing module.
If method is None then the default context is returned.
Otherwise method should be 'fork', 'spawn',
'forkserver'.  ValueError is raised if the specified
start method is not available.

New in version 3.4."
multiprocessing.get_start_method(allow_none=False),"Return the name of start method used for starting processes.
If the start method has not been fixed and allow_none is false,
then the start method is fixed to the default and the name is
returned.  If the start method has not been fixed and allow_none
is true then None is returned.
The return value can be 'fork', 'spawn', 'forkserver'
or None.  'fork' is the default on Unix, while 'spawn' is
the default on Windows.

New in version 3.4."
multiprocessing.set_executable(),"Sets the path of the Python interpreter to use when starting a child process.
(By default sys.executable is used).  Embedders will probably need to
do some thing like
set_executable(os.path.join(sys.exec_prefix, 'pythonw.exe'))


before they can create child processes.

Changed in version 3.4: Now supported on Unix when the 'spawn' start method is used."
multiprocessing.set_start_method(method),"Set the method which should be used to start child processes.
method can be 'fork', 'spawn' or 'forkserver'.
Note that this should be called at most once, and it should be
protected inside the if __name__ == '__main__' clause of the
main module.

New in version 3.4."
"multiprocessing.Value(typecode_or_type, *args, lock=True)","Return a ctypes object allocated from shared memory.  By default the
return value is actually a synchronized wrapper for the object.  The object
itself can be accessed via the value attribute of a Value.
typecode_or_type determines the type of the returned object: it is either a
ctypes type or a one character typecode of the kind used by the array
module.  *args is passed on to the constructor for the type.
If lock is True (the default) then a new recursive lock
object is created to synchronize access to the value.  If lock is
a Lock or RLock object then that will be used to
synchronize access to the value.  If lock is False then
access to the returned object will not be automatically protected
by a lock, so it will not necessarily be “process-safe”.
Operations like += which involve a read and write are not
atomic.  So if, for instance, you want to atomically increment a
shared value it is insufficient to just do
counter.value += 1


Assuming the associated lock is recursive (which it is by default)
you can instead do
with counter.get_lock():
    counter.value += 1


Note that lock is a keyword-only argument."
"multiprocessing.Array(typecode_or_type, size_or_initializer, *, lock=True)","Return a ctypes array allocated from shared memory.  By default the return
value is actually a synchronized wrapper for the array.
typecode_or_type determines the type of the elements of the returned array:
it is either a ctypes type or a one character typecode of the kind used by
the array module.  If size_or_initializer is an integer, then it
determines the length of the array, and the array will be initially zeroed.
Otherwise, size_or_initializer is a sequence which is used to initialize
the array and whose length determines the length of the array.
If lock is True (the default) then a new lock object is created to
synchronize access to the value.  If lock is a Lock or
RLock object then that will be used to synchronize access to the
value.  If lock is False then access to the returned object will not be
automatically protected by a lock, so it will not necessarily be
“process-safe”.
Note that lock is a keyword only argument.
Note that an array of ctypes.c_char has value and raw
attributes which allow one to use it to store and retrieve strings."
"multiprocessing.sharedctypes.RawArray(typecode_or_type, size_or_initializer)","Return a ctypes array allocated from shared memory.
typecode_or_type determines the type of the elements of the returned array:
it is either a ctypes type or a one character typecode of the kind used by
the array module.  If size_or_initializer is an integer then it
determines the length of the array, and the array will be initially zeroed.
Otherwise size_or_initializer is a sequence which is used to initialize the
array and whose length determines the length of the array.
Note that setting and getting an element is potentially non-atomic – use
Array() instead to make sure that access is automatically synchronized
using a lock."
"multiprocessing.sharedctypes.RawValue(typecode_or_type, *args)","Return a ctypes object allocated from shared memory.
typecode_or_type determines the type of the returned object: it is either a
ctypes type or a one character typecode of the kind used by the array
module.  *args is passed on to the constructor for the type.
Note that setting and getting the value is potentially non-atomic – use
Value() instead to make sure that access is automatically synchronized
using a lock.
Note that an array of ctypes.c_char has value and raw
attributes which allow one to use it to store and retrieve strings – see
documentation for ctypes."
"multiprocessing.sharedctypes.Array(typecode_or_type, size_or_initializer, *, lock=True)","The same as RawArray() except that depending on the value of lock a
process-safe synchronization wrapper may be returned instead of a raw ctypes
array.
If lock is True (the default) then a new lock object is created to
synchronize access to the value.  If lock is a
Lock or RLock object
then that will be used to synchronize access to the
value.  If lock is False then access to the returned object will not be
automatically protected by a lock, so it will not necessarily be
“process-safe”.
Note that lock is a keyword-only argument."
"multiprocessing.sharedctypes.Value(typecode_or_type, *args, lock=True)","The same as RawValue() except that depending on the value of lock a
process-safe synchronization wrapper may be returned instead of a raw ctypes
object.
If lock is True (the default) then a new lock object is created to
synchronize access to the value.  If lock is a Lock or
RLock object then that will be used to synchronize access to the
value.  If lock is False then access to the returned object will not be
automatically protected by a lock, so it will not necessarily be
“process-safe”.
Note that lock is a keyword-only argument."
multiprocessing.sharedctypes.copy(obj),"Return a ctypes object allocated from shared memory which is a copy of the
ctypes object obj."
"multiprocessing.sharedctypes.synchronized(obj[, lock])","Return a process-safe wrapper object for a ctypes object which uses lock to
synchronize access.  If lock is None (the default) then a
multiprocessing.RLock object is created automatically.
A synchronized wrapper will have two methods in addition to those of the
object it wraps: get_obj() returns the wrapped object and
get_lock() returns the lock object used for synchronization.
Note that accessing the ctypes object through the wrapper can be a lot slower
than accessing the raw ctypes object.

Changed in version 3.5: Synchronized objects support the context manager protocol."
multiprocessing.Manager(),"Returns a started SyncManager object which
can be used for sharing objects between processes.  The returned manager
object corresponds to a spawned child process and has methods which will
create shared objects and return corresponding proxies."
"multiprocessing.connection.deliver_challenge(connection, authkey)","Send a randomly generated message to the other end of the connection and wait
for a reply.
If the reply matches the digest of the message using authkey as the key
then a welcome message is sent to the other end of the connection.  Otherwise
AuthenticationError is raised."
"multiprocessing.connection.answer_challenge(connection, authkey)","Receive a message, calculate the digest of the message using authkey as the
key, and then send the digest back.
If a welcome message is not received, then
AuthenticationError is raised."
"multiprocessing.connection.Client(address[, family[, authkey]])","Attempt to set up a connection to the listener which is using address
address, returning a Connection.
The type of the connection is determined by family argument, but this can
generally be omitted since it can usually be inferred from the format of
address. (See Address Formats)
If authkey is given and not None, it should be a byte string and will be
used as the secret key for an HMAC-based authentication challenge. No
authentication is done if authkey is None.
AuthenticationError is raised if authentication fails.
See Authentication keys."
"multiprocessing.connection.wait(object_list, timeout=None)","Wait till an object in object_list is ready.  Returns the list of
those objects in object_list which are ready.  If timeout is a
float then the call blocks for at most that many seconds.  If
timeout is None then it will block for an unlimited period.
A negative timeout is equivalent to a zero timeout.
For both Unix and Windows, an object can appear in object_list if
it is

a readable Connection object;
a connected and readable socket.socket object; or
the sentinel attribute of a
Process object.

A connection or socket object is ready when there is data available
to be read from it, or the other end has been closed.
Unix: wait(object_list, timeout) almost equivalent
select.select(object_list, [], [], timeout).  The difference is
that, if select.select() is interrupted by a signal, it can
raise OSError with an error number of EINTR, whereas
wait() will not.
Windows: An item in object_list must either be an integer
handle which is waitable (according to the definition used by the
documentation of the Win32 function WaitForMultipleObjects())
or it can be an object with a fileno() method which returns a
socket handle or pipe handle.  (Note that pipe handles and socket
handles are not waitable handles.)

New in version 3.3."
multiprocessing.get_logger(),"Returns the logger used by multiprocessing.  If necessary, a new one
will be created.
When first created the logger has level logging.NOTSET and no
default handler. Messages sent to this logger will not by default propagate
to the root logger.
Note that on Windows child processes will only inherit the level of the
parent process’s logger – any other customization of the logger will not be
inherited."
multiprocessing.log_to_stderr(),"This function performs a call to get_logger() but in addition to
returning the logger created by get_logger, it adds a handler which sends
output to sys.stderr using format
'[%(levelname)s/%(processName)s] %(message)s'."
run(),"Method representing the process’s activity.
You may override this method in a subclass.  The standard run()
method invokes the callable object passed to the object’s constructor as
the target argument, if any, with sequential and keyword arguments taken
from the args and kwargs arguments, respectively."
start(),"Start the process’s activity.
This must be called at most once per process object.  It arranges for the
object’s run() method to be invoked in a separate process."
join([timeout]),"If the optional argument timeout is None (the default), the method
blocks until the process whose join() method is called terminates.
If timeout is a positive number, it blocks at most timeout seconds.
Note that the method returns None if its process terminates or if the
method times out.  Check the process’s exitcode to determine if
it terminated.
A process can be joined many times.
A process cannot join itself because this would cause a deadlock.  It is
an error to attempt to join a process before it has been started."
is_alive(),"Return whether the process is alive.
Roughly, a process object is alive from the moment the start()
method returns until the child process terminates."
terminate(),"Terminate the process.  On Unix this is done using the SIGTERM signal;
on Windows TerminateProcess() is used.  Note that exit handlers and
finally clauses, etc., will not be executed.
Note that descendant processes of the process will not be terminated –
they will simply become orphaned.

Warning
If this method is used when the associated process is using a pipe or
queue then the pipe or queue is liable to become corrupted and may
become unusable by other process.  Similarly, if the process has
acquired a lock or semaphore etc. then terminating it is liable to
cause other processes to deadlock."
kill(),"Same as terminate() but using the SIGKILL signal on Unix.

New in version 3.7."
close(),"Close the Process object, releasing all resources associated
with it.  ValueError is raised if the underlying process
is still running.  Once close() returns successfully, most
other methods and attributes of the Process object will
raise ValueError.

New in version 3.7."
qsize(),"Return the approximate size of the queue.  Because of
multithreading/multiprocessing semantics, this number is not reliable.
Note that this may raise NotImplementedError on Unix platforms like
Mac OS X where sem_getvalue() is not implemented."
empty(),"Return True if the queue is empty, False otherwise.  Because of
multithreading/multiprocessing semantics, this is not reliable."
full(),"Return True if the queue is full, False otherwise.  Because of
multithreading/multiprocessing semantics, this is not reliable."
"put(obj[, block[, timeout]])","Put obj into the queue.  If the optional argument block is True
(the default) and timeout is None (the default), block if necessary until
a free slot is available.  If timeout is a positive number, it blocks at
most timeout seconds and raises the queue.Full exception if no
free slot was available within that time.  Otherwise (block is
False), put an item on the queue if a free slot is immediately
available, else raise the queue.Full exception (timeout is
ignored in that case).

Changed in version 3.8: If the queue is closed, ValueError is raised instead of
AssertionError."
put_nowait(obj),"Equivalent to put(obj, False)."
"get([block[, timeout]])","Remove and return an item from the queue.  If optional args block is
True (the default) and timeout is None (the default), block if
necessary until an item is available.  If timeout is a positive number,
it blocks at most timeout seconds and raises the queue.Empty
exception if no item was available within that time.  Otherwise (block is
False), return an item if one is immediately available, else raise the
queue.Empty exception (timeout is ignored in that case).

Changed in version 3.8: If the queue is closed, ValueError is raised instead of
OSError."
get_nowait(),Equivalent to get(False).
close(),"Indicate that no more data will be put on this queue by the current
process.  The background thread will quit once it has flushed all buffered
data to the pipe.  This is called automatically when the queue is garbage
collected."
join_thread(),"Join the background thread.  This can only be used after close() has
been called.  It blocks until the background thread exits, ensuring that
all data in the buffer has been flushed to the pipe.
By default if a process is not the creator of the queue then on exit it
will attempt to join the queue’s background thread.  The process can call
cancel_join_thread() to make join_thread() do nothing."
cancel_join_thread(),"Prevent join_thread() from blocking.  In particular, this prevents
the background thread from being joined automatically when the process
exits – see join_thread().
A better name for this method might be
allow_exit_without_flush().  It is likely to cause enqueued
data to lost, and you almost certainly will not need to use it.
It is really only there if you need the current process to exit
immediately without waiting to flush enqueued data to the
underlying pipe, and you don’t care about lost data."
empty(),"Return True if the queue is empty, False otherwise."
get(),Remove and return an item from the queue.
put(item),Put item into the queue.
task_done(),"Indicate that a formerly enqueued task is complete. Used by queue
consumers.  For each get() used to fetch a task, a subsequent
call to task_done() tells the queue that the processing on the task
is complete.
If a join() is currently blocking, it will resume when all
items have been processed (meaning that a task_done() call was
received for every item that had been put() into the queue).
Raises a ValueError if called more times than there were items
placed in the queue."
join(),"Block until all items in the queue have been gotten and processed.
The count of unfinished tasks goes up whenever an item is added to the
queue.  The count goes down whenever a consumer calls
task_done() to indicate that the item was retrieved and all work on
it is complete.  When the count of unfinished tasks drops to zero,
join() unblocks."
send(obj),"Send an object to the other end of the connection which should be read
using recv().
The object must be picklable.  Very large pickles (approximately 32 MiB+,
though it depends on the OS) may raise a ValueError exception."
recv(),"Return an object sent from the other end of the connection using
send().  Blocks until there is something to receive.  Raises
EOFError if there is nothing left to receive
and the other end was closed."
fileno(),Return the file descriptor or handle used by the connection.
close(),"Close the connection.
This is called automatically when the connection is garbage collected."
poll([timeout]),"Return whether there is any data available to be read.
If timeout is not specified then it will return immediately.  If
timeout is a number then this specifies the maximum time in seconds to
block.  If timeout is None then an infinite timeout is used.
Note that multiple connection objects may be polled at once by
using multiprocessing.connection.wait()."
"send_bytes(buffer[, offset[, size]])","Send byte data from a bytes-like object as a complete message.
If offset is given then data is read from that position in buffer.  If
size is given then that many bytes will be read from buffer.  Very large
buffers (approximately 32 MiB+, though it depends on the OS) may raise a
ValueError exception"
recv_bytes([maxlength]),"Return a complete message of byte data sent from the other end of the
connection as a string.  Blocks until there is something to receive.
Raises EOFError if there is nothing left
to receive and the other end has closed.
If maxlength is specified and the message is longer than maxlength
then OSError is raised and the connection will no longer be
readable.

Changed in version 3.3: This function used to raise IOError, which is now an
alias of OSError."
"recv_bytes_into(buffer[, offset])","Read into buffer a complete message of byte data sent from the other end
of the connection and return the number of bytes in the message.  Blocks
until there is something to receive.  Raises
EOFError if there is nothing left to receive and the other end was
closed.
buffer must be a writable bytes-like object.  If
offset is given then the message will be written into the buffer from
that position.  Offset must be a non-negative integer less than the
length of buffer (in bytes).
If the buffer is too short then a BufferTooShort exception is
raised and the complete message is available as e.args[0] where e
is the exception instance."
"acquire(block=True, timeout=None)","Acquire a lock, blocking or non-blocking.
With the block argument set to True (the default), the method call
will block until the lock is in an unlocked state, then set it to locked
and return True.  Note that the name of this first argument differs
from that in threading.Lock.acquire().
With the block argument set to False, the method call does not
block.  If the lock is currently in a locked state, return False;
otherwise set the lock to a locked state and return True.
When invoked with a positive, floating-point value for timeout, block
for at most the number of seconds specified by timeout as long as
the lock can not be acquired.  Invocations with a negative value for
timeout are equivalent to a timeout of zero.  Invocations with a
timeout value of None (the default) set the timeout period to
infinite.  Note that the treatment of negative or None values for
timeout differs from the implemented behavior in
threading.Lock.acquire().  The timeout argument has no practical
implications if the block argument is set to False and is thus
ignored.  Returns True if the lock has been acquired or False if
the timeout period has elapsed."
release(),"Release a lock.  This can be called from any process or thread, not only
the process or thread which originally acquired the lock.
Behavior is the same as in threading.Lock.release() except that
when invoked on an unlocked lock, a ValueError is raised."
"acquire(block=True, timeout=None)","Acquire a lock, blocking or non-blocking.
When invoked with the block argument set to True, block until the
lock is in an unlocked state (not owned by any process or thread) unless
the lock is already owned by the current process or thread.  The current
process or thread then takes ownership of the lock (if it does not
already have ownership) and the recursion level inside the lock increments
by one, resulting in a return value of True.  Note that there are
several differences in this first argument’s behavior compared to the
implementation of threading.RLock.acquire(), starting with the name
of the argument itself.
When invoked with the block argument set to False, do not block.
If the lock has already been acquired (and thus is owned) by another
process or thread, the current process or thread does not take ownership
and the recursion level within the lock is not changed, resulting in
a return value of False.  If the lock is in an unlocked state, the
current process or thread takes ownership and the recursion level is
incremented, resulting in a return value of True.
Use and behaviors of the timeout argument are the same as in
Lock.acquire().  Note that some of these behaviors of timeout
differ from the implemented behaviors in threading.RLock.acquire()."
release(),"Release a lock, decrementing the recursion level.  If after the
decrement the recursion level is zero, reset the lock to unlocked (not
owned by any process or thread) and if any other processes or threads
are blocked waiting for the lock to become unlocked, allow exactly one
of them to proceed.  If after the decrement the recursion level is still
nonzero, the lock remains locked and owned by the calling process or
thread.
Only call this method when the calling process or thread owns the lock.
An AssertionError is raised if this method is called by a process
or thread other than the owner or if the lock is in an unlocked (unowned)
state.  Note that the type of exception raised in this situation
differs from the implemented behavior in threading.RLock.release()."
"start([initializer[, initargs]])","Start a subprocess to start the manager.  If initializer is not None
then the subprocess will call initializer(*initargs) when it starts."
get_server(),"Returns a Server object which represents the actual server under
the control of the Manager. The Server object supports the
serve_forever() method:
>>> from multiprocessing.managers import BaseManager
>>> manager = BaseManager(address=('', 50000), authkey=b'abc')
>>> server = manager.get_server()
>>> server.serve_forever()


Server additionally has an address attribute."
connect(),"Connect a local manager object to a remote manager process:
>>> from multiprocessing.managers import BaseManager
>>> m = BaseManager(address=('127.0.0.1', 50000), authkey=b'abc')
>>> m.connect()"
shutdown(),"Stop the process used by the manager.  This is only available if
start() has been used to start the server process.
This can be called multiple times."
"register(typeid[, callable[, proxytype[, exposed[, method_to_typeid[, create_method]]]]])","A classmethod which can be used for registering a type or callable with
the manager class.
typeid is a “type identifier” which is used to identify a particular
type of shared object.  This must be a string.
callable is a callable used for creating objects for this type
identifier.  If a manager instance will be connected to the
server using the connect() method, or if the
create_method argument is False then this can be left as
None.
proxytype is a subclass of BaseProxy which is used to create
proxies for shared objects with this typeid.  If None then a proxy
class is created automatically.
exposed is used to specify a sequence of method names which proxies for
this typeid should be allowed to access using
BaseProxy._callmethod().  (If exposed is None then
proxytype._exposed_ is used instead if it exists.)  In the case
where no exposed list is specified, all “public methods” of the shared
object will be accessible.  (Here a “public method” means any attribute
which has a __call__() method and whose name does not begin
with '_'.)
method_to_typeid is a mapping used to specify the return type of those
exposed methods which should return a proxy.  It maps method names to
typeid strings.  (If method_to_typeid is None then
proxytype._method_to_typeid_ is used instead if it exists.)  If a
method’s name is not a key of this mapping or if the mapping is None
then the object returned by the method will be copied by value.
create_method determines whether a method should be created with name
typeid which can be used to tell the server process to create a new
shared object and return a proxy for it.  By default it is True."
"Barrier(parties[, action[, timeout]])","Create a shared threading.Barrier object and return a
proxy for it.

New in version 3.3."
BoundedSemaphore([value]),"Create a shared threading.BoundedSemaphore object and return a
proxy for it."
Condition([lock]),"Create a shared threading.Condition object and return a proxy for
it.
If lock is supplied then it should be a proxy for a
threading.Lock or threading.RLock object.

Changed in version 3.3: The wait_for() method was added."
Event(),Create a shared threading.Event object and return a proxy for it.
Lock(),Create a shared threading.Lock object and return a proxy for it.
Namespace(),Create a shared Namespace object and return a proxy for it.
Queue([maxsize]),Create a shared queue.Queue object and return a proxy for it.
RLock(),Create a shared threading.RLock object and return a proxy for it.
Semaphore([value]),"Create a shared threading.Semaphore object and return a proxy for
it."
"Array(typecode, sequence)",Create an array and return a proxy for it.
"Value(typecode, value)","Create an object with a writable value attribute and return a proxy
for it."
dict(),Create a shared dict object and return a proxy for it.
list(),Create a shared list object and return a proxy for it.
"_callmethod(methodname[, args[, kwds]])","Call and return the result of a method of the proxy’s referent.
If proxy is a proxy whose referent is obj then the expression
proxy._callmethod(methodname, args, kwds)


will evaluate the expression
getattr(obj, methodname)(*args, **kwds)


in the manager’s process.
The returned value will be a copy of the result of the call or a proxy to
a new shared object – see documentation for the method_to_typeid
argument of BaseManager.register().
If an exception is raised by the call, then is re-raised by
_callmethod().  If some other exception is raised in the manager’s
process then this is converted into a RemoteError exception and is
raised by _callmethod().
Note in particular that an exception will be raised if methodname has
not been exposed.
An example of the usage of _callmethod():
>>> l = manager.list(range(10))
>>> l._callmethod('__len__')
10
>>> l._callmethod('__getitem__', (slice(2, 7),)) # equivalent to l[2:7]
[2, 3, 4, 5, 6]
>>> l._callmethod('__getitem__', (20,))          # equivalent to l[20]
Traceback (most recent call last):
...
IndexError: list index out of range"
_getvalue(),"Return a copy of the referent.
If the referent is unpicklable then this will raise an exception."
__repr__(),Return a representation of the proxy object.
__str__(),Return the representation of the referent.
"apply(func[, args[, kwds]])","Call func with arguments args and keyword arguments kwds.  It blocks
until the result is ready. Given this blocks, apply_async() is
better suited for performing work in parallel. Additionally, func
is only executed in one of the workers of the pool."
"apply_async(func[, args[, kwds[, callback[, error_callback]]]])","A variant of the apply() method which returns a result object.
If callback is specified then it should be a callable which accepts a
single argument.  When the result becomes ready callback is applied to
it, that is unless the call failed, in which case the error_callback
is applied instead.
If error_callback is specified then it should be a callable which
accepts a single argument.  If the target function fails, then
the error_callback is called with the exception instance.
Callbacks should complete immediately since otherwise the thread which
handles the results will get blocked."
"map(func, iterable[, chunksize])","A parallel equivalent of the map() built-in function (it supports only
one iterable argument though, for multiple iterables see starmap()).
It blocks until the result is ready.
This method chops the iterable into a number of chunks which it submits to
the process pool as separate tasks.  The (approximate) size of these
chunks can be specified by setting chunksize to a positive integer.
Note that it may cause high memory usage for very long iterables. Consider
using imap() or imap_unordered() with explicit chunksize
option for better efficiency."
"map_async(func, iterable[, chunksize[, callback[, error_callback]]])","A variant of the map() method which returns a result object.
If callback is specified then it should be a callable which accepts a
single argument.  When the result becomes ready callback is applied to
it, that is unless the call failed, in which case the error_callback
is applied instead.
If error_callback is specified then it should be a callable which
accepts a single argument.  If the target function fails, then
the error_callback is called with the exception instance.
Callbacks should complete immediately since otherwise the thread which
handles the results will get blocked."
"imap(func, iterable[, chunksize])","A lazier version of map().
The chunksize argument is the same as the one used by the map()
method.  For very long iterables using a large value for chunksize can
make the job complete much faster than using the default value of
1.
Also if chunksize is 1 then the next() method of the iterator
returned by the imap() method has an optional timeout parameter:
next(timeout) will raise multiprocessing.TimeoutError if the
result cannot be returned within timeout seconds."
"imap_unordered(func, iterable[, chunksize])","The same as imap() except that the ordering of the results from the
returned iterator should be considered arbitrary.  (Only when there is
only one worker process is the order guaranteed to be “correct”.)"
"starmap(func, iterable[, chunksize])","Like map() except that the elements of the iterable are expected
to be iterables that are unpacked as arguments.
Hence an iterable of [(1,2), (3, 4)] results in [func(1,2),
func(3,4)].

New in version 3.3."
"starmap_async(func, iterable[, chunksize[, callback[, error_callback]]])","A combination of starmap() and map_async() that iterates over
iterable of iterables and calls func with the iterables unpacked.
Returns a result object.

New in version 3.3."
close(),"Prevents any more tasks from being submitted to the pool.  Once all the
tasks have been completed the worker processes will exit."
terminate(),"Stops the worker processes immediately without completing outstanding
work.  When the pool object is garbage collected terminate() will be
called immediately."
join(),"Wait for the worker processes to exit.  One must call close() or
terminate() before using join()."
get([timeout]),"Return the result when it arrives.  If timeout is not None and the
result does not arrive within timeout seconds then
multiprocessing.TimeoutError is raised.  If the remote call raised
an exception then that exception will be reraised by get()."
wait([timeout]),Wait until the result is available or until timeout seconds pass.
ready(),Return whether the call has completed.
successful(),"Return whether the call completed without raising an exception.  Will
raise ValueError if the result is not ready.

Changed in version 3.7: If the result is not ready, ValueError is raised instead of
AssertionError."
accept(),"Accept a connection on the bound socket or named pipe of the listener
object and return a Connection object.
If authentication is attempted and fails, then
AuthenticationError is raised."
close(),"Close the bound socket or named pipe of the listener object.  This is
called automatically when the listener is garbage collected.  However it
is advisable to call it explicitly."
close(),"Closes access to the shared memory from this instance.  In order to
ensure proper cleanup of resources, all instances should call
close() once the instance is no longer needed.  Note that calling
close() does not cause the shared memory block itself to be
destroyed."
unlink(),"Requests that the underlying shared memory block be destroyed.  In
order to ensure proper cleanup of resources, unlink() should be
called once (and only once) across all processes which have need
for the shared memory block.  After requesting its destruction, a
shared memory block may or may not be immediately destroyed and
this behavior may differ across platforms.  Attempts to access data
inside the shared memory block after unlink() has been called may
result in memory access errors.  Note: the last process relinquishing
its hold on a shared memory block may call unlink() and
close() in either order."
SharedMemory(size),"Create and return a new SharedMemory object with the
specified size in bytes."
ShareableList(sequence),"Create and return a new ShareableList object, initialized
by the values from the input sequence."
count(value),Returns the number of occurrences of value.
index(value),"Returns first index position of value.  Raises ValueError if
value is not present."
"concurrent.futures.wait(fs, timeout=None, return_when=ALL_COMPLETED)","Wait for the Future instances (possibly created by different
Executor instances) given by fs to complete.  Returns a named
2-tuple of sets.  The first set, named done, contains the futures that
completed (finished or cancelled futures) before the wait completed.  The
second set, named not_done, contains the futures that did not complete
(pending or running futures).
timeout can be used to control the maximum number of seconds to wait before
returning.  timeout can be an int or float.  If timeout is not specified
or None, there is no limit to the wait time.
return_when indicates when this function should return.  It must be one of
the following constants:






Constant
Description



FIRST_COMPLETED
The function will return when any
future finishes or is cancelled.

FIRST_EXCEPTION
The function will return when any
future finishes by raising an
exception.  If no future raises an
exception then it is equivalent to
ALL_COMPLETED.

ALL_COMPLETED
The function will return when all
futures finish or are cancelled."
"concurrent.futures.as_completed(fs, timeout=None)","Returns an iterator over the Future instances (possibly created by
different Executor instances) given by fs that yields futures as
they complete (finished or cancelled futures). Any futures given by fs that
are duplicated will be returned once. Any futures that completed before
as_completed() is called will be yielded first.  The returned iterator
raises a concurrent.futures.TimeoutError if __next__()
is called and the result isn’t available after timeout seconds from the
original call to as_completed().  timeout can be an int or float. If
timeout is not specified or None, there is no limit to the wait time."
"submit(fn, *args, **kwargs)","Schedules the callable, fn, to be executed as fn(*args **kwargs)
and returns a Future object representing the execution of the
callable.
with ThreadPoolExecutor(max_workers=1) as executor:
    future = executor.submit(pow, 323, 1235)
    print(future.result())"
"map(func, *iterables, timeout=None, chunksize=1)","Similar to map(func, *iterables) except:

the iterables are collected immediately rather than lazily;
func is executed asynchronously and several calls to
func may be made concurrently.

The returned iterator raises a concurrent.futures.TimeoutError
if __next__() is called and the result isn’t available
after timeout seconds from the original call to Executor.map().
timeout can be an int or a float.  If timeout is not specified or
None, there is no limit to the wait time.
If a func call raises an exception, then that exception will be
raised when its value is retrieved from the iterator.
When using ProcessPoolExecutor, this method chops iterables
into a number of chunks which it submits to the pool as separate
tasks.  The (approximate) size of these chunks can be specified by
setting chunksize to a positive integer.  For very long iterables,
using a large value for chunksize can significantly improve
performance compared to the default size of 1.  With
ThreadPoolExecutor, chunksize has no effect.

Changed in version 3.5: Added the chunksize argument."
shutdown(wait=True),"Signal the executor that it should free any resources that it is using
when the currently pending futures are done executing.  Calls to
Executor.submit() and Executor.map() made after shutdown will
raise RuntimeError.
If wait is True then this method will not return until all the
pending futures are done executing and the resources associated with the
executor have been freed.  If wait is False then this method will
return immediately and the resources associated with the executor will be
freed when all pending futures are done executing.  Regardless of the
value of wait, the entire Python program will not exit until all
pending futures are done executing.
You can avoid having to call this method explicitly if you use the
with statement, which will shutdown the Executor
(waiting as if Executor.shutdown() were called with wait set to
True):
import shutil
with ThreadPoolExecutor(max_workers=4) as e:
    e.submit(shutil.copy, 'src1.txt', 'dest1.txt')
    e.submit(shutil.copy, 'src2.txt', 'dest2.txt')
    e.submit(shutil.copy, 'src3.txt', 'dest3.txt')
    e.submit(shutil.copy, 'src4.txt', 'dest4.txt')"
cancel(),"Attempt to cancel the call.  If the call is currently being executed or
finished running and cannot be cancelled then the method will return
False, otherwise the call will be cancelled and the method will
return True."
cancelled(),Return True if the call was successfully cancelled.
running(),"Return True if the call is currently being executed and cannot be
cancelled."
done(),"Return True if the call was successfully cancelled or finished
running."
result(timeout=None),"Return the value returned by the call. If the call hasn’t yet completed
then this method will wait up to timeout seconds.  If the call hasn’t
completed in timeout seconds, then a
concurrent.futures.TimeoutError will be raised. timeout can be
an int or float.  If timeout is not specified or None, there is no
limit to the wait time.
If the future is cancelled before completing then CancelledError
will be raised.
If the call raised, this method will raise the same exception."
exception(timeout=None),"Return the exception raised by the call.  If the call hasn’t yet
completed then this method will wait up to timeout seconds.  If the
call hasn’t completed in timeout seconds, then a
concurrent.futures.TimeoutError will be raised.  timeout can be
an int or float.  If timeout is not specified or None, there is no
limit to the wait time.
If the future is cancelled before completing then CancelledError
will be raised.
If the call completed without raising, None is returned."
add_done_callback(fn),"Attaches the callable fn to the future.  fn will be called, with the
future as its only argument, when the future is cancelled or finishes
running.
Added callables are called in the order that they were added and are
always called in a thread belonging to the process that added them.  If
the callable raises an Exception subclass, it will be logged and
ignored.  If the callable raises a BaseException subclass, the
behavior is undefined.
If the future has already completed or been cancelled, fn will be
called immediately."
set_running_or_notify_cancel(),"This method should only be called by Executor implementations
before executing the work associated with the Future and by unit
tests.
If the method returns False then the Future was cancelled,
i.e. Future.cancel() was called and returned True.  Any threads
waiting on the Future completing (i.e. through
as_completed() or wait()) will be woken up.
If the method returns True then the Future was not cancelled
and has been put in the running state, i.e. calls to
Future.running() will return True.
This method can only be called once and cannot be called after
Future.set_result() or Future.set_exception() have been
called."
set_result(result),"Sets the result of the work associated with the Future to
result.
This method should only be used by Executor implementations and
unit tests.

Changed in version 3.8: This method raises
concurrent.futures.InvalidStateError if the Future is
already done."
set_exception(exception),"Sets the result of the work associated with the Future to the
Exception exception.
This method should only be used by Executor implementations and
unit tests.

Changed in version 3.8: This method raises
concurrent.futures.InvalidStateError if the Future is
already done."
"subprocess.run(args, *, stdin=None, input=None, stdout=None, stderr=None, capture_output=False, shell=False, cwd=None, timeout=None, check=False, encoding=None, errors=None, text=None, env=None, universal_newlines=None)","Run the command described by args.  Wait for command to complete, then
return a CompletedProcess instance.
The arguments shown above are merely the most common ones, described below
in Frequently Used Arguments (hence the use of keyword-only notation
in the abbreviated signature). The full function signature is largely the
same as that of the Popen constructor - most of the arguments to
this function are passed through to that interface. (timeout,  input,
check, and capture_output are not.)
If capture_output is true, stdout and stderr will be captured.
When used, the internal Popen object is automatically created with
stdout=PIPE and stderr=PIPE. The stdout and stderr arguments may
not be supplied at the same time as capture_output.  If you wish to capture
and combine both streams into one, use stdout=PIPE and stderr=STDOUT
instead of capture_output.
The timeout argument is passed to Popen.communicate(). If the timeout
expires, the child process will be killed and waited for.  The
TimeoutExpired exception will be re-raised after the child process
has terminated.
The input argument is passed to Popen.communicate() and thus to the
subprocess’s stdin.  If used it must be a byte sequence, or a string if
encoding or errors is specified or text is true.  When
used, the internal Popen object is automatically created with
stdin=PIPE, and the stdin argument may not be used as well.
If check is true, and the process exits with a non-zero exit code, a
CalledProcessError exception will be raised. Attributes of that
exception hold the arguments, the exit code, and stdout and stderr if they
were captured.
If encoding or errors are specified, or text is true,
file objects for stdin, stdout and stderr are opened in text mode using the
specified encoding and errors or the io.TextIOWrapper default.
The universal_newlines argument is equivalent  to text and is provided
for backwards compatibility. By default, file objects are opened in binary mode.
If env is not None, it must be a mapping that defines the environment
variables for the new process; these are used instead of the default
behavior of inheriting the current process’ environment. It is passed directly
to Popen.
Examples:
>>> subprocess.run([""ls"", ""-l""])  # doesn't capture output
CompletedProcess(args=['ls', '-l'], returncode=0)

>>> subprocess.run(""exit 1"", shell=True, check=True)
Traceback (most recent call last):
  ...
subprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1

>>> subprocess.run([""ls"", ""-l"", ""/dev/null""], capture_output=True)
CompletedProcess(args=['ls', '-l', '/dev/null'], returncode=0,
stdout=b'crw-rw-rw- 1 root root 1, 3 Jan 23 16:23 /dev/null\n', stderr=b'')



New in version 3.5.


Changed in version 3.6: Added encoding and errors parameters


Changed in version 3.7: Added the text parameter, as a more understandable alias of universal_newlines.
Added the capture_output parameter."
"subprocess.call(args, *, stdin=None, stdout=None, stderr=None, shell=False, cwd=None, timeout=None)","Run the command described by args.  Wait for command to complete, then
return the returncode attribute.
Code needing to capture stdout or stderr should use run() instead:
run(...).returncode


To suppress stdout or stderr, supply a value of DEVNULL.
The arguments shown above are merely some common ones.
The full function signature is the
same as that of the Popen constructor - this function passes all
supplied arguments other than timeout directly through to that interface.

Note
Do not use stdout=PIPE or stderr=PIPE with this
function.  The child process will block if it generates enough
output to a pipe to fill up the OS pipe buffer as the pipes are
not being read from.


Changed in version 3.3: timeout was added."
"subprocess.check_call(args, *, stdin=None, stdout=None, stderr=None, shell=False, cwd=None, timeout=None)","Run command with arguments.  Wait for command to complete. If the return
code was zero then return, otherwise raise CalledProcessError. The
CalledProcessError object will have the return code in the
returncode attribute.
Code needing to capture stdout or stderr should use run() instead:
run(..., check=True)


To suppress stdout or stderr, supply a value of DEVNULL.
The arguments shown above are merely some common ones.
The full function signature is the
same as that of the Popen constructor - this function passes all
supplied arguments other than timeout directly through to that interface.

Note
Do not use stdout=PIPE or stderr=PIPE with this
function.  The child process will block if it generates enough
output to a pipe to fill up the OS pipe buffer as the pipes are
not being read from.


Changed in version 3.3: timeout was added."
"subprocess.check_output(args, *, stdin=None, stderr=None, shell=False, cwd=None, encoding=None, errors=None, universal_newlines=None, timeout=None, text=None)","Run command with arguments and return its output.
If the return code was non-zero it raises a CalledProcessError. The
CalledProcessError object will have the return code in the
returncode attribute and any output in the
output attribute.
This is equivalent to:
run(..., check=True, stdout=PIPE).stdout


The arguments shown above are merely some common ones.
The full function signature is largely the same as that of run() -
most arguments are passed directly through to that interface.
However, explicitly passing input=None to inherit the parent’s
standard input file handle is not supported.
By default, this function will return the data as encoded bytes. The actual
encoding of the output data may depend on the command being invoked, so the
decoding to text will often need to be handled at the application level.
This behaviour may be overridden by setting text, encoding, errors,
or universal_newlines to True as described in
Frequently Used Arguments and run().
To also capture standard error in the result, use
stderr=subprocess.STDOUT:
>>> subprocess.check_output(
...     ""ls non_existent_file; exit 0"",
...     stderr=subprocess.STDOUT,
...     shell=True)
'ls: non_existent_file: No such file or directory\n'



New in version 3.1.


Changed in version 3.3: timeout was added.


Changed in version 3.4: Support for the input keyword argument was added.


Changed in version 3.6: encoding and errors were added.  See run() for details.


New in version 3.7: text was added as a more readable alias for universal_newlines."
subprocess.getstatusoutput(cmd),"Return (exitcode, output) of executing cmd in a shell.
Execute the string cmd in a shell with Popen.check_output() and
return a 2-tuple (exitcode, output). The locale encoding is used;
see the notes on Frequently Used Arguments for more details.
A trailing newline is stripped from the output.
The exit code for the command can be interpreted as the return code
of subprocess.  Example:
>>> subprocess.getstatusoutput('ls /bin/ls')
(0, '/bin/ls')
>>> subprocess.getstatusoutput('cat /bin/junk')
(1, 'cat: /bin/junk: No such file or directory')
>>> subprocess.getstatusoutput('/bin/junk')
(127, 'sh: /bin/junk: not found')
>>> subprocess.getstatusoutput('/bin/kill $$')
(-15, '')


Availability: POSIX & Windows.

Changed in version 3.3.4: Windows support was added.
The function now returns (exitcode, output) instead of (status, output)
as it did in Python 3.3.3 and earlier.  exitcode has the same value as
returncode."
subprocess.getoutput(cmd),"Return output (stdout and stderr) of executing cmd in a shell.
Like getstatusoutput(), except the exit code is ignored and the return
value is a string containing the command’s output.  Example:
>>> subprocess.getoutput('ls /bin/ls')
'/bin/ls'


Availability: POSIX & Windows.

Changed in version 3.3.4: Windows support added"
check_returncode(),"If returncode is non-zero, raise a CalledProcessError."
Popen.poll(),"Check if child process has terminated.  Set and return
returncode attribute. Otherwise, returns None."
Popen.wait(timeout=None),"Wait for child process to terminate.  Set and return
returncode attribute.
If the process does not terminate after timeout seconds, raise a
TimeoutExpired exception.  It is safe to catch this exception and
retry the wait.

Note
This will deadlock when using stdout=PIPE or stderr=PIPE
and the child process generates enough output to a pipe such that
it blocks waiting for the OS pipe buffer to accept more data.
Use Popen.communicate() when using pipes to avoid that.


Note
The function is implemented using a busy loop (non-blocking call and
short sleeps). Use the asyncio module for an asynchronous wait:
see asyncio.create_subprocess_exec.


Changed in version 3.3: timeout was added."
"Popen.communicate(input=None, timeout=None)","Interact with process: Send data to stdin.  Read data from stdout and stderr,
until end-of-file is reached.  Wait for process to terminate.  The optional
input argument should be data to be sent to the child process, or
None, if no data should be sent to the child.  If streams were opened in
text mode, input must be a string.  Otherwise, it must be bytes.
communicate() returns a tuple (stdout_data, stderr_data).
The data will be strings if streams were opened in text mode; otherwise,
bytes.
Note that if you want to send data to the process’s stdin, you need to create
the Popen object with stdin=PIPE.  Similarly, to get anything other than
None in the result tuple, you need to give stdout=PIPE and/or
stderr=PIPE too.
If the process does not terminate after timeout seconds, a
TimeoutExpired exception will be raised.  Catching this exception and
retrying communication will not lose any output.
The child process is not killed if the timeout expires, so in order to
cleanup properly a well-behaved application should kill the child process and
finish communication:
proc = subprocess.Popen(...)
try:
    outs, errs = proc.communicate(timeout=15)
except TimeoutExpired:
    proc.kill()
    outs, errs = proc.communicate()



Note
The data read is buffered in memory, so do not use this method if the data
size is large or unlimited.


Changed in version 3.3: timeout was added."
Popen.send_signal(signal),"Sends the signal signal to the child.

Note
On Windows, SIGTERM is an alias for terminate(). CTRL_C_EVENT and
CTRL_BREAK_EVENT can be sent to processes started with a creationflags
parameter which includes CREATE_NEW_PROCESS_GROUP."
Popen.terminate(),"Stop the child. On Posix OSs the method sends SIGTERM to the
child. On Windows the Win32 API function TerminateProcess() is called
to stop the child."
Popen.kill(),"Kills the child. On Posix OSs the function sends SIGKILL to the child.
On Windows kill() is an alias for terminate()."
"scheduler.enterabs(time, priority, action, argument=(), kwargs={})","Schedule a new event. The time argument should be a numeric type compatible
with the return value of the timefunc function passed  to the constructor.
Events scheduled for the same time will be executed in the order of their
priority. A lower number represents a higher priority.
Executing the event means executing action(*argument, **kwargs).
argument is a sequence holding the positional arguments for action.
kwargs is a dictionary holding the keyword arguments for action.
Return value is an event which may be used for later cancellation of the event
(see cancel()).

Changed in version 3.3: argument parameter is optional.


Changed in version 3.3: kwargs parameter was added."
"scheduler.enter(delay, priority, action, argument=(), kwargs={})","Schedule an event for delay more time units. Other than the relative time, the
other arguments, the effect and the return value are the same as those for
enterabs().

Changed in version 3.3: argument parameter is optional.


Changed in version 3.3: kwargs parameter was added."
scheduler.cancel(event),"Remove the event from the queue. If event is not an event currently in the
queue, this method will raise a ValueError."
scheduler.empty(),Return True if the event queue is empty.
scheduler.run(blocking=True),"Run all scheduled events. This method will wait  (using the delayfunc()
function passed to the constructor) for the next event, then execute it and so
on until there are no more scheduled events.
If blocking is false executes the scheduled events due to expire soonest
(if any) and then return the deadline of the next scheduled call in the
scheduler (if any).
Either action or delayfunc can raise an exception.  In either case, the
scheduler will maintain a consistent state and propagate the exception.  If an
exception is raised by action, the event will not be attempted in future calls
to run().
If a sequence of events takes longer to run than the time available before the
next event, the scheduler will simply fall behind.  No events will be dropped;
the calling code is responsible for canceling  events which are no longer
pertinent.

Changed in version 3.3: blocking parameter was added."
Queue.qsize(),"Return the approximate size of the queue.  Note, qsize() > 0 doesn’t
guarantee that a subsequent get() will not block, nor will qsize() < maxsize
guarantee that put() will not block."
Queue.empty(),"Return True if the queue is empty, False otherwise.  If empty()
returns True it doesn’t guarantee that a subsequent call to put()
will not block.  Similarly, if empty() returns False it doesn’t
guarantee that a subsequent call to get() will not block."
Queue.full(),"Return True if the queue is full, False otherwise.  If full()
returns True it doesn’t guarantee that a subsequent call to get()
will not block.  Similarly, if full() returns False it doesn’t
guarantee that a subsequent call to put() will not block."
"Queue.put(item, block=True, timeout=None)","Put item into the queue. If optional args block is true and timeout is
None (the default), block if necessary until a free slot is available. If
timeout is a positive number, it blocks at most timeout seconds and raises
the Full exception if no free slot was available within that time.
Otherwise (block is false), put an item on the queue if a free slot is
immediately available, else raise the Full exception (timeout is
ignored in that case)."
Queue.put_nowait(item),"Equivalent to put(item, False)."
"Queue.get(block=True, timeout=None)","Remove and return an item from the queue. If optional args block is true and
timeout is None (the default), block if necessary until an item is available.
If timeout is a positive number, it blocks at most timeout seconds and
raises the Empty exception if no item was available within that time.
Otherwise (block is false), return an item if one is immediately available,
else raise the Empty exception (timeout is ignored in that case).
Prior to 3.0 on POSIX systems, and for all versions on Windows, if
block is true and timeout is None, this operation goes into
an uninterruptible wait on an underlying lock. This means that no exceptions
can occur, and in particular a SIGINT will not trigger a KeyboardInterrupt."
Queue.get_nowait(),Equivalent to get(False).
Queue.task_done(),"Indicate that a formerly enqueued task is complete.  Used by queue consumer
threads.  For each get() used to fetch a task, a subsequent call to
task_done() tells the queue that the processing on the task is complete.
If a join() is currently blocking, it will resume when all items have been
processed (meaning that a task_done() call was received for every item
that had been put() into the queue).
Raises a ValueError if called more times than there were items placed in
the queue."
Queue.join(),"Blocks until all items in the queue have been gotten and processed.
The count of unfinished tasks goes up whenever an item is added to the queue.
The count goes down whenever a consumer thread calls task_done() to
indicate that the item was retrieved and all work on it is complete. When the
count of unfinished tasks drops to zero, join() unblocks."
SimpleQueue.qsize(),"Return the approximate size of the queue.  Note, qsize() > 0 doesn’t
guarantee that a subsequent get() will not block."
SimpleQueue.empty(),"Return True if the queue is empty, False otherwise. If empty()
returns False it doesn’t guarantee that a subsequent call to get()
will not block."
"SimpleQueue.put(item, block=True, timeout=None)","Put item into the queue.  The method never blocks and always succeeds
(except for potential low-level errors such as failure to allocate memory).
The optional args block and timeout are ignored and only provided
for compatibility with Queue.put().

CPython implementation detail: This method has a C implementation which is reentrant.  That is, a
put() or get() call can be interrupted by another put()
call in the same thread without deadlocking or corrupting internal
state inside the queue.  This makes it appropriate for use in
destructors such as __del__ methods or weakref callbacks."
SimpleQueue.put_nowait(item),"Equivalent to put(item), provided for compatibility with
Queue.put_nowait()."
"SimpleQueue.get(block=True, timeout=None)","Remove and return an item from the queue.  If optional args block is true and
timeout is None (the default), block if necessary until an item is available.
If timeout is a positive number, it blocks at most timeout seconds and
raises the Empty exception if no item was available within that time.
Otherwise (block is false), return an item if one is immediately available,
else raise the Empty exception (timeout is ignored in that case)."
SimpleQueue.get_nowait(),Equivalent to get(False).
"_thread.start_new_thread(function, args[, kwargs])","Start a new thread and return its identifier.  The thread executes the
function function with the argument list args (which must be a tuple).
The optional kwargs argument specifies a dictionary of keyword arguments.
When the function returns, the thread silently exits.
When the function terminates with an unhandled exception,
sys.unraisablehook() is called to handle the exception. The object
attribute of the hook argument is function. By default, a stack trace is
printed and then the thread exits (but other threads continue to run).
When the function raises a SystemExit exception, it is silently
ignored.

Changed in version 3.8: sys.unraisablehook() is now used to handle unhandled exceptions."
_thread.interrupt_main(),"Simulate the effect of a signal.SIGINT signal arriving in the main
thread. A thread can use this function to interrupt the main thread.
If signal.SIGINT isn’t handled by Python (it was set to
signal.SIG_DFL or signal.SIG_IGN), this function does
nothing."
_thread.exit(),"Raise the SystemExit exception.  When not caught, this will cause the
thread to exit silently."
_thread.allocate_lock(),"Return a new lock object.  Methods of locks are described below.  The lock is
initially unlocked."
_thread.get_ident(),"Return the ‘thread identifier’ of the current thread.  This is a nonzero
integer.  Its value has no direct meaning; it is intended as a magic cookie to
be used e.g. to index a dictionary of thread-specific data.  Thread identifiers
may be recycled when a thread exits and another thread is created."
_thread.get_native_id(),"Return the native integral Thread ID of the current thread assigned by the kernel.
This is a non-negative integer.
Its value may be used to uniquely identify this particular thread system-wide
(until the thread terminates, after which the value may be recycled by the OS).
Availability: Windows, FreeBSD, Linux, macOS, OpenBSD, NetBSD, AIX.

New in version 3.8."
_thread.stack_size([size]),"Return the thread stack size used when creating new threads.  The optional
size argument specifies the stack size to be used for subsequently created
threads, and must be 0 (use platform or configured default) or a positive
integer value of at least 32,768 (32 KiB). If size is not specified,
0 is used.  If changing the thread stack size is
unsupported, a RuntimeError is raised.  If the specified stack size is
invalid, a ValueError is raised and the stack size is unmodified.  32 KiB
is currently the minimum supported stack size value to guarantee sufficient
stack space for the interpreter itself.  Note that some platforms may have
particular restrictions on values for the stack size, such as requiring a
minimum stack size > 32 KiB or requiring allocation in multiples of the system
memory page size - platform documentation should be referred to for more
information (4 KiB pages are common; using multiples of 4096 for the stack size is
the suggested approach in the absence of more specific information).
Availability: Windows, systems with POSIX threads."
"lock.acquire(waitflag=1, timeout=-1)","Without any optional argument, this method acquires the lock unconditionally, if
necessary waiting until it is released by another thread (only one thread at a
time can acquire a lock — that’s their reason for existence).
If the integer waitflag argument is present, the action depends on its
value: if it is zero, the lock is only acquired if it can be acquired
immediately without waiting, while if it is nonzero, the lock is acquired
unconditionally as above.
If the floating-point timeout argument is present and positive, it
specifies the maximum wait time in seconds before returning.  A negative
timeout argument specifies an unbounded wait.  You cannot specify
a timeout if waitflag is zero.
The return value is True if the lock is acquired successfully,
False if not.

Changed in version 3.2: The timeout parameter is new.


Changed in version 3.2: Lock acquires can now be interrupted by signals on POSIX."
lock.release(),"Releases the lock.  The lock must have been acquired earlier, but not
necessarily by the same thread."
lock.locked(),"Return the status of the lock: True if it has been acquired by some thread,
False if not."
contextvars.copy_context(),"Returns a copy of the current Context object.
The following snippet gets a copy of the current context and prints
all variables and their values that are set in it:
ctx: Context = copy_context()
print(list(ctx.items()))


The function has an O(1) complexity, i.e. works equally fast for
contexts with a few context variables and for contexts that have
a lot of them."
get([default]),"Return a value for the context variable for the current context.
If there is no value for the variable in the current context,
the method will:

return the value of the default argument of the method,
if provided; or
return the default value for the context variable,
if it was created with one; or
raise a LookupError."
set(value),"Call to set a new value for the context variable in the current
context.
The required value argument is the new value for the context
variable.
Returns a Token object that can be used
to restore the variable to its previous value via the
ContextVar.reset() method."
reset(token),"Reset the context variable to the value it had before the
ContextVar.set() that created the token was used.
For example:
var = ContextVar('var')

token = var.set('new value')
# code that uses 'var'; var.get() returns 'new value'.
var.reset(token)

# After the reset call the var has no value again, so
# var.get() would raise a LookupError."
"run(callable, *args, **kwargs)","Execute callable(*args, **kwargs) code in the context object
the run method is called on.  Return the result of the execution
or propagate an exception if one occurred.
Any changes to any context variables that callable makes will
be contained in the context object:
var = ContextVar('var')
var.set('spam')

def main():
    # 'var' was set to 'spam' before
    # calling 'copy_context()' and 'ctx.run(main)', so:
    # var.get() == ctx[var] == 'spam'

    var.set('ham')

    # Now, after setting 'var' to 'ham':
    # var.get() == ctx[var] == 'ham'

ctx = copy_context()

# Any changes that the 'main' function makes to 'var'
# will be contained in 'ctx'.
ctx.run(main)

# The 'main()' function was run in the 'ctx' context,
# so changes to 'var' are contained in it:
# ctx[var] == 'ham'

# However, outside of 'ctx', 'var' is still set to 'spam':
# var.get() == 'spam'


The method raises a RuntimeError when called on the same
context object from more than one OS thread, or when called
recursively."
copy(),Return a shallow copy of the context object.
"get(var[, default])","Return the value for var if var has the value in the context
object.  Return default otherwise.  If default is not given,
return None."
keys(),Return a list of all variables in the context object.
values(),Return a list of all variables’ values in the context object.
items(),"Return a list of 2-tuples containing all variables and their
values in the context object."
contextvars.copy_context(),"Returns a copy of the current Context object.
The following snippet gets a copy of the current context and prints
all variables and their values that are set in it:
ctx: Context = copy_context()
print(list(ctx.items()))


The function has an O(1) complexity, i.e. works equally fast for
contexts with a few context variables and for contexts that have
a lot of them."
get([default]),"Return a value for the context variable for the current context.
If there is no value for the variable in the current context,
the method will:

return the value of the default argument of the method,
if provided; or
return the default value for the context variable,
if it was created with one; or
raise a LookupError."
set(value),"Call to set a new value for the context variable in the current
context.
The required value argument is the new value for the context
variable.
Returns a Token object that can be used
to restore the variable to its previous value via the
ContextVar.reset() method."
reset(token),"Reset the context variable to the value it had before the
ContextVar.set() that created the token was used.
For example:
var = ContextVar('var')

token = var.set('new value')
# code that uses 'var'; var.get() returns 'new value'.
var.reset(token)

# After the reset call the var has no value again, so
# var.get() would raise a LookupError."
"run(callable, *args, **kwargs)","Execute callable(*args, **kwargs) code in the context object
the run method is called on.  Return the result of the execution
or propagate an exception if one occurred.
Any changes to any context variables that callable makes will
be contained in the context object:
var = ContextVar('var')
var.set('spam')

def main():
    # 'var' was set to 'spam' before
    # calling 'copy_context()' and 'ctx.run(main)', so:
    # var.get() == ctx[var] == 'spam'

    var.set('ham')

    # Now, after setting 'var' to 'ham':
    # var.get() == ctx[var] == 'ham'

ctx = copy_context()

# Any changes that the 'main' function makes to 'var'
# will be contained in 'ctx'.
ctx.run(main)

# The 'main()' function was run in the 'ctx' context,
# so changes to 'var' are contained in it:
# ctx[var] == 'ham'

# However, outside of 'ctx', 'var' is still set to 'spam':
# var.get() == 'spam'


The method raises a RuntimeError when called on the same
context object from more than one OS thread, or when called
recursively."
copy(),Return a shallow copy of the context object.
"get(var[, default])","Return the value for var if var has the value in the context
object.  Return default otherwise.  If default is not given,
return None."
keys(),Return a list of all variables in the context object.
values(),Return a list of all variables’ values in the context object.
items(),"Return a list of 2-tuples containing all variables and their
values in the context object."
contextvars.copy_context(),"Returns a copy of the current Context object.
The following snippet gets a copy of the current context and prints
all variables and their values that are set in it:
ctx: Context = copy_context()
print(list(ctx.items()))


The function has an O(1) complexity, i.e. works equally fast for
contexts with a few context variables and for contexts that have
a lot of them."
get([default]),"Return a value for the context variable for the current context.
If there is no value for the variable in the current context,
the method will:

return the value of the default argument of the method,
if provided; or
return the default value for the context variable,
if it was created with one; or
raise a LookupError."
set(value),"Call to set a new value for the context variable in the current
context.
The required value argument is the new value for the context
variable.
Returns a Token object that can be used
to restore the variable to its previous value via the
ContextVar.reset() method."
reset(token),"Reset the context variable to the value it had before the
ContextVar.set() that created the token was used.
For example:
var = ContextVar('var')

token = var.set('new value')
# code that uses 'var'; var.get() returns 'new value'.
var.reset(token)

# After the reset call the var has no value again, so
# var.get() would raise a LookupError."
"run(callable, *args, **kwargs)","Execute callable(*args, **kwargs) code in the context object
the run method is called on.  Return the result of the execution
or propagate an exception if one occurred.
Any changes to any context variables that callable makes will
be contained in the context object:
var = ContextVar('var')
var.set('spam')

def main():
    # 'var' was set to 'spam' before
    # calling 'copy_context()' and 'ctx.run(main)', so:
    # var.get() == ctx[var] == 'spam'

    var.set('ham')

    # Now, after setting 'var' to 'ham':
    # var.get() == ctx[var] == 'ham'

ctx = copy_context()

# Any changes that the 'main' function makes to 'var'
# will be contained in 'ctx'.
ctx.run(main)

# The 'main()' function was run in the 'ctx' context,
# so changes to 'var' are contained in it:
# ctx[var] == 'ham'

# However, outside of 'ctx', 'var' is still set to 'spam':
# var.get() == 'spam'


The method raises a RuntimeError when called on the same
context object from more than one OS thread, or when called
recursively."
copy(),Return a shallow copy of the context object.
"get(var[, default])","Return the value for var if var has the value in the context
object.  Return default otherwise.  If default is not given,
return None."
keys(),Return a list of all variables in the context object.
values(),Return a list of all variables’ values in the context object.
items(),"Return a list of 2-tuples containing all variables and their
values in the context object."
"socket.socket(family=AF_INET, type=SOCK_STREAM, proto=0, fileno=None)","Create a new socket using the given address family, socket type and protocol
number.  The address family should be AF_INET (the default),
AF_INET6, AF_UNIX, AF_CAN, AF_PACKET,
or AF_RDS. The socket type should be SOCK_STREAM (the
default), SOCK_DGRAM, SOCK_RAW or perhaps one of the other
SOCK_ constants. The protocol number is usually zero and may be omitted
or in the case where the address family is AF_CAN the protocol
should be one of CAN_RAW, CAN_BCM or CAN_ISOTP.
If fileno is specified, the values for family, type, and proto are
auto-detected from the specified file descriptor.  Auto-detection can be
overruled by calling the function with explicit family, type, or proto
arguments.  This only affects how Python represents e.g. the return value
of socket.getpeername() but not the actual OS resource.  Unlike
socket.fromfd(), fileno will return the same socket and not a
duplicate. This may help close a detached socket using
socket.close().
The newly created socket is non-inheritable.
Raises an auditing event socket.__new__ with arguments self, family, type, protocol.

Changed in version 3.3: The AF_CAN family was added.
The AF_RDS family was added.


Changed in version 3.4: The CAN_BCM protocol was added.


Changed in version 3.4: The returned socket is now non-inheritable.


Changed in version 3.7: The CAN_ISOTP protocol was added.


Changed in version 3.7: When SOCK_NONBLOCK or SOCK_CLOEXEC
bit flags are applied to type they are cleared, and
socket.type will not reflect them.  They are still passed
to the underlying system socket() call.  Therefore,
sock = socket.socket(
    socket.AF_INET,
    socket.SOCK_STREAM | socket.SOCK_NONBLOCK)


will still create a non-blocking socket on OSes that support
SOCK_NONBLOCK, but sock.type will be set to
socket.SOCK_STREAM."
"socket.socketpair([family[, type[, proto]]])","Build a pair of connected socket objects using the given address family, socket
type, and protocol number.  Address family, socket type, and protocol number are
as for the socket() function above. The default family is AF_UNIX
if defined on the platform; otherwise, the default is AF_INET.
The newly created sockets are non-inheritable.

Changed in version 3.2: The returned socket objects now support the whole socket API, rather
than a subset.


Changed in version 3.4: The returned sockets are now non-inheritable.


Changed in version 3.5: Windows support added."
"socket.create_connection(address[, timeout[, source_address]])","Connect to a TCP service listening on the Internet address (a 2-tuple
(host, port)), and return the socket object.  This is a higher-level
function than socket.connect(): if host is a non-numeric hostname,
it will try to resolve it for both AF_INET and AF_INET6,
and then try to connect to all possible addresses in turn until a
connection succeeds.  This makes it easy to write clients that are
compatible to both IPv4 and IPv6.
Passing the optional timeout parameter will set the timeout on the
socket instance before attempting to connect.  If no timeout is
supplied, the global default timeout setting returned by
getdefaulttimeout() is used.
If supplied, source_address must be a 2-tuple (host, port) for the
socket to bind to as its source address before connecting.  If host or port
are ‘’ or 0 respectively the OS default behavior will be used.

Changed in version 3.2: source_address was added."
"socket.create_server(address, *, family=AF_INET, backlog=None, reuse_port=False, dualstack_ipv6=False)","Convenience function which creates a TCP socket bound to address (a 2-tuple
(host, port)) and return the socket object.
family should be either AF_INET or AF_INET6.
backlog is the queue size passed to socket.listen(); when 0
a default reasonable value is chosen.
reuse_port dictates whether to set the SO_REUSEPORT socket option.
If dualstack_ipv6 is true and the platform supports it the socket will
be able to accept both IPv4 and IPv6 connections, else it will raise
ValueError. Most POSIX platforms and Windows are supposed to support
this functionality.
When this functionality is enabled the address returned by
socket.getpeername() when an IPv4 connection occurs will be an IPv6
address represented as an IPv4-mapped IPv6 address.
If dualstack_ipv6 is false it will explicitly disable this functionality
on platforms that enable it by default (e.g. Linux).
This parameter can be used in conjunction with has_dualstack_ipv6():
import socket

addr = ("""", 8080)  # all interfaces, port 8080
if socket.has_dualstack_ipv6():
    s = socket.create_server(addr, family=socket.AF_INET6, dualstack_ipv6=True)
else:
    s = socket.create_server(addr)



Note
On POSIX platforms the SO_REUSEADDR socket option is set in order to
immediately reuse previous sockets which were bound on the same address
and remained in TIME_WAIT state.


New in version 3.8."
socket.has_dualstack_ipv6(),"Return True if the platform supports creating a TCP socket which can
handle both IPv4 and IPv6 connections.

New in version 3.8."
"socket.fromfd(fd, family, type, proto=0)","Duplicate the file descriptor fd (an integer as returned by a file object’s
fileno() method) and build a socket object from the result.  Address
family, socket type and protocol number are as for the socket() function
above. The file descriptor should refer to a socket, but this is not checked —
subsequent operations on the object may fail if the file descriptor is invalid.
This function is rarely needed, but can be used to get or set socket options on
a socket passed to a program as standard input or output (such as a server
started by the Unix inet daemon).  The socket is assumed to be in blocking mode.
The newly created socket is non-inheritable.

Changed in version 3.4: The returned socket is now non-inheritable."
socket.fromshare(data),"Instantiate a socket from data obtained from the socket.share()
method.  The socket is assumed to be in blocking mode.
Availability: Windows.

New in version 3.3."
socket.close(fd),"Close a socket file descriptor. This is like os.close(), but for
sockets. On some platforms (most noticeable Windows) os.close()
does not work for socket file descriptors.

New in version 3.7."
"socket.getaddrinfo(host, port, family=0, type=0, proto=0, flags=0)","Translate the host/port argument into a sequence of 5-tuples that contain
all the necessary arguments for creating a socket connected to that service.
host is a domain name, a string representation of an IPv4/v6 address
or None. port is a string service name such as 'http', a numeric
port number or None.  By passing None as the value of host
and port, you can pass NULL to the underlying C API.
The family, type and proto arguments can be optionally specified
in order to narrow the list of addresses returned.  Passing zero as a
value for each of these arguments selects the full range of results.
The flags argument can be one or several of the AI_* constants,
and will influence how results are computed and returned.
For example, AI_NUMERICHOST will disable domain name resolution
and will raise an error if host is a domain name.
The function returns a list of 5-tuples with the following structure:
(family, type, proto, canonname, sockaddr)
In these tuples, family, type, proto are all integers and are
meant to be passed to the socket() function.  canonname will be
a string representing the canonical name of the host if
AI_CANONNAME is part of the flags argument; else canonname
will be empty.  sockaddr is a tuple describing a socket address, whose
format depends on the returned family (a (address, port) 2-tuple for
AF_INET, a (address, port, flow info, scope id) 4-tuple for
AF_INET6), and is meant to be passed to the socket.connect()
method.
Raises an auditing event socket.getaddrinfo with arguments host, port, family, type, protocol.
The following example fetches address information for a hypothetical TCP
connection to example.org on port 80 (results may differ on your
system if IPv6 isn’t enabled):
>>> socket.getaddrinfo(""example.org"", 80, proto=socket.IPPROTO_TCP)
[(<AddressFamily.AF_INET6: 10>, <SocketType.SOCK_STREAM: 1>,
 6, '', ('2606:2800:220:1:248:1893:25c8:1946', 80, 0, 0)),
 (<AddressFamily.AF_INET: 2>, <SocketType.SOCK_STREAM: 1>,
 6, '', ('93.184.216.34', 80))]



Changed in version 3.2: parameters can now be passed using keyword arguments.


Changed in version 3.7: for IPv6 multicast addresses, string representing an address will not
contain %scope part."
socket.getfqdn([name]),"Return a fully qualified domain name for name. If name is omitted or empty,
it is interpreted as the local host.  To find the fully qualified name, the
hostname returned by gethostbyaddr() is checked, followed by aliases for the
host, if available.  The first name which includes a period is selected.  In
case no fully qualified domain name is available, the hostname as returned by
gethostname() is returned."
socket.gethostbyname(hostname),"Translate a host name to IPv4 address format.  The IPv4 address is returned as a
string, such as  '100.50.200.5'.  If the host name is an IPv4 address itself
it is returned unchanged.  See gethostbyname_ex() for a more complete
interface. gethostbyname() does not support IPv6 name resolution, and
getaddrinfo() should be used instead for IPv4/v6 dual stack support.
Raises an auditing event socket.gethostbyname with argument hostname."
socket.gethostbyname_ex(hostname),"Translate a host name to IPv4 address format, extended interface. Return a
triple (hostname, aliaslist, ipaddrlist) where hostname is the primary
host name responding to the given ip_address, aliaslist is a (possibly
empty) list of alternative host names for the same address, and ipaddrlist is
a list of IPv4 addresses for the same interface on the same host (often but not
always a single address). gethostbyname_ex() does not support IPv6 name
resolution, and getaddrinfo() should be used instead for IPv4/v6 dual
stack support.
Raises an auditing event socket.gethostbyname with argument hostname."
socket.gethostname(),"Return a string containing the hostname of the machine where  the Python
interpreter is currently executing.
Raises an auditing event socket.gethostname with no arguments.
Note: gethostname() doesn’t always return the fully qualified domain
name; use getfqdn() for that."
socket.gethostbyaddr(ip_address),"Return a triple (hostname, aliaslist, ipaddrlist) where hostname is the
primary host name responding to the given ip_address, aliaslist is a
(possibly empty) list of alternative host names for the same address, and
ipaddrlist is a list of IPv4/v6 addresses for the same interface on the same
host (most likely containing only a single address). To find the fully qualified
domain name, use the function getfqdn(). gethostbyaddr() supports
both IPv4 and IPv6.
Raises an auditing event socket.gethostbyaddr with argument ip_address."
"socket.getnameinfo(sockaddr, flags)","Translate a socket address sockaddr into a 2-tuple (host, port). Depending
on the settings of flags, the result can contain a fully-qualified domain name
or numeric address representation in host.  Similarly, port can contain a
string port name or a numeric port number.
For IPv6 addresses, %scope is appended to the host part if sockaddr
contains meaningful scopeid. Usually this happens for multicast addresses.
For more information about flags you can consult getnameinfo(3).
Raises an auditing event socket.getnameinfo with argument sockaddr."
socket.getprotobyname(protocolname),"Translate an Internet protocol name (for example, 'icmp') to a constant
suitable for passing as the (optional) third argument to the socket()
function.  This is usually only needed for sockets opened in “raw” mode
(SOCK_RAW); for the normal socket modes, the correct protocol is chosen
automatically if the protocol is omitted or zero."
"socket.getservbyname(servicename[, protocolname])","Translate an Internet service name and protocol name to a port number for that
service.  The optional protocol name, if given, should be 'tcp' or
'udp', otherwise any protocol will match.
Raises an auditing event socket.getservbyname with arguments servicename, protocolname."
"socket.getservbyport(port[, protocolname])","Translate an Internet port number and protocol name to a service name for that
service.  The optional protocol name, if given, should be 'tcp' or
'udp', otherwise any protocol will match.
Raises an auditing event socket.getservbyport with arguments port, protocolname."
socket.ntohl(x),"Convert 32-bit positive integers from network to host byte order.  On machines
where the host byte order is the same as network byte order, this is a no-op;
otherwise, it performs a 4-byte swap operation."
socket.ntohs(x),"Convert 16-bit positive integers from network to host byte order.  On machines
where the host byte order is the same as network byte order, this is a no-op;
otherwise, it performs a 2-byte swap operation.

Deprecated since version 3.7: In case x does not fit in 16-bit unsigned integer, but does fit in a
positive C int, it is silently truncated to 16-bit unsigned integer.
This silent truncation feature is deprecated, and will raise an
exception in future versions of Python."
socket.htonl(x),"Convert 32-bit positive integers from host to network byte order.  On machines
where the host byte order is the same as network byte order, this is a no-op;
otherwise, it performs a 4-byte swap operation."
socket.htons(x),"Convert 16-bit positive integers from host to network byte order.  On machines
where the host byte order is the same as network byte order, this is a no-op;
otherwise, it performs a 2-byte swap operation.

Deprecated since version 3.7: In case x does not fit in 16-bit unsigned integer, but does fit in a
positive C int, it is silently truncated to 16-bit unsigned integer.
This silent truncation feature is deprecated, and will raise an
exception in future versions of Python."
socket.inet_aton(ip_string),"Convert an IPv4 address from dotted-quad string format (for example,
‘123.45.67.89’) to 32-bit packed binary format, as a bytes object four characters in
length.  This is useful when conversing with a program that uses the standard C
library and needs objects of type struct in_addr, which is the C type
for the 32-bit packed binary this function returns.
inet_aton() also accepts strings with less than three dots; see the
Unix manual page inet(3) for details.
If the IPv4 address string passed to this function is invalid,
OSError will be raised. Note that exactly what is valid depends on
the underlying C implementation of inet_aton().
inet_aton() does not support IPv6, and inet_pton() should be used
instead for IPv4/v6 dual stack support."
socket.inet_ntoa(packed_ip),"Convert a 32-bit packed IPv4 address (a bytes-like object four
bytes in length) to its standard dotted-quad string representation (for example,
‘123.45.67.89’).  This is useful when conversing with a program that uses the
standard C library and needs objects of type struct in_addr, which
is the C type for the 32-bit packed binary data this function takes as an
argument.
If the byte sequence passed to this function is not exactly 4 bytes in
length, OSError will be raised. inet_ntoa() does not
support IPv6, and inet_ntop() should be used instead for IPv4/v6 dual
stack support.

Changed in version 3.5: Writable bytes-like object is now accepted."
"socket.inet_pton(address_family, ip_string)","Convert an IP address from its family-specific string format to a packed,
binary format. inet_pton() is useful when a library or network protocol
calls for an object of type struct in_addr (similar to
inet_aton()) or struct in6_addr.
Supported values for address_family are currently AF_INET and
AF_INET6. If the IP address string ip_string is invalid,
OSError will be raised. Note that exactly what is valid depends on
both the value of address_family and the underlying implementation of
inet_pton().
Availability: Unix (maybe not all platforms), Windows.

Changed in version 3.4: Windows support added"
"socket.inet_ntop(address_family, packed_ip)","Convert a packed IP address (a bytes-like object of some number of
bytes) to its standard, family-specific string representation (for
example, '7.10.0.5' or '5aef:2b::8').
inet_ntop() is useful when a library or network protocol returns an
object of type struct in_addr (similar to inet_ntoa()) or
struct in6_addr.
Supported values for address_family are currently AF_INET and
AF_INET6. If the bytes object packed_ip is not the correct
length for the specified address family, ValueError will be raised.
OSError is raised for errors from the call to inet_ntop().
Availability: Unix (maybe not all platforms), Windows.

Changed in version 3.4: Windows support added


Changed in version 3.5: Writable bytes-like object is now accepted."
socket.CMSG_LEN(length),"Return the total length, without trailing padding, of an ancillary
data item with associated data of the given length.  This value
can often be used as the buffer size for recvmsg() to
receive a single item of ancillary data, but RFC 3542 requires
portable applications to use CMSG_SPACE() and thus include
space for padding, even when the item will be the last in the
buffer.  Raises OverflowError if length is outside the
permissible range of values.
Availability: most Unix platforms, possibly others.

New in version 3.3."
socket.CMSG_SPACE(length),"Return the buffer size needed for recvmsg() to
receive an ancillary data item with associated data of the given
length, along with any trailing padding.  The buffer space needed
to receive multiple items is the sum of the CMSG_SPACE()
values for their associated data lengths.  Raises
OverflowError if length is outside the permissible range
of values.
Note that some systems might support ancillary data without
providing this function.  Also note that setting the buffer size
using the results of this function may not precisely limit the
amount of ancillary data that can be received, since additional
data may be able to fit into the padding area.
Availability: most Unix platforms, possibly others.

New in version 3.3."
socket.getdefaulttimeout(),"Return the default timeout in seconds (float) for new socket objects. A value
of None indicates that new socket objects have no timeout. When the socket
module is first imported, the default is None."
socket.setdefaulttimeout(timeout),"Set the default timeout in seconds (float) for new socket objects.  When
the socket module is first imported, the default is None.  See
settimeout() for possible values and their respective
meanings."
socket.sethostname(name),"Set the machine’s hostname to name.  This will raise an
OSError if you don’t have enough rights.
Raises an auditing event socket.sethostname with argument name.
Availability: Unix.

New in version 3.3."
socket.if_nameindex(),"Return a list of network interface information
(index int, name string) tuples.
OSError if the system call fails.
Availability: Unix, Windows.

New in version 3.3.


Changed in version 3.8: Windows support was added."
socket.if_nametoindex(if_name),"Return a network interface index number corresponding to an
interface name.
OSError if no interface with the given name exists.
Availability: Unix, Windows.

New in version 3.3.


Changed in version 3.8: Windows support was added."
socket.if_indextoname(if_index),"Return a network interface name corresponding to an
interface index number.
OSError if no interface with the given index exists.
Availability: Unix, Windows.

New in version 3.3.


Changed in version 3.8: Windows support was added."
socket.accept(),"Accept a connection. The socket must be bound to an address and listening for
connections. The return value is a pair (conn, address) where conn is a
new socket object usable to send and receive data on the connection, and
address is the address bound to the socket on the other end of the connection.
The newly created socket is non-inheritable.

Changed in version 3.4: The socket is now non-inheritable.


Changed in version 3.5: If the system call is interrupted and the signal handler does not raise
an exception, the method now retries the system call instead of raising
an InterruptedError exception (see PEP 475 for the rationale)."
socket.bind(address),"Bind the socket to address.  The socket must not already be bound. (The format
of address depends on the address family — see above.)
Raises an auditing event socket.bind with arguments self, address."
socket.close(),"Mark the socket closed.  The underlying system resource (e.g. a file
descriptor) is also closed when all file objects from makefile()
are closed.  Once that happens, all future operations on the socket
object will fail. The remote end will receive no more data (after
queued data is flushed).
Sockets are automatically closed when they are garbage-collected, but
it is recommended to close() them explicitly, or to use a
with statement around them.

Changed in version 3.6: OSError is now raised if an error occurs when the underlying
close() call is made.


Note
close() releases the resource associated with a connection but
does not necessarily close the connection immediately.  If you want
to close the connection in a timely fashion, call shutdown()
before close()."
socket.connect(address),"Connect to a remote socket at address. (The format of address depends on the
address family — see above.)
If the connection is interrupted by a signal, the method waits until the
connection completes, or raise a socket.timeout on timeout, if the
signal handler doesn’t raise an exception and the socket is blocking or has
a timeout. For non-blocking sockets, the method raises an
InterruptedError exception if the connection is interrupted by a
signal (or the exception raised by the signal handler).
Raises an auditing event socket.connect with arguments self, address.

Changed in version 3.5: The method now waits until the connection completes instead of raising an
InterruptedError exception if the connection is interrupted by a
signal, the signal handler doesn’t raise an exception and the socket is
blocking or has a timeout (see the PEP 475 for the rationale)."
socket.connect_ex(address),"Like connect(address), but return an error indicator instead of raising an
exception for errors returned by the C-level connect() call (other
problems, such as “host not found,” can still raise exceptions).  The error
indicator is 0 if the operation succeeded, otherwise the value of the
errno variable.  This is useful to support, for example, asynchronous
connects.
Raises an auditing event socket.connect with arguments self, address."
socket.detach(),"Put the socket object into closed state without actually closing the
underlying file descriptor.  The file descriptor is returned, and can
be reused for other purposes.

New in version 3.2."
socket.dup(),"Duplicate the socket.
The newly created socket is non-inheritable.

Changed in version 3.4: The socket is now non-inheritable."
socket.fileno(),"Return the socket’s file descriptor (a small integer), or -1 on failure. This
is useful with select.select().
Under Windows the small integer returned by this method cannot be used where a
file descriptor can be used (such as os.fdopen()).  Unix does not have
this limitation."
socket.get_inheritable(),"Get the inheritable flag of the socket’s file
descriptor or socket’s handle: True if the socket can be inherited in
child processes, False if it cannot.

New in version 3.4."
socket.getpeername(),"Return the remote address to which the socket is connected.  This is useful to
find out the port number of a remote IPv4/v6 socket, for instance. (The format
of the address returned depends on the address family — see above.)  On some
systems this function is not supported."
socket.getsockname(),"Return the socket’s own address.  This is useful to find out the port number of
an IPv4/v6 socket, for instance. (The format of the address returned depends on
the address family — see above.)"
"socket.getsockopt(level, optname[, buflen])","Return the value of the given socket option (see the Unix man page
getsockopt(2)).  The needed symbolic constants (SO_* etc.)
are defined in this module.  If buflen is absent, an integer option is assumed
and its integer value is returned by the function.  If buflen is present, it
specifies the maximum length of the buffer used to receive the option in, and
this buffer is returned as a bytes object.  It is up to the caller to decode the
contents of the buffer (see the optional built-in module struct for a way
to decode C structures encoded as byte strings)."
socket.getblocking(),"Return True if socket is in blocking mode, False if in
non-blocking.
This is equivalent to checking socket.gettimeout() == 0.

New in version 3.7."
socket.gettimeout(),"Return the timeout in seconds (float) associated with socket operations,
or None if no timeout is set.  This reflects the last call to
setblocking() or settimeout()."
"socket.ioctl(control, option)","Platform
Windows


The ioctl() method is a limited interface to the WSAIoctl system
interface.  Please refer to the Win32 documentation for more
information.
On other platforms, the generic fcntl.fcntl() and fcntl.ioctl()
functions may be used; they accept a socket object as their first argument.
Currently only the following control codes are supported:
SIO_RCVALL, SIO_KEEPALIVE_VALS, and SIO_LOOPBACK_FAST_PATH.

Changed in version 3.6: SIO_LOOPBACK_FAST_PATH was added."
socket.listen([backlog]),"Enable a server to accept connections.  If backlog is specified, it must
be at least 0 (if it is lower, it is set to 0); it specifies the number of
unaccepted connections that the system will allow before refusing new
connections. If not specified, a default reasonable value is chosen.

Changed in version 3.5: The backlog parameter is now optional."
"socket.makefile(mode='r', buffering=None, *, encoding=None, errors=None, newline=None)","Return a file object associated with the socket.  The exact returned
type depends on the arguments given to makefile().  These arguments are
interpreted the same way as by the built-in open() function, except
the only supported mode values are 'r' (default), 'w' and 'b'.
The socket must be in blocking mode; it can have a timeout, but the file
object’s internal buffer may end up in an inconsistent state if a timeout
occurs.
Closing the file object returned by makefile() won’t close the
original socket unless all other file objects have been closed and
socket.close() has been called on the socket object.

Note
On Windows, the file-like object created by makefile() cannot be
used where a file object with a file descriptor is expected, such as the
stream arguments of subprocess.Popen()."
"socket.recv(bufsize[, flags])","Receive data from the socket.  The return value is a bytes object representing the
data received.  The maximum amount of data to be received at once is specified
by bufsize.  See the Unix manual page recv(2) for the meaning of
the optional argument flags; it defaults to zero.

Note
For best match with hardware and network realities, the value of  bufsize
should be a relatively small power of 2, for example, 4096.


Changed in version 3.5: If the system call is interrupted and the signal handler does not raise
an exception, the method now retries the system call instead of raising
an InterruptedError exception (see PEP 475 for the rationale)."
"socket.recvfrom(bufsize[, flags])","Receive data from the socket.  The return value is a pair (bytes, address)
where bytes is a bytes object representing the data received and address is the
address of the socket sending the data.  See the Unix manual page
recv(2) for the meaning of the optional argument flags; it defaults
to zero. (The format of address depends on the address family — see above.)

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise
an exception, the method now retries the system call instead of raising
an InterruptedError exception (see PEP 475 for the rationale).


Changed in version 3.7: For multicast IPv6 address, first item of address does not contain
%scope part anymore. In order to get full IPv6 address use
getnameinfo()."
"socket.recvmsg(bufsize[, ancbufsize[, flags]])","Receive normal data (up to bufsize bytes) and ancillary data from
the socket.  The ancbufsize argument sets the size in bytes of
the internal buffer used to receive the ancillary data; it defaults
to 0, meaning that no ancillary data will be received.  Appropriate
buffer sizes for ancillary data can be calculated using
CMSG_SPACE() or CMSG_LEN(), and items which do not fit
into the buffer might be truncated or discarded.  The flags
argument defaults to 0 and has the same meaning as for
recv().
The return value is a 4-tuple: (data, ancdata, msg_flags,
address).  The data item is a bytes object holding the
non-ancillary data received.  The ancdata item is a list of zero
or more tuples (cmsg_level, cmsg_type, cmsg_data) representing
the ancillary data (control messages) received: cmsg_level and
cmsg_type are integers specifying the protocol level and
protocol-specific type respectively, and cmsg_data is a
bytes object holding the associated data.  The msg_flags
item is the bitwise OR of various flags indicating conditions on
the received message; see your system documentation for details.
If the receiving socket is unconnected, address is the address of
the sending socket, if available; otherwise, its value is
unspecified.
On some systems, sendmsg() and recvmsg() can be used to
pass file descriptors between processes over an AF_UNIX
socket.  When this facility is used (it is often restricted to
SOCK_STREAM sockets), recvmsg() will return, in its
ancillary data, items of the form (socket.SOL_SOCKET,
socket.SCM_RIGHTS, fds), where fds is a bytes object
representing the new file descriptors as a binary array of the
native C int type.  If recvmsg() raises an
exception after the system call returns, it will first attempt to
close any file descriptors received via this mechanism.
Some systems do not indicate the truncated length of ancillary data
items which have been only partially received.  If an item appears
to extend beyond the end of the buffer, recvmsg() will issue
a RuntimeWarning, and will return the part of it which is
inside the buffer provided it has not been truncated before the
start of its associated data.
On systems which support the SCM_RIGHTS mechanism, the
following function will receive up to maxfds file descriptors,
returning the message data and a list containing the descriptors
(while ignoring unexpected conditions such as unrelated control
messages being received).  See also sendmsg().
import socket, array

def recv_fds(sock, msglen, maxfds):
    fds = array.array(""i"")   # Array of ints
    msg, ancdata, flags, addr = sock.recvmsg(msglen, socket.CMSG_LEN(maxfds * fds.itemsize))
    for cmsg_level, cmsg_type, cmsg_data in ancdata:
        if cmsg_level == socket.SOL_SOCKET and cmsg_type == socket.SCM_RIGHTS:
            # Append data, ignoring any truncated integers at the end.
            fds.frombytes(cmsg_data[:len(cmsg_data) - (len(cmsg_data) % fds.itemsize)])
    return msg, list(fds)


Availability: most Unix platforms, possibly others.

New in version 3.3.


Changed in version 3.5: If the system call is interrupted and the signal handler does not raise
an exception, the method now retries the system call instead of raising
an InterruptedError exception (see PEP 475 for the rationale)."
"socket.recvmsg_into(buffers[, ancbufsize[, flags]])","Receive normal data and ancillary data from the socket, behaving as
recvmsg() would, but scatter the non-ancillary data into a
series of buffers instead of returning a new bytes object.  The
buffers argument must be an iterable of objects that export
writable buffers (e.g. bytearray objects); these will be
filled with successive chunks of the non-ancillary data until it
has all been written or there are no more buffers.  The operating
system may set a limit (sysconf() value SC_IOV_MAX)
on the number of buffers that can be used.  The ancbufsize and
flags arguments have the same meaning as for recvmsg().
The return value is a 4-tuple: (nbytes, ancdata, msg_flags,
address), where nbytes is the total number of bytes of
non-ancillary data written into the buffers, and ancdata,
msg_flags and address are the same as for recvmsg().
Example:
>>> import socket
>>> s1, s2 = socket.socketpair()
>>> b1 = bytearray(b'----')
>>> b2 = bytearray(b'0123456789')
>>> b3 = bytearray(b'--------------')
>>> s1.send(b'Mary had a little lamb')
22
>>> s2.recvmsg_into([b1, memoryview(b2)[2:9], b3])
(22, [], 0, None)
>>> [b1, b2, b3]
[bytearray(b'Mary'), bytearray(b'01 had a 9'), bytearray(b'little lamb---')]


Availability: most Unix platforms, possibly others.

New in version 3.3."
"socket.recvfrom_into(buffer[, nbytes[, flags]])","Receive data from the socket, writing it into buffer instead of creating a
new bytestring.  The return value is a pair (nbytes, address) where nbytes is
the number of bytes received and address is the address of the socket sending
the data.  See the Unix manual page recv(2) for the meaning of the
optional argument flags; it defaults to zero.  (The format of address
depends on the address family — see above.)"
"socket.recv_into(buffer[, nbytes[, flags]])","Receive up to nbytes bytes from the socket, storing the data into a buffer
rather than creating a new bytestring.  If nbytes is not specified (or 0),
receive up to the size available in the given buffer.  Returns the number of
bytes received.  See the Unix manual page recv(2) for the meaning
of the optional argument flags; it defaults to zero."
"socket.send(bytes[, flags])","Send data to the socket.  The socket must be connected to a remote socket.  The
optional flags argument has the same meaning as for recv() above.
Returns the number of bytes sent. Applications are responsible for checking that
all data has been sent; if only some of the data was transmitted, the
application needs to attempt delivery of the remaining data. For further
information on this topic, consult the Socket Programming HOWTO.

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise
an exception, the method now retries the system call instead of raising
an InterruptedError exception (see PEP 475 for the rationale)."
"socket.sendall(bytes[, flags])","Send data to the socket.  The socket must be connected to a remote socket.  The
optional flags argument has the same meaning as for recv() above.
Unlike send(), this method continues to send data from bytes until
either all data has been sent or an error occurs.  None is returned on
success.  On error, an exception is raised, and there is no way to determine how
much data, if any, was successfully sent.

Changed in version 3.5: The socket timeout is no more reset each time data is sent successfully.
The socket timeout is now the maximum total duration to send all data.


Changed in version 3.5: If the system call is interrupted and the signal handler does not raise
an exception, the method now retries the system call instead of raising
an InterruptedError exception (see PEP 475 for the rationale)."
"socket.sendto(bytes, address)","Send data to the socket.  The socket should not be connected to a remote socket,
since the destination socket is specified by address.  The optional flags
argument has the same meaning as for recv() above.  Return the number of
bytes sent. (The format of address depends on the address family — see
above.)
Raises an auditing event socket.sendto with arguments self, address.

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise
an exception, the method now retries the system call instead of raising
an InterruptedError exception (see PEP 475 for the rationale)."
"socket.sendmsg(buffers[, ancdata[, flags[, address]]])","Send normal and ancillary data to the socket, gathering the
non-ancillary data from a series of buffers and concatenating it
into a single message.  The buffers argument specifies the
non-ancillary data as an iterable of
bytes-like objects
(e.g. bytes objects); the operating system may set a limit
(sysconf() value SC_IOV_MAX) on the number of buffers
that can be used.  The ancdata argument specifies the ancillary
data (control messages) as an iterable of zero or more tuples
(cmsg_level, cmsg_type, cmsg_data), where cmsg_level and
cmsg_type are integers specifying the protocol level and
protocol-specific type respectively, and cmsg_data is a
bytes-like object holding the associated data.  Note that
some systems (in particular, systems without CMSG_SPACE())
might support sending only one control message per call.  The
flags argument defaults to 0 and has the same meaning as for
send().  If address is supplied and not None, it sets a
destination address for the message.  The return value is the
number of bytes of non-ancillary data sent.
The following function sends the list of file descriptors fds
over an AF_UNIX socket, on systems which support the
SCM_RIGHTS mechanism.  See also recvmsg().
import socket, array

def send_fds(sock, msg, fds):
    return sock.sendmsg([msg], [(socket.SOL_SOCKET, socket.SCM_RIGHTS, array.array(""i"", fds))])


Availability: most Unix platforms, possibly others.
Raises an auditing event socket.sendmsg with arguments self, address.

New in version 3.3.


Changed in version 3.5: If the system call is interrupted and the signal handler does not raise
an exception, the method now retries the system call instead of raising
an InterruptedError exception (see PEP 475 for the rationale)."
"socket.sendmsg_afalg([msg, ]*, op[, iv[, assoclen[, flags]]])","Specialized version of sendmsg() for AF_ALG socket.
Set mode, IV, AEAD associated data length and flags for AF_ALG socket.
Availability: Linux >= 2.6.38.

New in version 3.6."
"socket.sendfile(file, offset=0, count=None)","Send a file until EOF is reached by using high-performance
os.sendfile and return the total number of bytes which were sent.
file must be a regular file object opened in binary mode. If
os.sendfile is not available (e.g. Windows) or file is not a
regular file send() will be used instead. offset tells from where to
start reading the file. If specified, count is the total number of bytes
to transmit as opposed to sending the file until EOF is reached. File
position is updated on return or also in case of error in which case
file.tell() can be used to figure out the number of
bytes which were sent. The socket must be of SOCK_STREAM type.
Non-blocking sockets are not supported.

New in version 3.5."
socket.set_inheritable(inheritable),"Set the inheritable flag of the socket’s file
descriptor or socket’s handle.

New in version 3.4."
socket.setblocking(flag),"Set blocking or non-blocking mode of the socket: if flag is false, the
socket is set to non-blocking, else to blocking mode.
This method is a shorthand for certain settimeout() calls:

sock.setblocking(True) is equivalent to sock.settimeout(None)
sock.setblocking(False) is equivalent to sock.settimeout(0.0)


Changed in version 3.7: The method no longer applies SOCK_NONBLOCK flag on
socket.type."
socket.settimeout(value),"Set a timeout on blocking socket operations.  The value argument can be a
nonnegative floating point number expressing seconds, or None.
If a non-zero value is given, subsequent socket operations will raise a
timeout exception if the timeout period value has elapsed before
the operation has completed.  If zero is given, the socket is put in
non-blocking mode. If None is given, the socket is put in blocking mode.
For further information, please consult the notes on socket timeouts.

Changed in version 3.7: The method no longer toggles SOCK_NONBLOCK flag on
socket.type."
"socket.setsockopt(level, optname, value: int)",
"socket.setsockopt(level, optname, value: buffer",
"socket.setsockopt(level, optname, None, optlen: int","Set the value of the given socket option (see the Unix manual page
setsockopt(2)).  The needed symbolic constants are defined in the
socket module (SO_* etc.).  The value can be an integer,
None or a bytes-like object representing a buffer. In the later
case it is up to the caller to ensure that the bytestring contains the
proper bits (see the optional built-in module struct for a way to
encode C structures as bytestrings). When value is set to None,
optlen argument is required. It’s equivalent to call setsockopt() C
function with optval=NULL and optlen=optlen.

Changed in version 3.5: Writable bytes-like object is now accepted.


Changed in version 3.6: setsockopt(level, optname, None, optlen: int) form added."
socket.shutdown(how),"Shut down one or both halves of the connection.  If how is SHUT_RD,
further receives are disallowed.  If how is SHUT_WR, further sends
are disallowed.  If how is SHUT_RDWR, further sends and receives are
disallowed."
socket.share(process_id),"Duplicate a socket and prepare it for sharing with a target process.  The
target process must be provided with process_id.  The resulting bytes object
can then be passed to the target process using some form of interprocess
communication and the socket can be recreated there using fromshare().
Once this method has been called, it is safe to close the socket since
the operating system has already duplicated it for the target process.
Availability: Windows.

New in version 3.3."
"ssl.create_default_context(purpose=Purpose.SERVER_AUTH, cafile=None, capath=None, cadata=None)","Return a new SSLContext object with default settings for
the given purpose.  The settings are chosen by the ssl module,
and usually represent a higher security level than when calling the
SSLContext constructor directly.
cafile, capath, cadata represent optional CA certificates to
trust for certificate verification, as in
SSLContext.load_verify_locations().  If all three are
None, this function can choose to trust the system’s default
CA certificates instead.
The settings are: PROTOCOL_TLS, OP_NO_SSLv2, and
OP_NO_SSLv3 with high encryption cipher suites without RC4 and
without unauthenticated cipher suites. Passing SERVER_AUTH
as purpose sets verify_mode to CERT_REQUIRED
and either loads CA certificates (when at least one of cafile, capath or
cadata is given) or uses SSLContext.load_default_certs() to load
default CA certificates.
When keylog_filename is supported and the environment
variable SSLKEYLOGFILE is set, create_default_context()
enables key logging.

Note
The protocol, options, cipher and other settings may change to more
restrictive values anytime without prior deprecation.  The values
represent a fair balance between compatibility and security.
If your application needs specific settings, you should create a
SSLContext and apply the settings yourself.


Note
If you find that when certain older clients or servers attempt to connect
with a SSLContext created by this function that they get an error
stating “Protocol or cipher suite mismatch”, it may be that they only
support SSL3.0 which this function excludes using the
OP_NO_SSLv3. SSL3.0 is widely considered to be completely broken. If you still wish to continue to
use this function but still allow SSL 3.0 connections you can re-enable
them using:
ctx = ssl.create_default_context(Purpose.CLIENT_AUTH)
ctx.options &= ~ssl.OP_NO_SSLv3




New in version 3.4.


Changed in version 3.4.4: RC4 was dropped from the default cipher string.


Changed in version 3.6: ChaCha20/Poly1305 was added to the default cipher string.
3DES was dropped from the default cipher string.


Changed in version 3.8: Support for key logging to SSLKEYLOGFILE was added."
ssl.RAND_bytes(num),"Return num cryptographically strong pseudo-random bytes. Raises an
SSLError if the PRNG has not been seeded with enough data or if the
operation is not supported by the current RAND method. RAND_status()
can be used to check the status of the PRNG and RAND_add() can be used
to seed the PRNG.
For almost all applications os.urandom() is preferable.
Read the Wikipedia article, Cryptographically secure pseudorandom number
generator (CSPRNG),
to get the requirements of a cryptographically generator.

New in version 3.3."
ssl.RAND_pseudo_bytes(num),"Return (bytes, is_cryptographic): bytes are num pseudo-random bytes,
is_cryptographic is True if the bytes generated are cryptographically
strong. Raises an SSLError if the operation is not supported by the
current RAND method.
Generated pseudo-random byte sequences will be unique if they are of
sufficient length, but are not necessarily unpredictable. They can be used
for non-cryptographic purposes and for certain purposes in cryptographic
protocols, but usually not for key generation etc.
For almost all applications os.urandom() is preferable.

New in version 3.3.


Deprecated since version 3.6: OpenSSL has deprecated ssl.RAND_pseudo_bytes(), use
ssl.RAND_bytes() instead."
ssl.RAND_status(),"Return True if the SSL pseudo-random number generator has been seeded
with ‘enough’ randomness, and False otherwise.  You can use
ssl.RAND_egd() and ssl.RAND_add() to increase the randomness of
the pseudo-random number generator."
ssl.RAND_egd(path),"If you are running an entropy-gathering daemon (EGD) somewhere, and path
is the pathname of a socket connection open to it, this will read 256 bytes
of randomness from the socket, and add it to the SSL pseudo-random number
generator to increase the security of generated secret keys.  This is
typically only necessary on systems without better sources of randomness.
See http://egd.sourceforge.net/ or http://prngd.sourceforge.net/ for sources
of entropy-gathering daemons.
Availability: not available with LibreSSL and OpenSSL > 1.1.0."
"ssl.RAND_add(bytes, entropy)","Mix the given bytes into the SSL pseudo-random number generator.  The
parameter entropy (a float) is a lower bound on the entropy contained in
string (so you can always use 0.0).  See RFC 1750 for more
information on sources of entropy.

Changed in version 3.5: Writable bytes-like object is now accepted."
"ssl.match_hostname(cert, hostname)","Verify that cert (in decoded format as returned by
SSLSocket.getpeercert()) matches the given hostname.  The rules
applied are those for checking the identity of HTTPS servers as outlined
in RFC 2818, RFC 5280 and RFC 6125.  In addition to HTTPS, this
function should be suitable for checking the identity of servers in
various SSL-based protocols such as FTPS, IMAPS, POPS and others.
CertificateError is raised on failure. On success, the function
returns nothing:
>>> cert = {'subject': ((('commonName', 'example.com'),),)}
>>> ssl.match_hostname(cert, ""example.com"")
>>> ssl.match_hostname(cert, ""example.org"")
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/py3k/Lib/ssl.py"", line 130, in match_hostname
ssl.CertificateError: hostname 'example.org' doesn't match 'example.com'



New in version 3.2.


Changed in version 3.3.3: The function now follows RFC 6125, section 6.4.3 and does neither
match multiple wildcards (e.g. *.*.com or *a*.example.org) nor
a wildcard inside an internationalized domain names (IDN) fragment.
IDN A-labels such as www*.xn--pthon-kva.org are still supported,
but x*.python.org no longer matches xn--tda.python.org.


Changed in version 3.5: Matching of IP addresses, when present in the subjectAltName field
of the certificate, is now supported.


Changed in version 3.7: The function is no longer used to TLS connections. Hostname matching
is now performed by OpenSSL.
Allow wildcard when it is the leftmost and the only character
in that segment. Partial wildcards like www*.example.com are no
longer supported.


Deprecated since version 3.7."
ssl.cert_time_to_seconds(cert_time),"Return the time in seconds since the Epoch, given the cert_time
string representing the “notBefore” or “notAfter” date from a
certificate in ""%b %d %H:%M:%S %Y %Z"" strptime format (C
locale).
Here’s an example:
>>> import ssl
>>> timestamp = ssl.cert_time_to_seconds(""Jan  5 09:34:43 2018 GMT"")
>>> timestamp  
1515144883
>>> from datetime import datetime
>>> print(datetime.utcfromtimestamp(timestamp))  
2018-01-05 09:34:43


“notBefore” or “notAfter” dates must use GMT (RFC 5280).

Changed in version 3.5: Interpret the input time as a time in UTC as specified by ‘GMT’
timezone in the input string. Local timezone was used
previously. Return an integer (no fractions of a second in the
input format)"
"ssl.get_server_certificate(addr, ssl_version=PROTOCOL_TLS, ca_certs=None)","Given the address addr of an SSL-protected server, as a (hostname,
port-number) pair, fetches the server’s certificate, and returns it as a
PEM-encoded string.  If ssl_version is specified, uses that version of
the SSL protocol to attempt to connect to the server.  If ca_certs is
specified, it should be a file containing a list of root certificates, the
same format as used for the same parameter in
SSLContext.wrap_socket().  The call will attempt to validate the
server certificate against that set of root certificates, and will fail
if the validation attempt fails.

Changed in version 3.3: This function is now IPv6-compatible.


Changed in version 3.5: The default ssl_version is changed from PROTOCOL_SSLv3 to
PROTOCOL_TLS for maximum compatibility with modern servers."
ssl.DER_cert_to_PEM_cert(DER_cert_bytes),"Given a certificate as a DER-encoded blob of bytes, returns a PEM-encoded
string version of the same certificate."
ssl.PEM_cert_to_DER_cert(PEM_cert_string),"Given a certificate as an ASCII PEM string, returns a DER-encoded sequence of
bytes for that same certificate."
ssl.get_default_verify_paths(),"Returns a named tuple with paths to OpenSSL’s default cafile and capath.
The paths are the same as used by
SSLContext.set_default_verify_paths(). The return value is a
named tuple DefaultVerifyPaths:

cafile - resolved path to cafile or None if the file doesn’t exist,
capath - resolved path to capath or None if the directory doesn’t exist,
openssl_cafile_env - OpenSSL’s environment key that points to a cafile,
openssl_cafile - hard coded path to a cafile,
openssl_capath_env - OpenSSL’s environment key that points to a capath,
openssl_capath - hard coded path to a capath directory

Availability: LibreSSL ignores the environment vars
openssl_cafile_env and openssl_capath_env.

New in version 3.4."
ssl.enum_certificates(store_name),"Retrieve certificates from Windows’ system cert store. store_name may be
one of CA, ROOT or MY. Windows may provide additional cert
stores, too.
The function returns a list of (cert_bytes, encoding_type, trust) tuples.
The encoding_type specifies the encoding of cert_bytes. It is either
x509_asn for X.509 ASN.1 data or pkcs_7_asn for
PKCS#7 ASN.1 data. Trust specifies the purpose of the certificate as a set
of OIDS or exactly True if the certificate is trustworthy for all
purposes.
Example:
>>> ssl.enum_certificates(""CA"")
[(b'data...', 'x509_asn', {'1.3.6.1.5.5.7.3.1', '1.3.6.1.5.5.7.3.2'}),
 (b'data...', 'x509_asn', True)]


Availability: Windows.

New in version 3.4."
ssl.enum_crls(store_name),"Retrieve CRLs from Windows’ system cert store. store_name may be
one of CA, ROOT or MY. Windows may provide additional cert
stores, too.
The function returns a list of (cert_bytes, encoding_type, trust) tuples.
The encoding_type specifies the encoding of cert_bytes. It is either
x509_asn for X.509 ASN.1 data or pkcs_7_asn for
PKCS#7 ASN.1 data.
Availability: Windows.

New in version 3.4."
"ssl.wrap_socket(sock, keyfile=None, certfile=None, server_side=False, cert_reqs=CERT_NONE, ssl_version=PROTOCOL_TLS, ca_certs=None, do_handshake_on_connect=True, suppress_ragged_eofs=True, ciphers=None)","Takes an instance sock of socket.socket, and returns an instance
of ssl.SSLSocket, a subtype of socket.socket, which wraps
the underlying socket in an SSL context.  sock must be a
SOCK_STREAM socket; other socket types are unsupported.
Internally, function creates a SSLContext with protocol
ssl_version and SSLContext.options set to cert_reqs. If
parameters keyfile, certfile, ca_certs or ciphers are set, then
the values are passed to SSLContext.load_cert_chain(),
SSLContext.load_verify_locations(), and
SSLContext.set_ciphers().
The arguments server_side, do_handshake_on_connect, and
suppress_ragged_eofs have the same meaning as
SSLContext.wrap_socket().

Deprecated since version 3.7: Since Python 3.2 and 2.7.9, it is recommended to use the
SSLContext.wrap_socket() instead of wrap_socket(). The
top-level function is limited and creates an insecure client socket
without server name indication or hostname matching."
"SSLSocket.read(len=1024, buffer=None)","Read up to len bytes of data from the SSL socket and return the result as
a bytes instance. If buffer is specified, then read into the buffer
instead, and return the number of bytes read.
Raise SSLWantReadError or SSLWantWriteError if the socket is
non-blocking and the read would block.
As at any time a re-negotiation is possible, a call to read() can also
cause write operations.

Changed in version 3.5: The socket timeout is no more reset each time bytes are received or sent.
The socket timeout is now to maximum total duration to read up to len
bytes.


Deprecated since version 3.6: Use recv() instead of read()."
SSLSocket.write(buf),"Write buf to the SSL socket and return the number of bytes written. The
buf argument must be an object supporting the buffer interface.
Raise SSLWantReadError or SSLWantWriteError if the socket is
non-blocking and the write would block.
As at any time a re-negotiation is possible, a call to write() can
also cause read operations.

Changed in version 3.5: The socket timeout is no more reset each time bytes are received or sent.
The socket timeout is now to maximum total duration to write buf.


Deprecated since version 3.6: Use send() instead of write()."
SSLSocket.do_handshake(),"Perform the SSL setup handshake.

Changed in version 3.4: The handshake method also performs match_hostname() when the
check_hostname attribute of the socket’s
context is true.


Changed in version 3.5: The socket timeout is no more reset each time bytes are received or sent.
The socket timeout is now to maximum total duration of the handshake.


Changed in version 3.7: Hostname or IP address is matched by OpenSSL during handshake. The
function match_hostname() is no longer used. In case OpenSSL
refuses a hostname or IP address, the handshake is aborted early and
a TLS alert message is send to the peer."
SSLSocket.getpeercert(binary_form=False),"If there is no certificate for the peer on the other end of the connection,
return None.  If the SSL handshake hasn’t been done yet, raise
ValueError.
If the binary_form parameter is False, and a certificate was
received from the peer, this method returns a dict instance.  If the
certificate was not validated, the dict is empty.  If the certificate was
validated, it returns a dict with several keys, amongst them subject
(the principal for which the certificate was issued) and issuer
(the principal issuing the certificate).  If a certificate contains an
instance of the Subject Alternative Name extension (see RFC 3280),
there will also be a subjectAltName key in the dictionary.
The subject and issuer fields are tuples containing the sequence
of relative distinguished names (RDNs) given in the certificate’s data
structure for the respective fields, and each RDN is a sequence of
name-value pairs.  Here is a real-world example:
{'issuer': ((('countryName', 'IL'),),
            (('organizationName', 'StartCom Ltd.'),),
            (('organizationalUnitName',
              'Secure Digital Certificate Signing'),),
            (('commonName',
              'StartCom Class 2 Primary Intermediate Server CA'),)),
 'notAfter': 'Nov 22 08:15:19 2013 GMT',
 'notBefore': 'Nov 21 03:09:52 2011 GMT',
 'serialNumber': '95F0',
 'subject': ((('description', '571208-SLe257oHY9fVQ07Z'),),
             (('countryName', 'US'),),
             (('stateOrProvinceName', 'California'),),
             (('localityName', 'San Francisco'),),
             (('organizationName', 'Electronic Frontier Foundation, Inc.'),),
             (('commonName', '*.eff.org'),),
             (('emailAddress', 'hostmaster@eff.org'),)),
 'subjectAltName': (('DNS', '*.eff.org'), ('DNS', 'eff.org')),
 'version': 3}



Note
To validate a certificate for a particular service, you can use the
match_hostname() function.

If the binary_form parameter is True, and a certificate was
provided, this method returns the DER-encoded form of the entire certificate
as a sequence of bytes, or None if the peer did not provide a
certificate.  Whether the peer provides a certificate depends on the SSL
socket’s role:

for a client SSL socket, the server will always provide a certificate,
regardless of whether validation was required;
for a server SSL socket, the client will only provide a certificate
when requested by the server; therefore getpeercert() will return
None if you used CERT_NONE (rather than
CERT_OPTIONAL or CERT_REQUIRED).


Changed in version 3.2: The returned dictionary includes additional items such as issuer
and notBefore.


Changed in version 3.4: ValueError is raised when the handshake isn’t done.
The returned dictionary includes additional X509v3 extension items
  such as crlDistributionPoints, caIssuers and OCSP URIs.


Changed in version 3.8.1: IPv6 address strings no longer have a trailing new line."
SSLSocket.cipher(),"Returns a three-value tuple containing the name of the cipher being used, the
version of the SSL protocol that defines its use, and the number of secret
bits being used.  If no connection has been established, returns None."
SSLSocket.shared_ciphers(),"Return the list of ciphers shared by the client during the handshake.  Each
entry of the returned list is a three-value tuple containing the name of the
cipher, the version of the SSL protocol that defines its use, and the number
of secret bits the cipher uses.  shared_ciphers() returns
None if no connection has been established or the socket is a client
socket.

New in version 3.5."
SSLSocket.compression(),"Return the compression algorithm being used as a string, or None
if the connection isn’t compressed.
If the higher-level protocol supports its own compression mechanism,
you can use OP_NO_COMPRESSION to disable SSL-level compression.

New in version 3.3."
"SSLSocket.get_channel_binding(cb_type=""tls-unique"")","Get channel binding data for current connection, as a bytes object.  Returns
None if not connected or the handshake has not been completed.
The cb_type parameter allow selection of the desired channel binding
type. Valid channel binding types are listed in the
CHANNEL_BINDING_TYPES list.  Currently only the ‘tls-unique’ channel
binding, defined by RFC 5929, is supported.  ValueError will be
raised if an unsupported channel binding type is requested.

New in version 3.3."
SSLSocket.selected_alpn_protocol(),"Return the protocol that was selected during the TLS handshake.  If
SSLContext.set_alpn_protocols() was not called, if the other party does
not support ALPN, if this socket does not support any of the client’s
proposed protocols, or if the handshake has not happened yet, None is
returned.

New in version 3.5."
SSLSocket.selected_npn_protocol(),"Return the higher-level protocol that was selected during the TLS/SSL
handshake. If SSLContext.set_npn_protocols() was not called, or
if the other party does not support NPN, or if the handshake has not yet
happened, this will return None.

New in version 3.3."
SSLSocket.unwrap(),"Performs the SSL shutdown handshake, which removes the TLS layer from the
underlying socket, and returns the underlying socket object.  This can be
used to go from encrypted operation over a connection to unencrypted.  The
returned socket should always be used for further communication with the
other side of the connection, rather than the original socket."
SSLSocket.verify_client_post_handshake(),"Requests post-handshake authentication (PHA) from a TLS 1.3 client. PHA
can only be initiated for a TLS 1.3 connection from a server-side socket,
after the initial TLS handshake and with PHA enabled on both sides, see
SSLContext.post_handshake_auth.
The method does not perform a cert exchange immediately. The server-side
sends a CertificateRequest during the next write event and expects the
client to respond with a certificate on the next read event.
If any precondition isn’t met (e.g. not TLS 1.3, PHA not enabled), an
SSLError is raised.

Note
Only available with OpenSSL 1.1.1 and TLS 1.3 enabled. Without TLS 1.3
support, the method raises NotImplementedError.


New in version 3.8."
SSLSocket.version(),"Return the actual SSL protocol version negotiated by the connection
as a string, or None is no secure connection is established.
As of this writing, possible return values include ""SSLv2"",
""SSLv3"", ""TLSv1"", ""TLSv1.1"" and ""TLSv1.2"".
Recent OpenSSL versions may define more return values.

New in version 3.5."
SSLSocket.pending(),"Returns the number of already decrypted bytes available for read, pending on
the connection."
SSLContext.cert_store_stats(),"Get statistics about quantities of loaded X.509 certificates, count of
X.509 certificates flagged as CA certificates and certificate revocation
lists as dictionary.
Example for a context with one CA cert and one other cert:
>>> context.cert_store_stats()
{'crl': 0, 'x509_ca': 1, 'x509': 2}



New in version 3.4."
"SSLContext.load_cert_chain(certfile, keyfile=None, password=None)","Load a private key and the corresponding certificate.  The certfile
string must be the path to a single file in PEM format containing the
certificate as well as any number of CA certificates needed to establish
the certificate’s authenticity.  The keyfile string, if present, must
point to a file containing the private key in.  Otherwise the private
key will be taken from certfile as well.  See the discussion of
Certificates for more information on how the certificate
is stored in the certfile.
The password argument may be a function to call to get the password for
decrypting the private key.  It will only be called if the private key is
encrypted and a password is necessary.  It will be called with no arguments,
and it should return a string, bytes, or bytearray.  If the return value is
a string it will be encoded as UTF-8 before using it to decrypt the key.
Alternatively a string, bytes, or bytearray value may be supplied directly
as the password argument.  It will be ignored if the private key is not
encrypted and no password is needed.
If the password argument is not specified and a password is required,
OpenSSL’s built-in password prompting mechanism will be used to
interactively prompt the user for a password.
An SSLError is raised if the private key doesn’t
match with the certificate.

Changed in version 3.3: New optional argument password."
SSLContext.load_default_certs(purpose=Purpose.SERVER_AUTH),"Load a set of default “certification authority” (CA) certificates from
default locations. On Windows it loads CA certs from the CA and
ROOT system stores. On other systems it calls
SSLContext.set_default_verify_paths(). In the future the method may
load CA certificates from other locations, too.
The purpose flag specifies what kind of CA certificates are loaded. The
default settings Purpose.SERVER_AUTH loads certificates, that are
flagged and trusted for TLS web server authentication (client side
sockets). Purpose.CLIENT_AUTH loads CA certificates for client
certificate verification on the server side.

New in version 3.4."
"SSLContext.load_verify_locations(cafile=None, capath=None, cadata=None)","Load a set of “certification authority” (CA) certificates used to validate
other peers’ certificates when verify_mode is other than
CERT_NONE.  At least one of cafile or capath must be specified.
This method can also load certification revocation lists (CRLs) in PEM or
DER format. In order to make use of CRLs, SSLContext.verify_flags
must be configured properly.
The cafile string, if present, is the path to a file of concatenated
CA certificates in PEM format. See the discussion of
Certificates for more information about how to arrange the
certificates in this file.
The capath string, if present, is
the path to a directory containing several CA certificates in PEM format,
following an OpenSSL specific layout.
The cadata object, if present, is either an ASCII string of one or more
PEM-encoded certificates or a bytes-like object of DER-encoded
certificates. Like with capath extra lines around PEM-encoded
certificates are ignored but at least one certificate must be present.

Changed in version 3.4: New optional argument cadata"
SSLContext.get_ca_certs(binary_form=False),"Get a list of loaded “certification authority” (CA) certificates. If the
binary_form parameter is False each list
entry is a dict like the output of SSLSocket.getpeercert(). Otherwise
the method returns a list of DER-encoded certificates. The returned list
does not contain certificates from capath unless a certificate was
requested and loaded by a SSL connection.

Note
Certificates in a capath directory aren’t loaded unless they have
been used at least once.


New in version 3.4."
SSLContext.get_ciphers(),"Get a list of enabled ciphers. The list is in order of cipher priority.
See SSLContext.set_ciphers().
Example:
>>> ctx = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
>>> ctx.set_ciphers('ECDHE+AESGCM:!ECDSA')
>>> ctx.get_ciphers()  # OpenSSL 1.0.x
[{'alg_bits': 256,
  'description': 'ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  '
                 'Enc=AESGCM(256) Mac=AEAD',
  'id': 50380848,
  'name': 'ECDHE-RSA-AES256-GCM-SHA384',
  'protocol': 'TLSv1/SSLv3',
  'strength_bits': 256},
 {'alg_bits': 128,
  'description': 'ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  '
                 'Enc=AESGCM(128) Mac=AEAD',
  'id': 50380847,
  'name': 'ECDHE-RSA-AES128-GCM-SHA256',
  'protocol': 'TLSv1/SSLv3',
  'strength_bits': 128}]


On OpenSSL 1.1 and newer the cipher dict contains additional fields:
>>> ctx.get_ciphers()  # OpenSSL 1.1+
[{'aead': True,
  'alg_bits': 256,
  'auth': 'auth-rsa',
  'description': 'ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  '
                 'Enc=AESGCM(256) Mac=AEAD',
  'digest': None,
  'id': 50380848,
  'kea': 'kx-ecdhe',
  'name': 'ECDHE-RSA-AES256-GCM-SHA384',
  'protocol': 'TLSv1.2',
  'strength_bits': 256,
  'symmetric': 'aes-256-gcm'},
 {'aead': True,
  'alg_bits': 128,
  'auth': 'auth-rsa',
  'description': 'ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  '
                 'Enc=AESGCM(128) Mac=AEAD',
  'digest': None,
  'id': 50380847,
  'kea': 'kx-ecdhe',
  'name': 'ECDHE-RSA-AES128-GCM-SHA256',
  'protocol': 'TLSv1.2',
  'strength_bits': 128,
  'symmetric': 'aes-128-gcm'}]


Availability: OpenSSL 1.0.2+.

New in version 3.6."
SSLContext.set_default_verify_paths(),"Load a set of default “certification authority” (CA) certificates from
a filesystem path defined when building the OpenSSL library.  Unfortunately,
there’s no easy way to know whether this method succeeds: no error is
returned if no certificates are to be found.  When the OpenSSL library is
provided as part of the operating system, though, it is likely to be
configured properly."
SSLContext.set_ciphers(ciphers),"Set the available ciphers for sockets created with this context.
It should be a string in the OpenSSL cipher list format.
If no cipher can be selected (because compile-time options or other
configuration forbids use of all the specified ciphers), an
SSLError will be raised.

Note
when connected, the SSLSocket.cipher() method of SSL sockets will
give the currently selected cipher.
OpenSSL 1.1.1 has TLS 1.3 cipher suites enabled by default. The suites
cannot be disabled with set_ciphers()."
SSLContext.set_alpn_protocols(protocols),"Specify which protocols the socket should advertise during the SSL/TLS
handshake. It should be a list of ASCII strings, like ['http/1.1',
'spdy/2'], ordered by preference. The selection of a protocol will happen
during the handshake, and will play out according to RFC 7301. After a
successful handshake, the SSLSocket.selected_alpn_protocol() method will
return the agreed-upon protocol.
This method will raise NotImplementedError if HAS_ALPN is
False.
OpenSSL 1.1.0 to 1.1.0e will abort the handshake and raise SSLError
when both sides support ALPN but cannot agree on a protocol. 1.1.0f+
behaves like 1.0.2, SSLSocket.selected_alpn_protocol() returns None.

New in version 3.5."
SSLContext.set_npn_protocols(protocols),"Specify which protocols the socket should advertise during the SSL/TLS
handshake. It should be a list of strings, like ['http/1.1', 'spdy/2'],
ordered by preference. The selection of a protocol will happen during the
handshake, and will play out according to the Application Layer Protocol Negotiation. After a
successful handshake, the SSLSocket.selected_npn_protocol() method will
return the agreed-upon protocol.
This method will raise NotImplementedError if HAS_NPN is
False.

New in version 3.3."
SSLContext.load_dh_params(dhfile),"Load the key generation parameters for Diffie-Hellman (DH) key exchange.
Using DH key exchange improves forward secrecy at the expense of
computational resources (both on the server and on the client).
The dhfile parameter should be the path to a file containing DH
parameters in PEM format.
This setting doesn’t apply to client sockets.  You can also use the
OP_SINGLE_DH_USE option to further improve security.

New in version 3.3."
SSLContext.set_ecdh_curve(curve_name),"Set the curve name for Elliptic Curve-based Diffie-Hellman (ECDH) key
exchange.  ECDH is significantly faster than regular DH while arguably
as secure.  The curve_name parameter should be a string describing
a well-known elliptic curve, for example prime256v1 for a widely
supported curve.
This setting doesn’t apply to client sockets.  You can also use the
OP_SINGLE_ECDH_USE option to further improve security.
This method is not available if HAS_ECDH is False.

New in version 3.3.


See also

SSL/TLS & Perfect Forward SecrecyVincent Bernat."
"SSLContext.wrap_socket(sock, server_side=False, do_handshake_on_connect=True, suppress_ragged_eofs=True, server_hostname=None, session=None)","Wrap an existing Python socket sock and return an instance of
SSLContext.sslsocket_class (default SSLSocket). The
returned SSL socket is tied to the context, its settings and certificates.
sock must be a SOCK_STREAM socket; other
socket types are unsupported.
The parameter server_side is a boolean which identifies whether
server-side or client-side behavior is desired from this socket.
For client-side sockets, the context construction is lazy; if the
underlying socket isn’t connected yet, the context construction will be
performed after connect() is called on the socket.  For
server-side sockets, if the socket has no remote peer, it is assumed
to be a listening socket, and the server-side SSL wrapping is
automatically performed on client connections accepted via the
accept() method. The method may raise SSLError.
On client connections, the optional parameter server_hostname specifies
the hostname of the service which we are connecting to.  This allows a
single server to host multiple SSL-based services with distinct certificates,
quite similarly to HTTP virtual hosts. Specifying server_hostname will
raise a ValueError if server_side is true.
The parameter do_handshake_on_connect specifies whether to do the SSL
handshake automatically after doing a socket.connect(), or whether the
application program will call it explicitly, by invoking the
SSLSocket.do_handshake() method.  Calling
SSLSocket.do_handshake() explicitly gives the program control over the
blocking behavior of the socket I/O involved in the handshake.
The parameter suppress_ragged_eofs specifies how the
SSLSocket.recv() method should signal unexpected EOF from the other end
of the connection.  If specified as True (the default), it returns a
normal EOF (an empty bytes object) in response to unexpected EOF errors
raised from the underlying socket; if False, it will raise the
exceptions back to the caller.
session, see session.

Changed in version 3.5: Always allow a server_hostname to be passed, even if OpenSSL does not
have SNI.


Changed in version 3.6: session argument was added.

Changed in version 3.7: The method returns on instance of SSLContext.sslsocket_class
instead of hard-coded SSLSocket."
"SSLContext.wrap_bio(incoming, outgoing, server_side=False, server_hostname=None, session=None)","Wrap the BIO objects incoming and outgoing and return an instance of
SSLContext.sslobject_class (default SSLObject). The SSL
routines will read input data from the incoming BIO and write data to the
outgoing BIO.
The server_side, server_hostname and session parameters have the
same meaning as in SSLContext.wrap_socket().

Changed in version 3.6: session argument was added.


Changed in version 3.7: The method returns on instance of SSLContext.sslobject_class
instead of hard-coded SSLObject."
SSLContext.session_stats(),"Get statistics about the SSL sessions created or managed by this context.
A dictionary is returned which maps the names of each piece of information to their
numeric values.  For example, here is the total number of hits and misses
in the session cache since the context was created:
>>> stats = context.session_stats()
>>> stats['hits'], stats['misses']
(0, 0)"
read(n=-1),"Read up to n bytes from the memory buffer. If n is not specified or
negative, all bytes are returned."
write(buf),"Write the bytes from buf to the memory BIO. The buf argument must be an
object supporting the buffer protocol.
The return value is the number of bytes written, which is always equal to
the length of buf."
write_eof(),"Write an EOF marker to the memory BIO. After this method has been called, it
is illegal to call write(). The attribute eof will
become true after all data currently in the buffer has been read."
select.devpoll(),"(Only supported on Solaris and derivatives.)  Returns a /dev/poll
polling object; see section /dev/poll Polling Objects below for the
methods supported by devpoll objects.
devpoll() objects are linked to the number of file
descriptors allowed at the time of instantiation. If your program
reduces this value, devpoll() will fail. If your program
increases this value, devpoll() may return an
incomplete list of active file descriptors.
The new file descriptor is non-inheritable.

New in version 3.3.


Changed in version 3.4: The new file descriptor is now non-inheritable."
"select.epoll(sizehint=-1, flags=0)","(Only supported on Linux 2.5.44 and newer.) Return an edge polling object,
which can be used as Edge or Level Triggered interface for I/O
events.
sizehint informs epoll about the expected number of events to be
registered.  It must be positive, or -1 to use the default. It is only
used on older systems where epoll_create1() is not available;
otherwise it has no effect (though its value is still checked).
flags is deprecated and completely ignored.  However, when supplied, its
value must be 0 or select.EPOLL_CLOEXEC, otherwise OSError is
raised.
See the Edge and Level Trigger Polling (epoll) Objects section below for the methods supported by
epolling objects.
epoll objects support the context management protocol: when used in a
with statement, the new file descriptor is automatically closed
at the end of the block.
The new file descriptor is non-inheritable.

Changed in version 3.3: Added the flags parameter.


Changed in version 3.4: Support for the with statement was added.
The new file descriptor is now non-inheritable.


Deprecated since version 3.4: The flags parameter.  select.EPOLL_CLOEXEC is used by default now.
Use os.set_inheritable() to make the file descriptor inheritable."
select.poll(),"(Not supported by all operating systems.)  Returns a polling object, which
supports registering and unregistering file descriptors, and then polling them
for I/O events; see section Polling Objects below for the methods supported
by polling objects."
select.kqueue(),"(Only supported on BSD.)  Returns a kernel queue object; see section
Kqueue Objects below for the methods supported by kqueue objects.
The new file descriptor is non-inheritable.

Changed in version 3.4: The new file descriptor is now non-inheritable."
"select.kevent(ident, filter=KQ_FILTER_READ, flags=KQ_EV_ADD, fflags=0, data=0, udata=0)","(Only supported on BSD.)  Returns a kernel event object; see section
Kevent Objects below for the methods supported by kevent objects."
"select.select(rlist, wlist, xlist[, timeout])","This is a straightforward interface to the Unix select() system call.
The first three arguments are sequences of ‘waitable objects’: either
integers representing file descriptors or objects with a parameterless method
named fileno() returning such an integer:

rlist: wait until ready for reading
wlist: wait until ready for writing
xlist: wait for an “exceptional condition” (see the manual page for what
your system considers such a condition)

Empty sequences are allowed, but acceptance of three empty sequences is
platform-dependent. (It is known to work on Unix but not on Windows.)  The
optional timeout argument specifies a time-out as a floating point number
in seconds.  When the timeout argument is omitted the function blocks until
at least one file descriptor is ready.  A time-out value of zero specifies a
poll and never blocks.
The return value is a triple of lists of objects that are ready: subsets of the
first three arguments.  When the time-out is reached without a file descriptor
becoming ready, three empty lists are returned.
Among the acceptable object types in the sequences are Python file
objects (e.g. sys.stdin, or objects returned by
open() or os.popen()), socket objects returned by
socket.socket().  You may also define a wrapper class yourself,
as long as it has an appropriate fileno() method (that
really returns a file descriptor, not just a random integer).

Note
File objects on Windows are not acceptable, but sockets are.  On Windows,
the underlying select() function is provided by the WinSock
library, and does not handle file descriptors that don’t originate from
WinSock.


Changed in version 3.5: The function is now retried with a recomputed timeout when interrupted by
a signal, except if the signal handler raises an exception (see
PEP 475 for the rationale), instead of raising
InterruptedError."
devpoll.close(),"Close the file descriptor of the polling object.

New in version 3.4."
devpoll.fileno(),"Return the file descriptor number of the polling object.

New in version 3.4."
"devpoll.register(fd[, eventmask])","Register a file descriptor with the polling object.  Future calls to the
poll() method will then check whether the file descriptor has any
pending I/O events.  fd can be either an integer, or an object with a
fileno() method that returns an integer.  File objects
implement fileno(), so they can also be used as the argument.
eventmask is an optional bitmask describing the type of events you want to
check for. The constants are the same that with poll()
object. The default value is a combination of the constants POLLIN,
POLLPRI, and POLLOUT.

Warning
Registering a file descriptor that’s already registered is not an
error, but the result is undefined. The appropriate action is to
unregister or modify it first. This is an important difference
compared with poll()."
"devpoll.modify(fd[, eventmask])","This method does an unregister() followed by a
register(). It is (a bit) more efficient that doing the same
explicitly."
devpoll.unregister(fd),"Remove a file descriptor being tracked by a polling object.  Just like the
register() method, fd can be an integer or an object with a
fileno() method that returns an integer.
Attempting to remove a file descriptor that was never registered is
safely ignored."
devpoll.poll([timeout]),"Polls the set of registered file descriptors, and returns a possibly-empty list
containing (fd, event) 2-tuples for the descriptors that have events or
errors to report. fd is the file descriptor, and event is a bitmask with
bits set for the reported events for that descriptor — POLLIN for
waiting input, POLLOUT to indicate that the descriptor can be written
to, and so forth. An empty list indicates that the call timed out and no file
descriptors had any events to report. If timeout is given, it specifies the
length of time in milliseconds which the system will wait for events before
returning. If timeout is omitted, -1, or None, the call will
block until there is an event for this poll object.

Changed in version 3.5: The function is now retried with a recomputed timeout when interrupted by
a signal, except if the signal handler raises an exception (see
PEP 475 for the rationale), instead of raising
InterruptedError."
epoll.close(),Close the control file descriptor of the epoll object.
epoll.fileno(),Return the file descriptor number of the control fd.
epoll.fromfd(fd),Create an epoll object from a given file descriptor.
"epoll.register(fd[, eventmask])",Register a fd descriptor with the epoll object.
"epoll.modify(fd, eventmask)",Modify a registered file descriptor.
epoll.unregister(fd),Remove a registered file descriptor from the epoll object.
"epoll.poll(timeout=None, maxevents=-1)","Wait for events. timeout in seconds (float)

Changed in version 3.5: The function is now retried with a recomputed timeout when interrupted by
a signal, except if the signal handler raises an exception (see
PEP 475 for the rationale), instead of raising
InterruptedError."
"poll.register(fd[, eventmask])","Register a file descriptor with the polling object.  Future calls to the
poll() method will then check whether the file descriptor has any
pending I/O events.  fd can be either an integer, or an object with a
fileno() method that returns an integer.  File objects
implement fileno(), so they can also be used as the argument.
eventmask is an optional bitmask describing the type of events you want to
check for, and can be a combination of the constants POLLIN,
POLLPRI, and POLLOUT, described in the table below.  If not
specified, the default value used will check for all 3 types of events.






Constant
Meaning



POLLIN
There is data to read

POLLPRI
There is urgent data to read

POLLOUT
Ready for output: writing will not block

POLLERR
Error condition of some sort

POLLHUP
Hung up

POLLRDHUP
Stream socket peer closed connection, or
shut down writing half of connection

POLLNVAL
Invalid request: descriptor not open



Registering a file descriptor that’s already registered is not an error, and has
the same effect as registering the descriptor exactly once."
"poll.modify(fd, eventmask)","Modifies an already registered fd. This has the same effect as
register(fd, eventmask).  Attempting to modify a file descriptor
that was never registered causes an OSError exception with errno
ENOENT to be raised."
poll.unregister(fd),"Remove a file descriptor being tracked by a polling object.  Just like the
register() method, fd can be an integer or an object with a
fileno() method that returns an integer.
Attempting to remove a file descriptor that was never registered causes a
KeyError exception to be raised."
poll.poll([timeout]),"Polls the set of registered file descriptors, and returns a possibly-empty list
containing (fd, event) 2-tuples for the descriptors that have events or
errors to report. fd is the file descriptor, and event is a bitmask with
bits set for the reported events for that descriptor — POLLIN for
waiting input, POLLOUT to indicate that the descriptor can be written
to, and so forth. An empty list indicates that the call timed out and no file
descriptors had any events to report. If timeout is given, it specifies the
length of time in milliseconds which the system will wait for events before
returning. If timeout is omitted, negative, or None, the call will
block until there is an event for this poll object.

Changed in version 3.5: The function is now retried with a recomputed timeout when interrupted by
a signal, except if the signal handler raises an exception (see
PEP 475 for the rationale), instead of raising
InterruptedError."
kqueue.close(),Close the control file descriptor of the kqueue object.
kqueue.fileno(),Return the file descriptor number of the control fd.
kqueue.fromfd(fd),Create a kqueue object from a given file descriptor.
"abstractmethod register(fileobj, events, data=None)","Register a file object for selection, monitoring it for I/O events.
fileobj is the file object to monitor.  It may either be an integer
file descriptor or an object with a fileno() method.
events is a bitwise mask of events to monitor.
data is an opaque object.
This returns a new SelectorKey instance, or raises a
ValueError in case of invalid event mask or file descriptor, or
KeyError if the file object is already registered."
abstractmethod unregister(fileobj),"Unregister a file object from selection, removing it from monitoring. A
file object shall be unregistered prior to being closed.
fileobj must be a file object previously registered.
This returns the associated SelectorKey instance, or raises a
KeyError if fileobj is not registered.  It will raise
ValueError if fileobj is invalid (e.g. it has no fileno()
method or its fileno() method has an invalid return value)."
"modify(fileobj, events, data=None)","Change a registered file object’s monitored events or attached data.
This is equivalent to BaseSelector.unregister(fileobj)() followed
by BaseSelector.register(fileobj, events, data)(), except that it
can be implemented more efficiently.
This returns a new SelectorKey instance, or raises a
ValueError in case of invalid event mask or file descriptor, or
KeyError if the file object is not registered."
abstractmethod select(timeout=None),"Wait until some registered file objects become ready, or the timeout
expires.
If timeout > 0, this specifies the maximum wait time, in seconds.
If timeout <= 0, the call won’t block, and will report the currently
ready file objects.
If timeout is None, the call will block until a monitored file object
becomes ready.
This returns a list of (key, events) tuples, one for each ready file
object.
key is the SelectorKey instance corresponding to a ready file
object.
events is a bitmask of events ready on this file object.

Note
This method can return before any file object becomes ready or the
timeout has elapsed if the current process receives a signal: in this
case, an empty list will be returned.


Changed in version 3.5: The selector is now retried with a recomputed timeout when interrupted
by a signal if the signal handler did not raise an exception (see
PEP 475 for the rationale), instead of returning an empty list
of events before the timeout."
close(),"Close the selector.
This must be called to make sure that any underlying resource is freed.
The selector shall not be used once it has been closed."
get_key(fileobj),"Return the key associated with a registered file object.
This returns the SelectorKey instance associated to this file
object, or raises KeyError if the file object is not registered."
abstractmethod get_map(),"Return a mapping of file objects to selector keys.
This returns a Mapping instance mapping
registered file objects to their associated SelectorKey
instance."
fileno(),"This returns the file descriptor used by the underlying
select.epoll() object."
fileno(),"This returns the file descriptor used by the underlying
select.devpoll() object."
fileno(),"This returns the file descriptor used by the underlying
select.kqueue() object."
"asyncore.loop([timeout[, use_poll[, map[, count]]]])","Enter a polling loop that terminates after count passes or all open
channels have been closed.  All arguments are optional.  The count
parameter defaults to None, resulting in the loop terminating only when all
channels have been closed.  The timeout argument sets the timeout
parameter for the appropriate select() or poll()
call, measured in seconds; the default is 30 seconds.  The use_poll
parameter, if true, indicates that poll() should be used in
preference to select() (the default is False).
The map parameter is a dictionary whose items are the channels to watch.
As channels are closed they are deleted from their map.  If map is
omitted, a global map is used. Channels (instances of
asyncore.dispatcher, asynchat.async_chat and subclasses
thereof) can freely be mixed in the map."
handle_read(),"Called when the asynchronous loop detects that a read() call on the
channel’s socket will succeed."
handle_write(),"Called when the asynchronous loop detects that a writable socket can be
written.  Often this method will implement the necessary buffering for
performance.  For example:
def handle_write(self):
    sent = self.send(self.buffer)
    self.buffer = self.buffer[sent:]"
handle_expt(),"Called when there is out of band (OOB) data for a socket connection.  This
will almost never happen, as OOB is tenuously supported and rarely used."
handle_connect(),"Called when the active opener’s socket actually makes a connection.  Might
send a “welcome” banner, or initiate a protocol negotiation with the
remote endpoint, for example."
handle_close(),Called when the socket is closed.
handle_error(),"Called when an exception is raised and not otherwise handled.  The default
version prints a condensed traceback."
handle_accept(),"Called on listening channels (passive openers) when a connection can be
established with a new remote endpoint that has issued a connect()
call for the local endpoint. Deprecated in version 3.2; use
handle_accepted() instead.

Deprecated since version 3.2."
"handle_accepted(sock, addr)","Called on listening channels (passive openers) when a connection has been
established with a new remote endpoint that has issued a connect()
call for the local endpoint.  sock is a new socket object usable to
send and receive data on the connection, and addr is the address
bound to the socket on the other end of the connection.

New in version 3.2."
readable(),"Called each time around the asynchronous loop to determine whether a
channel’s socket should be added to the list on which read events can
occur.  The default method simply returns True, indicating that by
default, all channels will be interested in read events."
writable(),"Called each time around the asynchronous loop to determine whether a
channel’s socket should be added to the list on which write events can
occur.  The default method simply returns True, indicating that by
default, all channels will be interested in write events."
"create_socket(family=socket.AF_INET, type=socket.SOCK_STREAM)","This is identical to the creation of a normal socket, and will use the
same options for creation.  Refer to the socket documentation for
information on creating sockets.

Changed in version 3.3: family and type arguments can be omitted."
connect(address),"As with the normal socket object, address is a tuple with the first
element the host to connect to, and the second the port number."
send(data),Send data to the remote end-point of the socket.
recv(buffer_size),"Read at most buffer_size bytes from the socket’s remote end-point.  An
empty bytes object implies that the channel has been closed from the
other end.
Note that recv() may raise BlockingIOError , even though
select.select() or select.poll() has reported the socket
ready for reading."
listen(backlog),"Listen for connections made to the socket.  The backlog argument
specifies the maximum number of queued connections and should be at least
1; the maximum value is system-dependent (usually 5)."
bind(address),"Bind the socket to address.  The socket must not already be bound.  (The
format of address depends on the address family — refer to the
socket documentation for more information.)  To mark
the socket as re-usable (setting the SO_REUSEADDR option), call
the dispatcher object’s set_reuse_addr() method."
accept(),"Accept a connection.  The socket must be bound to an address and listening
for connections.  The return value can be either None or a pair
(conn, address) where conn is a new socket object usable to send
and receive data on the connection, and address is the address bound to
the socket on the other end of the connection.
When None is returned it means the connection didn’t take place, in
which case the server should just ignore this event and keep listening
for further incoming connections."
close(),"Close the socket.  All future operations on the socket object will fail.
The remote end-point will receive no more data (after queued data is
flushed).  Sockets are automatically closed when they are
garbage-collected."
async_chat.close_when_done(),"Pushes a None on to the producer queue. When this producer is popped off
the queue it causes the channel to be closed."
async_chat.collect_incoming_data(data),"Called with data holding an arbitrary amount of received data.  The
default method, which must be overridden, raises a
NotImplementedError exception."
async_chat.discard_buffers(),"In emergencies this method will discard any data held in the input and/or
output buffers and the producer queue."
async_chat.found_terminator(),"Called when the incoming data stream  matches the termination condition set
by set_terminator(). The default method, which must be overridden,
raises a NotImplementedError exception. The buffered input data
should be available via an instance attribute."
async_chat.get_terminator(),Returns the current terminator for the channel.
async_chat.push(data),"Pushes data on to the channel’s queue to ensure its transmission.
This is all you need to do to have the channel write the data out to the
network, although it is possible to use your own producers in more complex
schemes to implement encryption and chunking, for example."
async_chat.push_with_producer(producer),"Takes a producer object and adds it to the producer queue associated with
the channel.  When all currently-pushed producers have been exhausted the
channel will consume this producer’s data by calling its more()
method and send the data to the remote endpoint."
async_chat.set_terminator(term),"Sets the terminating condition to be recognized on the channel.  term
may be any of three types of value, corresponding to three different ways
to handle incoming protocol data.






term
Description



string
Will call found_terminator() when the
string is found in the input stream

integer
Will call found_terminator() when the
indicated number of characters have been
received

None
The channel continues to collect data
forever



Note that any data following the terminator will be available for reading
by the channel after found_terminator() is called."
signal.alarm(time),"If time is non-zero, this function requests that a SIGALRM signal be
sent to the process in time seconds. Any previously scheduled alarm is
canceled (only one alarm can be scheduled at any time).  The returned value is
then the number of seconds before any previously set alarm was to have been
delivered. If time is zero, no alarm is scheduled, and any scheduled alarm is
canceled.  If the return value is zero, no alarm is currently scheduled.
Availability: Unix.  See the man page alarm(2) for further
information."
signal.getsignal(signalnum),"Return the current signal handler for the signal signalnum. The returned value
may be a callable Python object, or one of the special values
signal.SIG_IGN, signal.SIG_DFL or None.  Here,
signal.SIG_IGN means that the signal was previously ignored,
signal.SIG_DFL means that the default way of handling the signal was
previously in use, and None means that the previous signal handler was not
installed from Python."
signal.strsignal(signalnum),"Return the system description of the signal signalnum, such as
“Interrupt”, “Segmentation fault”, etc. Returns None if the signal
is not recognized.

New in version 3.8."
signal.valid_signals(),"Return the set of valid signal numbers on this platform.  This can be
less than range(1, NSIG) if some signals are reserved by the system
for internal use.

New in version 3.8."
signal.pause(),"Cause the process to sleep until a signal is received; the appropriate handler
will then be called.  Returns nothing.
Availability: Unix.  See the man page signal(2) for further
information.
See also sigwait(), sigwaitinfo(), sigtimedwait() and
sigpending()."
signal.raise_signal(signum),"Sends a signal to the calling process. Returns nothing.

New in version 3.8."
"signal.pthread_kill(thread_id, signalnum)","Send the signal signalnum to the thread thread_id, another thread in the
same process as the caller.  The target thread can be executing any code
(Python or not).  However, if the target thread is executing the Python
interpreter, the Python signal handlers will be executed by the main
thread.  Therefore, the only point of sending a
signal to a particular Python thread would be to force a running system call
to fail with InterruptedError.
Use threading.get_ident() or the ident
attribute of threading.Thread objects to get a suitable value
for thread_id.
If signalnum is 0, then no signal is sent, but error checking is still
performed; this can be used to check if the target thread is still running.
Raises an auditing event signal.pthread_kill with arguments thread_id, signalnum.
Availability: Unix.  See the man page pthread_kill(3) for further
information.
See also os.kill().

New in version 3.3."
"signal.pthread_sigmask(how, mask)","Fetch and/or change the signal mask of the calling thread.  The signal mask
is the set of signals whose delivery is currently blocked for the caller.
Return the old signal mask as a set of signals.
The behavior of the call is dependent on the value of how, as follows.

SIG_BLOCK: The set of blocked signals is the union of the current
set and the mask argument.
SIG_UNBLOCK: The signals in mask are removed from the current
set of blocked signals.  It is permissible to attempt to unblock a
signal which is not blocked.
SIG_SETMASK: The set of blocked signals is set to the mask
argument.

mask is a set of signal numbers (e.g. {signal.SIGINT,
signal.SIGTERM}). Use valid_signals() for a full
mask including all signals.
For example, signal.pthread_sigmask(signal.SIG_BLOCK, []) reads the
signal mask of the calling thread.
Availability: Unix.  See the man page sigprocmask(3) and
pthread_sigmask(3) for further information.
See also pause(), sigpending() and sigwait().

New in version 3.3."
"signal.setitimer(which, seconds, interval=0.0)","Sets given interval timer (one of signal.ITIMER_REAL,
signal.ITIMER_VIRTUAL or signal.ITIMER_PROF) specified
by which to fire after seconds (float is accepted, different from
alarm()) and after that every interval seconds (if interval
is non-zero). The interval timer specified by which can be cleared by
setting seconds to zero.
When an interval timer fires, a signal is sent to the process.
The signal sent is dependent on the timer being used;
signal.ITIMER_REAL will deliver SIGALRM,
signal.ITIMER_VIRTUAL sends SIGVTALRM,
and signal.ITIMER_PROF will deliver SIGPROF.
The old values are returned as a tuple: (delay, interval).
Attempting to pass an invalid interval timer will cause an
ItimerError.
Availability: Unix."
signal.getitimer(which),"Returns current value of a given interval timer specified by which.
Availability: Unix."
"signal.set_wakeup_fd(fd, *, warn_on_full_buffer=True)","Set the wakeup file descriptor to fd.  When a signal is received, the
signal number is written as a single byte into the fd.  This can be used by
a library to wakeup a poll or select call, allowing the signal to be fully
processed.
The old wakeup fd is returned (or -1 if file descriptor wakeup was not
enabled).  If fd is -1, file descriptor wakeup is disabled.
If not -1, fd must be non-blocking.  It is up to the library to remove
any bytes from fd before calling poll or select again.
When threads are enabled, this function can only be called from the main thread;
attempting to call it from other threads will cause a ValueError
exception to be raised.
There are two common ways to use this function. In both approaches,
you use the fd to wake up when a signal arrives, but then they
differ in how they determine which signal or signals have
arrived.
In the first approach, we read the data out of the fd’s buffer, and
the byte values give you the signal numbers. This is simple, but in
rare cases it can run into a problem: generally the fd will have a
limited amount of buffer space, and if too many signals arrive too
quickly, then the buffer may become full, and some signals may be
lost. If you use this approach, then you should set
warn_on_full_buffer=True, which will at least cause a warning
to be printed to stderr when signals are lost.
In the second approach, we use the wakeup fd only for wakeups,
and ignore the actual byte values. In this case, all we care about
is whether the fd’s buffer is empty or non-empty; a full buffer
doesn’t indicate a problem at all. If you use this approach, then
you should set warn_on_full_buffer=False, so that your users
are not confused by spurious warning messages.

Changed in version 3.5: On Windows, the function now also supports socket handles.


Changed in version 3.7: Added warn_on_full_buffer parameter."
"signal.siginterrupt(signalnum, flag)","Change system call restart behaviour: if flag is False, system
calls will be restarted when interrupted by signal signalnum, otherwise
system calls will be interrupted.  Returns nothing.
Availability: Unix.  See the man page siginterrupt(3)
for further information.
Note that installing a signal handler with signal() will reset the
restart behaviour to interruptible by implicitly calling
siginterrupt() with a true flag value for the given signal."
"signal.signal(signalnum, handler)","Set the handler for signal signalnum to the function handler.  handler can
be a callable Python object taking two arguments (see below), or one of the
special values signal.SIG_IGN or signal.SIG_DFL.  The previous
signal handler will be returned (see the description of getsignal()
above).  (See the Unix man page signal(2) for further information.)
When threads are enabled, this function can only be called from the main thread;
attempting to call it from other threads will cause a ValueError
exception to be raised.
The handler is called with two arguments: the signal number and the current
stack frame (None or a frame object; for a description of frame objects,
see the description in the type hierarchy or see the
attribute descriptions in the inspect module).
On Windows, signal() can only be called with SIGABRT,
SIGFPE, SIGILL, SIGINT, SIGSEGV,
SIGTERM, or SIGBREAK.
A ValueError will be raised in any other case.
Note that not all systems define the same set of signal names; an
AttributeError will be raised if a signal name is not defined as
SIG* module level constant."
signal.sigpending(),"Examine the set of signals that are pending for delivery to the calling
thread (i.e., the signals which have been raised while blocked).  Return the
set of the pending signals.
Availability: Unix.  See the man page sigpending(2) for further
information.
See also pause(), pthread_sigmask() and sigwait().

New in version 3.3."
signal.sigwait(sigset),"Suspend execution of the calling thread until the delivery of one of the
signals specified in the signal set sigset.  The function accepts the signal
(removes it from the pending list of signals), and returns the signal number.
Availability: Unix.  See the man page sigwait(3) for further
information.
See also pause(), pthread_sigmask(), sigpending(),
sigwaitinfo() and sigtimedwait().

New in version 3.3."
signal.sigwaitinfo(sigset),"Suspend execution of the calling thread until the delivery of one of the
signals specified in the signal set sigset.  The function accepts the
signal and removes it from the pending list of signals. If one of the
signals in sigset is already pending for the calling thread, the function
will return immediately with information about that signal. The signal
handler is not called for the delivered signal. The function raises an
InterruptedError if it is interrupted by a signal that is not in
sigset.
The return value is an object representing the data contained in the
siginfo_t structure, namely: si_signo, si_code,
si_errno, si_pid, si_uid, si_status,
si_band.
Availability: Unix.  See the man page sigwaitinfo(2) for further
information.
See also pause(), sigwait() and sigtimedwait().

New in version 3.3.


Changed in version 3.5: The function is now retried if interrupted by a signal not in sigset
and the signal handler does not raise an exception (see PEP 475 for
the rationale)."
"signal.sigtimedwait(sigset, timeout)","Like sigwaitinfo(), but takes an additional timeout argument
specifying a timeout. If timeout is specified as 0, a poll is
performed. Returns None if a timeout occurs.
Availability: Unix.  See the man page sigtimedwait(2) for further
information.
See also pause(), sigwait() and sigwaitinfo().

New in version 3.3.


Changed in version 3.5: The function is now retried with the recomputed timeout if interrupted
by a signal not in sigset and the signal handler does not raise an
exception (see PEP 475 for the rationale)."
close(),"Closes the mmap. Subsequent calls to other methods of the object will
result in a ValueError exception being raised. This will not close
the open file."
"find(sub[, start[, end]])","Returns the lowest index in the object where the subsequence sub is
found, such that sub is contained in the range [start, end].
Optional arguments start and end are interpreted as in slice notation.
Returns -1 on failure.

Changed in version 3.5: Writable bytes-like object is now accepted."
"flush([offset[, size]])","Flushes changes made to the in-memory copy of a file back to disk. Without
use of this call there is no guarantee that changes are written back before
the object is destroyed.  If offset and size are specified, only
changes to the given range of bytes will be flushed to disk; otherwise, the
whole extent of the mapping is flushed.  offset must be a multiple of the
PAGESIZE or ALLOCATIONGRANULARITY.
None is returned to indicate success.  An exception is raised when the
call failed.

Changed in version 3.8: Previously, a nonzero value was returned on success; zero was returned
on error under Windows.  A zero value was returned on success; an
exception was raised on error under Unix."
"madvise(option[, start[, length]])","Send advice option to the kernel about the memory region beginning at
start and extending length bytes.  option must be one of the
MADV_* constants available on the system.  If
start and length are omitted, the entire mapping is spanned.  On
some systems (including Linux), start must be a multiple of the
PAGESIZE.
Availability: Systems with the madvise() system call.

New in version 3.8."
"move(dest, src, count)","Copy the count bytes starting at offset src to the destination index
dest.  If the mmap was created with ACCESS_READ, then calls to
move will raise a TypeError exception."
read([n]),"Return a bytes containing up to n bytes starting from the
current file position. If the argument is omitted, None or negative,
return all bytes from the current file position to the end of the
mapping. The file position is updated to point after the bytes that were
returned.

Changed in version 3.3: Argument can be omitted or None."
read_byte(),"Returns a byte at the current file position as an integer, and advances
the file position by 1."
readline(),"Returns a single line, starting at the current file position and up to the
next newline."
resize(newsize),"Resizes the map and the underlying file, if any. If the mmap was created
with ACCESS_READ or ACCESS_COPY, resizing the map will
raise a TypeError exception."
"rfind(sub[, start[, end]])","Returns the highest index in the object where the subsequence sub is
found, such that sub is contained in the range [start, end].
Optional arguments start and end are interpreted as in slice notation.
Returns -1 on failure.

Changed in version 3.5: Writable bytes-like object is now accepted."
"seek(pos[, whence])","Set the file’s current position.  whence argument is optional and
defaults to os.SEEK_SET or 0 (absolute file positioning); other
values are os.SEEK_CUR or 1 (seek relative to the current
position) and os.SEEK_END or 2 (seek relative to the file’s end)."
size(),"Return the length of the file, which can be larger than the size of the
memory-mapped area."
tell(),Returns the current position of the file pointer.
write(bytes),"Write the bytes in bytes into memory at the current position of the
file pointer and return the number of bytes written (never less than
len(bytes), since if the write fails, a ValueError will be
raised).  The file position is updated to point after the bytes that
were written.  If the mmap was created with ACCESS_READ, then
writing to it will raise a TypeError exception.

Changed in version 3.5: Writable bytes-like object is now accepted.


Changed in version 3.6: The number of bytes written is now returned."
write_byte(byte),"Write the integer byte into memory at the current
position of the file pointer; the file position is advanced by 1. If
the mmap was created with ACCESS_READ, then writing to it will
raise a TypeError exception."
"json.dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)","Serialize obj as a JSON formatted stream to fp (a .write()-supporting
file-like object) using this conversion table.
If skipkeys is true (default: False), then dict keys that are not
of a basic type (str, int, float, bool,
None) will be skipped instead of raising a TypeError.
The json module always produces str objects, not
bytes objects. Therefore, fp.write() must support str
input.
If ensure_ascii is true (the default), the output is guaranteed to
have all incoming non-ASCII characters escaped.  If ensure_ascii is
false, these characters will be output as-is.
If check_circular is false (default: True), then the circular
reference check for container types will be skipped and a circular reference
will result in an OverflowError (or worse).
If allow_nan is false (default: True), then it will be a
ValueError to serialize out of range float values (nan,
inf, -inf) in strict compliance of the JSON specification.
If allow_nan is true, their JavaScript equivalents (NaN,
Infinity, -Infinity) will be used.
If indent is a non-negative integer or string, then JSON array elements and
object members will be pretty-printed with that indent level.  An indent level
of 0, negative, or """" will only insert newlines.  None (the default)
selects the most compact representation. Using a positive integer indent
indents that many spaces per level.  If indent is a string (such as ""\t""),
that string is used to indent each level.

Changed in version 3.2: Allow strings for indent in addition to integers.

If specified, separators should be an (item_separator, key_separator)
tuple.  The default is (', ', ': ') if indent is None and
(',', ': ') otherwise.  To get the most compact JSON representation,
you should specify (',', ':') to eliminate whitespace.

Changed in version 3.4: Use (',', ': ') as default if indent is not None.

If specified, default should be a function that gets called for objects that
can’t otherwise be serialized.  It should return a JSON encodable version of
the object or raise a TypeError.  If not specified, TypeError
is raised.
If sort_keys is true (default: False), then the output of
dictionaries will be sorted by key.
To use a custom JSONEncoder subclass (e.g. one that overrides the
default() method to serialize additional types), specify it with the
cls kwarg; otherwise JSONEncoder is used.

Changed in version 3.6: All optional parameters are now keyword-only.


Note
Unlike pickle and marshal, JSON is not a framed protocol,
so trying to serialize multiple objects with repeated calls to
dump() using the same fp will result in an invalid JSON file."
"json.dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)","Serialize obj to a JSON formatted str using this conversion
table.  The arguments have the same meaning as in
dump().

Note
Keys in key/value pairs of JSON are always of the type str. When
a dictionary is converted into JSON, all the keys of the dictionary are
coerced to strings. As a result of this, if a dictionary is converted
into JSON and then back into a dictionary, the dictionary may not equal
the original one. That is, loads(dumps(x)) != x if x has non-string
keys."
"json.load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)","Deserialize fp (a .read()-supporting text file or
binary file containing a JSON document) to a Python object using
this conversion table.
object_hook is an optional function that will be called with the result of
any object literal decoded (a dict).  The return value of
object_hook will be used instead of the dict.  This feature can be used
to implement custom decoders (e.g. JSON-RPC
class hinting).
object_pairs_hook is an optional function that will be called with the
result of any object literal decoded with an ordered list of pairs.  The
return value of object_pairs_hook will be used instead of the
dict.  This feature can be used to implement custom decoders.
If object_hook is also defined, the object_pairs_hook takes priority.

Changed in version 3.1: Added support for object_pairs_hook.

parse_float, if specified, will be called with the string of every JSON
float to be decoded.  By default, this is equivalent to float(num_str).
This can be used to use another datatype or parser for JSON floats
(e.g. decimal.Decimal).
parse_int, if specified, will be called with the string of every JSON int
to be decoded.  By default, this is equivalent to int(num_str).  This can
be used to use another datatype or parser for JSON integers
(e.g. float).
parse_constant, if specified, will be called with one of the following
strings: '-Infinity', 'Infinity', 'NaN'.
This can be used to raise an exception if invalid JSON numbers
are encountered.

Changed in version 3.1: parse_constant doesn’t get called on ‘null’, ‘true’, ‘false’ anymore.

To use a custom JSONDecoder subclass, specify it with the cls
kwarg; otherwise JSONDecoder is used.  Additional keyword arguments
will be passed to the constructor of the class.
If the data being deserialized is not a valid JSON document, a
JSONDecodeError will be raised.

Changed in version 3.6: All optional parameters are now keyword-only.


Changed in version 3.6: fp can now be a binary file. The input encoding should be
UTF-8, UTF-16 or UTF-32."
"json.loads(s, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)","Deserialize s (a str, bytes or bytearray
instance containing a JSON document) to a Python object using this
conversion table.
The other arguments have the same meaning as in load(), except
encoding which is ignored and deprecated since Python 3.1.
If the data being deserialized is not a valid JSON document, a
JSONDecodeError will be raised.

Deprecated since version 3.1, will be removed in version 3.9: encoding keyword argument.


Changed in version 3.6: s can now be of type bytes or bytearray. The
input encoding should be UTF-8, UTF-16 or UTF-32."
decode(s),"Return the Python representation of s (a str instance
containing a JSON document).
JSONDecodeError will be raised if the given JSON document is not
valid."
raw_decode(s),"Decode a JSON document from s (a str beginning with a
JSON document) and return a 2-tuple of the Python representation
and the index in s where the document ended.
This can be used to decode a JSON document from a string that may have
extraneous data at the end."
default(o),"Implement this method in a subclass such that it returns a serializable
object for o, or calls the base implementation (to raise a
TypeError).
For example, to support arbitrary iterators, you could implement default
like this:
def default(self, o):
   try:
       iterable = iter(o)
   except TypeError:
       pass
   else:
       return list(iterable)
   # Let the base class default method raise the TypeError
   return json.JSONEncoder.default(self, o)"
encode(o),"Return a JSON string representation of a Python data structure, o.  For
example:
>>> json.JSONEncoder().encode({""foo"": [""bar"", ""baz""]})
'{""foo"": [""bar"", ""baz""]}'"
iterencode(o),"Encode the given object, o, and yield each string representation as
available.  For example:
for chunk in json.JSONEncoder().iterencode(bigobject):
    mysocket.write(chunk)"
"mailcap.findmatch(caps, MIMEtype, key='view', filename='/dev/null', plist=[])","Return a 2-tuple; the first element is a string containing the command line to
be executed (which can be passed to os.system()), and the second element
is the mailcap entry for a given MIME type.  If no matching MIME type can be
found, (None, None) is returned.
key is the name of the field desired, which represents the type of activity to
be performed; the default value is ‘view’, since in the  most common case you
simply want to view the body of the MIME-typed data.  Other possible values
might be ‘compose’ and ‘edit’, if you wanted to create a new body of the given
MIME type or alter the existing body data.  See RFC 1524 for a complete list
of these fields.
filename is the filename to be substituted for %s in the command line; the
default value is '/dev/null' which is almost certainly not what you want, so
usually you’ll override it by specifying a filename.
plist can be a list containing named parameters; the default value is simply
an empty list.  Each entry in the list must be a string containing the parameter
name, an equals sign ('='), and the parameter’s value.  Mailcap entries can
contain  named parameters like %{foo}, which will be replaced by the value
of the parameter named ‘foo’.  For example, if the command line showpartial
%{id} %{number} %{total} was in a mailcap file, and plist was set to
['id=1', 'number=2', 'total=3'], the resulting command line would be
'showpartial 1 2 3'.
In a mailcap file, the “test” field can optionally be specified to test some
external condition (such as the machine architecture, or the window system in
use) to determine whether or not the mailcap line applies.  findmatch()
will automatically check such conditions and skip the entry if the check fails."
mailcap.getcaps(),"Returns a dictionary mapping MIME types to a list of mailcap file entries. This
dictionary must be passed to the findmatch() function.  An entry is stored
as a list of dictionaries, but it shouldn’t be necessary to know the details of
this representation.
The information is derived from all of the mailcap files found on the system.
Settings in the user’s mailcap file $HOME/.mailcap will override
settings in the system mailcap files /etc/mailcap,
/usr/etc/mailcap, and /usr/local/etc/mailcap."
add(message),"Add message to the mailbox and return the key that has been assigned to
it.
Parameter message may be a Message instance, an
email.message.Message instance, a string, a byte string, or a
file-like object (which should be open in binary mode). If message is
an instance of the
appropriate format-specific Message subclass (e.g., if it’s an
mboxMessage instance and this is an mbox instance), its
format-specific information is used. Otherwise, reasonable defaults for
format-specific information are used.

Changed in version 3.2: Support for binary input was added."
remove(key),"Delete the message corresponding to key from the mailbox.
If no such message exists, a KeyError exception is raised if the
method was called as remove() or __delitem__() but no
exception is raised if the method was called as discard(). The
behavior of discard() may be preferred if the underlying mailbox
format supports concurrent modification by other processes."
"__setitem__(key, message)","Replace the message corresponding to key with message. Raise a
KeyError exception if no message already corresponds to key.
As with add(), parameter message may be a Message
instance, an email.message.Message instance, a string, a byte
string, or a file-like object (which should be open in binary mode). If
message is an
instance of the appropriate format-specific Message subclass
(e.g., if it’s an mboxMessage instance and this is an
mbox instance), its format-specific information is
used. Otherwise, the format-specific information of the message that
currently corresponds to key is left unchanged."
iterkeys(),"Return an iterator over all keys if called as iterkeys() or return a
list of keys if called as keys()."
itervalues(),"Return an iterator over representations of all messages if called as
itervalues() or __iter__() or return a list of such
representations if called as values(). The messages are represented
as instances of the appropriate format-specific Message subclass
unless a custom message factory was specified when the Mailbox
instance was initialized.

Note
The behavior of __iter__() is unlike that of dictionaries, which
iterate over keys."
iteritems(),"Return an iterator over (key, message) pairs, where key is a key and
message is a message representation, if called as iteritems() or
return a list of such pairs if called as items(). The messages are
represented as instances of the appropriate format-specific
Message subclass unless a custom message factory was specified
when the Mailbox instance was initialized."
"get(key, default=None)","Return a representation of the message corresponding to key. If no such
message exists, default is returned if the method was called as
get() and a KeyError exception is raised if the method was
called as __getitem__(). The message is represented as an instance
of the appropriate format-specific Message subclass unless a
custom message factory was specified when the Mailbox instance
was initialized."
get_message(key),"Return a representation of the message corresponding to key as an
instance of the appropriate format-specific Message subclass, or
raise a KeyError exception if no such message exists."
get_bytes(key),"Return a byte representation of the message corresponding to key, or
raise a KeyError exception if no such message exists.

New in version 3.2."
get_string(key),"Return a string representation of the message corresponding to key, or
raise a KeyError exception if no such message exists.  The
message is processed through email.message.Message to
convert it to a 7bit clean representation."
get_file(key),"Return a file-like representation of the message corresponding to key,
or raise a KeyError exception if no such message exists.  The
file-like object behaves as if open in binary mode.  This file should be
closed once it is no longer needed.

Changed in version 3.2: The file object really is a binary file; previously it was incorrectly
returned in text mode.  Also, the file-like object now supports the
context management protocol: you can use a with statement to
automatically close it.


Note
Unlike other representations of messages, file-like representations are
not necessarily independent of the Mailbox instance that
created them or of the underlying mailbox.  More specific documentation
is provided by each subclass."
__contains__(key),"Return True if key corresponds to a message, False otherwise."
__len__(),Return a count of messages in the mailbox.
clear(),Delete all messages from the mailbox.
"pop(key, default=None)","Return a representation of the message corresponding to key and delete
the message. If no such message exists, return default. The message is
represented as an instance of the appropriate format-specific
Message subclass unless a custom message factory was specified
when the Mailbox instance was initialized."
popitem(),"Return an arbitrary (key, message) pair, where key is a key and
message is a message representation, and delete the corresponding
message. If the mailbox is empty, raise a KeyError exception. The
message is represented as an instance of the appropriate format-specific
Message subclass unless a custom message factory was specified
when the Mailbox instance was initialized."
update(arg),"Parameter arg should be a key-to-message mapping or an iterable of
(key, message) pairs. Updates the mailbox so that, for each given
key and message, the message corresponding to key is set to
message as if by using __setitem__(). As with __setitem__(),
each key must already correspond to a message in the mailbox or else a
KeyError exception will be raised, so in general it is incorrect
for arg to be a Mailbox instance.

Note
Unlike with dictionaries, keyword arguments are not supported."
flush(),"Write any pending changes to the filesystem. For some Mailbox
subclasses, changes are always written immediately and flush() does
nothing, but you should still make a habit of calling this method."
lock(),"Acquire an exclusive advisory lock on the mailbox so that other processes
know not to modify it. An ExternalClashError is raised if the lock
is not available. The particular locking mechanisms used depend upon the
mailbox format.  You should always lock the mailbox before making any
modifications to its contents."
unlock(),"Release the lock on the mailbox, if any."
close(),"Flush the mailbox, unlock it if necessary, and close any open files. For
some Mailbox subclasses, this method does nothing."
list_folders(),Return a list of the names of all folders.
get_folder(folder),"Return a Maildir instance representing the folder whose name is
folder. A NoSuchMailboxError exception is raised if the folder
does not exist."
add_folder(folder),"Create a folder whose name is folder and return a Maildir
instance representing it."
remove_folder(folder),"Delete the folder whose name is folder. If the folder contains any
messages, a NotEmptyError exception will be raised and the folder
will not be deleted."
clean(),"Delete temporary files from the mailbox that have not been accessed in the
last 36 hours. The Maildir specification says that mail-reading programs
should do this occasionally."
add(message),"Warning
These methods generate unique file names based upon the current process
ID. When using multiple threads, undetected name clashes may occur and
cause corruption of the mailbox unless threads are coordinated to avoid
using these methods to manipulate the same mailbox simultaneously."
flush(),"All changes to Maildir mailboxes are immediately applied, so this method
does nothing."
lock(),"Maildir mailboxes do not support (or require) locking, so these methods do
nothing."
close(),"Maildir instances do not keep any open files and the underlying
mailboxes do not support locking, so this method does nothing."
get_file(key),"Depending upon the host platform, it may not be possible to modify or
remove the underlying message while the returned file remains open."
get_file(key),"Using the file after calling flush() or close() on the
mbox instance may yield unpredictable results or raise an
exception."
lock(),"Three locking mechanisms are used—dot locking and, if available, the
flock() and lockf() system calls."
list_folders(),Return a list of the names of all folders.
get_folder(folder),"Return an MH instance representing the folder whose name is
folder. A NoSuchMailboxError exception is raised if the folder
does not exist."
add_folder(folder),"Create a folder whose name is folder and return an MH instance
representing it."
remove_folder(folder),"Delete the folder whose name is folder. If the folder contains any
messages, a NotEmptyError exception will be raised and the folder
will not be deleted."
get_sequences(),"Return a dictionary of sequence names mapped to key lists. If there are no
sequences, the empty dictionary is returned."
set_sequences(sequences),"Re-define the sequences that exist in the mailbox based upon sequences,
a dictionary of names mapped to key lists, like returned by
get_sequences()."
pack(),"Rename messages in the mailbox as necessary to eliminate gaps in
numbering.  Entries in the sequences list are updated correspondingly.

Note
Already-issued keys are invalidated by this operation and should not be
subsequently used."
remove(key),"These methods immediately delete the message. The MH convention of marking
a message for deletion by prepending a comma to its name is not used."
lock(),"Three locking mechanisms are used—dot locking and, if available, the
flock() and lockf() system calls. For MH mailboxes, locking
the mailbox means locking the .mh_sequences file and, only for the
duration of any operations that affect them, locking individual message
files."
get_file(key),"Depending upon the host platform, it may not be possible to remove the
underlying message while the returned file remains open."
flush(),"All changes to MH mailboxes are immediately applied, so this method does
nothing."
close(),"MH instances do not keep any open files, so this method is
equivalent to unlock()."
get_labels(),"Return a list of the names of all user-defined labels used in the mailbox.

Note
The actual messages are inspected to determine which labels exist in
the mailbox rather than consulting the list of labels in the Babyl
options section, but the Babyl section is updated whenever the mailbox
is modified."
get_file(key),"In Babyl mailboxes, the headers of a message are not stored contiguously
with the body of the message. To generate a file-like representation, the
headers and body are copied together into an io.BytesIO instance,
which has an API identical to that of a
file. As a result, the file-like object is truly independent of the
underlying mailbox but does not save memory compared to a string
representation."
lock(),"Three locking mechanisms are used—dot locking and, if available, the
flock() and lockf() system calls."
get_file(key),"Using the file after calling flush() or close() on the
MMDF instance may yield unpredictable results or raise an
exception."
lock(),"Three locking mechanisms are used—dot locking and, if available, the
flock() and lockf() system calls."
get_subdir(),"Return either “new” (if the message should be stored in the new
subdirectory) or “cur” (if the message should be stored in the cur
subdirectory).

Note
A message is typically moved from new to cur after its
mailbox has been accessed, whether or not the message is has been
read. A message msg has been read if ""S"" in msg.get_flags() is
True."
set_subdir(subdir),"Set the subdirectory the message should be stored in. Parameter subdir
must be either “new” or “cur”."
get_flags(),"Return a string specifying the flags that are currently set. If the
message complies with the standard Maildir format, the result is the
concatenation in alphabetical order of zero or one occurrence of each of
'D', 'F', 'P', 'R', 'S', and 'T'. The empty string
is returned if no flags are set or if “info” contains experimental
semantics."
set_flags(flags),Set the flags specified by flags and unset all others.
add_flag(flag),"Set the flag(s) specified by flag without changing other flags. To add
more than one flag at a time, flag may be a string of more than one
character. The current “info” is overwritten whether or not it contains
experimental information rather than flags."
remove_flag(flag),"Unset the flag(s) specified by flag without changing other flags. To
remove more than one flag at a time, flag maybe a string of more than
one character.  If “info” contains experimental information rather than
flags, the current “info” is not modified."
get_date(),"Return the delivery date of the message as a floating-point number
representing seconds since the epoch."
set_date(date),"Set the delivery date of the message to date, a floating-point number
representing seconds since the epoch."
get_info(),"Return a string containing the “info” for a message. This is useful for
accessing and modifying “info” that is experimental (i.e., not a list of
flags)."
set_info(info),"Set “info” to info, which should be a string."
get_from(),"Return a string representing the “From ” line that marks the start of the
message in an mbox mailbox. The leading “From ” and the trailing newline
are excluded."
"set_from(from_, time_=None)","Set the “From ” line to from_, which should be specified without a
leading “From ” or trailing newline. For convenience, time_ may be
specified and will be formatted appropriately and appended to from_. If
time_ is specified, it should be a time.struct_time instance, a
tuple suitable for passing to time.strftime(), or True (to use
time.gmtime())."
get_flags(),"Return a string specifying the flags that are currently set. If the
message complies with the conventional format, the result is the
concatenation in the following order of zero or one occurrence of each of
'R', 'O', 'D', 'F', and 'A'."
set_flags(flags),"Set the flags specified by flags and unset all others. Parameter flags
should be the concatenation in any order of zero or more occurrences of
each of 'R', 'O', 'D', 'F', and 'A'."
add_flag(flag),"Set the flag(s) specified by flag without changing other flags. To add
more than one flag at a time, flag may be a string of more than one
character."
remove_flag(flag),"Unset the flag(s) specified by flag without changing other flags. To
remove more than one flag at a time, flag maybe a string of more than
one character."
get_sequences(),Return a list of the names of sequences that include this message.
set_sequences(sequences),Set the list of sequences that include this message.
add_sequence(sequence),Add sequence to the list of sequences that include this message.
remove_sequence(sequence),Remove sequence from the list of sequences that include this message.
get_labels(),Return a list of labels on the message.
set_labels(labels),Set the list of labels on the message to labels.
add_label(label),Add label to the list of labels on the message.
remove_label(label),Remove label from the list of labels on the message.
get_visible(),"Return an Message instance whose headers are the message’s
visible headers and whose body is empty."
set_visible(visible),"Set the message’s visible headers to be the same as the headers in
message.  Parameter visible should be a Message instance, an
email.message.Message instance, a string, or a file-like object
(which should be open in text mode)."
update_visible(),"When a BabylMessage instance’s original headers are modified, the
visible headers are not automatically modified to correspond. This method
updates the visible headers as follows: each visible header with a
corresponding original header is set to the value of the original header,
each visible header without a corresponding original header is removed,
and any of Date, From, Reply-To,
To, CC, and Subject that are
present in the original headers but not the visible headers are added to
the visible headers."
get_from(),"Return a string representing the “From ” line that marks the start of the
message in an mbox mailbox. The leading “From ” and the trailing newline
are excluded."
"set_from(from_, time_=None)","Set the “From ” line to from_, which should be specified without a
leading “From ” or trailing newline. For convenience, time_ may be
specified and will be formatted appropriately and appended to from_. If
time_ is specified, it should be a time.struct_time instance, a
tuple suitable for passing to time.strftime(), or True (to use
time.gmtime())."
get_flags(),"Return a string specifying the flags that are currently set. If the
message complies with the conventional format, the result is the
concatenation in the following order of zero or one occurrence of each of
'R', 'O', 'D', 'F', and 'A'."
set_flags(flags),"Set the flags specified by flags and unset all others. Parameter flags
should be the concatenation in any order of zero or more occurrences of
each of 'R', 'O', 'D', 'F', and 'A'."
add_flag(flag),"Set the flag(s) specified by flag without changing other flags. To add
more than one flag at a time, flag may be a string of more than one
character."
remove_flag(flag),"Unset the flag(s) specified by flag without changing other flags. To
remove more than one flag at a time, flag maybe a string of more than
one character."
"mimetypes.guess_type(url, strict=True)","Guess the type of a file based on its filename, path or URL, given by url.
URL can be a string or a path-like object.
The return value is a tuple (type, encoding) where type is None if the
type can’t be guessed (missing or unknown suffix) or a string of the form
'type/subtype', usable for a MIME content-type header.
encoding is None for no encoding or the name of the program used to encode
(e.g. compress or gzip). The encoding is suitable for use
as a Content-Encoding header, not as a
Content-Transfer-Encoding header. The mappings are table driven.
Encoding suffixes are case sensitive; type suffixes are first tried case
sensitively, then case insensitively.
The optional strict argument is a flag specifying whether the list of known MIME types
is limited to only the official types registered with IANA.
When strict is True (the default), only the IANA types are supported; when
strict is False, some additional non-standard but commonly used MIME types
are also recognized.

Changed in version 3.8: Added support for url being a path-like object."
"mimetypes.guess_all_extensions(type, strict=True)","Guess the extensions for a file based on its MIME type, given by type. The
return value is a list of strings giving all possible filename extensions,
including the leading dot ('.').  The extensions are not guaranteed to have
been associated with any particular data stream, but would be mapped to the MIME
type type by guess_type().
The optional strict argument has the same meaning as with the guess_type() function."
"mimetypes.guess_extension(type, strict=True)","Guess the extension for a file based on its MIME type, given by type. The
return value is a string giving a filename extension, including the leading dot
('.').  The extension is not guaranteed to have been associated with any
particular data stream, but would be mapped to the MIME type type by
guess_type().  If no extension can be guessed for type, None is
returned.
The optional strict argument has the same meaning as with the guess_type() function."
mimetypes.init(files=None),"Initialize the internal data structures.  If given, files must be a sequence
of file names which should be used to augment the default type map.  If omitted,
the file names to use are taken from knownfiles; on Windows, the
current registry settings are loaded.  Each file named in files or
knownfiles takes precedence over those named before it.  Calling
init() repeatedly is allowed.
Specifying an empty list for files will prevent the system defaults from
being applied: only the well-known values will be present from a built-in list.
If files is None the internal data structure is completely rebuilt to its
initial default value. This is a stable operation and will produce the same results
when called multiple times.

Changed in version 3.2: Previously, Windows registry settings were ignored."
mimetypes.read_mime_types(filename),"Load the type map given in the file filename, if it exists.  The type map is
returned as a dictionary mapping filename extensions, including the leading dot
('.'), to strings of the form 'type/subtype'.  If the file filename
does not exist or cannot be read, None is returned."
"mimetypes.add_type(type, ext, strict=True)","Add a mapping from the MIME type type to the extension ext. When the
extension is already known, the new type will replace the old one. When the type
is already known the extension will be added to the list of known extensions.
When strict is True (the default), the mapping will be added to the
official MIME types, otherwise to the non-standard ones."
"guess_extension(type, strict=True)","Similar to the guess_extension() function, using the tables stored as part
of the object."
"guess_type(url, strict=True)","Similar to the guess_type() function, using the tables stored as part of
the object."
"guess_all_extensions(type, strict=True)","Similar to the guess_all_extensions() function, using the tables stored
as part of the object."
"read(filename, strict=True)","Load MIME information from a file named filename.  This uses readfp() to
parse the file.
If strict is True, information will be added to list of standard types,
else to the list of non-standard types."
"readfp(fp, strict=True)","Load MIME type information from an open file fp.  The file must have the format of
the standard mime.types files.
If strict is True, information will be added to the list of standard
types, else to the list of non-standard types."
read_windows_registry(strict=True),"Load MIME type information from the Windows registry.
Availability: Windows.
If strict is True, information will be added to the list of standard
types, else to the list of non-standard types.

New in version 3.2."
"base64.b64encode(s, altchars=None)","Encode the bytes-like object s using Base64 and return the encoded
bytes.
Optional altchars must be a bytes-like object of at least
length 2 (additional characters are ignored) which specifies an alternative
alphabet for the + and / characters.  This allows an application to e.g.
generate URL or filesystem safe Base64 strings.  The default is None, for
which the standard Base64 alphabet is used."
"base64.b64decode(s, altchars=None, validate=False)","Decode the Base64 encoded bytes-like object or ASCII string
s and return the decoded bytes.
Optional altchars must be a bytes-like object or ASCII string of
at least length 2 (additional characters are ignored) which specifies the
alternative alphabet used instead of the + and / characters.
A binascii.Error exception is raised
if s is incorrectly padded.
If validate is False (the default), characters that are neither
in the normal base-64 alphabet nor the alternative alphabet are
discarded prior to the padding check.  If validate is True,
these non-alphabet characters in the input result in a
binascii.Error."
base64.standard_b64encode(s),"Encode bytes-like object s using the standard Base64 alphabet
and return the encoded bytes."
base64.standard_b64decode(s),"Decode bytes-like object or ASCII string s using the standard
Base64 alphabet and return the decoded bytes."
base64.urlsafe_b64encode(s),"Encode bytes-like object s using the
URL- and filesystem-safe alphabet, which
substitutes - instead of + and _ instead of / in the
standard Base64 alphabet, and return the encoded bytes.  The result
can still contain =."
base64.urlsafe_b64decode(s),"Decode bytes-like object or ASCII string s
using the URL- and filesystem-safe
alphabet, which substitutes - instead of + and _ instead of
/ in the standard Base64 alphabet, and return the decoded
bytes."
base64.b32encode(s),"Encode the bytes-like object s using Base32 and return the
encoded bytes."
"base64.b32decode(s, casefold=False, map01=None)","Decode the Base32 encoded bytes-like object or ASCII string s and
return the decoded bytes.
Optional casefold is a flag specifying
whether a lowercase alphabet is acceptable as input.  For security purposes,
the default is False.
RFC 3548 allows for optional mapping of the digit 0 (zero) to the letter O
(oh), and for optional mapping of the digit 1 (one) to either the letter I (eye)
or letter L (el).  The optional argument map01 when not None, specifies
which letter the digit 1 should be mapped to (when map01 is not None, the
digit 0 is always mapped to the letter O).  For security purposes the default is
None, so that 0 and 1 are not allowed in the input.
A binascii.Error is raised if s is
incorrectly padded or if there are non-alphabet characters present in the
input."
base64.b16encode(s),"Encode the bytes-like object s using Base16 and return the
encoded bytes."
"base64.b16decode(s, casefold=False)","Decode the Base16 encoded bytes-like object or ASCII string s and
return the decoded bytes.
Optional casefold is a flag specifying whether a
lowercase alphabet is acceptable as input.  For security purposes, the default
is False.
A binascii.Error is raised if s is
incorrectly padded or if there are non-alphabet characters present in the
input."
"base64.a85encode(b, *, foldspaces=False, wrapcol=0, pad=False, adobe=False)","Encode the bytes-like object b using Ascii85 and return the
encoded bytes.
foldspaces is an optional flag that uses the special short sequence ‘y’
instead of 4 consecutive spaces (ASCII 0x20) as supported by ‘btoa’. This
feature is not supported by the “standard” Ascii85 encoding.
wrapcol controls whether the output should have newline (b'\n')
characters added to it. If this is non-zero, each output line will be
at most this many characters long.
pad controls whether the input is padded to a multiple of 4
before encoding. Note that the btoa implementation always pads.
adobe controls whether the encoded byte sequence is framed with <~
and ~>, which is used by the Adobe implementation.

New in version 3.4."
"base64.a85decode(b, *, foldspaces=False, adobe=False, ignorechars=b' \t\n\r\v')","Decode the Ascii85 encoded bytes-like object or ASCII string b and
return the decoded bytes.
foldspaces is a flag that specifies whether the ‘y’ short sequence
should be accepted as shorthand for 4 consecutive spaces (ASCII 0x20).
This feature is not supported by the “standard” Ascii85 encoding.
adobe controls whether the input sequence is in Adobe Ascii85 format
(i.e. is framed with <~ and ~>).
ignorechars should be a bytes-like object or ASCII string
containing characters to ignore
from the input. This should only contain whitespace characters, and by
default contains all whitespace characters in ASCII.

New in version 3.4."
"base64.b85encode(b, pad=False)","Encode the bytes-like object b using base85 (as used in e.g.
git-style binary diffs) and return the encoded bytes.
If pad is true, the input is padded with b'\0' so its length is a
multiple of 4 bytes before encoding.

New in version 3.4."
base64.b85decode(b),"Decode the base85-encoded bytes-like object or ASCII string b and
return the decoded bytes.  Padding is implicitly removed, if
necessary.

New in version 3.4."
"base64.decode(input, output)","Decode the contents of the binary input file and write the resulting binary
data to the output file. input and output must be file objects. input will be read until input.readline() returns an
empty bytes object."
base64.decodebytes(s),"Decode the bytes-like object s, which must contain one or more
lines of base64 encoded data, and return the decoded bytes.

New in version 3.1."
base64.decodestring(s),"Deprecated alias of decodebytes().

Deprecated since version 3.1."
"base64.encode(input, output)","Encode the contents of the binary input file and write the resulting base64
encoded data to the output file. input and output must be file
objects. input will be read until input.read() returns
an empty bytes object. encode() inserts a newline character (b'\n')
after every 76 bytes of the output, as well as ensuring that the output
always ends with a newline, as per RFC 2045 (MIME)."
base64.encodebytes(s),"Encode the bytes-like object s, which can contain arbitrary binary
data, and return bytes containing the base64-encoded data, with newlines
(b'\n') inserted after every 76 bytes of output, and ensuring that
there is a trailing newline, as per RFC 2045 (MIME).

New in version 3.1."
base64.encodestring(s),"Deprecated alias of encodebytes().

Deprecated since version 3.1."
"binhex.binhex(input, output)","Convert a binary file with filename input to binhex file output. The
output parameter can either be a filename or a file-like object (any object
supporting a write() and close() method)."
"binhex.hexbin(input, output)","Decode a binhex file input. input may be a filename or a file-like object
supporting read() and close() methods. The resulting file is written
to a file named output, unless the argument is None in which case the
output filename is read from the binhex file."
binascii.a2b_uu(string),"Convert a single line of uuencoded data back to binary and return the binary
data. Lines normally contain 45 (binary) bytes, except for the last line. Line
data may be followed by whitespace."
"binascii.b2a_uu(data, *, backtick=False)","Convert binary data to a line of ASCII characters, the return value is the
converted line, including a newline char. The length of data should be at most
45. If backtick is true, zeros are represented by '`' instead of spaces.

Changed in version 3.7: Added the backtick parameter."
binascii.a2b_base64(string),"Convert a block of base64 data back to binary and return the binary data. More
than one line may be passed at a time."
"binascii.b2a_base64(data, *, newline=True)","Convert binary data to a line of ASCII characters in base64 coding. The return
value is the converted line, including a newline char if newline is
true.  The output of this function conforms to RFC 3548.

Changed in version 3.6: Added the newline parameter."
"binascii.a2b_qp(data, header=False)","Convert a block of quoted-printable data back to binary and return the binary
data. More than one line may be passed at a time. If the optional argument
header is present and true, underscores will be decoded as spaces."
"binascii.b2a_qp(data, quotetabs=False, istext=True, header=False)","Convert binary data to a line(s) of ASCII characters in quoted-printable
encoding.  The return value is the converted line(s). If the optional argument
quotetabs is present and true, all tabs and spaces will be encoded.   If the
optional argument istext is present and true, newlines are not encoded but
trailing whitespace will be encoded. If the optional argument header is
present and true, spaces will be encoded as underscores per RFC 1522. If the
optional argument header is present and false, newline characters will be
encoded as well; otherwise linefeed conversion might corrupt the binary data
stream."
binascii.a2b_hqx(string),"Convert binhex4 formatted ASCII data to binary, without doing RLE-decompression.
The string should contain a complete number of binary bytes, or (in case of the
last portion of the binhex4 data) have the remaining bits zero."
binascii.rledecode_hqx(data),"Perform RLE-decompression on the data, as per the binhex4 standard. The
algorithm uses 0x90 after a byte as a repeat indicator, followed by a count.
A count of 0 specifies a byte value of 0x90. The routine returns the
decompressed data, unless data input data ends in an orphaned repeat indicator,
in which case the Incomplete exception is raised.

Changed in version 3.2: Accept only bytestring or bytearray objects as input."
binascii.rlecode_hqx(data),Perform binhex4 style RLE-compression on data and return the result.
binascii.b2a_hqx(data),"Perform hexbin4 binary-to-ASCII translation and return the resulting string. The
argument should already be RLE-coded, and have a length divisible by 3 (except
possibly the last fragment)."
"binascii.crc_hqx(data, value)","Compute a 16-bit CRC value of data, starting with value as the
initial CRC, and return the result.  This uses the CRC-CCITT polynomial
x16 + x12 + x5 + 1, often represented as
0x1021.  This CRC is used in the binhex4 format."
"binascii.crc32(data[, value])","Compute CRC-32, the 32-bit checksum of data, starting with an
initial CRC of value.  The default initial CRC is zero.  The algorithm
is consistent with the ZIP file checksum.  Since the algorithm is designed for
use as a checksum algorithm, it is not suitable for use as a general hash
algorithm.  Use as follows:
print(binascii.crc32(b""hello world""))
# Or, in two pieces:
crc = binascii.crc32(b""hello"")
crc = binascii.crc32(b"" world"", crc)
print('crc32 = {:#010x}'.format(crc))



Changed in version 3.0: The result is always unsigned.
To generate the same numeric value across all Python versions and
platforms, use crc32(data) & 0xffffffff."
"binascii.b2a_hex(data[, sep[, bytes_per_sep=1]])","Return the hexadecimal representation of the binary data.  Every byte of
data is converted into the corresponding 2-digit hex representation.  The
returned bytes object is therefore twice as long as the length of data.
Similar functionality (but returning a text string) is also conveniently
accessible using the bytes.hex() method.
If sep is specified, it must be a single character str or bytes object.
It will be inserted in the output after every bytes_per_sep input bytes.
Separator placement is counted from the right end of the output by default,
if you wish to count from the left, supply a negative bytes_per_sep value.
>>> import binascii
>>> binascii.b2a_hex(b'\xb9\x01\xef')
b'b901ef'
>>> binascii.hexlify(b'\xb9\x01\xef', '-')
b'b9-01-ef'
>>> binascii.b2a_hex(b'\xb9\x01\xef', b'_', 2)
b'b9_01ef'
>>> binascii.b2a_hex(b'\xb9\x01\xef', b' ', -2)
b'b901 ef'



Changed in version 3.8: The sep and bytes_per_sep parameters were added."
binascii.a2b_hex(hexstr),"Return the binary data represented by the hexadecimal string hexstr.  This
function is the inverse of b2a_hex(). hexstr must contain an even number
of hexadecimal digits (which can be upper or lower case), otherwise an
Error exception is raised.
Similar functionality (accepting only text string arguments, but more
liberal towards whitespace) is also accessible using the
bytes.fromhex() class method."
"quopri.decode(input, output, header=False)","Decode the contents of the input file and write the resulting decoded binary
data to the output file. input and output must be binary file objects.  If the optional argument header is present and true, underscore
will be decoded as space. This is used to decode “Q”-encoded headers as
described in RFC 1522: “MIME (Multipurpose Internet Mail Extensions)
Part Two: Message Header Extensions for Non-ASCII Text”."
"quopri.encode(input, output, quotetabs, header=False)","Encode the contents of the input file and write the resulting quoted-printable
data to the output file. input and output must be
binary file objects. quotetabs, a
non-optional flag which controls whether to encode embedded spaces
and tabs; when true it encodes such embedded whitespace, and when
false it leaves them unencoded.
Note that spaces and tabs appearing at the end of lines are always encoded,
as per RFC 1521.  header is a flag which controls if spaces are encoded
as underscores as per RFC 1522."
"quopri.decodestring(s, header=False)","Like decode(), except that it accepts a source bytes and
returns the corresponding decoded bytes."
"quopri.encodestring(s, quotetabs=False, header=False)","Like encode(), except that it accepts a source bytes and
returns the corresponding encoded bytes. By default, it sends a
False value to quotetabs parameter of the encode() function."
"uu.encode(in_file, out_file, name=None, mode=None, *, backtick=False)","Uuencode file in_file into file out_file.  The uuencoded file will have
the header specifying name and mode as the defaults for the results of
decoding the file. The default defaults are taken from in_file, or '-'
and 0o666 respectively.  If backtick is true, zeros are represented by
'`' instead of spaces.

Changed in version 3.7: Added the backtick parameter."
"uu.decode(in_file, out_file=None, mode=None, quiet=False)","This call decodes uuencoded file in_file placing the result on file
out_file. If out_file is a pathname, mode is used to set the permission
bits if the file must be created. Defaults for out_file and mode are taken
from the uuencode header.  However, if the file specified in the header already
exists, a uu.Error is raised.
decode() may print a warning to standard error if the input was produced
by an incorrect uuencoder and Python could recover from that error.  Setting
quiet to a true value silences this warning."
"html.escape(s, quote=True)","Convert the characters &, < and > in string s to HTML-safe
sequences.  Use this if you need to display text that might contain such
characters in HTML.  If the optional flag quote is true, the characters
("") and (') are also translated; this helps for inclusion in an HTML
attribute value delimited by quotes, as in <a href=""..."">.

New in version 3.2."
html.unescape(s),"Convert all named and numeric character references (e.g. &gt;,
&#62;, &#x3e;) in the string s to the corresponding Unicode
characters.  This function uses the rules defined by the HTML 5 standard
for both valid and invalid character references, and the list of
HTML 5 named character references.

New in version 3.4."
HTMLParser.feed(data),"Feed some text to the parser.  It is processed insofar as it consists of
complete elements; incomplete data is buffered until more data is fed or
close() is called.  data must be str."
HTMLParser.close(),"Force processing of all buffered data as if it were followed by an end-of-file
mark.  This method may be redefined by a derived class to define additional
processing at the end of the input, but the redefined version should always call
the HTMLParser base class method close()."
HTMLParser.reset(),"Reset the instance.  Loses all unprocessed data.  This is called implicitly at
instantiation time."
HTMLParser.getpos(),Return current line number and offset.
HTMLParser.get_starttag_text(),"Return the text of the most recently opened start tag.  This should not normally
be needed for structured processing, but may be useful in dealing with HTML “as
deployed” or for re-generating input with minimal changes (whitespace between
attributes can be preserved, etc.)."
"HTMLParser.handle_starttag(tag, attrs)","This method is called to handle the start of a tag (e.g. <div id=""main"">).
The tag argument is the name of the tag converted to lower case. The attrs
argument is a list of (name, value) pairs containing the attributes found
inside the tag’s <> brackets.  The name will be translated to lower case,
and quotes in the value have been removed, and character and entity references
have been replaced.
For instance, for the tag <A HREF=""https://www.cwi.nl/"">, this method
would be called as handle_starttag('a', [('href', 'https://www.cwi.nl/')]).
All entity references from html.entities are replaced in the attribute
values."
HTMLParser.handle_endtag(tag),"This method is called to handle the end tag of an element (e.g. </div>).
The tag argument is the name of the tag converted to lower case."
"HTMLParser.handle_startendtag(tag, attrs)","Similar to handle_starttag(), but called when the parser encounters an
XHTML-style empty tag (<img ... />).  This method may be overridden by
subclasses which require this particular lexical information; the default
implementation simply calls handle_starttag() and handle_endtag()."
HTMLParser.handle_data(data),"This method is called to process arbitrary data (e.g. text nodes and the
content of <script>...</script> and <style>...</style>)."
HTMLParser.handle_entityref(name),"This method is called to process a named character reference of the form
&name; (e.g. &gt;), where name is a general entity reference
(e.g. 'gt').  This method is never called if convert_charrefs is
True."
HTMLParser.handle_charref(name),"This method is called to process decimal and hexadecimal numeric character
references of the form &#NNN; and &#xNNN;.  For example, the decimal
equivalent for &gt; is &#62;, whereas the hexadecimal is &#x3E;;
in this case the method will receive '62' or 'x3E'.  This method
is never called if convert_charrefs is True."
HTMLParser.handle_comment(data),"This method is called when a comment is encountered (e.g. <!--comment-->).
For example, the comment <!-- comment --> will cause this method to be
called with the argument ' comment '.
The content of Internet Explorer conditional comments (condcoms) will also be
sent to this method, so, for <!--[if IE 9]>IE9-specific content<![endif]-->,
this method will receive '[if IE 9]>IE9-specific content<![endif]'."
HTMLParser.handle_decl(decl),"This method is called to handle an HTML doctype declaration (e.g.
<!DOCTYPE html>).
The decl parameter will be the entire contents of the declaration inside
the <!...> markup (e.g. 'DOCTYPE html')."
HTMLParser.handle_pi(data),"Method called when a processing instruction is encountered.  The data
parameter will contain the entire processing instruction. For example, for the
processing instruction <?proc color='red'>, this method would be called as
handle_pi(""proc color='red'"").  It is intended to be overridden by a derived
class; the base class implementation does nothing.

Note
The HTMLParser class uses the SGML syntactic rules for processing
instructions.  An XHTML processing instruction using the trailing '?' will
cause the '?' to be included in data."
HTMLParser.unknown_decl(data),"This method is called when an unrecognized declaration is read by the parser.
The data parameter will be the entire contents of the declaration inside
the <![...]> markup.  It is sometimes useful to be overridden by a
derived class.  The base class implementation does nothing."
"xml.etree.ElementTree.canonicalize(xml_data=None, *, out=None, from_file=None, **options)","C14N 2.0 transformation function.
Canonicalization is a way to normalise XML output in a way that allows
byte-by-byte comparisons and digital signatures.  It reduced the freedom
that XML serializers have and instead generates a more constrained XML
representation.  The main restrictions regard the placement of namespace
declarations, the ordering of attributes, and ignorable whitespace.
This function takes an XML data string (xml_data) or a file path or
file-like object (from_file) as input, converts it to the canonical
form, and writes it out using the out file(-like) object, if provided,
or returns it as a text string if not.  The output file receives text,
not bytes.  It should therefore be opened in text mode with utf-8
encoding.
Typical uses:
xml_data = ""<root>...</root>""
print(canonicalize(xml_data))

with open(""c14n_output.xml"", mode='w', encoding='utf-8') as out_file:
    canonicalize(xml_data, out=out_file)

with open(""c14n_output.xml"", mode='w', encoding='utf-8') as out_file:
    canonicalize(from_file=""inputfile.xml"", out=out_file)


The configuration options are as follows:

with_comments: set to true to include comments (default: false)

strip_text: set to true to strip whitespace before and after text content(default: false)




rewrite_prefixes: set to true to replace namespace prefixes by “n{number}”(default: false)




qname_aware_tags: a set of qname aware tag names in which prefixesshould be replaced in text content (default: empty)




qname_aware_attrs: a set of qname aware attribute names in which prefixesshould be replaced in text content (default: empty)



exclude_attrs: a set of attribute names that should not be serialised
exclude_tags: a set of tag names that should not be serialised

In the option list above, “a set” refers to any collection or iterable of
strings, no ordering is expected.

New in version 3.8."
xml.etree.ElementTree.Comment(text=None),"Comment element factory.  This factory function creates a special element
that will be serialized as an XML comment by the standard serializer.  The
comment string can be either a bytestring or a Unicode string.  text is a
string containing the comment string.  Returns an element instance
representing a comment.
Note that XMLParser skips over comments in the input
instead of creating comment objects for them. An ElementTree will
only contain comment nodes if they have been inserted into to
the tree using one of the Element methods."
xml.etree.ElementTree.dump(elem),"Writes an element tree or element structure to sys.stdout.  This function
should be used for debugging only.
The exact output format is implementation dependent.  In this version, it’s
written as an ordinary XML file.
elem is an element tree or an individual element.

Changed in version 3.8: The dump() function now preserves the attribute order specified
by the user."
"xml.etree.ElementTree.fromstring(text, parser=None)","Parses an XML section from a string constant.  Same as XML().  text
is a string containing XML data.  parser is an optional parser instance.
If not given, the standard XMLParser parser is used.
Returns an Element instance."
"xml.etree.ElementTree.fromstringlist(sequence, parser=None)","Parses an XML document from a sequence of string fragments.  sequence is a
list or other sequence containing XML data fragments.  parser is an
optional parser instance.  If not given, the standard XMLParser
parser is used.  Returns an Element instance.

New in version 3.2."
xml.etree.ElementTree.iselement(element),"Check if an object appears to be a valid element object.  element is an
element instance.  Return True if this is an element object."
"xml.etree.ElementTree.iterparse(source, events=None, parser=None)","Parses an XML section into an element tree incrementally, and reports what’s
going on to the user.  source is a filename or file object
containing XML data.  events is a sequence of events to report back.  The
supported events are the strings ""start"", ""end"", ""comment"",
""pi"", ""start-ns"" and ""end-ns""
(the “ns” events are used to get detailed namespace
information).  If events is omitted, only ""end"" events are reported.
parser is an optional parser instance.  If not given, the standard
XMLParser parser is used.  parser must be a subclass of
XMLParser and can only use the default TreeBuilder as a
target.  Returns an iterator providing (event, elem) pairs.
Note that while iterparse() builds the tree incrementally, it issues
blocking reads on source (or the file it names).  As such, it’s unsuitable
for applications where blocking reads can’t be made.  For fully non-blocking
parsing, see XMLPullParser.

Note
iterparse() only guarantees that it has seen the “>” character of a
starting tag when it emits a “start” event, so the attributes are defined,
but the contents of the text and tail attributes are undefined at that
point.  The same applies to the element children; they may or may not be
present.
If you need a fully populated element, look for “end” events instead.


Deprecated since version 3.4: The parser argument.


Changed in version 3.8: The comment and pi events were added."
"xml.etree.ElementTree.parse(source, parser=None)","Parses an XML section into an element tree.  source is a filename or file
object containing XML data.  parser is an optional parser instance.  If
not given, the standard XMLParser parser is used.  Returns an
ElementTree instance."
"xml.etree.ElementTree.ProcessingInstruction(target, text=None)","PI element factory.  This factory function creates a special element that
will be serialized as an XML processing instruction.  target is a string
containing the PI target.  text is a string containing the PI contents, if
given.  Returns an element instance, representing a processing instruction.
Note that XMLParser skips over processing instructions
in the input instead of creating comment objects for them. An
ElementTree will only contain processing instruction nodes if
they have been inserted into to the tree using one of the
Element methods."
"xml.etree.ElementTree.register_namespace(prefix, uri)","Registers a namespace prefix.  The registry is global, and any existing
mapping for either the given prefix or the namespace URI will be removed.
prefix is a namespace prefix.  uri is a namespace uri.  Tags and
attributes in this namespace will be serialized with the given prefix, if at
all possible.

New in version 3.2."
"xml.etree.ElementTree.SubElement(parent, tag, attrib={}, **extra)","Subelement factory.  This function creates an element instance, and appends
it to an existing element.
The element name, attribute names, and attribute values can be either
bytestrings or Unicode strings.  parent is the parent element.  tag is
the subelement name.  attrib is an optional dictionary, containing element
attributes.  extra contains additional attributes, given as keyword
arguments.  Returns an element instance."
"xml.etree.ElementTree.tostring(element, encoding=""us-ascii"", method=""xml"", *, xml_declaration=None, default_namespace=None, short_empty_elements=True)","Generates a string representation of an XML element, including all
subelements.  element is an Element instance.  encoding 1 is
the output encoding (default is US-ASCII).  Use encoding=""unicode"" to
generate a Unicode string (otherwise, a bytestring is generated).  method
is either ""xml"", ""html"" or ""text"" (default is ""xml"").
xml_declaration, default_namespace and short_empty_elements has the same
meaning as in ElementTree.write(). Returns an (optionally) encoded string
containing the XML data.

New in version 3.4: The short_empty_elements parameter.


New in version 3.8: The xml_declaration and default_namespace parameters.


Changed in version 3.8: The tostring() function now preserves the attribute order
specified by the user."
"xml.etree.ElementTree.tostringlist(element, encoding=""us-ascii"", method=""xml"", *, xml_declaration=None, default_namespace=None, short_empty_elements=True)","Generates a string representation of an XML element, including all
subelements.  element is an Element instance.  encoding 1 is
the output encoding (default is US-ASCII).  Use encoding=""unicode"" to
generate a Unicode string (otherwise, a bytestring is generated).  method
is either ""xml"", ""html"" or ""text"" (default is ""xml"").
xml_declaration, default_namespace and short_empty_elements has the same
meaning as in ElementTree.write(). Returns a list of (optionally) encoded
strings containing the XML data. It does not guarantee any specific sequence,
except that b"""".join(tostringlist(element)) == tostring(element).

New in version 3.2.


New in version 3.4: The short_empty_elements parameter.


New in version 3.8: The xml_declaration and default_namespace parameters.


Changed in version 3.8: The tostringlist() function now preserves the attribute order
specified by the user."
"xml.etree.ElementTree.XML(text, parser=None)","Parses an XML section from a string constant.  This function can be used to
embed “XML literals” in Python code.  text is a string containing XML
data.  parser is an optional parser instance.  If not given, the standard
XMLParser parser is used.  Returns an Element instance."
"xml.etree.ElementTree.XMLID(text, parser=None)","Parses an XML section from a string constant, and also returns a dictionary
which maps from element id:s to elements.  text is a string containing XML
data.  parser is an optional parser instance.  If not given, the standard
XMLParser parser is used.  Returns a tuple containing an
Element instance and a dictionary."
"xml.etree.ElementInclude.default_loader(href, parse, encoding=None)","Default loader. This default loader reads an included resource from disk.  href is a URL.
parse is for parse mode either “xml” or “text”.  encoding
is an optional text encoding.  If not given, encoding is utf-8.  Returns the
expanded resource.  If the parse mode is ""xml"", this is an ElementTree
instance.  If the parse mode is “text”, this is a Unicode string.  If the
loader fails, it can return None or raise an exception."
"xml.etree.ElementInclude.include(elem, loader=None)","This function expands XInclude directives.  elem is the root element.  loader is
an optional resource loader.  If omitted, it defaults to default_loader().
If given, it should be a callable that implements the same interface as
default_loader().  Returns the expanded resource.  If the parse mode is
""xml"", this is an ElementTree instance.  If the parse mode is “text”,
this is a Unicode string.  If the loader fails, it can return None or
raise an exception."
clear(),"Resets an element.  This function removes all subelements, clears all
attributes, and sets the text and tail attributes to None."
"get(key, default=None)","Gets the element attribute named key.
Returns the attribute value, or default if the attribute was not found."
items(),"Returns the element attributes as a sequence of (name, value) pairs.  The
attributes are returned in an arbitrary order."
keys(),"Returns the elements attribute names as a list.  The names are returned
in an arbitrary order."
"set(key, value)",Set the attribute key on the element to value.
append(subelement),"Adds the element subelement to the end of this element’s internal list
of subelements.  Raises TypeError if subelement is not an
Element."
extend(subelements),"Appends subelements from a sequence object with zero or more elements.
Raises TypeError if a subelement is not an Element.

New in version 3.2."
"find(match, namespaces=None)","Finds the first subelement matching match.  match may be a tag name
or a path.  Returns an element instance
or None.  namespaces is an optional mapping from namespace prefix
to full name.  Pass '' as prefix to move all unprefixed tag names
in the expression into the given namespace."
"findall(match, namespaces=None)","Finds all matching subelements, by tag name or
path.  Returns a list containing all matching
elements in document order.  namespaces is an optional mapping from
namespace prefix to full name.  Pass '' as prefix to move all
unprefixed tag names in the expression into the given namespace."
"findtext(match, default=None, namespaces=None)","Finds text for the first subelement matching match.  match may be
a tag name or a path.  Returns the text content
of the first matching element, or default if no element was found.
Note that if the matching element has no text content an empty string
is returned. namespaces is an optional mapping from namespace prefix
to full name.  Pass '' as prefix to move all unprefixed tag names
in the expression into the given namespace."
getchildren(),"Deprecated since version 3.2, will be removed in version 3.9: Use list(elem) or iteration."
getiterator(tag=None),"Deprecated since version 3.2, will be removed in version 3.9: Use method Element.iter() instead."
"insert(index, subelement)","Inserts subelement at the given position in this element.  Raises
TypeError if subelement is not an Element."
iter(tag=None),"Creates a tree iterator with the current element as the root.
The iterator iterates over this element and all elements below it, in
document (depth first) order.  If tag is not None or '*', only
elements whose tag equals tag are returned from the iterator.  If the
tree structure is modified during iteration, the result is undefined.

New in version 3.2."
"iterfind(match, namespaces=None)","Finds all matching subelements, by tag name or
path.  Returns an iterable yielding all
matching elements in document order. namespaces is an optional mapping
from namespace prefix to full name.

New in version 3.2."
itertext(),"Creates a text iterator.  The iterator loops over this element and all
subelements, in document order, and returns all inner text.

New in version 3.2."
"makeelement(tag, attrib)","Creates a new element object of the same type as this element.  Do not
call this method, use the SubElement() factory function instead."
remove(subelement),"Removes subelement from the element.  Unlike the find* methods this
method compares elements based on the instance identity, not on tag value
or contents."
_setroot(element),"Replaces the root element for this tree.  This discards the current
contents of the tree, and replaces it with the given element.  Use with
care.  element is an element instance."
"find(match, namespaces=None)","Same as Element.find(), starting at the root of the tree."
"findall(match, namespaces=None)","Same as Element.findall(), starting at the root of the tree."
"findtext(match, default=None, namespaces=None)","Same as Element.findtext(), starting at the root of the tree."
getiterator(tag=None),"Deprecated since version 3.2, will be removed in version 3.9: Use method ElementTree.iter() instead."
getroot(),Returns the root element for this tree.
iter(tag=None),"Creates and returns a tree iterator for the root element.  The iterator
loops over all elements in this tree, in section order.  tag is the tag
to look for (default is to return all elements)."
"iterfind(match, namespaces=None)","Same as Element.iterfind(), starting at the root of the tree.

New in version 3.2."
"parse(source, parser=None)","Loads an external XML section into this element tree.  source is a file
name or file object.  parser is an optional parser instance.
If not given, the standard XMLParser parser is used.  Returns the
section root element."
"write(file, encoding=""us-ascii"", xml_declaration=None, default_namespace=None, method=""xml"", *, short_empty_elements=True)","Writes the element tree to a file, as XML.  file is a file name, or a
file object opened for writing.  encoding 1 is the output
encoding (default is US-ASCII).
xml_declaration controls if an XML declaration should be added to the
file.  Use False for never, True for always, None
for only if not US-ASCII or UTF-8 or Unicode (default is None).
default_namespace sets the default XML namespace (for “xmlns”).
method is either ""xml"", ""html"" or ""text"" (default is
""xml"").
The keyword-only short_empty_elements parameter controls the formatting
of elements that contain no content.  If True (the default), they are
emitted as a single self-closed tag, otherwise they are emitted as a pair
of start/end tags.
The output is either a string (str) or binary (bytes).
This is controlled by the encoding argument.  If encoding is
""unicode"", the output is a string; otherwise, it’s binary.  Note that
this may conflict with the type of file if it’s an open
file object; make sure you do not try to write a string to a
binary stream and vice versa.

New in version 3.4: The short_empty_elements parameter.


Changed in version 3.8: The write() method now preserves the attribute order specified
by the user."
close(),"Flushes the builder buffers, and returns the toplevel document
element.  Returns an Element instance."
data(data),"Adds text to the current element.  data is a string.  This should be
either a bytestring, or a Unicode string."
end(tag),"Closes the current element.  tag is the element name.  Returns the
closed element."
"start(tag, attrs)","Opens a new element.  tag is the element name.  attrs is a dictionary
containing element attributes.  Returns the opened element."
comment(text),"Creates a comment with the given text.  If insert_comments is true,
this will also add it to the tree.

New in version 3.8."
"pi(target, text)","Creates a comment with the given target name and text.  If
insert_pis is true, this will also add it to the tree.

New in version 3.8."
"doctype(name, pubid, system)","Handles a doctype declaration.  name is the doctype name.  pubid is
the public identifier.  system is the system identifier.  This method
does not exist on the default TreeBuilder class.

New in version 3.2."
"start_ns(prefix, uri)","Is called whenever the parser encounters a new namespace declaration,
before the start() callback for the opening element that defines it.
prefix is '' for the default namespace and the declared
namespace prefix name otherwise.  uri is the namespace URI.

New in version 3.8."
end_ns(prefix),"Is called after the end() callback of an element that declared
a namespace prefix mapping, with the name of the prefix that went
out of scope.

New in version 3.8."
close(),"Finishes feeding data to the parser.  Returns the result of calling the
close() method of the target passed during construction; by default,
this is the toplevel document element."
feed(data),Feeds data to the parser.  data is encoded data.
feed(data),Feed the given bytes data to the parser.
close(),"Signal the parser that the data stream is terminated. Unlike
XMLParser.close(), this method always returns None.
Any events not yet retrieved when the parser is closed can still be
read with read_events()."
read_events(),"Return an iterator over the events which have been encountered in the
data fed to the
parser.  The iterator yields (event, elem) pairs, where event is a
string representing the type of event (e.g. ""end"") and elem is the
encountered Element object, or other context value as follows.

start, end: the current Element.
comment, pi: the current comment / processing instruction
start-ns: a tuple (prefix, uri) naming the declared namespace
mapping.
end-ns: None (this may change in a future version)

Events provided in a previous call to read_events() will not be
yielded again.  Events are consumed from the internal queue only when
they are retrieved from the iterator, so multiple readers iterating in
parallel over iterators obtained from read_events() will have
unpredictable results."
"xml.dom.registerDOMImplementation(name, factory)","Register the factory function with the name name.  The factory function
should return an object which implements the DOMImplementation
interface.  The factory function can return the same object every time, or a new
one for each call, as appropriate for the specific implementation (e.g. if that
implementation supports some customization)."
"xml.dom.getDOMImplementation(name=None, features=())","Return a suitable DOM implementation. The name is either well-known, the
module name of a DOM implementation, or None. If it is not None, imports
the corresponding module and returns a DOMImplementation object if the
import succeeds.  If no name is given, and if the environment variable
PYTHON_DOM is set, this variable is used to find the implementation.
If name is not given, this examines the available implementations to find one
with the required feature set.  If no implementation can be found, raise an
ImportError.  The features list must be a sequence of (feature,
version) pairs which are passed to the hasFeature() method on available
DOMImplementation objects."
"DOMImplementation.hasFeature(feature, version)","Return True if the feature identified by the pair of strings feature and
version is implemented."
"DOMImplementation.createDocument(namespaceUri, qualifiedName, doctype)","Return a new Document object (the root of the DOM), with a child
Element object having the given namespaceUri and qualifiedName. The
doctype must be a DocumentType object created by
createDocumentType(), or None. In the Python DOM API, the first two
arguments can also be None in order to indicate that no Element
child is to be created."
"DOMImplementation.createDocumentType(qualifiedName, publicId, systemId)","Return a new DocumentType object that encapsulates the given
qualifiedName, publicId, and systemId strings, representing the
information contained in an XML document type declaration."
Node.hasAttributes(),Return True if the node has any attributes.
Node.hasChildNodes(),Return True if the node has any child nodes.
Node.isSameNode(other),"Return True if other refers to the same node as this node. This is especially
useful for DOM implementations which use any sort of proxy architecture (because
more than one object can refer to the same node).

Note
This is based on a proposed DOM Level 3 API which is still in the “working
draft” stage, but this particular interface appears uncontroversial.  Changes
from the W3C will not necessarily affect this method in the Python DOM interface
(though any new W3C API for this would also be supported)."
Node.appendChild(newChild),"Add a new child node to this node at the end of the list of
children, returning newChild. If the node was already in
the tree, it is removed first."
"Node.insertBefore(newChild, refChild)","Insert a new child node before an existing child.  It must be the case that
refChild is a child of this node; if not, ValueError is raised.
newChild is returned. If refChild is None, it inserts newChild at the
end of the children’s list."
Node.removeChild(oldChild),"Remove a child node.  oldChild must be a child of this node; if not,
ValueError is raised.  oldChild is returned on success.  If oldChild
will not be used further, its unlink() method should be called."
"Node.replaceChild(newChild, oldChild)","Replace an existing node with a new node. It must be the case that  oldChild
is a child of this node; if not, ValueError is raised."
Node.normalize(),"Join adjacent text nodes so that all stretches of text are stored as single
Text instances.  This simplifies processing text from a DOM tree for
many applications."
Node.cloneNode(deep),"Clone this node.  Setting deep means to clone all child nodes as well.  This
returns the clone."
NodeList.item(i),"Return the i’th item from the sequence, if there is one, or None.  The
index i is not allowed to be less than zero or greater than or equal to the
length of the sequence."
Document.createElement(tagName),"Create and return a new element node.  The element is not inserted into the
document when it is created.  You need to explicitly insert it with one of the
other methods such as insertBefore() or appendChild()."
"Document.createElementNS(namespaceURI, tagName)","Create and return a new element with a namespace.  The tagName may have a
prefix.  The element is not inserted into the document when it is created.  You
need to explicitly insert it with one of the other methods such as
insertBefore() or appendChild()."
Document.createTextNode(data),"Create and return a text node containing the data passed as a parameter.  As
with the other creation methods, this one does not insert the node into the
tree."
Document.createComment(data),"Create and return a comment node containing the data passed as a parameter.  As
with the other creation methods, this one does not insert the node into the
tree."
"Document.createProcessingInstruction(target, data)","Create and return a processing instruction node containing the target and
data passed as parameters.  As with the other creation methods, this one does
not insert the node into the tree."
Document.createAttribute(name),"Create and return an attribute node.  This method does not associate the
attribute node with any particular element.  You must use
setAttributeNode() on the appropriate Element object to use the
newly created attribute instance."
"Document.createAttributeNS(namespaceURI, qualifiedName)","Create and return an attribute node with a namespace.  The tagName may have a
prefix.  This method does not associate the attribute node with any particular
element.  You must use setAttributeNode() on the appropriate
Element object to use the newly created attribute instance."
Document.getElementsByTagName(tagName),"Search for all descendants (direct children, children’s children, etc.) with a
particular element type name."
"Document.getElementsByTagNameNS(namespaceURI, localName)","Search for all descendants (direct children, children’s children, etc.) with a
particular namespace URI and localname.  The localname is the part of the
namespace after the prefix."
Element.getElementsByTagName(tagName),Same as equivalent method in the Document class.
"Element.getElementsByTagNameNS(namespaceURI, localName)",Same as equivalent method in the Document class.
Element.hasAttribute(name),Return True if the element has an attribute named by name.
"Element.hasAttributeNS(namespaceURI, localName)","Return True if the element has an attribute named by namespaceURI and
localName."
Element.getAttribute(name),"Return the value of the attribute named by name as a string. If no such
attribute exists, an empty string is returned, as if the attribute had no value."
Element.getAttributeNode(attrname),Return the Attr node for the attribute named by attrname.
"Element.getAttributeNS(namespaceURI, localName)","Return the value of the attribute named by namespaceURI and localName as a
string. If no such attribute exists, an empty string is returned, as if the
attribute had no value."
"Element.getAttributeNodeNS(namespaceURI, localName)","Return an attribute value as a node, given a namespaceURI and localName."
Element.removeAttribute(name),"Remove an attribute by name.  If there is no matching attribute, a
NotFoundErr is raised."
Element.removeAttributeNode(oldAttr),"Remove and return oldAttr from the attribute list, if present. If oldAttr is
not present, NotFoundErr is raised."
"Element.removeAttributeNS(namespaceURI, localName)","Remove an attribute by name.  Note that it uses a localName, not a qname.  No
exception is raised if there is no matching attribute."
"Element.setAttribute(name, value)",Set an attribute value from a string.
Element.setAttributeNode(newAttr),"Add a new attribute node to the element, replacing an existing attribute if
necessary if the name attribute matches.  If a replacement occurs, the
old attribute node will be returned.  If newAttr is already in use,
InuseAttributeErr will be raised."
Element.setAttributeNodeNS(newAttr),"Add a new attribute node to the element, replacing an existing attribute if
necessary if the namespaceURI and localName attributes match.
If a replacement occurs, the old attribute node will be returned.  If newAttr
is already in use, InuseAttributeErr will be raised."
"Element.setAttributeNS(namespaceURI, qname, value)","Set an attribute value from a string, given a namespaceURI and a qname.
Note that a qname is the whole attribute name.  This is different than above."
NamedNodeMap.item(index),"Return an attribute with a particular index.  The order you get the attributes
in is arbitrary but will be consistent for the life of a DOM.  Each item is an
attribute node.  Get its value with the value attribute."
"xml.dom.minidom.parse(filename_or_file, parser=None, bufsize=None)","Return a Document from the given input. filename_or_file may be
either a file name, or a file-like object. parser, if given, must be a SAX2
parser object. This function will change the document handler of the parser and
activate namespace support; other parser configuration (like setting an entity
resolver) must have been done in advance."
"xml.dom.minidom.parseString(string, parser=None)","Return a Document that represents the string. This method creates an
io.StringIO object for the string and passes that on to parse()."
Node.unlink(),"Break internal references within the DOM so that it will be garbage collected on
versions of Python without cyclic GC.  Even when cyclic GC is available, using
this can make large amounts of memory available sooner, so calling this on DOM
objects as soon as they are no longer needed is good practice.  This only needs
to be called on the Document object, but may be called on child nodes
to discard children of that node.
You can avoid calling this method explicitly by using the with
statement. The following code will automatically unlink dom when the
with block is exited:
with xml.dom.minidom.parse(datasource) as dom:
    ... # Work with dom."
"Node.writexml(writer, indent="""", addindent="""", newl="""")","Write XML to the writer object.  The writer receives texts but not bytes as input,
it should have a write() method which matches that of the file object
interface.  The indent parameter is the indentation of the current node.
The addindent parameter is the incremental indentation to use for subnodes
of the current one.  The newl parameter specifies the string to use to
terminate newlines.
For the Document node, an additional keyword argument encoding can
be used to specify the encoding field of the XML header.

Changed in version 3.8: The writexml() method now preserves the attribute order specified
by the user."
Node.toxml(encoding=None),"Return a string or byte string containing the XML represented by
the DOM node.
With an explicit encoding 1 argument, the result is a byte
string in the specified encoding.
With no encoding argument, the result is a Unicode string, and the
XML declaration in the resulting string does not specify an
encoding. Encoding this string in an encoding other than UTF-8 is
likely incorrect, since UTF-8 is the default encoding of XML.

Changed in version 3.8: The toxml() method now preserves the attribute order specified
by the user."
"Node.toprettyxml(indent=""\t"", newl=""\n"", encoding=None)","Return a pretty-printed version of the document. indent specifies the
indentation string and defaults to a tabulator; newl specifies the string
emitted at the end of each line and defaults to \n.
The encoding argument behaves like the corresponding argument of
toxml().

Changed in version 3.8: The toprettyxml() method now preserves the attribute order specified
by the user."
"xml.dom.pulldom.parse(stream_or_string, parser=None, bufsize=None)","Return a DOMEventStream from the given input. stream_or_string may be
either a file name, or a file-like object. parser, if given, must be an
XMLReader object. This function will change the
document handler of the
parser and activate namespace support; other parser configuration (like
setting an entity resolver) must have been done in advance."
"xml.dom.pulldom.parseString(string, parser=None)",Return a DOMEventStream that represents the (Unicode) string.
getEvent(),"Return a tuple containing event and the current node as
xml.dom.minidom.Document if event equals START_DOCUMENT,
xml.dom.minidom.Element if event equals START_ELEMENT or
END_ELEMENT or xml.dom.minidom.Text if event equals
CHARACTERS.
The current node does not contain information about its children, unless
expandNode() is called."
expandNode(node),"Expands all children of node into node. Example:
from xml.dom import pulldom

xml = '<html><title>Foo</title> <p>Some text <div>and more</div></p> </html>'
doc = pulldom.parseString(xml)
for event, node in doc:
    if event == pulldom.START_ELEMENT and node.tagName == 'p':
        # Following statement only prints '<p/>'
        print(node.toxml())
        doc.expandNode(node)
        # Following statement prints node with all its children '<p>Some text <div>and more</div></p>'
        print(node.toxml())"
reset(),
xml.sax.make_parser(parser_list=[]),"Create and return a SAX XMLReader object.  The
first parser found will
be used.  If parser_list is provided, it must be an iterable of strings which
name modules that have a function named create_parser().  Modules listed
in parser_list will be used before modules in the default list of parsers.

Changed in version 3.8: The parser_list argument can be any iterable, not just a list."
"xml.sax.parse(filename_or_stream, handler, error_handler=handler.ErrorHandler())","Create a SAX parser and use it to parse a document.  The document, passed in as
filename_or_stream, can be a filename or a file object.  The handler
parameter needs to be a SAX ContentHandler instance.  If
error_handler is given, it must be a SAX ErrorHandler
instance; if
omitted,  SAXParseException will be raised on all errors.  There is no
return value; all work must be done by the handler passed in."
"xml.sax.parseString(string, handler, error_handler=handler.ErrorHandler())","Similar to parse(), but parses from a buffer string received as a
parameter.  string must be a str instance or a
bytes-like object.

Changed in version 3.5: Added support of str instances."
SAXException.getMessage(),Return a human-readable message describing the error condition.
SAXException.getException(),"Return an encapsulated exception object, or None."
ContentHandler.setDocumentLocator(locator),"Called by the parser to give the application a locator for locating the origin
of document events.
SAX parsers are strongly encouraged (though not absolutely required) to supply a
locator: if it does so, it must supply the locator to the application by
invoking this method before invoking any of the other methods in the
DocumentHandler interface.
The locator allows the application to determine the end position of any
document-related event, even if the parser is not reporting an error. Typically,
the application will use this information for reporting its own errors (such as
character content that does not match an application’s business rules). The
information returned by the locator is probably not sufficient for use with a
search engine.
Note that the locator will return correct information only during the invocation
of the events in this interface. The application should not attempt to use it at
any other time."
ContentHandler.startDocument(),"Receive notification of the beginning of a document.
The SAX parser will invoke this method only once, before any other methods in
this interface or in DTDHandler (except for setDocumentLocator())."
ContentHandler.endDocument(),"Receive notification of the end of a document.
The SAX parser will invoke this method only once, and it will be the last method
invoked during the parse. The parser shall not invoke this method until it has
either abandoned parsing (because of an unrecoverable error) or reached the end
of input."
"ContentHandler.startPrefixMapping(prefix, uri)","Begin the scope of a prefix-URI Namespace mapping.
The information from this event is not necessary for normal Namespace
processing: the SAX XML reader will automatically replace prefixes for element
and attribute names when the feature_namespaces feature is enabled (the
default).
There are cases, however, when applications need to use prefixes in character
data or in attribute values, where they cannot safely be expanded automatically;
the startPrefixMapping() and endPrefixMapping() events supply the
information to the application to expand prefixes in those contexts itself, if
necessary.
Note that startPrefixMapping() and endPrefixMapping() events are not
guaranteed to be properly nested relative to each-other: all
startPrefixMapping() events will occur before the corresponding
startElement() event, and all endPrefixMapping() events will occur
after the corresponding endElement() event, but their order is not
guaranteed."
ContentHandler.endPrefixMapping(prefix),"End the scope of a prefix-URI mapping.
See startPrefixMapping() for details. This event will always occur after
the corresponding endElement() event, but the order of
endPrefixMapping() events is not otherwise guaranteed."
"ContentHandler.startElement(name, attrs)","Signals the start of an element in non-namespace mode.
The name parameter contains the raw XML 1.0 name of the element type as a
string and the attrs parameter holds an object of the
Attributes
interface (see The Attributes Interface) containing the attributes of
the element.  The object passed as attrs may be re-used by the parser; holding
on to a reference to it is not a reliable way to keep a copy of the attributes.
To keep a copy of the attributes, use the copy() method of the attrs
object."
ContentHandler.endElement(name),"Signals the end of an element in non-namespace mode.
The name parameter contains the name of the element type, just as with the
startElement() event."
"ContentHandler.startElementNS(name, qname, attrs)","Signals the start of an element in namespace mode.
The name parameter contains the name of the element type as a (uri,
localname) tuple, the qname parameter contains the raw XML 1.0 name used in
the source document, and the attrs parameter holds an instance of the
AttributesNS interface (see
The AttributesNS Interface)
containing the attributes of the element.  If no namespace is associated with
the element, the uri component of name will be None.  The object passed
as attrs may be re-used by the parser; holding on to a reference to it is not
a reliable way to keep a copy of the attributes.  To keep a copy of the
attributes, use the copy() method of the attrs object.
Parsers may set the qname parameter to None, unless the
feature_namespace_prefixes feature is activated."
"ContentHandler.endElementNS(name, qname)","Signals the end of an element in namespace mode.
The name parameter contains the name of the element type, just as with the
startElementNS() method, likewise the qname parameter."
ContentHandler.characters(content),"Receive notification of character data.
The Parser will call this method to report each chunk of character data. SAX
parsers may return all contiguous character data in a single chunk, or they may
split it into several chunks; however, all of the characters in any single event
must come from the same external entity so that the Locator provides useful
information.
content may be a string or bytes instance; the expat reader module
always produces strings.

Note
The earlier SAX 1 interface provided by the Python XML Special Interest Group
used a more Java-like interface for this method.  Since most parsers used from
Python did not take advantage of the older interface, the simpler signature was
chosen to replace it.  To convert old code to the new interface, use content
instead of slicing content with the old offset and length parameters."
ContentHandler.ignorableWhitespace(whitespace),"Receive notification of ignorable whitespace in element content.
Validating Parsers must use this method to report each chunk of ignorable
whitespace (see the W3C XML 1.0 recommendation, section 2.10): non-validating
parsers may also use this method if they are capable of parsing and using
content models.
SAX parsers may return all contiguous whitespace in a single chunk, or they may
split it into several chunks; however, all of the characters in any single event
must come from the same external entity, so that the Locator provides useful
information."
"ContentHandler.processingInstruction(target, data)","Receive notification of a processing instruction.
The Parser will invoke this method once for each processing instruction found:
note that processing instructions may occur before or after the main document
element.
A SAX parser should never report an XML declaration (XML 1.0, section 2.8) or a
text declaration (XML 1.0, section 4.3.1) using this method."
ContentHandler.skippedEntity(name),"Receive notification of a skipped entity.
The Parser will invoke this method once for each entity skipped. Non-validating
processors may skip entities if they have not seen the declarations (because,
for example, the entity was declared in an external DTD subset). All processors
may skip external entities, depending on the values of the
feature_external_ges and the feature_external_pes properties."
"DTDHandler.notationDecl(name, publicId, systemId)",Handle a notation declaration event.
"DTDHandler.unparsedEntityDecl(name, publicId, systemId, ndata)",Handle an unparsed entity declaration event.
"EntityResolver.resolveEntity(publicId, systemId)","Resolve the system identifier of an entity and return either the system
identifier to read from as a string, or an InputSource to read from. The default
implementation returns systemId."
ErrorHandler.error(exception),"Called when the parser encounters a recoverable error.  If this method does not
raise an exception, parsing may continue, but further document information
should not be expected by the application.  Allowing the parser to continue may
allow additional errors to be discovered in the input document."
ErrorHandler.fatalError(exception),"Called when the parser encounters an error it cannot recover from; parsing is
expected to terminate when this method returns."
ErrorHandler.warning(exception),"Called when the parser presents minor warning information to the application.
Parsing is expected to continue when this method returns, and document
information will continue to be passed to the application. Raising an exception
in this method will cause parsing to end."
"xml.sax.saxutils.escape(data, entities={})","Escape '&', '<', and '>' in a string of data.
You can escape other strings of data by passing a dictionary as the optional
entities parameter.  The keys and values must all be strings; each key will be
replaced with its corresponding value.  The characters '&', '<' and
'>' are always escaped, even if entities is provided."
"xml.sax.saxutils.unescape(data, entities={})","Unescape '&amp;', '&lt;', and '&gt;' in a string of data.
You can unescape other strings of data by passing a dictionary as the optional
entities parameter.  The keys and values must all be strings; each key will be
replaced with its corresponding value.  '&amp', '&lt;', and '&gt;'
are always unescaped, even if entities is provided."
"xml.sax.saxutils.quoteattr(data, entities={})","Similar to escape(), but also prepares data to be used as an
attribute value.  The return value is a quoted version of data with any
additional required replacements. quoteattr() will select a quote
character based on the content of data, attempting to avoid encoding any
quote characters in the string.  If both single- and double-quote characters
are already in data, the double-quote characters will be encoded and data
will be wrapped in double-quotes.  The resulting string can be used directly
as an attribute value:
>>> print(""<element attr=%s>"" % quoteattr(""ab ' cd \"" ef""))
<element attr=""ab ' cd &quot; ef"">


This function is useful when generating attribute values for HTML or any SGML
using the reference concrete syntax."
"xml.sax.saxutils.prepare_input_source(source, base='')","This function takes an input source and an optional base URL and returns a
fully resolved InputSource object ready for
reading.  The input source can be given as a string, a file-like object, or
an InputSource object; parsers will use this
function to implement the polymorphic source argument to their
parse() method."
XMLReader.parse(source),"Process an input source, producing SAX events. The source object can be a
system identifier (a string identifying the input source – typically a file
name or a URL), a pathlib.Path or path-like
object, or an InputSource object. When
parse() returns, the input is completely processed, and the parser object
can be discarded or reset.

Changed in version 3.5: Added support of character streams.


Changed in version 3.8: Added support of path-like objects."
XMLReader.getContentHandler(),Return the current ContentHandler.
XMLReader.setContentHandler(handler),"Set the current ContentHandler.  If no
ContentHandler is set, content events will be
discarded."
XMLReader.getDTDHandler(),Return the current DTDHandler.
XMLReader.setDTDHandler(handler),"Set the current DTDHandler.  If no
DTDHandler is set, DTD
events will be discarded."
XMLReader.getEntityResolver(),Return the current EntityResolver.
XMLReader.setEntityResolver(handler),"Set the current EntityResolver.  If no
EntityResolver is set,
attempts to resolve an external entity will result in opening the system
identifier for the entity, and fail if it is not available."
XMLReader.getErrorHandler(),Return the current ErrorHandler.
XMLReader.setErrorHandler(handler),"Set the current error handler.  If no ErrorHandler
is set, errors will be raised as exceptions, and warnings will be printed."
XMLReader.setLocale(locale),"Allow an application to set the locale for errors and warnings.
SAX parsers are not required to provide localization for errors and warnings; if
they cannot support the requested locale, however, they must raise a SAX
exception.  Applications may request a locale change in the middle of a parse."
XMLReader.getFeature(featurename),"Return the current setting for feature featurename.  If the feature is not
recognized, SAXNotRecognizedException is raised. The well-known
featurenames are listed in the module xml.sax.handler."
"XMLReader.setFeature(featurename, value)","Set the featurename to value. If the feature is not recognized,
SAXNotRecognizedException is raised. If the feature or its setting is not
supported by the parser, SAXNotSupportedException is raised."
XMLReader.getProperty(propertyname),"Return the current setting for property propertyname. If the property is not
recognized, a SAXNotRecognizedException is raised. The well-known
propertynames are listed in the module xml.sax.handler."
"XMLReader.setProperty(propertyname, value)","Set the propertyname to value. If the property is not recognized,
SAXNotRecognizedException is raised. If the property or its setting is
not supported by the parser, SAXNotSupportedException is raised."
IncrementalParser.feed(data),Process a chunk of data.
IncrementalParser.close(),"Assume the end of the document. That will check well-formedness conditions that
can be checked only at the end, invoke handlers, and may clean up resources
allocated during parsing."
IncrementalParser.reset(),"This method is called after close has been called to reset the parser so that it
is ready to parse new documents. The results of calling parse or feed after
close without calling reset are undefined."
Locator.getColumnNumber(),Return the column number where the current event begins.
Locator.getLineNumber(),Return the line number where the current event begins.
Locator.getPublicId(),Return the public identifier for the current event.
Locator.getSystemId(),Return the system identifier for the current event.
InputSource.setPublicId(id),Sets the public identifier of this InputSource.
InputSource.getPublicId(),Returns the public identifier of this InputSource.
InputSource.setSystemId(id),Sets the system identifier of this InputSource.
InputSource.getSystemId(),Returns the system identifier of this InputSource.
InputSource.setEncoding(encoding),"Sets the character encoding of this InputSource.
The encoding must be a string acceptable for an XML encoding declaration (see
section 4.3.3 of the XML recommendation).
The encoding attribute of the InputSource is ignored if the
InputSource also contains a character stream."
InputSource.getEncoding(),Get the character encoding of this InputSource.
InputSource.setByteStream(bytefile),"Set the byte stream (a binary file) for this input source.
The SAX parser will ignore this if there is also a character stream specified,
but it will use a byte stream in preference to opening a URI connection itself.
If the application knows the character encoding of the byte stream, it should
set it with the setEncoding method."
InputSource.getByteStream(),"Get the byte stream for this input source.
The getEncoding method will return the character encoding for this byte stream,
or None if unknown."
InputSource.setCharacterStream(charfile),"Set the character stream (a text file) for this input source.
If there is a character stream specified, the SAX parser will ignore any byte
stream and will not attempt to open a URI connection to the system identifier."
InputSource.getCharacterStream(),Get the character stream for this input source.
Attributes.getLength(),Return the number of attributes.
Attributes.getNames(),Return the names of the attributes.
Attributes.getType(name),"Returns the type of the attribute name, which is normally 'CDATA'."
Attributes.getValue(name),Return the value of attribute name.
AttributesNS.getValueByQName(name),Return the value for a qualified name.
AttributesNS.getNameByQName(name),"Return the (namespace, localname) pair for a qualified name."
AttributesNS.getQNameByName(name),"Return the qualified name for a (namespace, localname) pair."
AttributesNS.getQNames(),Return the qualified names of all attributes.
xml.parsers.expat.ErrorString(errno),Returns an explanatory string for a given error number errno.
"xml.parsers.expat.ParserCreate(encoding=None, namespace_separator=None)","Creates and returns a new xmlparser object.   encoding, if specified,
must be a string naming the encoding  used by the XML data.  Expat doesn’t
support as many encodings as Python does, and its repertoire of encodings can’t
be extended; it supports UTF-8, UTF-16, ISO-8859-1 (Latin1), and ASCII.  If
encoding 1 is given it will override the implicit or explicit encoding of the
document.
Expat can optionally do XML namespace processing for you, enabled by providing a
value for namespace_separator.  The value must be a one-character string; a
ValueError will be raised if the string has an illegal length (None
is considered the same as omission).  When namespace processing is enabled,
element type names and attribute names that belong to a namespace will be
expanded.  The element name passed to the element handlers
StartElementHandler and EndElementHandler will be the
concatenation of the namespace URI, the namespace separator character, and the
local part of the name.  If the namespace separator is a zero byte (chr(0))
then the namespace URI and the local part will be concatenated without any
separator.
For example, if namespace_separator is set to a space character (' ') and
the following document is parsed:
<?xml version=""1.0""?>
<root xmlns    = ""http://default-namespace.org/""
      xmlns:py = ""http://www.python.org/ns/"">
  <py:elem1 />
  <elem2 xmlns="""" />
</root>


StartElementHandler will receive the following strings for each
element:
http://default-namespace.org/ root
http://www.python.org/ns/ elem1
elem2


Due to limitations in the Expat library used by pyexpat,
the xmlparser instance returned can only be used to parse a single
XML document.  Call ParserCreate for each document to provide unique
parser instances."
"xmlparser.Parse(data[, isfinal])","Parses the contents of the string data, calling the appropriate handler
functions to process the parsed data.  isfinal must be true on the final call
to this method; it allows the parsing of a single file in fragments,
not the submission of multiple files.
data can be the empty string at any time."
xmlparser.ParseFile(file),"Parse XML data reading from the object file.  file only needs to provide
the read(nbytes) method, returning the empty string when there’s no more
data."
xmlparser.SetBase(base),"Sets the base to be used for resolving relative URIs in system identifiers in
declarations.  Resolving relative identifiers is left to the application: this
value will be passed through as the base argument to the
ExternalEntityRefHandler(), NotationDeclHandler(), and
UnparsedEntityDeclHandler() functions."
xmlparser.GetBase(),"Returns a string containing the base set by a previous call to SetBase(),
or None if  SetBase() hasn’t been called."
xmlparser.GetInputContext(),"Returns the input data that generated the current event as a string. The data is
in the encoding of the entity which contains the text. When called while an
event handler is not active, the return value is None."
"xmlparser.ExternalEntityParserCreate(context[, encoding])","Create a “child” parser which can be used to parse an external parsed entity
referred to by content parsed by the parent parser.  The context parameter
should be the string passed to the ExternalEntityRefHandler() handler
function, described below. The child parser is created with the
ordered_attributes and specified_attributes set to the values of
this parser."
xmlparser.SetParamEntityParsing(flag),"Control parsing of parameter entities (including the external DTD subset).
Possible flag values are XML_PARAM_ENTITY_PARSING_NEVER,
XML_PARAM_ENTITY_PARSING_UNLESS_STANDALONE and
XML_PARAM_ENTITY_PARSING_ALWAYS.  Return true if setting the flag
was successful."
xmlparser.UseForeignDTD([flag]),"Calling this with a true value for flag (the default) will cause Expat to call
the ExternalEntityRefHandler with None for all arguments to
allow an alternate DTD to be loaded.  If the document does not contain a
document type declaration, the ExternalEntityRefHandler will still be
called, but the StartDoctypeDeclHandler and
EndDoctypeDeclHandler will not be called.
Passing a false value for flag will cancel a previous call that passed a true
value, but otherwise has no effect.
This method can only be called before the Parse() or ParseFile()
methods are called; calling it after either of those have been called causes
ExpatError to be raised with the code attribute set to
errors.codes[errors.XML_ERROR_CANT_CHANGE_FEATURE_ONCE_PARSING]."
"xmlparser.XmlDeclHandler(version, encoding, standalone)","Called when the XML declaration is parsed.  The XML declaration is the
(optional) declaration of the applicable version of the XML recommendation, the
encoding of the document text, and an optional “standalone” declaration.
version and encoding will be strings, and standalone will be 1 if the
document is declared standalone, 0 if it is declared not to be standalone,
or -1 if the standalone clause was omitted. This is only available with
Expat version 1.95.0 or newer."
"xmlparser.StartDoctypeDeclHandler(doctypeName, systemId, publicId, has_internal_subset)","Called when Expat begins parsing the document type declaration (<!DOCTYPE
...).  The doctypeName is provided exactly as presented.  The systemId and
publicId parameters give the system and public identifiers if specified, or
None if omitted.  has_internal_subset will be true if the document
contains and internal document declaration subset. This requires Expat version
1.2 or newer."
xmlparser.EndDoctypeDeclHandler(),"Called when Expat is done parsing the document type declaration. This requires
Expat version 1.2 or newer."
"xmlparser.ElementDeclHandler(name, model)","Called once for each element type declaration.  name is the name of the
element type, and model is a representation of the content model."
"xmlparser.AttlistDeclHandler(elname, attname, type, default, required)","Called for each declared attribute for an element type.  If an attribute list
declaration declares three attributes, this handler is called three times, once
for each attribute.  elname is the name of the element to which the
declaration applies and attname is the name of the attribute declared.  The
attribute type is a string passed as type; the possible values are
'CDATA', 'ID', 'IDREF', … default gives the default value for
the attribute used when the attribute is not specified by the document instance,
or None if there is no default value (#IMPLIED values).  If the
attribute is required to be given in the document instance, required will be
true. This requires Expat version 1.95.0 or newer."
"xmlparser.StartElementHandler(name, attributes)","Called for the start of every element.  name is a string containing the
element name, and attributes is the element attributes. If
ordered_attributes is true, this is a list (see
ordered_attributes for a full description). Otherwise it’s a
dictionary mapping names to values."
xmlparser.EndElementHandler(name),Called for the end of every element.
"xmlparser.ProcessingInstructionHandler(target, data)",Called for every processing instruction.
xmlparser.CharacterDataHandler(data),"Called for character data.  This will be called for normal character data, CDATA
marked content, and ignorable whitespace.  Applications which must distinguish
these cases can use the StartCdataSectionHandler,
EndCdataSectionHandler, and ElementDeclHandler callbacks to
collect the required information."
"xmlparser.UnparsedEntityDeclHandler(entityName, base, systemId, publicId, notationName)","Called for unparsed (NDATA) entity declarations.  This is only present for
version 1.2 of the Expat library; for more recent versions, use
EntityDeclHandler instead.  (The underlying function in the Expat
library has been declared obsolete.)"
"xmlparser.EntityDeclHandler(entityName, is_parameter_entity, value, base, systemId, publicId, notationName)","Called for all entity declarations.  For parameter and internal entities,
value will be a string giving the declared contents of the entity; this will
be None for external entities.  The notationName parameter will be
None for parsed entities, and the name of the notation for unparsed
entities. is_parameter_entity will be true if the entity is a parameter entity
or false for general entities (most applications only need to be concerned with
general entities). This is only available starting with version 1.95.0 of the
Expat library."
"xmlparser.NotationDeclHandler(notationName, base, systemId, publicId)","Called for notation declarations.  notationName, base, and systemId, and
publicId are strings if given.  If the public identifier is omitted,
publicId will be None."
"xmlparser.StartNamespaceDeclHandler(prefix, uri)","Called when an element contains a namespace declaration.  Namespace declarations
are processed before the StartElementHandler is called for the element
on which declarations are placed."
xmlparser.EndNamespaceDeclHandler(prefix),"Called when the closing tag is reached for an element  that contained a
namespace declaration.  This is called once for each namespace declaration on
the element in the reverse of the order for which the
StartNamespaceDeclHandler was called to indicate the start of each
namespace declaration’s scope.  Calls to this handler are made after the
corresponding EndElementHandler for the end of the element."
xmlparser.CommentHandler(data),"Called for comments.  data is the text of the comment, excluding the leading
'<!--' and trailing '-->'."
xmlparser.StartCdataSectionHandler(),"Called at the start of a CDATA section.  This and EndCdataSectionHandler
are needed to be able to identify the syntactical start and end for CDATA
sections."
xmlparser.EndCdataSectionHandler(),Called at the end of a CDATA section.
xmlparser.DefaultHandler(data),"Called for any characters in the XML document for which no applicable handler
has been specified.  This means characters that are part of a construct which
could be reported, but for which no handler has been supplied."
xmlparser.DefaultHandlerExpand(data),"This is the same as the DefaultHandler(),  but doesn’t inhibit expansion
of internal entities. The entity reference will not be passed to the default
handler."
xmlparser.NotStandaloneHandler(),"Called if the XML document hasn’t been declared as being a standalone document.
This happens when there is an external subset or a reference to a parameter
entity, but the XML declaration does not set standalone to yes in an XML
declaration.  If this handler returns 0, then the parser will raise an
XML_ERROR_NOT_STANDALONE error.  If this handler is not set, no
exception is raised by the parser for this condition."
"xmlparser.ExternalEntityRefHandler(context, base, systemId, publicId)","Called for references to external entities.  base is the current base, as set
by a previous call to SetBase().  The public and system identifiers,
systemId and publicId, are strings if given; if the public identifier is not
given, publicId will be None.  The context value is opaque and should
only be used as described below.
For external entities to be parsed, this handler must be implemented. It is
responsible for creating the sub-parser using
ExternalEntityParserCreate(context), initializing it with the appropriate
callbacks, and parsing the entity.  This handler should return an integer; if it
returns 0, the parser will raise an
XML_ERROR_EXTERNAL_ENTITY_HANDLING error, otherwise parsing will
continue.
If this handler is not provided, external entities are reported by the
DefaultHandler callback, if provided."
"webbrowser.open(url, new=0, autoraise=True)","Display url using the default browser. If new is 0, the url is opened
in the same browser window if possible.  If new is 1, a new browser window
is opened if possible.  If new is 2, a new browser page (“tab”) is opened
if possible.  If autoraise is True, the window is raised if possible
(note that under many window managers this will occur regardless of the
setting of this variable).
Note that on some platforms, trying to open a filename using this function,
may work and start the operating system’s associated program.  However, this
is neither supported nor portable.
Raises an auditing event webbrowser.open with argument url."
webbrowser.open_new(url),"Open url in a new window of the default browser, if possible, otherwise, open
url in the only browser window."
webbrowser.open_new_tab(url),"Open url in a new page (“tab”) of the default browser, if possible, otherwise
equivalent to open_new()."
webbrowser.get(using=None),"Return a controller object for the browser type using.  If using is
None, return a controller for a default browser appropriate to the
caller’s environment."
"webbrowser.register(name, constructor, instance=None, *, preferred=False)","Register the browser type name.  Once a browser type is registered, the
get() function can return a controller for that browser type.  If
instance is not provided, or is None, constructor will be called without
parameters to create an instance when needed.  If instance is provided,
constructor will never be called, and may be None.
Setting preferred to True makes this browser a preferred result for
a get() call with no argument.  Otherwise, this entry point is only
useful if you plan to either set the BROWSER variable or call
get() with a nonempty argument matching the name of a handler you
declare.

Changed in version 3.7: preferred keyword-only parameter was added."
"controller.open(url, new=0, autoraise=True)","Display url using the browser handled by this controller. If new is 1, a new
browser window is opened if possible. If new is 2, a new browser page (“tab”)
is opened if possible."
controller.open_new(url),"Open url in a new window of the browser handled by this controller, if
possible, otherwise, open url in the only browser window.  Alias
open_new()."
controller.open_new_tab(url),"Open url in a new page (“tab”) of the browser handled by this controller, if
possible, otherwise equivalent to open_new()."
"cgi.parse(fp=None, environ=os.environ, keep_blank_values=False, strict_parsing=False)","Parse a query in the environment or from a file (the file defaults to
sys.stdin).  The keep_blank_values and strict_parsing parameters are
passed to urllib.parse.parse_qs() unchanged."
"cgi.parse_multipart(fp, pdict, encoding=""utf-8"", errors=""replace"")","Parse input of type multipart/form-data (for  file uploads).
Arguments are fp for the input file, pdict for a dictionary containing
other parameters in the Content-Type header, and encoding,
the request encoding.
Returns a dictionary just like urllib.parse.parse_qs(): keys are the
field names, each value is a list of values for that field. For non-file
fields, the value is a list of strings.
This is easy to use but not much good if you are expecting megabytes to be
uploaded — in that case, use the FieldStorage class instead
which is much more flexible.

Changed in version 3.7: Added the encoding and errors parameters.  For non-file fields, the
value is now a list of strings, not bytes."
cgi.parse_header(string),"Parse a MIME header (such as Content-Type) into a main value and a
dictionary of parameters."
cgi.test(),"Robust test CGI script, usable as main program. Writes minimal HTTP headers and
formats all information provided to the script in HTML form."
cgi.print_environ(),Format the shell environment in HTML.
cgi.print_form(form),Format a form in HTML.
cgi.print_directory(),Format the current directory in HTML.
cgi.print_environ_usage(),Print a list of useful (used by CGI) environment variables in HTML.
"FieldStorage.getfirst(name, default=None)","This method always returns only one value associated with form field name.
The method returns only the first value in case that more values were posted
under such name.  Please note that the order in which the values are received
may vary from browser to browser and should not be counted on. 1  If no such
form field or value exists then the method returns the value specified by the
optional parameter default.  This parameter defaults to None if not
specified."
FieldStorage.getlist(name),"This method always returns a list of values associated with form field name.
The method returns an empty list if no such form field or value exists for
name.  It returns a list consisting of one item if only one such value exists."
"cgitb.enable(display=1, logdir=None, context=5, format=""html"")","This function causes the cgitb module to take over the interpreter’s
default handling for exceptions by setting the value of sys.excepthook.
The optional argument display defaults to 1 and can be set to 0 to
suppress sending the traceback to the browser. If the argument logdir is
present, the traceback reports are written to files.  The value of logdir
should be a directory where these files will be placed. The optional argument
context is the number of lines of context to display around the current line
of source code in the traceback; this defaults to 5. If the optional
argument format is ""html"", the output is formatted as HTML.  Any other
value forces plain text output.  The default value is ""html""."
"cgitb.text(info, context=5)","This function handles the exception described by info (a 3-tuple containing
the result of sys.exc_info()), formatting its traceback as text and
returning the result as a string. The optional argument context is the
number of lines of context to display around the current line of source code
in the traceback; this defaults to 5."
"cgitb.html(info, context=5)","This function handles the exception described by info (a 3-tuple containing
the result of sys.exc_info()), formatting its traceback as HTML and
returning the result as a string. The optional argument context is the
number of lines of context to display around the current line of source code
in the traceback; this defaults to 5."
cgitb.handler(info=None),"This function handles an exception using the default settings (that is, show a
report in the browser, but don’t log to a file). This can be used when you’ve
caught an exception and want to report it using cgitb.  The optional
info argument should be a 3-tuple containing an exception type, exception
value, and traceback object, exactly like the tuple returned by
sys.exc_info().  If the info argument is not supplied, the current
exception is obtained from sys.exc_info()."
wsgiref.util.guess_scheme(environ),"Return a guess for whether wsgi.url_scheme should be “http” or “https”, by
checking for a HTTPS environment variable in the environ dictionary.  The
return value is a string.
This function is useful when creating a gateway that wraps CGI or a CGI-like
protocol such as FastCGI.  Typically, servers providing such protocols will
include a HTTPS variable with a value of “1”, “yes”, or “on” when a request
is received via SSL.  So, this function returns “https” if such a value is
found, and “http” otherwise."
"wsgiref.util.request_uri(environ, include_query=True)","Return the full request URI, optionally including the query string, using the
algorithm found in the “URL Reconstruction” section of PEP 3333.  If
include_query is false, the query string is not included in the resulting URI."
wsgiref.util.application_uri(environ),"Similar to request_uri(), except that the PATH_INFO and
QUERY_STRING variables are ignored.  The result is the base URI of the
application object addressed by the request."
wsgiref.util.shift_path_info(environ),"Shift a single name from PATH_INFO to SCRIPT_NAME and return the name.
The environ dictionary is modified in-place; use a copy if you need to keep
the original PATH_INFO or SCRIPT_NAME intact.
If there are no remaining path segments in PATH_INFO, None is returned.
Typically, this routine is used to process each portion of a request URI path,
for example to treat the path as a series of dictionary keys. This routine
modifies the passed-in environment to make it suitable for invoking another WSGI
application that is located at the target URI. For example, if there is a WSGI
application at /foo, and the request URI path is /foo/bar/baz, and the
WSGI application at /foo calls shift_path_info(), it will receive the
string “bar”, and the environment will be updated to be suitable for passing to
a WSGI application at /foo/bar.  That is, SCRIPT_NAME will change from
/foo to /foo/bar, and PATH_INFO will change from /bar/baz to
/baz.
When PATH_INFO is just a “/”, this routine returns an empty string and
appends a trailing slash to SCRIPT_NAME, even though empty path segments are
normally ignored, and SCRIPT_NAME doesn’t normally end in a slash.  This is
intentional behavior, to ensure that an application can tell the difference
between URIs ending in /x from ones ending in /x/ when using this
routine to do object traversal."
wsgiref.util.setup_testing_defaults(environ),"Update environ with trivial defaults for testing purposes.
This routine adds various parameters required for WSGI, including HTTP_HOST,
SERVER_NAME, SERVER_PORT, REQUEST_METHOD, SCRIPT_NAME,
PATH_INFO, and all of the PEP 3333-defined wsgi.* variables.  It
only supplies default values, and does not replace any existing settings for
these variables.
This routine is intended to make it easier for unit tests of WSGI servers and
applications to set up dummy environments.  It should NOT be used by actual WSGI
servers or applications, since the data is fake!
Example usage:
from wsgiref.util import setup_testing_defaults
from wsgiref.simple_server import make_server

# A relatively simple WSGI application. It's going to print out the
# environment dictionary after being updated by setup_testing_defaults
def simple_app(environ, start_response):
    setup_testing_defaults(environ)

    status = '200 OK'
    headers = [('Content-type', 'text/plain; charset=utf-8')]

    start_response(status, headers)

    ret = [(""%s: %s\n"" % (key, value)).encode(""utf-8"")
           for key, value in environ.items()]
    return ret

with make_server('', 8000, simple_app) as httpd:
    print(""Serving on port 8000..."")
    httpd.serve_forever()"
wsgiref.util.is_hop_by_hop(header_name),"Return True if ‘header_name’ is an HTTP/1.1 “Hop-by-Hop” header, as defined by
RFC 2616."
"wsgiref.simple_server.make_server(host, port, app, server_class=WSGIServer, handler_class=WSGIRequestHandler)","Create a new WSGI server listening on host and port, accepting connections
for app.  The return value is an instance of the supplied server_class, and
will process requests using the specified handler_class.  app must be a WSGI
application object, as defined by PEP 3333.
Example usage:
from wsgiref.simple_server import make_server, demo_app

with make_server('', 8000, demo_app) as httpd:
    print(""Serving HTTP on port 8000..."")

    # Respond to requests until process is killed
    httpd.serve_forever()

    # Alternative: serve one request, then exit
    httpd.handle_request()"
"wsgiref.simple_server.demo_app(environ, start_response)","This function is a small but complete WSGI application that returns a text page
containing the message “Hello world!” and a list of the key/value pairs provided
in the environ parameter.  It’s useful for verifying that a WSGI server (such
as wsgiref.simple_server) is able to run a simple WSGI application
correctly."
wsgiref.validate.validator(application),"Wrap application and return a new WSGI application object.  The returned
application will forward all requests to the original application, and will
check that both the application and the server invoking it are conforming to
the WSGI specification and to RFC 2616.
Any detected nonconformance results in an AssertionError being raised;
note, however, that how these errors are handled is server-dependent.  For
example, wsgiref.simple_server and other servers based on
wsgiref.handlers (that don’t override the error handling methods to do
something else) will simply output a message that an error has occurred, and
dump the traceback to sys.stderr or some other error stream.
This wrapper may also generate output using the warnings module to
indicate behaviors that are questionable but which may not actually be
prohibited by PEP 3333.  Unless they are suppressed using Python command-line
options or the warnings API, any such warnings will be written to
sys.stderr (not wsgi.errors, unless they happen to be the same
object).
Example usage:
from wsgiref.validate import validator
from wsgiref.simple_server import make_server

# Our callable object which is intentionally not compliant to the
# standard, so the validator is going to break
def simple_app(environ, start_response):
    status = '200 OK'  # HTTP Status
    headers = [('Content-type', 'text/plain')]  # HTTP Headers
    start_response(status, headers)

    # This is going to break because we need to return a list, and
    # the validator is going to inform us
    return b""Hello World""

# This is the application wrapped in a validator
validator_app = validator(simple_app)

with make_server('', 8000, validator_app) as httpd:
    print(""Listening on port 8000...."")
    httpd.serve_forever()"
wsgiref.handlers.read_environ(),"Transcode CGI variables from os.environ to PEP 3333 “bytes in unicode”
strings, returning a new dictionary.  This function is used by
CGIHandler and IISCGIHandler in place of directly using
os.environ, which is not necessarily WSGI-compliant on all platforms
and web servers using Python 3 – specifically, ones where the OS’s
actual environment is Unicode (i.e. Windows), or ones where the environment
is bytes, but the system encoding used by Python to decode it is anything
other than ISO-8859-1 (e.g. Unix systems using UTF-8).
If you are implementing a CGI-based handler of your own, you probably want
to use this routine instead of just copying values out of os.environ
directly.

New in version 3.2."
get_all(name),"Return a list of all the values for the named header.
The returned list will be sorted in the order they appeared in the original
header list or were added to this instance, and may contain duplicates.  Any
fields deleted and re-inserted are always appended to the header list.  If no
fields exist with the given name, returns an empty list."
"add_header(name, value, **_params)","Add a (possibly multi-valued) header, with optional MIME parameters specified
via keyword arguments.
name is the header field to add.  Keyword arguments can be used to set MIME
parameters for the header field.  Each parameter must be a string or None.
Underscores in parameter names are converted to dashes, since dashes are illegal
in Python identifiers, but many MIME parameter names include dashes.  If the
parameter value is a string, it is added to the header value parameters in the
form name=""value"". If it is None, only the parameter name is added.
(This is used for MIME parameters without a value.)  Example usage:
h.add_header('content-disposition', 'attachment', filename='bud.gif')


The above will add a header that looks like this:
Content-Disposition: attachment; filename=""bud.gif"""
set_app(application),"Sets the callable application as the WSGI application that will receive
requests."
get_app(),Returns the currently-set application callable.
get_environ(),"Returns a dictionary containing the WSGI environment for a request.  The default
implementation copies the contents of the WSGIServer object’s
base_environ dictionary attribute and then adds various headers derived
from the HTTP request.  Each call to this method should return a new dictionary
containing all of the relevant CGI environment variables as specified in
PEP 3333."
get_stderr(),"Return the object that should be used as the wsgi.errors stream. The default
implementation just returns sys.stderr."
handle(),"Process the HTTP request.  The default implementation creates a handler instance
using a wsgiref.handlers class to implement the actual WSGI application
interface."
run(app),"Run the specified WSGI application, app."
_write(data),"Buffer the bytes data for transmission to the client.  It’s okay if this
method actually transmits the data; BaseHandler just separates write
and flush operations for greater efficiency when the underlying system actually
has such a distinction."
_flush(),"Force buffered data to be transmitted to the client.  It’s okay if this method
is a no-op (i.e., if _write() actually sends the data)."
get_stdin(),"Return an input stream object suitable for use as the wsgi.input of the
request currently being processed."
get_stderr(),"Return an output stream object suitable for use as the wsgi.errors of the
request currently being processed."
add_cgi_vars(),Insert CGI variables for the current request into the environ attribute.
get_scheme(),"Return the URL scheme being used for the current request.  The default
implementation uses the guess_scheme() function from wsgiref.util
to guess whether the scheme should be “http” or “https”, based on the current
request’s environ variables."
setup_environ(),"Set the environ attribute to a fully-populated WSGI environment.  The
default implementation uses all of the above methods and attributes, plus the
get_stdin(), get_stderr(), and add_cgi_vars() methods and the
wsgi_file_wrapper attribute.  It also inserts a SERVER_SOFTWARE key
if not present, as long as the origin_server attribute is a true value
and the server_software attribute is set."
log_exception(exc_info),"Log the exc_info tuple in the server log.  exc_info is a (type, value,
traceback) tuple.  The default implementation simply writes the traceback to
the request’s wsgi.errors stream and flushes it.  Subclasses can override
this method to change the format or retarget the output, mail the traceback to
an administrator, or whatever other action may be deemed suitable."
"error_output(environ, start_response)","This method is a WSGI application to generate an error page for the user.  It is
only invoked if an error occurs before headers are sent to the client.
This method can access the current error information using sys.exc_info(),
and should pass that information to start_response when calling it (as
described in the “Error Handling” section of PEP 3333).
The default implementation just uses the error_status,
error_headers, and error_body attributes to generate an output
page.  Subclasses can override this to produce more dynamic error output.
Note, however, that it’s not recommended from a security perspective to spit out
diagnostics to any old user; ideally, you should have to do something special to
enable diagnostic output, which is why the default implementation doesn’t
include any."
sendfile(),"Override to implement platform-specific file transmission.  This method is
called only if the application’s return value is an instance of the class
specified by the wsgi_file_wrapper attribute.  It should return a true
value if it was able to successfully transmit the file, so that the default
transmission code will not be executed. The default implementation of this
method just returns a false value."
"urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)","Open the URL url, which can be either a string or a
Request object.
data must be an object specifying additional data to be sent to the
server, or None if no such data is needed.  See Request
for details.
urllib.request module uses HTTP/1.1 and includes Connection:close header
in its HTTP requests.
The optional timeout parameter specifies a timeout in seconds for
blocking operations like the connection attempt (if not specified,
the global default timeout setting will be used).  This actually
only works for HTTP, HTTPS and FTP connections.
If context is specified, it must be a ssl.SSLContext instance
describing the various SSL options. See HTTPSConnection
for more details.
The optional cafile and capath parameters specify a set of trusted
CA certificates for HTTPS requests.  cafile should point to a single
file containing a bundle of CA certificates, whereas capath should
point to a directory of hashed certificate files.  More information can
be found in ssl.SSLContext.load_verify_locations().
The cadefault parameter is ignored.
This function always returns an object which can work as a
context manager and has methods such as

geturl() — return the URL of the resource retrieved,
commonly used to determine if a redirect was followed
info() — return the meta-information of the page, such as headers,
in the form of an email.message_from_string() instance (see
Quick Reference to HTTP Headers)
getcode() – return the HTTP status code of the response.

For HTTP and HTTPS URLs, this function returns a
http.client.HTTPResponse object slightly modified. In addition
to the three new methods above, the msg attribute contains the
same information as the reason
attribute — the reason phrase returned by server — instead of
the response headers as it is specified in the documentation for
HTTPResponse.
For FTP, file, and data URLs and requests explicitly handled by legacy
URLopener and FancyURLopener classes, this function
returns a urllib.response.addinfourl object.
Raises URLError on protocol errors.
Note that None may be returned if no handler handles the request (though
the default installed global OpenerDirector uses
UnknownHandler to ensure this never happens).
In addition, if proxy settings are detected (for example, when a *_proxy
environment variable like http_proxy is set),
ProxyHandler is default installed and makes sure the requests are
handled through the proxy.
The legacy urllib.urlopen function from Python 2.6 and earlier has been
discontinued; urllib.request.urlopen() corresponds to the old
urllib2.urlopen.  Proxy handling, which was done by passing a dictionary
parameter to urllib.urlopen, can be obtained by using
ProxyHandler objects.
The default opener raises an auditing event
urllib.Request with arguments fullurl, data, headers,
method taken from the request object.

Changed in version 3.2: cafile and capath were added.


Changed in version 3.2: HTTPS virtual hosts are now supported if possible (that is, if
ssl.HAS_SNI is true).


New in version 3.2: data can be an iterable object.


Changed in version 3.3: cadefault was added.


Changed in version 3.4.3: context was added.


Deprecated since version 3.6: cafile, capath and cadefault are deprecated in favor of context.
Please use ssl.SSLContext.load_cert_chain() instead, or let
ssl.create_default_context() select the system’s trusted CA
certificates for you."
urllib.request.install_opener(opener),"Install an OpenerDirector instance as the default global opener.
Installing an opener is only necessary if you want urlopen to use that
opener; otherwise, simply call OpenerDirector.open() instead of
urlopen().  The code does not check for a real
OpenerDirector, and any class with the appropriate interface will
work."
"urllib.request.build_opener([handler, ...])","Return an OpenerDirector instance, which chains the handlers in the
order given. handlers can be either instances of BaseHandler, or
subclasses of BaseHandler (in which case it must be possible to call
the constructor without any parameters).  Instances of the following classes
will be in front of the handlers, unless the handlers contain them,
instances of them or subclasses of them: ProxyHandler (if proxy
settings are detected), UnknownHandler, HTTPHandler,
HTTPDefaultErrorHandler, HTTPRedirectHandler,
FTPHandler, FileHandler, HTTPErrorProcessor.
If the Python installation has SSL support (i.e., if the ssl module
can be imported), HTTPSHandler will also be added.
A BaseHandler subclass may also change its handler_order
attribute to modify its position in the handlers list."
urllib.request.pathname2url(path),"Convert the pathname path from the local syntax for a path to the form used in
the path component of a URL.  This does not produce a complete URL.  The return
value will already be quoted using the quote() function."
urllib.request.url2pathname(path),"Convert the path component path from a percent-encoded URL to the local syntax for a
path.  This does not accept a complete URL.  This function uses
unquote() to decode path."
urllib.request.getproxies(),"This helper function returns a dictionary of scheme to proxy server URL
mappings. It scans the environment for variables named <scheme>_proxy,
in a case insensitive approach, for all operating systems first, and when it
cannot find it, looks for proxy information from Mac OSX System
Configuration for Mac OS X and Windows Systems Registry for Windows.
If both lowercase and uppercase environment variables exist (and disagree),
lowercase is preferred.

Note
If the environment variable REQUEST_METHOD is set, which usually
indicates your script is running in a CGI environment, the environment
variable HTTP_PROXY (uppercase _PROXY) will be ignored. This is
because that variable can be injected by a client using the “Proxy:” HTTP
header. If you need to use an HTTP proxy in a CGI environment, either use
ProxyHandler explicitly, or make sure the variable name is in
lowercase (or at least the _proxy suffix)."
"urllib.request.urlretrieve(url, filename=None, reporthook=None, data=None)","Copy a network object denoted by a URL to a local file. If the URL
points to a local file, the object will not be copied unless filename is supplied.
Return a tuple (filename, headers) where filename is the
local file name under which the object can be found, and headers is whatever
the info() method of the object returned by urlopen() returned (for
a remote object). Exceptions are the same as for urlopen().
The second argument, if present, specifies the file location to copy to (if
absent, the location will be a tempfile with a generated name). The third
argument, if present, is a callable that will be called once on
establishment of the network connection and once after each block read
thereafter.  The callable will be passed three arguments; a count of blocks
transferred so far, a block size in bytes, and the total size of the file.  The
third argument may be -1 on older FTP servers which do not return a file
size in response to a retrieval request.
The following example illustrates the most common usage scenario:
>>> import urllib.request
>>> local_filename, headers = urllib.request.urlretrieve('http://python.org/')
>>> html = open(local_filename)
>>> html.close()


If the url uses the http: scheme identifier, the optional data
argument may be given to specify a POST request (normally the request
type is GET).  The data argument must be a bytes object in standard
application/x-www-form-urlencoded format; see the
urllib.parse.urlencode() function.
urlretrieve() will raise ContentTooShortError when it detects that
the amount of data available  was less than the expected amount (which is the
size reported by a  Content-Length header). This can occur, for example, when
the  download is interrupted.
The Content-Length is treated as a lower bound: if there’s more data  to read,
urlretrieve reads more data, but if less data is available,  it raises the
exception.
You can still retrieve the downloaded data in this case, it is stored  in the
content attribute of the exception instance.
If no Content-Length header was supplied, urlretrieve can not check the size
of the data it has downloaded, and just returns it.  In this case you just have
to assume that the download was successful."
urllib.request.urlcleanup(),"Cleans up temporary files that may have been left behind by previous
calls to urlretrieve()."
Request.get_method(),"Return a string indicating the HTTP request method.  If
Request.method is not None, return its value, otherwise return
'GET' if Request.data is None, or 'POST' if it’s not.
This is only meaningful for HTTP requests.

Changed in version 3.3: get_method now looks at the value of Request.method."
"Request.add_header(key, val)","Add another header to the request.  Headers are currently ignored by all
handlers except HTTP handlers, where they are added to the list of headers sent
to the server.  Note that there cannot be more than one header with the same
name, and later calls will overwrite previous calls in case the key collides.
Currently, this is no loss of HTTP functionality, since all headers which have
meaning when used more than once have a (header-specific) way of gaining the
same functionality using only one header."
"Request.add_unredirected_header(key, header)",Add a header that will not be added to a redirected request.
Request.has_header(header),"Return whether the instance has the named header (checks both regular and
unredirected)."
Request.remove_header(header),"Remove named header from the request instance (both from regular and
unredirected headers).

New in version 3.4."
Request.get_full_url(),"Return the URL given in the constructor.

Changed in version 3.4.

Returns Request.full_url"
"Request.set_proxy(host, type)","Prepare the request by connecting to a proxy server. The host and type will
replace those of the instance, and the instance’s selector will be the original
URL given in the constructor."
"Request.get_header(header_name, default=None)","Return the value of the given header. If the header is not present, return
the default value."
Request.header_items(),"Return a list of tuples (header_name, header_value) of the Request headers."
OpenerDirector.add_handler(handler),"handler should be an instance of BaseHandler.  The following methods
are searched, and added to the possible chains (note that HTTP errors are a
special case).  Note that, in the following, protocol should be replaced
with the actual protocol to handle, for example http_response() would
be the HTTP protocol response handler.  Also type should be replaced with
the actual HTTP code, for example http_error_404() would handle HTTP
404 errors.

<protocol>_open() — signal that the handler knows how to open protocol
URLs.
See BaseHandler.<protocol>_open() for more information.

http_error_<type>() — signal that the handler knows how to handle HTTP
errors with HTTP error code type.
See BaseHandler.http_error_<nnn>() for more information.

<protocol>_error() — signal that the handler knows how to handle errors
from (non-http) protocol.
<protocol>_request() — signal that the handler knows how to pre-process
protocol requests.
See BaseHandler.<protocol>_request() for more information.

<protocol>_response() — signal that the handler knows how to
post-process protocol responses.
See BaseHandler.<protocol>_response() for more information."
"OpenerDirector.open(url, data=None[, timeout])","Open the given url (which can be a request object or a string), optionally
passing the given data. Arguments, return values and exceptions raised are
the same as those of urlopen() (which simply calls the open()
method on the currently installed global OpenerDirector).  The
optional timeout parameter specifies a timeout in seconds for blocking
operations like the connection attempt (if not specified, the global default
timeout setting will be used). The timeout feature actually works only for
HTTP, HTTPS and FTP connections)."
"OpenerDirector.error(proto, *args)","Handle an error of the given protocol.  This will call the registered error
handlers for the given protocol with the given arguments (which are protocol
specific).  The HTTP protocol is a special case which uses the HTTP response
code to determine the specific error handler; refer to the http_error_<type>()
methods of the handler classes.
Return values and exceptions raised are the same as those of urlopen()."
BaseHandler.add_parent(director),Add a director as parent.
BaseHandler.close(),Remove any parents.
BaseHandler.default_open(req),"This method is not defined in BaseHandler, but subclasses should
define it if they want to catch all URLs.
This method, if implemented, will be called by the parent
OpenerDirector.  It should return a file-like object as described in
the return value of the open() of OpenerDirector, or None.
It should raise URLError, unless a truly exceptional
thing happens (for example, MemoryError should not be mapped to
URLError).
This method will be called before any protocol-specific open method."
BaseHandler.<protocol>_open(req,"This method is not defined in BaseHandler, but subclasses should
define it if they want to handle URLs with the given protocol.
This method, if defined, will be called by the parent OpenerDirector.
Return values should be the same as for  default_open()."
BaseHandler.unknown_open(req),"This method is not defined in BaseHandler, but subclasses should
define it if they want to catch all URLs with no specific registered handler to
open it.
This method, if implemented, will be called by the parent
OpenerDirector.  Return values should be the same as for
default_open()."
"BaseHandler.http_error_default(req, fp, code, msg, hdrs)","This method is not defined in BaseHandler, but subclasses should
override it if they intend to provide a catch-all for otherwise unhandled HTTP
errors.  It will be called automatically by the  OpenerDirector getting
the error, and should not normally be called in other circumstances.
req will be a Request object, fp will be a file-like object with
the HTTP error body, code will be the three-digit code of the error, msg
will be the user-visible explanation of the code and hdrs will be a mapping
object with the headers of the error.
Return values and exceptions raised should be the same as those of
urlopen()."
"BaseHandler.http_error_<nnn>(req, fp, code, msg, hdrs","nnn should be a three-digit HTTP error code.  This method is also not defined
in BaseHandler, but will be called, if it exists, on an instance of a
subclass, when an HTTP error with code nnn occurs.
Subclasses should override this method to handle specific HTTP errors.
Arguments, return values and exceptions raised should be the same as for
http_error_default()."
BaseHandler.<protocol>_request(req,"This method is not defined in BaseHandler, but subclasses should
define it if they want to pre-process requests of the given protocol.
This method, if defined, will be called by the parent OpenerDirector.
req will be a Request object. The return value should be a
Request object."
"BaseHandler.<protocol>_response(req, response","This method is not defined in BaseHandler, but subclasses should
define it if they want to post-process responses of the given protocol.
This method, if defined, will be called by the parent OpenerDirector.
req will be a Request object. response will be an object
implementing the same interface as the return value of urlopen().  The
return value should implement the same interface as the return value of
urlopen()."
"HTTPRedirectHandler.redirect_request(req, fp, code, msg, hdrs, newurl)","Return a Request or None in response to a redirect. This is called
by the default implementations of the http_error_30*() methods when a
redirection is received from the server.  If a redirection should take place,
return a new Request to allow http_error_30*() to perform the
redirect to newurl.  Otherwise, raise HTTPError if
no other handler should try to handle this URL, or return None if you
can’t but another handler might.

Note
The default implementation of this method does not strictly follow RFC 2616,
which says that 301 and 302 responses to POST requests must not be
automatically redirected without confirmation by the user.  In reality, browsers
do allow automatic redirection of these responses, changing the POST to a
GET, and the default implementation reproduces this behavior."
"HTTPRedirectHandler.http_error_301(req, fp, code, msg, hdrs)","Redirect to the Location: or URI: URL.  This method is called by the
parent OpenerDirector when getting an HTTP ‘moved permanently’ response."
"HTTPRedirectHandler.http_error_302(req, fp, code, msg, hdrs)","The same as http_error_301(), but called for the ‘found’ response."
"HTTPRedirectHandler.http_error_303(req, fp, code, msg, hdrs)","The same as http_error_301(), but called for the ‘see other’ response."
"HTTPRedirectHandler.http_error_307(req, fp, code, msg, hdrs)","The same as http_error_301(), but called for the ‘temporary redirect’
response."
ProxyHandler.<protocol>_open(request,"The ProxyHandler will have a method <protocol>_open() for every
protocol which has a proxy in the proxies dictionary given in the
constructor.  The method will modify requests to go through the proxy, by
calling request.set_proxy(), and call the next handler in the chain to
actually execute the protocol."
"HTTPPasswordMgr.add_password(realm, uri, user, passwd)","uri can be either a single URI, or a sequence of URIs. realm, user and
passwd must be strings. This causes (user, passwd) to be used as
authentication tokens when authentication for realm and a super-URI of any of
the given URIs is given."
"HTTPPasswordMgr.find_user_password(realm, authuri)","Get user/password for given realm and URI, if any.  This method will return
(None, None) if there is no matching user/password.
For HTTPPasswordMgrWithDefaultRealm objects, the realm None will be
searched if the given realm has no matching user/password."
"HTTPPasswordMgrWithPriorAuth.add_password(realm, uri, user, passwd, is_authenticated=False)","realm, uri, user, passwd are as for
HTTPPasswordMgr.add_password().  is_authenticated sets the initial
value of the is_authenticated flag for the given URI or list of URIs.
If is_authenticated is specified as True, realm is ignored."
"HTTPPasswordMgr.find_user_password(realm, authuri",Same as for HTTPPasswordMgrWithDefaultRealm objects
"HTTPPasswordMgrWithPriorAuth.update_authenticated(self, uri, is_authenticated=False)","Update the is_authenticated flag for the given uri or list
of URIs."
"HTTPPasswordMgrWithPriorAuth.is_authenticated(self, authuri)","Returns the current state of the is_authenticated flag for
the given URI."
"AbstractBasicAuthHandler.http_error_auth_reqed(authreq, host, req, headers)","Handle an authentication request by getting a user/password pair, and re-trying
the request.  authreq should be the name of the header where the information
about the realm is included in the request, host specifies the URL and path to
authenticate for, req should be the (failed) Request object, and
headers should be the error headers.
host is either an authority (e.g. ""python.org"") or a URL containing an
authority component (e.g. ""http://python.org/""). In either case, the
authority must not contain a userinfo component (so, ""python.org"" and
""python.org:80"" are fine, ""joe:password@python.org"" is not)."
"HTTPBasicAuthHandler.http_error_401(req, fp, code, msg, hdrs)","Retry the request with authentication information, if available."
"ProxyBasicAuthHandler.http_error_407(req, fp, code, msg, hdrs)","Retry the request with authentication information, if available."
"AbstractDigestAuthHandler.http_error_auth_reqed(authreq, host, req, headers)","authreq should be the name of the header where the information about the realm
is included in the request, host should be the host to authenticate to, req
should be the (failed) Request object, and headers should be the
error headers."
"HTTPDigestAuthHandler.http_error_401(req, fp, code, msg, hdrs)","Retry the request with authentication information, if available."
"ProxyDigestAuthHandler.http_error_407(req, fp, code, msg, hdrs)","Retry the request with authentication information, if available."
HTTPHandler.http_open(req),"Send an HTTP request, which can be either GET or POST, depending on
req.has_data()."
HTTPSHandler.https_open(req),"Send an HTTPS request, which can be either GET or POST, depending on
req.has_data()."
FileHandler.file_open(req),"Open the file locally, if there is no host name, or the host name is
'localhost'.

Changed in version 3.2: This method is applicable only for local hostnames.  When a remote
hostname is given, an URLError is raised."
DataHandler.data_open(req),"Read a data URL. This kind of URL contains the content encoded in the URL
itself. The data URL syntax is specified in RFC 2397. This implementation
ignores white spaces in base64 encoded data URLs so the URL may be wrapped
in whatever source file it comes from. But even though some browsers don’t
mind about a missing padding at the end of a base64 encoded data URL, this
implementation will raise an ValueError in that case."
FTPHandler.ftp_open(req),"Open the FTP file indicated by req. The login is always done with empty
username and password."
CacheFTPHandler.setTimeout(t),Set timeout of connections to t seconds.
CacheFTPHandler.setMaxConns(m),Set maximum number of cached connections to m.
UnknownHandler.unknown_open(),Raise a URLError exception.
"HTTPErrorProcessor.http_response(request, response)","Process HTTP error responses.
For 200 error codes, the response object is returned immediately.
For non-200 error codes, this simply passes the job on to the
http_error_<type>() handler methods, via OpenerDirector.error().
Eventually, HTTPDefaultErrorHandler will raise an
HTTPError if no other handler handles the error."
"HTTPErrorProcessor.https_response(request, response)","Process HTTPS error responses.
The behavior is same as http_response()."
"open(fullurl, data=None)","Open fullurl using the appropriate protocol.  This method sets up cache and
proxy information, then calls the appropriate open method with its input
arguments.  If the scheme is not recognized, open_unknown() is called.
The data argument has the same meaning as the data argument of
urlopen().
This method always quotes fullurl using quote()."
"open_unknown(fullurl, data=None)",Overridable interface to open unknown URL types.
"retrieve(url, filename=None, reporthook=None, data=None)","Retrieves the contents of url and places it in filename.  The return value
is a tuple consisting of a local filename and either an
email.message.Message object containing the response headers (for remote
URLs) or None (for local URLs).  The caller must then open and read the
contents of filename.  If filename is not given and the URL refers to a
local file, the input filename is returned.  If the URL is non-local and
filename is not given, the filename is the output of tempfile.mktemp()
with a suffix that matches the suffix of the last path component of the input
URL.  If reporthook is given, it must be a function accepting three numeric
parameters: A chunk number, the maximum size chunks are read in and the total size of the download
(-1 if unknown).  It will be called once at the start and after each chunk of data is read from the
network.  reporthook is ignored for local URLs.
If the url uses the http: scheme identifier, the optional data
argument may be given to specify a POST request (normally the request type
is GET).  The data argument must in standard
application/x-www-form-urlencoded format; see the
urllib.parse.urlencode() function."
"prompt_user_passwd(host, realm)","Return information needed to authenticate the user at the given host in the
specified security realm.  The return value should be a tuple, (user,
password), which can be used for basic authentication.
The implementation prompts for this information on the terminal; an application
should override this method to use an appropriate interaction model in the local
environment."
"urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)","Open the URL url, which can be either a string or a
Request object.
data must be an object specifying additional data to be sent to the
server, or None if no such data is needed.  See Request
for details.
urllib.request module uses HTTP/1.1 and includes Connection:close header
in its HTTP requests.
The optional timeout parameter specifies a timeout in seconds for
blocking operations like the connection attempt (if not specified,
the global default timeout setting will be used).  This actually
only works for HTTP, HTTPS and FTP connections.
If context is specified, it must be a ssl.SSLContext instance
describing the various SSL options. See HTTPSConnection
for more details.
The optional cafile and capath parameters specify a set of trusted
CA certificates for HTTPS requests.  cafile should point to a single
file containing a bundle of CA certificates, whereas capath should
point to a directory of hashed certificate files.  More information can
be found in ssl.SSLContext.load_verify_locations().
The cadefault parameter is ignored.
This function always returns an object which can work as a
context manager and has methods such as

geturl() — return the URL of the resource retrieved,
commonly used to determine if a redirect was followed
info() — return the meta-information of the page, such as headers,
in the form of an email.message_from_string() instance (see
Quick Reference to HTTP Headers)
getcode() – return the HTTP status code of the response.

For HTTP and HTTPS URLs, this function returns a
http.client.HTTPResponse object slightly modified. In addition
to the three new methods above, the msg attribute contains the
same information as the reason
attribute — the reason phrase returned by server — instead of
the response headers as it is specified in the documentation for
HTTPResponse.
For FTP, file, and data URLs and requests explicitly handled by legacy
URLopener and FancyURLopener classes, this function
returns a urllib.response.addinfourl object.
Raises URLError on protocol errors.
Note that None may be returned if no handler handles the request (though
the default installed global OpenerDirector uses
UnknownHandler to ensure this never happens).
In addition, if proxy settings are detected (for example, when a *_proxy
environment variable like http_proxy is set),
ProxyHandler is default installed and makes sure the requests are
handled through the proxy.
The legacy urllib.urlopen function from Python 2.6 and earlier has been
discontinued; urllib.request.urlopen() corresponds to the old
urllib2.urlopen.  Proxy handling, which was done by passing a dictionary
parameter to urllib.urlopen, can be obtained by using
ProxyHandler objects.
The default opener raises an auditing event
urllib.Request with arguments fullurl, data, headers,
method taken from the request object.

Changed in version 3.2: cafile and capath were added.


Changed in version 3.2: HTTPS virtual hosts are now supported if possible (that is, if
ssl.HAS_SNI is true).


New in version 3.2: data can be an iterable object.


Changed in version 3.3: cadefault was added.


Changed in version 3.4.3: context was added.


Deprecated since version 3.6: cafile, capath and cadefault are deprecated in favor of context.
Please use ssl.SSLContext.load_cert_chain() instead, or let
ssl.create_default_context() select the system’s trusted CA
certificates for you."
urllib.request.install_opener(opener),"Install an OpenerDirector instance as the default global opener.
Installing an opener is only necessary if you want urlopen to use that
opener; otherwise, simply call OpenerDirector.open() instead of
urlopen().  The code does not check for a real
OpenerDirector, and any class with the appropriate interface will
work."
"urllib.request.build_opener([handler, ...])","Return an OpenerDirector instance, which chains the handlers in the
order given. handlers can be either instances of BaseHandler, or
subclasses of BaseHandler (in which case it must be possible to call
the constructor without any parameters).  Instances of the following classes
will be in front of the handlers, unless the handlers contain them,
instances of them or subclasses of them: ProxyHandler (if proxy
settings are detected), UnknownHandler, HTTPHandler,
HTTPDefaultErrorHandler, HTTPRedirectHandler,
FTPHandler, FileHandler, HTTPErrorProcessor.
If the Python installation has SSL support (i.e., if the ssl module
can be imported), HTTPSHandler will also be added.
A BaseHandler subclass may also change its handler_order
attribute to modify its position in the handlers list."
urllib.request.pathname2url(path),"Convert the pathname path from the local syntax for a path to the form used in
the path component of a URL.  This does not produce a complete URL.  The return
value will already be quoted using the quote() function."
urllib.request.url2pathname(path),"Convert the path component path from a percent-encoded URL to the local syntax for a
path.  This does not accept a complete URL.  This function uses
unquote() to decode path."
urllib.request.getproxies(),"This helper function returns a dictionary of scheme to proxy server URL
mappings. It scans the environment for variables named <scheme>_proxy,
in a case insensitive approach, for all operating systems first, and when it
cannot find it, looks for proxy information from Mac OSX System
Configuration for Mac OS X and Windows Systems Registry for Windows.
If both lowercase and uppercase environment variables exist (and disagree),
lowercase is preferred.

Note
If the environment variable REQUEST_METHOD is set, which usually
indicates your script is running in a CGI environment, the environment
variable HTTP_PROXY (uppercase _PROXY) will be ignored. This is
because that variable can be injected by a client using the “Proxy:” HTTP
header. If you need to use an HTTP proxy in a CGI environment, either use
ProxyHandler explicitly, or make sure the variable name is in
lowercase (or at least the _proxy suffix)."
"urllib.request.urlretrieve(url, filename=None, reporthook=None, data=None)","Copy a network object denoted by a URL to a local file. If the URL
points to a local file, the object will not be copied unless filename is supplied.
Return a tuple (filename, headers) where filename is the
local file name under which the object can be found, and headers is whatever
the info() method of the object returned by urlopen() returned (for
a remote object). Exceptions are the same as for urlopen().
The second argument, if present, specifies the file location to copy to (if
absent, the location will be a tempfile with a generated name). The third
argument, if present, is a callable that will be called once on
establishment of the network connection and once after each block read
thereafter.  The callable will be passed three arguments; a count of blocks
transferred so far, a block size in bytes, and the total size of the file.  The
third argument may be -1 on older FTP servers which do not return a file
size in response to a retrieval request.
The following example illustrates the most common usage scenario:
>>> import urllib.request
>>> local_filename, headers = urllib.request.urlretrieve('http://python.org/')
>>> html = open(local_filename)
>>> html.close()


If the url uses the http: scheme identifier, the optional data
argument may be given to specify a POST request (normally the request
type is GET).  The data argument must be a bytes object in standard
application/x-www-form-urlencoded format; see the
urllib.parse.urlencode() function.
urlretrieve() will raise ContentTooShortError when it detects that
the amount of data available  was less than the expected amount (which is the
size reported by a  Content-Length header). This can occur, for example, when
the  download is interrupted.
The Content-Length is treated as a lower bound: if there’s more data  to read,
urlretrieve reads more data, but if less data is available,  it raises the
exception.
You can still retrieve the downloaded data in this case, it is stored  in the
content attribute of the exception instance.
If no Content-Length header was supplied, urlretrieve can not check the size
of the data it has downloaded, and just returns it.  In this case you just have
to assume that the download was successful."
urllib.request.urlcleanup(),"Cleans up temporary files that may have been left behind by previous
calls to urlretrieve()."
Request.get_method(),"Return a string indicating the HTTP request method.  If
Request.method is not None, return its value, otherwise return
'GET' if Request.data is None, or 'POST' if it’s not.
This is only meaningful for HTTP requests.

Changed in version 3.3: get_method now looks at the value of Request.method."
"Request.add_header(key, val)","Add another header to the request.  Headers are currently ignored by all
handlers except HTTP handlers, where they are added to the list of headers sent
to the server.  Note that there cannot be more than one header with the same
name, and later calls will overwrite previous calls in case the key collides.
Currently, this is no loss of HTTP functionality, since all headers which have
meaning when used more than once have a (header-specific) way of gaining the
same functionality using only one header."
"Request.add_unredirected_header(key, header)",Add a header that will not be added to a redirected request.
Request.has_header(header),"Return whether the instance has the named header (checks both regular and
unredirected)."
Request.remove_header(header),"Remove named header from the request instance (both from regular and
unredirected headers).

New in version 3.4."
Request.get_full_url(),"Return the URL given in the constructor.

Changed in version 3.4.

Returns Request.full_url"
"Request.set_proxy(host, type)","Prepare the request by connecting to a proxy server. The host and type will
replace those of the instance, and the instance’s selector will be the original
URL given in the constructor."
"Request.get_header(header_name, default=None)","Return the value of the given header. If the header is not present, return
the default value."
Request.header_items(),"Return a list of tuples (header_name, header_value) of the Request headers."
OpenerDirector.add_handler(handler),"handler should be an instance of BaseHandler.  The following methods
are searched, and added to the possible chains (note that HTTP errors are a
special case).  Note that, in the following, protocol should be replaced
with the actual protocol to handle, for example http_response() would
be the HTTP protocol response handler.  Also type should be replaced with
the actual HTTP code, for example http_error_404() would handle HTTP
404 errors.

<protocol>_open() — signal that the handler knows how to open protocol
URLs.
See BaseHandler.<protocol>_open() for more information.

http_error_<type>() — signal that the handler knows how to handle HTTP
errors with HTTP error code type.
See BaseHandler.http_error_<nnn>() for more information.

<protocol>_error() — signal that the handler knows how to handle errors
from (non-http) protocol.
<protocol>_request() — signal that the handler knows how to pre-process
protocol requests.
See BaseHandler.<protocol>_request() for more information.

<protocol>_response() — signal that the handler knows how to
post-process protocol responses.
See BaseHandler.<protocol>_response() for more information."
"OpenerDirector.open(url, data=None[, timeout])","Open the given url (which can be a request object or a string), optionally
passing the given data. Arguments, return values and exceptions raised are
the same as those of urlopen() (which simply calls the open()
method on the currently installed global OpenerDirector).  The
optional timeout parameter specifies a timeout in seconds for blocking
operations like the connection attempt (if not specified, the global default
timeout setting will be used). The timeout feature actually works only for
HTTP, HTTPS and FTP connections)."
"OpenerDirector.error(proto, *args)","Handle an error of the given protocol.  This will call the registered error
handlers for the given protocol with the given arguments (which are protocol
specific).  The HTTP protocol is a special case which uses the HTTP response
code to determine the specific error handler; refer to the http_error_<type>()
methods of the handler classes.
Return values and exceptions raised are the same as those of urlopen()."
BaseHandler.add_parent(director),Add a director as parent.
BaseHandler.close(),Remove any parents.
BaseHandler.default_open(req),"This method is not defined in BaseHandler, but subclasses should
define it if they want to catch all URLs.
This method, if implemented, will be called by the parent
OpenerDirector.  It should return a file-like object as described in
the return value of the open() of OpenerDirector, or None.
It should raise URLError, unless a truly exceptional
thing happens (for example, MemoryError should not be mapped to
URLError).
This method will be called before any protocol-specific open method."
BaseHandler.<protocol>_open(req,"This method is not defined in BaseHandler, but subclasses should
define it if they want to handle URLs with the given protocol.
This method, if defined, will be called by the parent OpenerDirector.
Return values should be the same as for  default_open()."
BaseHandler.unknown_open(req),"This method is not defined in BaseHandler, but subclasses should
define it if they want to catch all URLs with no specific registered handler to
open it.
This method, if implemented, will be called by the parent
OpenerDirector.  Return values should be the same as for
default_open()."
"BaseHandler.http_error_default(req, fp, code, msg, hdrs)","This method is not defined in BaseHandler, but subclasses should
override it if they intend to provide a catch-all for otherwise unhandled HTTP
errors.  It will be called automatically by the  OpenerDirector getting
the error, and should not normally be called in other circumstances.
req will be a Request object, fp will be a file-like object with
the HTTP error body, code will be the three-digit code of the error, msg
will be the user-visible explanation of the code and hdrs will be a mapping
object with the headers of the error.
Return values and exceptions raised should be the same as those of
urlopen()."
"BaseHandler.http_error_<nnn>(req, fp, code, msg, hdrs","nnn should be a three-digit HTTP error code.  This method is also not defined
in BaseHandler, but will be called, if it exists, on an instance of a
subclass, when an HTTP error with code nnn occurs.
Subclasses should override this method to handle specific HTTP errors.
Arguments, return values and exceptions raised should be the same as for
http_error_default()."
BaseHandler.<protocol>_request(req,"This method is not defined in BaseHandler, but subclasses should
define it if they want to pre-process requests of the given protocol.
This method, if defined, will be called by the parent OpenerDirector.
req will be a Request object. The return value should be a
Request object."
"BaseHandler.<protocol>_response(req, response","This method is not defined in BaseHandler, but subclasses should
define it if they want to post-process responses of the given protocol.
This method, if defined, will be called by the parent OpenerDirector.
req will be a Request object. response will be an object
implementing the same interface as the return value of urlopen().  The
return value should implement the same interface as the return value of
urlopen()."
"HTTPRedirectHandler.redirect_request(req, fp, code, msg, hdrs, newurl)","Return a Request or None in response to a redirect. This is called
by the default implementations of the http_error_30*() methods when a
redirection is received from the server.  If a redirection should take place,
return a new Request to allow http_error_30*() to perform the
redirect to newurl.  Otherwise, raise HTTPError if
no other handler should try to handle this URL, or return None if you
can’t but another handler might.

Note
The default implementation of this method does not strictly follow RFC 2616,
which says that 301 and 302 responses to POST requests must not be
automatically redirected without confirmation by the user.  In reality, browsers
do allow automatic redirection of these responses, changing the POST to a
GET, and the default implementation reproduces this behavior."
"HTTPRedirectHandler.http_error_301(req, fp, code, msg, hdrs)","Redirect to the Location: or URI: URL.  This method is called by the
parent OpenerDirector when getting an HTTP ‘moved permanently’ response."
"HTTPRedirectHandler.http_error_302(req, fp, code, msg, hdrs)","The same as http_error_301(), but called for the ‘found’ response."
"HTTPRedirectHandler.http_error_303(req, fp, code, msg, hdrs)","The same as http_error_301(), but called for the ‘see other’ response."
"HTTPRedirectHandler.http_error_307(req, fp, code, msg, hdrs)","The same as http_error_301(), but called for the ‘temporary redirect’
response."
ProxyHandler.<protocol>_open(request,"The ProxyHandler will have a method <protocol>_open() for every
protocol which has a proxy in the proxies dictionary given in the
constructor.  The method will modify requests to go through the proxy, by
calling request.set_proxy(), and call the next handler in the chain to
actually execute the protocol."
"HTTPPasswordMgr.add_password(realm, uri, user, passwd)","uri can be either a single URI, or a sequence of URIs. realm, user and
passwd must be strings. This causes (user, passwd) to be used as
authentication tokens when authentication for realm and a super-URI of any of
the given URIs is given."
"HTTPPasswordMgr.find_user_password(realm, authuri)","Get user/password for given realm and URI, if any.  This method will return
(None, None) if there is no matching user/password.
For HTTPPasswordMgrWithDefaultRealm objects, the realm None will be
searched if the given realm has no matching user/password."
"HTTPPasswordMgrWithPriorAuth.add_password(realm, uri, user, passwd, is_authenticated=False)","realm, uri, user, passwd are as for
HTTPPasswordMgr.add_password().  is_authenticated sets the initial
value of the is_authenticated flag for the given URI or list of URIs.
If is_authenticated is specified as True, realm is ignored."
"HTTPPasswordMgr.find_user_password(realm, authuri",Same as for HTTPPasswordMgrWithDefaultRealm objects
"HTTPPasswordMgrWithPriorAuth.update_authenticated(self, uri, is_authenticated=False)","Update the is_authenticated flag for the given uri or list
of URIs."
"HTTPPasswordMgrWithPriorAuth.is_authenticated(self, authuri)","Returns the current state of the is_authenticated flag for
the given URI."
"AbstractBasicAuthHandler.http_error_auth_reqed(authreq, host, req, headers)","Handle an authentication request by getting a user/password pair, and re-trying
the request.  authreq should be the name of the header where the information
about the realm is included in the request, host specifies the URL and path to
authenticate for, req should be the (failed) Request object, and
headers should be the error headers.
host is either an authority (e.g. ""python.org"") or a URL containing an
authority component (e.g. ""http://python.org/""). In either case, the
authority must not contain a userinfo component (so, ""python.org"" and
""python.org:80"" are fine, ""joe:password@python.org"" is not)."
"HTTPBasicAuthHandler.http_error_401(req, fp, code, msg, hdrs)","Retry the request with authentication information, if available."
"ProxyBasicAuthHandler.http_error_407(req, fp, code, msg, hdrs)","Retry the request with authentication information, if available."
"AbstractDigestAuthHandler.http_error_auth_reqed(authreq, host, req, headers)","authreq should be the name of the header where the information about the realm
is included in the request, host should be the host to authenticate to, req
should be the (failed) Request object, and headers should be the
error headers."
"HTTPDigestAuthHandler.http_error_401(req, fp, code, msg, hdrs)","Retry the request with authentication information, if available."
"ProxyDigestAuthHandler.http_error_407(req, fp, code, msg, hdrs)","Retry the request with authentication information, if available."
HTTPHandler.http_open(req),"Send an HTTP request, which can be either GET or POST, depending on
req.has_data()."
HTTPSHandler.https_open(req),"Send an HTTPS request, which can be either GET or POST, depending on
req.has_data()."
FileHandler.file_open(req),"Open the file locally, if there is no host name, or the host name is
'localhost'.

Changed in version 3.2: This method is applicable only for local hostnames.  When a remote
hostname is given, an URLError is raised."
DataHandler.data_open(req),"Read a data URL. This kind of URL contains the content encoded in the URL
itself. The data URL syntax is specified in RFC 2397. This implementation
ignores white spaces in base64 encoded data URLs so the URL may be wrapped
in whatever source file it comes from. But even though some browsers don’t
mind about a missing padding at the end of a base64 encoded data URL, this
implementation will raise an ValueError in that case."
FTPHandler.ftp_open(req),"Open the FTP file indicated by req. The login is always done with empty
username and password."
CacheFTPHandler.setTimeout(t),Set timeout of connections to t seconds.
CacheFTPHandler.setMaxConns(m),Set maximum number of cached connections to m.
UnknownHandler.unknown_open(),Raise a URLError exception.
"HTTPErrorProcessor.http_response(request, response)","Process HTTP error responses.
For 200 error codes, the response object is returned immediately.
For non-200 error codes, this simply passes the job on to the
http_error_<type>() handler methods, via OpenerDirector.error().
Eventually, HTTPDefaultErrorHandler will raise an
HTTPError if no other handler handles the error."
"HTTPErrorProcessor.https_response(request, response)","Process HTTPS error responses.
The behavior is same as http_response()."
"open(fullurl, data=None)","Open fullurl using the appropriate protocol.  This method sets up cache and
proxy information, then calls the appropriate open method with its input
arguments.  If the scheme is not recognized, open_unknown() is called.
The data argument has the same meaning as the data argument of
urlopen().
This method always quotes fullurl using quote()."
"open_unknown(fullurl, data=None)",Overridable interface to open unknown URL types.
"retrieve(url, filename=None, reporthook=None, data=None)","Retrieves the contents of url and places it in filename.  The return value
is a tuple consisting of a local filename and either an
email.message.Message object containing the response headers (for remote
URLs) or None (for local URLs).  The caller must then open and read the
contents of filename.  If filename is not given and the URL refers to a
local file, the input filename is returned.  If the URL is non-local and
filename is not given, the filename is the output of tempfile.mktemp()
with a suffix that matches the suffix of the last path component of the input
URL.  If reporthook is given, it must be a function accepting three numeric
parameters: A chunk number, the maximum size chunks are read in and the total size of the download
(-1 if unknown).  It will be called once at the start and after each chunk of data is read from the
network.  reporthook is ignored for local URLs.
If the url uses the http: scheme identifier, the optional data
argument may be given to specify a POST request (normally the request type
is GET).  The data argument must in standard
application/x-www-form-urlencoded format; see the
urllib.parse.urlencode() function."
"prompt_user_passwd(host, realm)","Return information needed to authenticate the user at the given host in the
specified security realm.  The return value should be a tuple, (user,
password), which can be used for basic authentication.
The implementation prompts for this information on the terminal; an application
should override this method to use an appropriate interaction model in the local
environment."
"urllib.parse.urlparse(urlstring, scheme='', allow_fragments=True)","Parse a URL into six components, returning a 6-item named tuple.  This
corresponds to the general structure of a URL:
scheme://netloc/path;parameters?query#fragment.
Each tuple item is a string, possibly empty. The components are not broken up in
smaller parts (for example, the network location is a single string), and %
escapes are not expanded. The delimiters as shown above are not part of the
result, except for a leading slash in the path component, which is retained if
present.  For example:
>>> from urllib.parse import urlparse
>>> o = urlparse('http://www.cwi.nl:80/%7Eguido/Python.html')
>>> o   
ParseResult(scheme='http', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
            params='', query='', fragment='')
>>> o.scheme
'http'
>>> o.port
80
>>> o.geturl()
'http://www.cwi.nl:80/%7Eguido/Python.html'


Following the syntax specifications in RFC 1808, urlparse recognizes
a netloc only if it is properly introduced by ‘//’.  Otherwise the
input is presumed to be a relative URL and thus to start with
a path component.
 >>> from urllib.parse import urlparse
 >>> urlparse('//www.cwi.nl:80/%7Eguido/Python.html')
 ParseResult(scheme='', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
            params='', query='', fragment='')
 >>> urlparse('www.cwi.nl/%7Eguido/Python.html')
 ParseResult(scheme='', netloc='', path='www.cwi.nl/%7Eguido/Python.html',
            params='', query='', fragment='')
 >>> urlparse('help/Python.html')
 ParseResult(scheme='', netloc='', path='help/Python.html', params='',
            query='', fragment='')


The scheme argument gives the default addressing scheme, to be
used only if the URL does not specify one.  It should be the same type
(text or bytes) as urlstring, except that the default value '' is
always allowed, and is automatically converted to b'' if appropriate.
If the allow_fragments argument is false, fragment identifiers are not
recognized.  Instead, they are parsed as part of the path, parameters
or query component, and fragment is set to the empty string in
the return value.
The return value is a named tuple, which means that its items can
be accessed by index or as named attributes, which are:








Attribute
Index
Value
Value if not present



scheme
0
URL scheme specifier
scheme parameter

netloc
1
Network location part
empty string

path
2
Hierarchical path
empty string

params
3
Parameters for last path
element
empty string

query
4
Query component
empty string

fragment
5
Fragment identifier
empty string

username

User name
None

password

Password
None

hostname

Host name (lower case)
None

port

Port number as integer,
if present
None



Reading the port attribute will raise a ValueError if
an invalid port is specified in the URL.  See section
Structured Parse Results for more information on the result object.
Unmatched square brackets in the netloc attribute will raise a
ValueError.
Characters in the netloc attribute that decompose under NFKC
normalization (as used by the IDNA encoding) into any of /, ?,
#, @, or : will raise a ValueError. If the URL is
decomposed before parsing, no error will be raised.
As is the case with all named tuples, the subclass has a few additional methods
and attributes that are particularly useful. One such method is _replace().
The _replace() method will return a new ParseResult object replacing specified
fields with new values.
 >>> from urllib.parse import urlparse
 >>> u = urlparse('//www.cwi.nl:80/%7Eguido/Python.html')
 >>> u
 ParseResult(scheme='', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
             params='', query='', fragment='')
 >>> u._replace(scheme='http')
 ParseResult(scheme='http', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
             params='', query='', fragment='')



Changed in version 3.2: Added IPv6 URL parsing capabilities.


Changed in version 3.3: The fragment is now parsed for all URL schemes (unless allow_fragment is
false), in accordance with RFC 3986.  Previously, a whitelist of
schemes that support fragments existed.


Changed in version 3.6: Out-of-range port numbers now raise ValueError, instead of
returning None.


Changed in version 3.8: Characters that affect netloc parsing under NFKC normalization will
now raise ValueError."
"urllib.parse.parse_qs(qs, keep_blank_values=False, strict_parsing=False, encoding='utf-8', errors='replace', max_num_fields=None)","Parse a query string given as a string argument (data of type
application/x-www-form-urlencoded).  Data are returned as a
dictionary.  The dictionary keys are the unique query variable names and the
values are lists of values for each name.
The optional argument keep_blank_values is a flag indicating whether blank
values in percent-encoded queries should be treated as blank strings. A true value
indicates that blanks should be retained as  blank strings.  The default false
value indicates that blank values are to be ignored and treated as if they were
not included.
The optional argument strict_parsing is a flag indicating what to do with
parsing errors.  If false (the default), errors are silently ignored.  If true,
errors raise a ValueError exception.
The optional encoding and errors parameters specify how to decode
percent-encoded sequences into Unicode characters, as accepted by the
bytes.decode() method.
The optional argument max_num_fields is the maximum number of fields to
read. If set, then throws a ValueError if there are more than
max_num_fields fields read.
Use the urllib.parse.urlencode() function (with the doseq
parameter set to True) to convert such dictionaries into query
strings.

Changed in version 3.2: Add encoding and errors parameters.


Changed in version 3.8: Added max_num_fields parameter."
"urllib.parse.parse_qsl(qs, keep_blank_values=False, strict_parsing=False, encoding='utf-8', errors='replace', max_num_fields=None)","Parse a query string given as a string argument (data of type
application/x-www-form-urlencoded).  Data are returned as a list of
name, value pairs.
The optional argument keep_blank_values is a flag indicating whether blank
values in percent-encoded queries should be treated as blank strings. A true value
indicates that blanks should be retained as  blank strings.  The default false
value indicates that blank values are to be ignored and treated as if they were
not included.
The optional argument strict_parsing is a flag indicating what to do with
parsing errors.  If false (the default), errors are silently ignored.  If true,
errors raise a ValueError exception.
The optional encoding and errors parameters specify how to decode
percent-encoded sequences into Unicode characters, as accepted by the
bytes.decode() method.
The optional argument max_num_fields is the maximum number of fields to
read. If set, then throws a ValueError if there are more than
max_num_fields fields read.
Use the urllib.parse.urlencode() function to convert such lists of pairs into
query strings.

Changed in version 3.2: Add encoding and errors parameters.


Changed in version 3.8: Added max_num_fields parameter."
urllib.parse.urlunparse(parts),"Construct a URL from a tuple as returned by urlparse(). The parts
argument can be any six-item iterable. This may result in a slightly
different, but equivalent URL, if the URL that was parsed originally had
unnecessary delimiters (for example, a ? with an empty query; the RFC
states that these are equivalent)."
"urllib.parse.urlsplit(urlstring, scheme='', allow_fragments=True)","This is similar to urlparse(), but does not split the params from the URL.
This should generally be used instead of urlparse() if the more recent URL
syntax allowing parameters to be applied to each segment of the path portion
of the URL (see RFC 2396) is wanted.  A separate function is needed to
separate the path segments and parameters.  This function returns a 5-item
named tuple:
(addressing scheme, network location, path, query, fragment identifier).


The return value is a named tuple, its items can be accessed by index
or as named attributes:








Attribute
Index
Value
Value if not present



scheme
0
URL scheme specifier
scheme parameter

netloc
1
Network location part
empty string

path
2
Hierarchical path
empty string

query
3
Query component
empty string

fragment
4
Fragment identifier
empty string

username

User name
None

password

Password
None

hostname

Host name (lower case)
None

port

Port number as integer,
if present
None



Reading the port attribute will raise a ValueError if
an invalid port is specified in the URL.  See section
Structured Parse Results for more information on the result object.
Unmatched square brackets in the netloc attribute will raise a
ValueError.
Characters in the netloc attribute that decompose under NFKC
normalization (as used by the IDNA encoding) into any of /, ?,
#, @, or : will raise a ValueError. If the URL is
decomposed before parsing, no error will be raised.

Changed in version 3.6: Out-of-range port numbers now raise ValueError, instead of
returning None.


Changed in version 3.8: Characters that affect netloc parsing under NFKC normalization will
now raise ValueError."
urllib.parse.urlunsplit(parts),"Combine the elements of a tuple as returned by urlsplit() into a
complete URL as a string. The parts argument can be any five-item
iterable. This may result in a slightly different, but equivalent URL, if the
URL that was parsed originally had unnecessary delimiters (for example, a ?
with an empty query; the RFC states that these are equivalent)."
"urllib.parse.urljoin(base, url, allow_fragments=True)","Construct a full (“absolute”) URL by combining a “base URL” (base) with
another URL (url).  Informally, this uses components of the base URL, in
particular the addressing scheme, the network location and (part of) the
path, to provide missing components in the relative URL.  For example:
>>> from urllib.parse import urljoin
>>> urljoin('http://www.cwi.nl/%7Eguido/Python.html', 'FAQ.html')
'http://www.cwi.nl/%7Eguido/FAQ.html'


The allow_fragments argument has the same meaning and default as for
urlparse().

Note
If url is an absolute URL (that is, starting with // or scheme://),
the url’s host name and/or scheme will be present in the result.  For example:

>>> urljoin('http://www.cwi.nl/%7Eguido/Python.html',
...         '//www.python.org/%7Eguido')
'http://www.python.org/%7Eguido'


If you do not want that behavior, preprocess the url with urlsplit() and
urlunsplit(), removing possible scheme and netloc parts.

Changed in version 3.5: Behaviour updated to match the semantics defined in RFC 3986."
urllib.parse.urldefrag(url),"If url contains a fragment identifier, return a modified version of url
with no fragment identifier, and the fragment identifier as a separate
string.  If there is no fragment identifier in url, return url unmodified
and an empty string.
The return value is a named tuple, its items can be accessed by index
or as named attributes:








Attribute
Index
Value
Value if not present



url
0
URL with no fragment
empty string

fragment
1
Fragment identifier
empty string



See section Structured Parse Results for more information on the result
object.

Changed in version 3.2: Result is a structured object rather than a simple 2-tuple."
urllib.parse.unwrap(url),"Extract the url from a wrapped URL (that is, a string formatted as
<URL:scheme://host/path>, <scheme://host/path>, URL:scheme://host/path
or scheme://host/path). If url is not a wrapped URL, it is returned
without changes."
"urllib.parse.quote(string, safe='/', encoding=None, errors=None)","Replace special characters in string using the %xx escape. Letters,
digits, and the characters '_.-~' are never quoted. By default, this
function is intended for quoting the path section of URL. The optional safe
parameter specifies additional ASCII characters that should not be quoted
— its default value is '/'.
string may be either a str or a bytes.

Changed in version 3.7: Moved from RFC 2396 to RFC 3986 for quoting URL strings. “~” is now
included in the set of unreserved characters.

The optional encoding and errors parameters specify how to deal with
non-ASCII characters, as accepted by the str.encode() method.
encoding defaults to 'utf-8'.
errors defaults to 'strict', meaning unsupported characters raise a
UnicodeEncodeError.
encoding and errors must not be supplied if string is a
bytes, or a TypeError is raised.
Note that quote(string, safe, encoding, errors) is equivalent to
quote_from_bytes(string.encode(encoding, errors), safe).
Example: quote('/El Niño/') yields '/El%20Ni%C3%B1o/'."
"urllib.parse.quote_plus(string, safe='', encoding=None, errors=None)","Like quote(), but also replace spaces by plus signs, as required for
quoting HTML form values when building up a query string to go into a URL.
Plus signs in the original string are escaped unless they are included in
safe.  It also does not have safe default to '/'.
Example: quote_plus('/El Niño/') yields '%2FEl+Ni%C3%B1o%2F'."
"urllib.parse.quote_from_bytes(bytes, safe='/')","Like quote(), but accepts a bytes object rather than a
str, and does not perform string-to-bytes encoding.
Example: quote_from_bytes(b'a&\xef') yields
'a%26%EF'."
"urllib.parse.unquote(string, encoding='utf-8', errors='replace')","Replace %xx escapes by their single-character equivalent.
The optional encoding and errors parameters specify how to decode
percent-encoded sequences into Unicode characters, as accepted by the
bytes.decode() method.
string must be a str.
encoding defaults to 'utf-8'.
errors defaults to 'replace', meaning invalid sequences are replaced
by a placeholder character.
Example: unquote('/El%20Ni%C3%B1o/') yields '/El Niño/'."
"urllib.parse.unquote_plus(string, encoding='utf-8', errors='replace')","Like unquote(), but also replace plus signs by spaces, as required for
unquoting HTML form values.
string must be a str.
Example: unquote_plus('/El+Ni%C3%B1o/') yields '/El Niño/'."
urllib.parse.unquote_to_bytes(string),"Replace %xx escapes by their single-octet equivalent, and return a
bytes object.
string may be either a str or a bytes.
If it is a str, unescaped non-ASCII characters in string
are encoded into UTF-8 bytes.
Example: unquote_to_bytes('a%26%EF') yields b'a&\xef'."
"urllib.parse.urlencode(query, doseq=False, safe='', encoding=None, errors=None, quote_via=quote_plus)","Convert a mapping object or a sequence of two-element tuples, which may
contain str or bytes objects, to a percent-encoded ASCII
text string.  If the resultant string is to be used as a data for POST
operation with the urlopen() function, then
it should be encoded to bytes, otherwise it would result in a
TypeError.
The resulting string is a series of key=value pairs separated by '&'
characters, where both key and value are quoted using the quote_via
function.  By default, quote_plus() is used to quote the values, which
means spaces are quoted as a '+' character and ‘/’ characters are
encoded as %2F, which follows the standard for GET requests
(application/x-www-form-urlencoded).  An alternate function that can be
passed as quote_via is quote(), which will encode spaces as %20
and not encode ‘/’ characters.  For maximum control of what is quoted, use
quote and specify a value for safe.
When a sequence of two-element tuples is used as the query
argument, the first element of each tuple is a key and the second is a
value. The value element in itself can be a sequence and in that case, if
the optional parameter doseq is evaluates to True, individual
key=value pairs separated by '&' are generated for each element of
the value sequence for the key.  The order of parameters in the encoded
string will match the order of parameter tuples in the sequence.
The safe, encoding, and errors parameters are passed down to
quote_via (the encoding and errors parameters are only passed
when a query element is a str).
To reverse this encoding process, parse_qs() and parse_qsl() are
provided in this module to parse query strings into Python data structures.
Refer to urllib examples to find out how urlencode
method can be used for generating query string for a URL or data for POST.

Changed in version 3.2: Query parameter supports bytes and string objects.


New in version 3.5: quote_via parameter."
urllib.parse.SplitResult.geturl(),"Return the re-combined version of the original URL as a string. This may
differ from the original URL in that the scheme may be normalized to lower
case and empty components may be dropped. Specifically, empty parameters,
queries, and fragment identifiers will be removed.
For urldefrag() results, only empty fragment identifiers will be removed.
For urlsplit() and urlparse() results, all noted changes will be
made to the URL returned by this method.
The result of this method remains unchanged if passed back through the original
parsing function:
>>> from urllib.parse import urlsplit
>>> url = 'HTTP://www.Python.org/doc/#'
>>> r1 = urlsplit(url)
>>> r1.geturl()
'http://www.Python.org/doc/'
>>> r2 = urlsplit(r1.geturl())
>>> r2.geturl()
'http://www.Python.org/doc/'"
set_url(url),Sets the URL referring to a robots.txt file.
read(),Reads the robots.txt URL and feeds it to the parser.
parse(lines),Parses the lines argument.
"can_fetch(useragent, url)","Returns True if the useragent is allowed to fetch the url
according to the rules contained in the parsed robots.txt
file."
mtime(),"Returns the time the robots.txt file was last fetched.  This is
useful for long-running web spiders that need to check for new
robots.txt files periodically."
modified(),"Sets the time the robots.txt file was last fetched to the current
time."
crawl_delay(useragent),"Returns the value of the Crawl-delay parameter from robots.txt
for the useragent in question.  If there is no such parameter or it
doesn’t apply to the useragent specified or the robots.txt entry
for this parameter has invalid syntax, return None.

New in version 3.6."
request_rate(useragent),"Returns the contents of the Request-rate parameter from
robots.txt as a named tuple RequestRate(requests, seconds).
If there is no such parameter or it doesn’t apply to the useragent
specified or the robots.txt entry for this parameter has invalid
syntax, return None.

New in version 3.6."
site_maps(),"Returns the contents of the Sitemap parameter from
robots.txt in the form of a list(). If there is no such
parameter or the robots.txt entry for this parameter has
invalid syntax, return None.

New in version 3.8."
http.client.parse_headers(fp),"Parse the headers from a file pointer fp representing a HTTP
request/response. The file has to be a BufferedIOBase reader
(i.e. not text) and must provide a valid RFC 2822 style header.
This function returns an instance of http.client.HTTPMessage
that holds the header fields, but no payload
(the same as HTTPResponse.msg
and http.server.BaseHTTPRequestHandler.headers).
After returning, the file pointer fp is ready to read the HTTP body.

Note
parse_headers() does not parse the start-line of a HTTP message;
it only parses the Name: value lines. The file has to be ready to
read these field lines, so the first line should already be consumed
before calling the function."
"HTTPConnection.request(method, url, body=None, headers={}, *, encode_chunked=False)","This will send a request to the server using the HTTP request
method method and the selector url.
If body is specified, the specified data is sent after the headers are
finished.  It may be a str, a bytes-like object, an
open file object, or an iterable of bytes.  If body
is a string, it is encoded as ISO-8859-1, the default for HTTP.  If it
is a bytes-like object, the bytes are sent as is.  If it is a file
object, the contents of the file is sent; this file object should
support at least the read() method.  If the file object is an
instance of io.TextIOBase, the data returned by the read()
method will be encoded as ISO-8859-1, otherwise the data returned by
read() is sent as is.  If body is an iterable, the elements of the
iterable are sent as is until the iterable is exhausted.
The headers argument should be a mapping of extra HTTP headers to send
with the request.
If headers contains neither Content-Length nor Transfer-Encoding,
but there is a request body, one of those
header fields will be added automatically.  If
body is None, the Content-Length header is set to 0 for
methods that expect a body (PUT, POST, and PATCH).  If
body is a string or a bytes-like object that is not also a
file, the Content-Length header is
set to its length.  Any other type of body (files
and iterables in general) will be chunk-encoded, and the
Transfer-Encoding header will automatically be set instead of
Content-Length.
The encode_chunked argument is only relevant if Transfer-Encoding is
specified in headers.  If encode_chunked is False, the
HTTPConnection object assumes that all encoding is handled by the
calling code.  If it is True, the body will be chunk-encoded.

Note
Chunked transfer encoding has been added to the HTTP protocol
version 1.1.  Unless the HTTP server is known to handle HTTP 1.1,
the caller must either specify the Content-Length, or must pass a
str or bytes-like object that is not also a file as the
body representation.


New in version 3.2: body can now be an iterable.


Changed in version 3.6: If neither Content-Length nor Transfer-Encoding are set in
headers, file and iterable body objects are now chunk-encoded.
The encode_chunked argument was added.
No attempt is made to determine the Content-Length for file
objects."
HTTPConnection.getresponse(),"Should be called after a request is sent to get the response from the server.
Returns an HTTPResponse instance.

Note
Note that you must have read the whole response before you can send a new
request to the server.


Changed in version 3.5: If a ConnectionError or subclass is raised, the
HTTPConnection object will be ready to reconnect when
a new request is sent."
HTTPConnection.set_debuglevel(level),"Set the debugging level.  The default debug level is 0, meaning no
debugging output is printed.  Any value greater than 0 will cause all
currently defined debug output to be printed to stdout.  The debuglevel
is passed to any new HTTPResponse objects that are created.

New in version 3.1."
"HTTPConnection.set_tunnel(host, port=None, headers=None)","Set the host and the port for HTTP Connect Tunnelling. This allows running
the connection through a proxy server.
The host and port arguments specify the endpoint of the tunneled connection
(i.e. the address included in the CONNECT request, not the address of the
proxy server).
The headers argument should be a mapping of extra HTTP headers to send with
the CONNECT request.
For example, to tunnel through a HTTPS proxy server running locally on port
8080, we would pass the address of the proxy to the HTTPSConnection
constructor, and the address of the host that we eventually want to reach to
the set_tunnel() method:
>>> import http.client
>>> conn = http.client.HTTPSConnection(""localhost"", 8080)
>>> conn.set_tunnel(""www.python.org"")
>>> conn.request(""HEAD"",""/index.html"")



New in version 3.2."
HTTPConnection.connect(),"Connect to the server specified when the object was created.  By default,
this is called automatically when making a request if the client does not
already have a connection."
HTTPConnection.close(),Close the connection to the server.
"HTTPConnection.putrequest(method, url, skip_host=False, skip_accept_encoding=False)","This should be the first call after the connection to the server has been
made. It sends a line to the server consisting of the method string,
the url string, and the HTTP version (HTTP/1.1).  To disable automatic
sending of Host: or Accept-Encoding: headers (for example to accept
additional content encodings), specify skip_host or skip_accept_encoding
with non-False values."
"HTTPConnection.putheader(header, argument[, ...])","Send an RFC 822-style header to the server.  It sends a line to the server
consisting of the header, a colon and a space, and the first argument.  If more
arguments are given, continuation lines are sent, each consisting of a tab and
an argument."
"HTTPConnection.endheaders(message_body=None, *, encode_chunked=False)","Send a blank line to the server, signalling the end of the headers. The
optional message_body argument can be used to pass a message body
associated with the request.
If encode_chunked is True, the result of each iteration of
message_body will be chunk-encoded as specified in RFC 7230,
Section 3.3.1.  How the data is encoded is dependent on the type of
message_body.  If message_body implements the buffer interface the encoding will result in a single chunk.
If message_body is a collections.abc.Iterable, each iteration
of message_body will result in a chunk.  If message_body is a
file object, each call to .read() will result in a chunk.
The method automatically signals the end of the chunk-encoded data
immediately after message_body.

Note
Due to the chunked encoding specification, empty chunks
yielded by an iterator body will be ignored by the chunk-encoder.
This is to avoid premature termination of the read of the request by
the target server due to malformed encoding.


New in version 3.6: Chunked encoding support.  The encode_chunked parameter was
added."
HTTPConnection.send(data),"Send data to the server.  This should be used directly only after the
endheaders() method has been called and before getresponse() is
called."
HTTPResponse.read([amt]),"Reads and returns the response body, or up to the next amt bytes."
HTTPResponse.readinto(b),"Reads up to the next len(b) bytes of the response body into the buffer b.
Returns the number of bytes read.

New in version 3.3."
"HTTPResponse.getheader(name, default=None)","Return the value of the header name, or default if there is no header
matching name.  If there is more than one  header with the name name,
return all of the values joined by ‘, ‘.  If ‘default’ is any iterable other
than a single string, its elements are similarly returned joined by commas."
HTTPResponse.getheaders(),"Return a list of (header, value) tuples."
HTTPResponse.fileno(),Return the fileno of the underlying socket.
FTP.set_debuglevel(level),"Set the instance’s debugging level.  This controls the amount of debugging
output printed.  The default, 0, produces no debugging output.  A value of
1 produces a moderate amount of debugging output, generally a single line
per request.  A value of 2 or higher produces the maximum amount of
debugging output, logging each line sent and received on the control connection."
"FTP.connect(host='', port=0, timeout=None, source_address=None)","Connect to the given host and port.  The default port number is 21, as
specified by the FTP protocol specification.  It is rarely needed to specify a
different port number.  This function should be called only once for each
instance; it should not be called at all if a host was given when the instance
was created.  All other methods can only be used after a connection has been
made.
The optional timeout parameter specifies a timeout in seconds for the
connection attempt. If no timeout is passed, the global default timeout
setting will be used.
source_address is a 2-tuple (host, port) for the socket to bind to as
its source address before connecting.
Raises an auditing event ftplib.connect with arguments self, host, port.

Changed in version 3.3: source_address parameter was added."
FTP.getwelcome(),"Return the welcome message sent by the server in reply to the initial
connection.  (This message sometimes contains disclaimers or help information
that may be relevant to the user.)"
"FTP.login(user='anonymous', passwd='', acct='')","Log in as the given user.  The passwd and acct parameters are optional and
default to the empty string.  If no user is specified, it defaults to
'anonymous'.  If user is 'anonymous', the default passwd is
'anonymous@'.  This function should be called only once for each instance,
after a connection has been established; it should not be called at all if a
host and user were given when the instance was created.  Most FTP commands are
only allowed after the client has logged in.  The acct parameter supplies
“accounting information”; few systems implement this."
FTP.abort(),"Abort a file transfer that is in progress.  Using this does not always work, but
it’s worth a try."
FTP.sendcmd(cmd),"Send a simple command string to the server and return the response string.
Raises an auditing event ftplib.sendcmd with arguments self, cmd."
FTP.voidcmd(cmd),"Send a simple command string to the server and handle the response.  Return
nothing if a response code corresponding to success (codes in the range
200–299) is received.  Raise error_reply otherwise.
Raises an auditing event ftplib.sendcmd with arguments self, cmd."
"FTP.retrbinary(cmd, callback, blocksize=8192, rest=None)","Retrieve a file in binary transfer mode.  cmd should be an appropriate
RETR command: 'RETR filename'. The callback function is called for
each block of data received, with a single bytes argument giving the data
block. The optional blocksize argument specifies the maximum chunk size to
read on the low-level socket object created to do the actual transfer (which
will also be the largest size of the data blocks passed to callback).  A
reasonable default is chosen. rest means the same thing as in the
transfercmd() method."
"FTP.retrlines(cmd, callback=None)","Retrieve a file or directory listing in ASCII transfer mode.  cmd should be
an appropriate RETR command (see retrbinary()) or a command such as
LIST or NLST (usually just the string 'LIST').
LIST retrieves a list of files and information about those files.
NLST retrieves a list of file names.
The callback function is called for each line with a string argument
containing the line with the trailing CRLF stripped.  The default callback
prints the line to sys.stdout."
FTP.set_pasv(val),"Enable “passive” mode if val is true, otherwise disable passive mode.
Passive mode is on by default."
"FTP.storbinary(cmd, fp, blocksize=8192, callback=None, rest=None)","Store a file in binary transfer mode.  cmd should be an appropriate
STOR command: ""STOR filename"". fp is a file object
(opened in binary mode) which is read until EOF using its read()
method in blocks of size blocksize to provide the data to be stored.
The blocksize argument defaults to 8192.  callback is an optional single
parameter callable that is called on each block of data after it is sent.
rest means the same thing as in the transfercmd() method.

Changed in version 3.2: rest parameter added."
"FTP.storlines(cmd, fp, callback=None)","Store a file in ASCII transfer mode.  cmd should be an appropriate
STOR command (see storbinary()).  Lines are read until EOF from the
file object fp (opened in binary mode) using its readline()
method to provide the data to be stored.  callback is an optional single
parameter callable that is called on each line after it is sent."
"FTP.transfercmd(cmd, rest=None)","Initiate a transfer over the data connection.  If the transfer is active, send an
EPRT or  PORT command and the transfer command specified by cmd, and
accept the connection.  If the server is passive, send an EPSV or PASV
command, connect to it, and start the transfer command.  Either way, return the
socket for the connection.
If optional rest is given, a REST command is sent to the server, passing
rest as an argument.  rest is usually a byte offset into the requested file,
telling the server to restart sending the file’s bytes at the requested offset,
skipping over the initial bytes.  Note however that RFC 959 requires only that
rest be a string containing characters in the printable range from ASCII code
33 to ASCII code 126.  The transfercmd() method, therefore, converts
rest to a string, but no check is performed on the string’s contents.  If the
server does not recognize the REST command, an error_reply exception
will be raised.  If this happens, simply call transfercmd() without a
rest argument."
"FTP.ntransfercmd(cmd, rest=None)","Like transfercmd(), but returns a tuple of the data connection and the
expected size of the data.  If the expected size could not be computed, None
will be returned as the expected size.  cmd and rest means the same thing as
in transfercmd()."
"FTP.mlsd(path="""", facts=[])","List a directory in a standardized format by using MLSD command
(RFC 3659).  If path is omitted the current directory is assumed.
facts is a list of strings representing the type of information desired
(e.g. [""type"", ""size"", ""perm""]).  Return a generator object yielding a
tuple of two elements for every file found in path.  First element is the
file name, the second one is a dictionary containing facts about the file
name.  Content of this dictionary might be limited by the facts argument
but server is not guaranteed to return all requested facts.

New in version 3.3."
"FTP.nlst(argument[, ...])","Return a list of file names as returned by the NLST command.  The
optional argument is a directory to list (default is the current server
directory).  Multiple arguments can be used to pass non-standard options to
the NLST command.

Note
If your server supports the command, mlsd() offers a better API."
"FTP.dir(argument[, ...])","Produce a directory listing as returned by the LIST command, printing it to
standard output.  The optional argument is a directory to list (default is the
current server directory).  Multiple arguments can be used to pass non-standard
options to the LIST command.  If the last argument is a function, it is used
as a callback function as for retrlines(); the default prints to
sys.stdout.  This method returns None.

Note
If your server supports the command, mlsd() offers a better API."
"FTP.rename(fromname, toname)",Rename file fromname on the server to toname.
FTP.delete(filename),"Remove the file named filename from the server.  If successful, returns the
text of the response, otherwise raises error_perm on permission errors or
error_reply on other errors."
FTP.cwd(pathname),Set the current directory on the server.
FTP.mkd(pathname),Create a new directory on the server.
FTP.pwd(),Return the pathname of the current directory on the server.
FTP.rmd(dirname),Remove the directory named dirname on the server.
FTP.size(filename),"Request the size of the file named filename on the server.  On success, the
size of the file is returned as an integer, otherwise None is returned.
Note that the SIZE command is not  standardized, but is supported by many
common server implementations."
FTP.quit(),"Send a QUIT command to the server and close the connection. This is the
“polite” way to close a connection, but it may raise an exception if the server
responds with an error to the QUIT command.  This implies a call to the
close() method which renders the FTP instance useless for
subsequent calls (see below)."
FTP.close(),"Close the connection unilaterally.  This should not be applied to an already
closed connection such as after a successful call to quit().
After this call the FTP instance should not be used any more (after
a call to close() or quit() you cannot reopen the
connection by issuing another login() method)."
FTP_TLS.auth(),"Set up a secure control connection by using TLS or SSL, depending on what
is specified in the ssl_version attribute.

Changed in version 3.4: The method now supports hostname check with
ssl.SSLContext.check_hostname and Server Name Indication (see
ssl.HAS_SNI)."
FTP_TLS.ccc(),"Revert control channel back to plaintext.  This can be useful to take
advantage of firewalls that know how to handle NAT with non-secure FTP
without opening fixed ports.

New in version 3.3."
FTP_TLS.prot_p(),Set up secure data connection.
FTP_TLS.prot_c(),Set up clear text data connection.
POP3.set_debuglevel(level),"Set the instance’s debugging level.  This controls the amount of debugging
output printed.  The default, 0, produces no debugging output.  A value of
1 produces a moderate amount of debugging output, generally a single line
per request.  A value of 2 or higher produces the maximum amount of
debugging output, logging each line sent and received on the control connection."
POP3.getwelcome(),Returns the greeting string sent by the POP3 server.
POP3.capa(),"Query the server’s capabilities as specified in RFC 2449.
Returns a dictionary in the form {'name': ['param'...]}.

New in version 3.4."
POP3.user(username),"Send user command, response should indicate that a password is required."
POP3.pass_(password),"Send password, response includes message count and mailbox size. Note: the
mailbox on the server is locked until quit() is called."
"POP3.apop(user, secret)",Use the more secure APOP authentication to log into the POP3 server.
POP3.rpop(user),Use RPOP authentication (similar to UNIX r-commands) to log into POP3 server.
POP3.stat(),"Get mailbox status.  The result is a tuple of 2 integers: (message count,
mailbox size)."
POP3.list([which]),"Request message list, result is in the form (response, ['mesg_num octets',
...], octets). If which is set, it is the message to list."
POP3.retr(which),"Retrieve whole message number which, and set its seen flag. Result is in form
(response, ['line', ...], octets)."
POP3.dele(which),"Flag message number which for deletion.  On most servers deletions are not
actually performed until QUIT (the major exception is Eudora QPOP, which
deliberately violates the RFCs by doing pending deletes on any disconnect)."
POP3.rset(),Remove any deletion marks for the mailbox.
POP3.noop(),Do nothing.  Might be used as a keep-alive.
POP3.quit(),"Signoff:  commit changes, unlock mailbox, drop connection."
"POP3.top(which, howmuch)","Retrieves the message header plus howmuch lines of the message after the
header of message number which. Result is in form (response, ['line', ...],
octets).
The POP3 TOP command this method uses, unlike the RETR command, doesn’t set the
message’s seen flag; unfortunately, TOP is poorly specified in the RFCs and is
frequently broken in off-brand servers. Test this method by hand against the
POP3 servers you will use before trusting it."
POP3.uidl(which=None),"Return message digest (unique id) list. If which is specified, result contains
the unique id for that message in the form 'response mesgnum uid, otherwise
result is list (response, ['mesgnum uid', ...], octets)."
POP3.utf8(),"Try to switch to UTF-8 mode. Returns the server response if successful,
raises error_proto if not. Specified in RFC 6856.

New in version 3.5."
POP3.stls(context=None),"Start a TLS session on the active connection as specified in RFC 2595.
This is only allowed before user authentication
context parameter is a ssl.SSLContext object which allows
bundling SSL configuration options, certificates and private keys into
a single (potentially long-lived) structure.  Please read Security considerations
for best practices.
This method supports hostname checking via
ssl.SSLContext.check_hostname and Server Name Indication (see
ssl.HAS_SNI).

New in version 3.4."
imaplib.Internaldate2tuple(datestr),"Parse an IMAP4 INTERNALDATE string and return corresponding local
time.  The return value is a time.struct_time tuple or
None if the string has wrong format."
imaplib.Int2AP(num),"Converts an integer into a string representation using characters from the set
[A .. P]."
imaplib.ParseFlags(flagstr),Converts an IMAP4 FLAGS response to a tuple of individual flags.
imaplib.Time2Internaldate(date_time),"Convert date_time to an IMAP4 INTERNALDATE representation.
The return value is a string in the form: ""DD-Mmm-YYYY HH:MM:SS
+HHMM"" (including double-quotes).  The date_time argument can
be a number (int or float) representing seconds since epoch (as
returned by time.time()), a 9-tuple representing local time
an instance of time.struct_time (as returned by
time.localtime()), an aware instance of
datetime.datetime, or a double-quoted string.  In the last
case, it is assumed to already be in the correct format."
"IMAP4.append(mailbox, flags, date_time, message)",Append message to named mailbox.
"IMAP4.authenticate(mechanism, authobject)","Authenticate command — requires response processing.
mechanism specifies which authentication mechanism is to be used - it should
appear in the instance variable capabilities in the form AUTH=mechanism.
authobject must be a callable object:
data = authobject(response)


It will be called to process server continuation responses; the response
argument it is passed will be bytes.  It should return bytes data
that will be base64 encoded and sent to the server.  It should return
None if the client abort response * should be sent instead.

Changed in version 3.5: string usernames and passwords are now encoded to utf-8 instead of
being limited to ASCII."
IMAP4.check(),Checkpoint mailbox on server.
IMAP4.close(),"Close currently selected mailbox. Deleted messages are removed from writable
mailbox. This is the recommended command before LOGOUT."
"IMAP4.copy(message_set, new_mailbox)",Copy message_set messages onto end of new_mailbox.
IMAP4.create(mailbox),Create new mailbox named mailbox.
IMAP4.delete(mailbox),Delete old mailbox named mailbox.
"IMAP4.deleteacl(mailbox, who)",Delete the ACLs (remove any rights) set for who on mailbox.
IMAP4.enable(capability),"Enable capability (see RFC 5161).  Most capabilities do not need to be
enabled.  Currently only the UTF8=ACCEPT capability is supported
(see RFC 6855).

New in version 3.5: The enable() method itself, and RFC 6855 support."
IMAP4.expunge(),"Permanently remove deleted items from selected mailbox. Generates an EXPUNGE
response for each deleted message. Returned data contains a list of EXPUNGE
message numbers in order received."
"IMAP4.fetch(message_set, message_parts)","Fetch (parts of) messages.  message_parts should be a string of message part
names enclosed within parentheses, eg: ""(UID BODY[TEXT])"".  Returned data
are tuples of message part envelope and data."
IMAP4.getacl(mailbox),"Get the ACLs for mailbox. The method is non-standard, but is supported
by the Cyrus server."
"IMAP4.getannotation(mailbox, entry, attribute)","Retrieve the specified ANNOTATIONs for mailbox. The method is
non-standard, but is supported by the Cyrus server."
IMAP4.getquota(root),"Get the quota root’s resource usage and limits. This method is part of the
IMAP4 QUOTA extension defined in rfc2087."
IMAP4.getquotaroot(mailbox),"Get the list of quota roots for the named mailbox. This method is part
of the IMAP4 QUOTA extension defined in rfc2087."
"IMAP4.list([directory[, pattern]])","List mailbox names in directory matching pattern.  directory defaults to
the top-level mail folder, and pattern defaults to match anything.  Returned
data contains a list of LIST responses."
"IMAP4.login(user, password)",Identify the client using a plaintext password. The password will be quoted.
"IMAP4.login_cram_md5(user, password)","Force use of CRAM-MD5 authentication when identifying the client to protect
the password.  Will only work if the server CAPABILITY response includes the
phrase AUTH=CRAM-MD5."
IMAP4.logout(),"Shutdown connection to server. Returns server BYE response.

Changed in version 3.8: The method no longer ignores silently arbitrary exceptions."
"IMAP4.lsub(directory='""""', pattern='*')","List subscribed mailbox names in directory matching pattern. directory
defaults to the top level directory and pattern defaults to match any mailbox.
Returned data are tuples of message part envelope and data."
IMAP4.myrights(mailbox),Show my ACLs for a mailbox (i.e. the rights that I have on mailbox).
IMAP4.namespace(),Returns IMAP namespaces as defined in RFC 2342.
IMAP4.noop(),Send NOOP to server.
"IMAP4.open(host, port)","Opens socket to port at host.  This method is implicitly called by
the IMAP4 constructor.  The connection objects established by this
method will be used in the IMAP4.read(), IMAP4.readline(),
IMAP4.send(), and IMAP4.shutdown() methods.  You may override
this method.
Raises an auditing event imaplib.open with arguments self, host, port."
"IMAP4.partial(message_num, message_part, start, length)","Fetch truncated part of a message. Returned data is a tuple of message part
envelope and data."
IMAP4.proxyauth(user),"Assume authentication as user. Allows an authorised administrator to proxy
into any user’s mailbox."
IMAP4.read(size),Reads size bytes from the remote server. You may override this method.
IMAP4.readline(),Reads one line from the remote server. You may override this method.
IMAP4.recent(),"Prompt server for an update. Returned data is None if no new messages, else
value of RECENT response."
"IMAP4.rename(oldmailbox, newmailbox)",Rename mailbox named oldmailbox to newmailbox.
IMAP4.response(code),"Return data for response code if received, or None. Returns the given
code, instead of the usual type."
"IMAP4.search(charset, criterion[, ...])","Search mailbox for matching messages.  charset may be None, in which case
no CHARSET will be specified in the request to the server.  The IMAP
protocol requires that at least one criterion be specified; an exception will be
raised when the server returns an error.  charset must be None if
the UTF8=ACCEPT capability was enabled using the enable()
command.
Example:
# M is a connected IMAP4 instance...
typ, msgnums = M.search(None, 'FROM', '""LDJ""')

# or:
typ, msgnums = M.search(None, '(FROM ""LDJ"")')"
"IMAP4.select(mailbox='INBOX', readonly=False)","Select a mailbox. Returned data is the count of messages in mailbox
(EXISTS response).  The default mailbox is 'INBOX'.  If the readonly
flag is set, modifications to the mailbox are not allowed."
IMAP4.send(data),"Sends data to the remote server. You may override this method.
Raises an auditing event imaplib.send with arguments self, data."
"IMAP4.setacl(mailbox, who, what)","Set an ACL for mailbox. The method is non-standard, but is supported by
the Cyrus server."
"IMAP4.setannotation(mailbox, entry, attribute[, ...])","Set ANNOTATIONs for mailbox. The method is non-standard, but is
supported by the Cyrus server."
"IMAP4.setquota(root, limits)","Set the quota root’s resource limits. This method is part of the IMAP4
QUOTA extension defined in rfc2087."
IMAP4.shutdown(),"Close connection established in open.  This method is implicitly
called by IMAP4.logout().  You may override this method."
IMAP4.socket(),Returns socket instance used to connect to server.
"IMAP4.sort(sort_criteria, charset, search_criterion[, ...])","The sort command is a variant of search with sorting semantics for the
results.  Returned data contains a space separated list of matching message
numbers.
Sort has two arguments before the search_criterion argument(s); a
parenthesized list of sort_criteria, and the searching charset.  Note that
unlike search, the searching charset argument is mandatory.  There is also
a uid sort command which corresponds to sort the way that uid search
corresponds to search.  The sort command first searches the mailbox for
messages that match the given searching criteria using the charset argument for
the interpretation of strings in the searching criteria.  It then returns the
numbers of matching messages.
This is an IMAP4rev1 extension command."
IMAP4.starttls(ssl_context=None),"Send a STARTTLS command.  The ssl_context argument is optional
and should be a ssl.SSLContext object.  This will enable
encryption on the IMAP connection.  Please read Security considerations for
best practices.

New in version 3.2.


Changed in version 3.4: The method now supports hostname check with
ssl.SSLContext.check_hostname and Server Name Indication (see
ssl.HAS_SNI)."
"IMAP4.status(mailbox, names)",Request named status conditions for mailbox.
"IMAP4.store(message_set, command, flag_list)","Alters flag dispositions for messages in mailbox.  command is specified by
section 6.4.6 of RFC 2060 as being one of “FLAGS”, “+FLAGS”, or “-FLAGS”,
optionally with a suffix of “.SILENT”.
For example, to set the delete flag on all messages:
typ, data = M.search(None, 'ALL')
for num in data[0].split():
   M.store(num, '+FLAGS', '\\Deleted')
M.expunge()



Note
Creating flags containing ‘]’ (for example: “[test]”) violates
RFC 3501 (the IMAP protocol).  However, imaplib has historically
allowed creation of such tags, and popular IMAP servers, such as Gmail,
accept and produce such flags.  There are non-Python programs which also
create such tags.  Although it is an RFC violation and IMAP clients and
servers are supposed to be strict, imaplib nonetheless continues to allow
such tags to be created for backward compatibility reasons, and as of
Python 3.6, handles them if they are sent from the server, since this
improves real-world compatibility."
IMAP4.subscribe(mailbox),Subscribe to new mailbox.
"IMAP4.thread(threading_algorithm, charset, search_criterion[, ...])","The thread command is a variant of search with threading semantics for
the results.  Returned data contains a space separated list of thread members.
Thread members consist of zero or more messages numbers, delimited by spaces,
indicating successive parent and child.
Thread has two arguments before the search_criterion argument(s); a
threading_algorithm, and the searching charset.  Note that unlike
search, the searching charset argument is mandatory.  There is also a
uid thread command which corresponds to thread the way that uid
search corresponds to search.  The thread command first searches the
mailbox for messages that match the given searching criteria using the charset
argument for the interpretation of strings in the searching criteria. It then
returns the matching messages threaded according to the specified threading
algorithm.
This is an IMAP4rev1 extension command."
"IMAP4.uid(command, arg[, ...])","Execute command args with messages identified by UID, rather than message
number.  Returns response appropriate to command.  At least one argument must be
supplied; if none are provided, the server will return an error and an exception
will be raised."
IMAP4.unsubscribe(mailbox),Unsubscribe from old mailbox.
"IMAP4.xatom(name[, ...])",Allow simple extension commands notified by server in CAPABILITY response.
nntplib.decode_header(header_str),"Decode a header value, un-escaping any escaped non-ASCII characters.
header_str must be a str object.  The unescaped value is
returned.  Using this function is recommended to display some headers
in a human readable form:
>>> decode_header(""Some subject"")
'Some subject'
>>> decode_header(""=?ISO-8859-15?Q?D=E9buter_en_Python?="")
'Débuter en Python'
>>> decode_header(""Re: =?UTF-8?B?cHJvYmzDqG1lIGRlIG1hdHJpY2U=?="")
'Re: problème de matrice'"
NNTP.quit(),"Send a QUIT command and close the connection.  Once this method has been
called, no other methods of the NNTP object should be called."
NNTP.getwelcome(),"Return the welcome message sent by the server in reply to the initial
connection.  (This message sometimes contains disclaimers or help information
that may be relevant to the user.)"
NNTP.getcapabilities(),"Return the RFC 3977 capabilities advertised by the server, as a
dict instance mapping capability names to (possibly empty) lists
of values. On legacy servers which don’t understand the CAPABILITIES
command, an empty dictionary is returned instead.
>>> s = NNTP('news.gmane.io')
>>> 'POST' in s.getcapabilities()
True



New in version 3.2."
"NNTP.login(user=None, password=None, usenetrc=True)","Send AUTHINFO commands with the user name and password.  If user
and password are None and usenetrc is true, credentials from
~/.netrc will be used if possible.
Unless intentionally delayed, login is normally performed during the
NNTP object initialization and separately calling this function
is unnecessary.  To force authentication to be delayed, you must not set
user or password when creating the object, and must set usenetrc to
False.

New in version 3.2."
NNTP.starttls(context=None),"Send a STARTTLS command.  This will enable encryption on the NNTP
connection.  The context argument is optional and should be a
ssl.SSLContext object.  Please read Security considerations for best
practices.
Note that this may not be done after authentication information has
been transmitted, and authentication occurs by default if possible during a
NNTP object initialization.  See NNTP.login() for information
on suppressing this behavior.

New in version 3.2.


Changed in version 3.4: The method now supports hostname check with
ssl.SSLContext.check_hostname and Server Name Indication (see
ssl.HAS_SNI)."
"NNTP.newgroups(date, *, file=None)","Send a NEWGROUPS command.  The date argument should be a
datetime.date or datetime.datetime object.
Return a pair (response, groups) where groups is a list representing
the groups that are new since the given date. If file is supplied,
though, then groups will be empty.
>>> from datetime import date, timedelta
>>> resp, groups = s.newgroups(date.today() - timedelta(days=3))
>>> len(groups) 
85
>>> groups[0] 
GroupInfo(group='gmane.network.tor.devel', last='4', first='1', flag='m')"
"NNTP.newnews(group, date, *, file=None)","Send a NEWNEWS command.  Here, group is a group name or '*', and
date has the same meaning as for newgroups().  Return a pair
(response, articles) where articles is a list of message ids.
This command is frequently disabled by NNTP server administrators."
"NNTP.list(group_pattern=None, *, file=None)","Send a LIST or LIST ACTIVE command.  Return a pair
(response, list) where list is a list of tuples representing all
the groups available from this NNTP server, optionally matching the
pattern string group_pattern.  Each tuple has the form
(group, last, first, flag), where group is a group name, last
and first are the last and first article numbers, and flag usually
takes one of these values:

y: Local postings and articles from peers are allowed.
m: The group is moderated and all postings must be approved.
n: No local postings are allowed, only articles from peers.
j: Articles from peers are filed in the junk group instead.
x: No local postings, and articles from peers are ignored.
=foo.bar: Articles are filed in the foo.bar group instead.

If flag has another value, then the status of the newsgroup should be
considered unknown.
This command can return very large results, especially if group_pattern
is not specified.  It is best to cache the results offline unless you
really need to refresh them.

Changed in version 3.2: group_pattern was added."
NNTP.descriptions(grouppattern),"Send a LIST NEWSGROUPS command, where grouppattern is a wildmat string as
specified in RFC 3977 (it’s essentially the same as DOS or UNIX shell wildcard
strings).  Return a pair (response, descriptions), where descriptions
is a dictionary mapping group names to textual descriptions.
>>> resp, descs = s.descriptions('gmane.comp.python.*')
>>> len(descs) 
295
>>> descs.popitem() 
('gmane.comp.python.bio.general', 'BioPython discussion list (Moderated)')"
NNTP.description(group),"Get a description for a single group group.  If more than one group matches
(if ‘group’ is a real wildmat string), return the first match.   If no group
matches, return an empty string.
This elides the response code from the server.  If the response code is needed,
use descriptions()."
NNTP.group(name),"Send a GROUP command, where name is the group name.  The group is
selected as the current group, if it exists.  Return a tuple
(response, count, first, last, name) where count is the (estimated)
number of articles in the group, first is the first article number in
the group, last is the last article number in the group, and name
is the group name."
"NNTP.over(message_spec, *, file=None)","Send an OVER command, or an XOVER command on legacy servers.
message_spec can be either a string representing a message id, or
a (first, last) tuple of numbers indicating a range of articles in
the current group, or a (first, None) tuple indicating a range of
articles starting from first to the last article in the current group,
or None to select the current article in the current group.
Return a pair (response, overviews).  overviews is a list of
(article_number, overview) tuples, one for each article selected
by message_spec.  Each overview is a dictionary with the same number
of items, but this number depends on the server.  These items are either
message headers (the key is then the lower-cased header name) or metadata
items (the key is then the metadata name prepended with "":"").  The
following items are guaranteed to be present by the NNTP specification:

the subject, from, date, message-id and references
headers
the :bytes metadata: the number of bytes in the entire raw article
(including headers and body)
the :lines metadata: the number of lines in the article body

The value of each item is either a string, or None if not present.
It is advisable to use the decode_header() function on header
values when they may contain non-ASCII characters:
>>> _, _, first, last, _ = s.group('gmane.comp.python.devel')
>>> resp, overviews = s.over((last, last))
>>> art_num, over = overviews[0]
>>> art_num
117216
>>> list(over.keys())
['xref', 'from', ':lines', ':bytes', 'references', 'date', 'message-id', 'subject']
>>> over['from']
'=?UTF-8?B?Ik1hcnRpbiB2LiBMw7Z3aXMi?= <martin@v.loewis.de>'
>>> nntplib.decode_header(over['from'])
'""Martin v. Löwis"" <martin@v.loewis.de>'



New in version 3.2."
"NNTP.help(*, file=None)","Send a HELP command.  Return a pair (response, list) where list is a
list of help strings."
NNTP.stat(message_spec=None),"Send a STAT command, where message_spec is either a message id
(enclosed in '<' and '>') or an article number in the current group.
If message_spec is omitted or None, the current article in the
current group is considered.  Return a triple (response, number, id)
where number is the article number and id is the message id.
>>> _, _, first, last, _ = s.group('gmane.comp.python.devel')
>>> resp, number, message_id = s.stat(first)
>>> number, message_id
(9099, '<20030112190404.GE29873@epoch.metaslash.com>')"
NNTP.next(),Send a NEXT command.  Return as for stat().
NNTP.last(),Send a LAST command.  Return as for stat().
"NNTP.article(message_spec=None, *, file=None)","Send an ARTICLE command, where message_spec has the same meaning as
for stat().  Return a tuple (response, info) where info
is a namedtuple with three attributes number,
message_id and lines (in that order).  number is the article number
in the group (or 0 if the information is not available), message_id the
message id as a string, and lines a list of lines (without terminating
newlines) comprising the raw message including headers and body.
>>> resp, info = s.article('<20030112190404.GE29873@epoch.metaslash.com>')
>>> info.number
0
>>> info.message_id
'<20030112190404.GE29873@epoch.metaslash.com>'
>>> len(info.lines)
65
>>> info.lines[0]
b'Path: main.gmane.org!not-for-mail'
>>> info.lines[1]
b'From: Neal Norwitz <neal@metaslash.com>'
>>> info.lines[-3:]
[b'There is a patch for 2.3 as well as 2.2.', b'', b'Neal']"
"NNTP.head(message_spec=None, *, file=None)","Same as article(), but sends a HEAD command.  The lines
returned (or written to file) will only contain the message headers, not
the body."
"NNTP.body(message_spec=None, *, file=None)","Same as article(), but sends a BODY command.  The lines
returned (or written to file) will only contain the message body, not the
headers."
NNTP.post(data),"Post an article using the POST command.  The data argument is either
a file object opened for binary reading, or any iterable of bytes
objects (representing raw lines of the article to be posted).  It should
represent a well-formed news article, including the required headers.  The
post() method automatically escapes lines beginning with . and
appends the termination line.
If the method succeeds, the server’s response is returned.  If the server
refuses posting, a NNTPReplyError is raised."
"NNTP.ihave(message_id, data)","Send an IHAVE command. message_id is the id of the message to send
to the server (enclosed in  '<' and '>').  The data parameter
and the return value are the same as for post()."
NNTP.date(),"Return a pair (response, date).  date is a datetime
object containing the current date and time of the server."
NNTP.slave(),Send a SLAVE command.  Return the server’s response.
NNTP.set_debuglevel(level),"Set the instance’s debugging level.  This controls the amount of debugging
output printed.  The default, 0, produces no debugging output.  A value of
1 produces a moderate amount of debugging output, generally a single line
per request or response.  A value of 2 or higher produces the maximum amount
of debugging output, logging each line sent and received on the connection
(including message text)."
"NNTP.xhdr(hdr, str, *, file=None)","Send an XHDR command.  The hdr argument is a header keyword, e.g.
'subject'.  The str argument should have the form 'first-last'
where first and last are the first and last article numbers to search.
Return a pair (response, list), where list is a list of pairs (id,
text), where id is an article number (as a string) and text is the text of
the requested header for that article. If the file parameter is supplied, then
the output of the  XHDR command is stored in a file.  If file is a string,
then the method will open a file with that name, write to it  then close it.
If file is a file object, then it will start calling write() on
it to store the lines of the command output. If file is supplied, then the
returned list is an empty list."
"NNTP.xover(start, end, *, file=None)","Send an XOVER command.  start and end are article numbers
delimiting the range of articles to select.  The return value is the
same of for over().  It is recommended to use over()
instead, since it will automatically use the newer OVER command
if available."
NNTP.xpath(id),"Return a pair (resp, path), where path is the directory path to the
article with message ID id.  Most of the time, this extension is not
enabled by NNTP server administrators.

Deprecated since version 3.3: The XPATH extension is not actively used."
SMTP.set_debuglevel(level),"Set the debug output level.  A value of 1 or True for level results in
debug messages for connection and for all messages sent to and received from
the server.  A value of 2 for level results in these messages being
timestamped.

Changed in version 3.5: Added debuglevel 2."
"SMTP.docmd(cmd, args='')","Send a command cmd to the server.  The optional argument args is simply
concatenated to the command, separated by a space.
This returns a 2-tuple composed of a numeric response code and the actual
response line (multiline responses are joined into one long line.)
In normal operation it should not be necessary to call this method explicitly.
It is used to implement other methods and may be useful for testing private
extensions.
If the connection to the server is lost while waiting for the reply,
SMTPServerDisconnected will be raised."
"SMTP.connect(host='localhost', port=0)","Connect to a host on a given port.  The defaults are to connect to the local
host at the standard SMTP port (25). If the hostname ends with a colon (':')
followed by a number, that suffix will be stripped off and the number
interpreted as the port number to use. This method is automatically invoked by
the constructor if a host is specified during instantiation.  Returns a
2-tuple of the response code and message sent by the server in its
connection response.
Raises an auditing event smtplib.connect with arguments self, host, port."
SMTP.helo(name=''),"Identify yourself to the SMTP server using HELO.  The hostname argument
defaults to the fully qualified domain name of the local host.
The message returned by the server is stored as the helo_resp attribute
of the object.
In normal operation it should not be necessary to call this method explicitly.
It will be implicitly called by the sendmail() when necessary."
SMTP.ehlo(name=''),"Identify yourself to an ESMTP server using EHLO.  The hostname argument
defaults to the fully qualified domain name of the local host.  Examine the
response for ESMTP option and store them for use by has_extn().
Also sets several informational attributes: the message returned by
the server is stored as the ehlo_resp attribute, does_esmtp
is set to true or false depending on whether the server supports ESMTP, and
esmtp_features will be a dictionary containing the names of the
SMTP service extensions this server supports, and their parameters (if any).
Unless you wish to use has_extn() before sending mail, it should not be
necessary to call this method explicitly.  It will be implicitly called by
sendmail() when necessary."
SMTP.ehlo_or_helo_if_needed(),"This method calls ehlo() and/or helo() if there has been no
previous EHLO or HELO command this session.  It tries ESMTP EHLO
first.

SMTPHeloErrorThe server didn’t reply properly to the HELO greeting."
SMTP.has_extn(name),"Return True if name is in the set of SMTP service extensions returned
by the server, False otherwise. Case is ignored."
SMTP.verify(address),"Check the validity of an address on this server using SMTP VRFY. Returns a
tuple consisting of code 250 and a full RFC 822 address (including human
name) if the user address is valid. Otherwise returns an SMTP error code of 400
or greater and an error string.

Note
Many sites disable SMTP VRFY in order to foil spammers."
"SMTP.login(user, password, *, initial_response_ok=True)","Log in on an SMTP server that requires authentication. The arguments are the
username and the password to authenticate with. If there has been no previous
EHLO or HELO command this session, this method tries ESMTP EHLO
first. This method will return normally if the authentication was successful, or
may raise the following exceptions:

SMTPHeloErrorThe server didn’t reply properly to the HELO greeting.

SMTPAuthenticationErrorThe server didn’t accept the username/password combination.

SMTPNotSupportedErrorThe AUTH command is not supported by the server.

SMTPExceptionNo suitable authentication method was found.


Each of the authentication methods supported by smtplib are tried in
turn if they are advertised as supported by the server.  See auth()
for a list of supported authentication methods.  initial_response_ok is
passed through to auth().
Optional keyword argument initial_response_ok specifies whether, for
authentication methods that support it, an “initial response” as specified
in RFC 4954 can be sent along with the AUTH command, rather than
requiring a challenge/response.

Changed in version 3.5: SMTPNotSupportedError may be raised, and the
initial_response_ok parameter was added."
"SMTP.auth(mechanism, authobject, *, initial_response_ok=True)","Issue an SMTP AUTH command for the specified authentication
mechanism, and handle the challenge response via authobject.
mechanism specifies which authentication mechanism is to
be used as argument to the AUTH command; the valid values are
those listed in the auth element of esmtp_features.
authobject must be a callable object taking an optional single argument:

data = authobject(challenge=None)

If optional keyword argument initial_response_ok is true,
authobject() will be called first with no argument.  It can return the
RFC 4954 “initial response” ASCII str which will be encoded and sent with
the AUTH command as below.  If the authobject() does not support an
initial response (e.g. because it requires a challenge), it should return
None when called with challenge=None.  If initial_response_ok is
false, then authobject() will not be called first with None.
If the initial response check returns None, or if initial_response_ok is
false, authobject() will be called to process the server’s challenge
response; the challenge argument it is passed will be a bytes.  It
should return ASCII str data that will be base64 encoded and sent to the
server.
The SMTP class provides authobjects for the CRAM-MD5, PLAIN,
and LOGIN mechanisms; they are named SMTP.auth_cram_md5,
SMTP.auth_plain, and SMTP.auth_login respectively.  They all require
that the user and password properties of the SMTP instance are
set to appropriate values.
User code does not normally need to call auth directly, but can instead
call the login() method, which will try each of the above mechanisms
in turn, in the order listed.  auth is exposed to facilitate the
implementation of authentication methods not (or not yet) supported
directly by smtplib.

New in version 3.5."
"SMTP.starttls(keyfile=None, certfile=None, context=None)","Put the SMTP connection in TLS (Transport Layer Security) mode.  All SMTP
commands that follow will be encrypted.  You should then call ehlo()
again.
If keyfile and certfile are provided, they are used to create an
ssl.SSLContext.
Optional context parameter is an ssl.SSLContext object; This is
an alternative to using a keyfile and a certfile and if specified both
keyfile and certfile should be None.
If there has been no previous EHLO or HELO command this session,
this method tries ESMTP EHLO first.

Deprecated since version 3.6: keyfile and certfile are deprecated in favor of context.
Please use ssl.SSLContext.load_cert_chain() instead, or let
ssl.create_default_context() select the system’s trusted CA
certificates for you.


SMTPHeloErrorThe server didn’t reply properly to the HELO greeting.

SMTPNotSupportedErrorThe server does not support the STARTTLS extension.

RuntimeErrorSSL/TLS support is not available to your Python interpreter.



Changed in version 3.3: context was added.


Changed in version 3.4: The method now supports hostname check with
SSLContext.check_hostname and Server Name Indicator (see
HAS_SNI).


Changed in version 3.5: The error raised for lack of STARTTLS support is now the
SMTPNotSupportedError subclass instead of the base
SMTPException."
"SMTP.sendmail(from_addr, to_addrs, msg, mail_options=(), rcpt_options=())","Send mail.  The required arguments are an RFC 822 from-address string, a list
of RFC 822 to-address strings (a bare string will be treated as a list with 1
address), and a message string.  The caller may pass a list of ESMTP options
(such as 8bitmime) to be used in MAIL FROM commands as mail_options.
ESMTP options (such as DSN commands) that should be used with all RCPT
commands can be passed as rcpt_options.  (If you need to use different ESMTP
options to different recipients you have to use the low-level methods such as
mail(), rcpt() and data() to send the message.)

Note
The from_addr and to_addrs parameters are used to construct the message
envelope used by the transport agents.  sendmail does not modify the
message headers in any way.

msg may be a string containing characters in the ASCII range, or a byte
string.  A string is encoded to bytes using the ascii codec, and lone \r
and \n characters are converted to \r\n characters.  A byte string is
not modified.
If there has been no previous EHLO or HELO command this session, this
method tries ESMTP EHLO first. If the server does ESMTP, message size and
each of the specified options will be passed to it (if the option is in the
feature set the server advertises).  If EHLO fails, HELO will be tried
and ESMTP options suppressed.
This method will return normally if the mail is accepted for at least one
recipient. Otherwise it will raise an exception.  That is, if this method does
not raise an exception, then someone should get your mail. If this method does
not raise an exception, it returns a dictionary, with one entry for each
recipient that was refused.  Each entry contains a tuple of the SMTP error code
and the accompanying error message sent by the server.
If SMTPUTF8 is included in mail_options, and the server supports it,
from_addr and to_addrs may contain non-ASCII characters.
This method may raise the following exceptions:

SMTPRecipientsRefusedAll recipients were refused.  Nobody got the mail.  The recipients
attribute of the exception object is a dictionary with information about the
refused recipients (like the one returned when at least one recipient was
accepted).

SMTPHeloErrorThe server didn’t reply properly to the HELO greeting.

SMTPSenderRefusedThe server didn’t accept the from_addr.

SMTPDataErrorThe server replied with an unexpected error code (other than a refusal of a
recipient).

SMTPNotSupportedErrorSMTPUTF8 was given in the mail_options but is not supported by the
server.


Unless otherwise noted, the connection will be open even after an exception is
raised.

Changed in version 3.2: msg may be a byte string.


Changed in version 3.5: SMTPUTF8 support added, and SMTPNotSupportedError may be
raised if SMTPUTF8 is specified but the server does not support it."
"SMTP.send_message(msg, from_addr=None, to_addrs=None, mail_options=(), rcpt_options=())","This is a convenience method for calling sendmail() with the message
represented by an email.message.Message object.  The arguments have
the same meaning as for sendmail(), except that msg is a Message
object.
If from_addr is None or to_addrs is None, send_message fills
those arguments with addresses extracted from the headers of msg as
specified in RFC 5322: from_addr is set to the Sender
field if it is present, and otherwise to the From field.
to_addrs combines the values (if any) of the To,
Cc, and Bcc fields from msg.  If exactly one
set of Resent-* headers appear in the message, the regular
headers are ignored and the Resent-* headers are used instead.
If the message contains more than one set of Resent-* headers,
a ValueError is raised, since there is no way to unambiguously detect
the most recent set of Resent- headers.
send_message serializes msg using
BytesGenerator with \r\n as the linesep, and
calls sendmail() to transmit the resulting message.  Regardless of the
values of from_addr and to_addrs, send_message does not transmit any
Bcc or Resent-Bcc headers that may appear
in msg.  If any of the addresses in from_addr and to_addrs contain
non-ASCII characters and the server does not advertise SMTPUTF8 support,
an SMTPNotSupported error is raised.  Otherwise the Message is
serialized with a clone of its policy with the
utf8 attribute set to True, and
SMTPUTF8 and BODY=8BITMIME are added to mail_options.

New in version 3.2.


New in version 3.5: Support for internationalized addresses (SMTPUTF8)."
SMTP.quit(),"Terminate the SMTP session and close the connection.  Return the result of
the SMTP QUIT command."
"process_message(peer, mailfrom, rcpttos, data, **kwargs)","Raise a NotImplementedError exception. Override this in subclasses to
do something useful with this message. Whatever was passed in the
constructor as remoteaddr will be available as the _remoteaddr
attribute. peer is the remote host’s address, mailfrom is the envelope
originator, rcpttos are the envelope recipients and data is a string
containing the contents of the e-mail (which should be in RFC 5321
format).
If the decode_data constructor keyword is set to True, the data
argument will be a unicode string.  If it is set to False, it
will be a bytes object.
kwargs is a dictionary containing additional information. It is empty
if decode_data=True was given as an init argument, otherwise
it contains the following keys:


mail_options:a list of all received parameters to the MAIL
command (the elements are uppercase strings; example:
['BODY=8BITMIME', 'SMTPUTF8']).

rcpt_options:same as mail_options but for the RCPT command.
Currently no RCPT TO options are supported, so for now
this will always be an empty list.



Implementations of process_message should use the **kwargs
signature to accept arbitrary keyword arguments, since future feature
enhancements may add keys to the kwargs dictionary.
Return None to request a normal 250 Ok response; otherwise
return the desired response string in RFC 5321 format."
"Telnet.read_until(expected, timeout=None)","Read until a given byte string, expected, is encountered or until timeout
seconds have passed.
When no match is found, return whatever is available instead, possibly empty
bytes.  Raise EOFError if the connection is closed and no cooked data
is available."
Telnet.read_all(),Read all data until EOF as bytes; block until connection closed.
Telnet.read_some(),"Read at least one byte of cooked data unless EOF is hit. Return b'' if
EOF is hit.  Block if no data is immediately available."
Telnet.read_very_eager(),"Read everything that can be without blocking in I/O (eager).
Raise EOFError if connection closed and no cooked data available.
Return b'' if no cooked data available otherwise. Do not block unless in
the midst of an IAC sequence."
Telnet.read_eager(),"Read readily available data.
Raise EOFError if connection closed and no cooked data available.
Return b'' if no cooked data available otherwise. Do not block unless in
the midst of an IAC sequence."
Telnet.read_lazy(),"Process and return data already in the queues (lazy).
Raise EOFError if connection closed and no data available. Return
b'' if no cooked data available otherwise.  Do not block unless in the
midst of an IAC sequence."
Telnet.read_very_lazy(),"Return any data available in the cooked queue (very lazy).
Raise EOFError if connection closed and no data available. Return
b'' if no cooked data available otherwise.  This method never blocks."
Telnet.read_sb_data(),"Return the data collected between a SB/SE pair (suboption begin/end). The
callback should access these data when it was invoked with a SE command.
This method never blocks."
"Telnet.open(host, port=0[, timeout])","Connect to a host. The optional second argument is the port number, which
defaults to the standard Telnet port (23). The optional timeout parameter
specifies a timeout in seconds for blocking operations like the connection
attempt (if not specified, the global default timeout setting will be used).
Do not try to reopen an already connected instance.
Raises an auditing event telnetlib.Telnet.open with arguments self, host, port."
"Telnet.msg(msg, *args)","Print a debug message when the debug level is > 0. If extra arguments are
present, they are substituted in the message using the standard string
formatting operator."
Telnet.set_debuglevel(debuglevel),"Set the debug level.  The higher the value of debuglevel, the more debug
output you get (on sys.stdout)."
Telnet.close(),Close the connection.
Telnet.get_socket(),Return the socket object used internally.
Telnet.fileno(),Return the file descriptor of the socket object used internally.
Telnet.write(buffer),"Write a byte string to the socket, doubling any IAC characters. This can
block if the connection is blocked.  May raise OSError if the
connection is closed.
Raises an auditing event telnetlib.Telnet.write with arguments self, buffer.

Changed in version 3.3: This method used to raise socket.error, which is now an alias
of OSError."
Telnet.interact(),"Interaction function, emulates a very dumb Telnet client."
Telnet.mt_interact(),Multithreaded version of interact().
"Telnet.expect(list, timeout=None)","Read until one from a list of a regular expressions matches.
The first argument is a list of regular expressions, either compiled
(regex objects) or uncompiled (byte strings). The
optional second argument is a timeout, in seconds; the default is to block
indefinitely.
Return a tuple of three items: the index in the list of the first regular
expression that matches; the match object returned; and the bytes read up
till and including the match.
If end of file is found and no bytes were read, raise EOFError.
Otherwise, when nothing matches, return (-1, None, data) where data is
the bytes received so far (may be empty bytes if a timeout happened).
If a regular expression ends with a greedy match (such as .*) or if more
than one expression can match the same input, the results are
non-deterministic, and may depend on the I/O timing."
Telnet.set_option_negotiation_callback(callback),"Each time a telnet option is read on the input flow, this callback (if set) is
called with the following parameters: callback(telnet socket, command
(DO/DONT/WILL/WONT), option).  No other action is done afterwards by telnetlib."
uuid.getnode(),"Get the hardware address as a 48-bit positive integer.  The first time this
runs, it may launch a separate program, which could be quite slow.  If all
attempts to obtain the hardware address fail, we choose a random 48-bit
number with the multicast bit (least significant bit of the first octet)
set to 1 as recommended in RFC 4122.  “Hardware address” means the MAC
address of a network interface.  On a machine with multiple network
interfaces, universally administered MAC addresses (i.e. where the second
least significant bit of the first octet is unset) will be preferred over
locally administered MAC addresses, but with no other ordering guarantees.

Changed in version 3.7: Universally administered MAC addresses are preferred over locally
administered MAC addresses, since the former are guaranteed to be
globally unique, while the latter are not."
"uuid.uuid1(node=None, clock_seq=None)","Generate a UUID from a host ID, sequence number, and the current time. If node
is not given, getnode() is used to obtain the hardware address. If
clock_seq is given, it is used as the sequence number; otherwise a random
14-bit sequence number is chosen."
"uuid.uuid3(namespace, name)","Generate a UUID based on the MD5 hash of a namespace identifier (which is a
UUID) and a name (which is a string)."
uuid.uuid4(),Generate a random UUID.
"uuid.uuid5(namespace, name)","Generate a UUID based on the SHA-1 hash of a namespace identifier (which is a
UUID) and a name (which is a string)."
fileno(),"Return an integer file descriptor for the socket on which the server is
listening.  This function is most commonly passed to selectors, to
allow monitoring multiple servers in the same process."
handle_request(),"Process a single request.  This function calls the following methods in
order: get_request(), verify_request(), and
process_request().  If the user-provided
handle() method of the
handler class raises an exception, the server’s handle_error() method
will be called.  If no request is received within timeout
seconds, handle_timeout() will be called and handle_request()
will return."
serve_forever(poll_interval=0.5),"Handle requests until an explicit shutdown() request.  Poll for
shutdown every poll_interval seconds.
Ignores the timeout attribute.  It
also calls service_actions(), which may be used by a subclass or mixin
to provide actions specific to a given service.  For example, the
ForkingMixIn class uses service_actions() to clean up zombie
child processes.

Changed in version 3.3: Added service_actions call to the serve_forever method."
service_actions(),"This is called in the serve_forever() loop. This method can be
overridden by subclasses or mixin classes to perform actions specific to
a given service, such as cleanup actions.

New in version 3.3."
shutdown(),Tell the serve_forever() loop to stop and wait until it does.
server_close(),Clean up the server. May be overridden.
"finish_request(request, client_address)","Actually processes the request by instantiating RequestHandlerClass and
calling its handle() method."
get_request(),"Must accept a request from the socket, and return a 2-tuple containing the new
socket object to be used to communicate with the client, and the client’s
address."
"handle_error(request, client_address)","This function is called if the handle()
method of a RequestHandlerClass instance raises
an exception.  The default action is to print the traceback to
standard error and continue handling further requests.

Changed in version 3.6: Now only called for exceptions derived from the Exception
class."
handle_timeout(),"This function is called when the timeout attribute has been set to a
value other than None and the timeout period has passed with no
requests being received.  The default action for forking servers is
to collect the status of any child processes that have exited, while
in threading servers this method does nothing."
"process_request(request, client_address)","Calls finish_request() to create an instance of the
RequestHandlerClass.  If desired, this function can create a new process
or thread to handle the request; the ForkingMixIn and
ThreadingMixIn classes do this."
server_activate(),"Called by the server’s constructor to activate the server.  The default behavior
for a TCP server just invokes listen()
on the server’s socket.  May be overridden."
server_bind(),"Called by the server’s constructor to bind the socket to the desired address.
May be overridden."
"verify_request(request, client_address)","Must return a Boolean value; if the value is True, the request will
be processed, and if it’s False, the request will be denied.  This
function can be overridden to implement access controls for a server. The
default implementation always returns True."
setup(),"Called before the handle() method to perform any initialization actions
required.  The default implementation does nothing."
handle(),"This function must do all the work required to service a request.  The
default implementation does nothing.  Several instance attributes are
available to it; the request is available as self.request; the client
address as self.client_address; and the server instance as
self.server, in case it needs access to per-server information.
The type of self.request is different for datagram or stream
services.  For stream services, self.request is a socket object; for
datagram services, self.request is a pair of string and socket."
finish(),"Called after the handle() method to perform any clean-up actions
required.  The default implementation does nothing.  If setup()
raises an exception, this function will not be called."
handle(),"Calls handle_one_request() once (or, if persistent connections are
enabled, multiple times) to handle incoming HTTP requests. You should
never need to override it; instead, implement appropriate do_*()
methods."
handle_one_request(),"This method will parse and dispatch the request to the appropriate
do_*() method.  You should never need to override it."
handle_expect_100(),"When a HTTP/1.1 compliant server receives an Expect: 100-continue
request header it responds back with a 100 Continue followed by 200
OK headers.
This method can be overridden to raise an error if the server does not
want the client to continue.  For e.g. server can chose to send 417
Expectation Failed as a response header and return False.

New in version 3.2."
"send_error(code, message=None, explain=None)","Sends and logs a complete error reply to the client. The numeric code
specifies the HTTP error code, with message as an optional, short, human
readable description of the error.  The explain argument can be used to
provide more detailed information about the error; it will be formatted
using the error_message_format attribute and emitted, after
a complete set of headers, as the response body.  The responses
attribute holds the default values for message and explain that
will be used if no value is provided; for unknown codes the default value
for both is the string ???. The body will be empty if the method is
HEAD or the response code is one of the following: 1xx,
204 No Content, 205 Reset Content, 304 Not Modified.

Changed in version 3.4: The error response includes a Content-Length header.
Added the explain argument."
"send_response(code, message=None)","Adds a response header to the headers buffer and logs the accepted
request. The HTTP response line is written to the internal buffer,
followed by Server and Date headers. The values for these two headers
are picked up from the version_string() and
date_time_string() methods, respectively. If the server does not
intend to send any other headers using the send_header() method,
then send_response() should be followed by an end_headers()
call.

Changed in version 3.3: Headers are stored to an internal buffer and end_headers()
needs to be called explicitly."
"send_header(keyword, value)","Adds the HTTP header to an internal buffer which will be written to the
output stream when either end_headers() or flush_headers() is
invoked. keyword should specify the header keyword, with value
specifying its value. Note that, after the send_header calls are done,
end_headers() MUST BE called in order to complete the operation.

Changed in version 3.2: Headers are stored in an internal buffer."
"send_response_only(code, message=None)","Sends the response header only, used for the purposes when 100
Continue response is sent by the server to the client. The headers not
buffered and sent directly the output stream.If the message is not
specified, the HTTP message corresponding the response code  is sent.

New in version 3.2."
end_headers(),"Adds a blank line
(indicating the end of the HTTP headers in the response)
to the headers buffer and calls flush_headers().

Changed in version 3.2: The buffered headers are written to the output stream."
flush_headers(),"Finally send the headers to the output stream and flush the internal
headers buffer.

New in version 3.3."
"log_request(code='-', size='-')","Logs an accepted (successful) request. code should specify the numeric
HTTP code associated with the response. If a size of the response is
available, then it should be passed as the size parameter."
log_error(...),"Logs an error when a request cannot be fulfilled. By default, it passes
the message to log_message(), so it takes the same arguments
(format and additional values)."
"log_message(format, ...)","Logs an arbitrary message to sys.stderr. This is typically overridden
to create custom error logging mechanisms. The format argument is a
standard printf-style format string, where the additional arguments to
log_message() are applied as inputs to the formatting. The client
ip address and current date and time are prefixed to every message logged."
version_string(),"Returns the server software’s version string. This is a combination of the
server_version and sys_version attributes."
date_time_string(timestamp=None),"Returns the date and time given by timestamp (which must be None or in
the format returned by time.time()), formatted for a message
header. If timestamp is omitted, it uses the current date and time.
The result looks like 'Sun, 06 Nov 1994 08:49:37 GMT'."
log_date_time_string(),"Returns the current date and time, formatted for logging."
address_string(),"Returns the client address.

Changed in version 3.3: Previously, a name lookup was performed. To avoid name resolution
delays, it now always returns the IP address."
do_HEAD(),"This method serves the 'HEAD' request type: it sends the headers it
would send for the equivalent GET request. See the do_GET()
method for a more complete explanation of the possible headers."
do_GET(),"The request is mapped to a local file by interpreting the request as a
path relative to the current working directory.
If the request was mapped to a directory, the directory is checked for a
file named index.html or index.htm (in that order). If found, the
file’s contents are returned; otherwise a directory listing is generated
by calling the list_directory() method. This method uses
os.listdir() to scan the directory, and returns a 404 error
response if the listdir() fails.
If the request was mapped to a file, it is opened. Any OSError
exception in opening the requested file is mapped to a 404,
'File not found' error. If there was a 'If-Modified-Since'
header in the request, and the file was not modified after this time,
a 304, 'Not Modified' response is sent. Otherwise, the content
type is guessed by calling the guess_type() method, which in turn
uses the extensions_map variable, and the file contents are returned.
A 'Content-type:' header with the guessed content type is output,
followed by a 'Content-Length:' header with the file’s size and a
'Last-Modified:' header with the file’s modification time.
Then follows a blank line signifying the end of the headers, and then the
contents of the file are output. If the file’s MIME type starts with
text/ the file is opened in text mode; otherwise binary mode is used.
For example usage, see the implementation of the test() function
invocation in the http.server module.

Changed in version 3.7: Support of the 'If-Modified-Since' header."
do_POST(),"This method serves the 'POST' request type, only allowed for CGI
scripts.  Error 501, “Can only POST to CGI scripts”, is output when trying
to POST to a non-CGI url."
BaseCookie.value_decode(val),"Return a tuple (real_value, coded_value) from a string representation.
real_value can be any type. This method does no decoding in
BaseCookie — it exists so it can be overridden."
BaseCookie.value_encode(val),"Return a tuple (real_value, coded_value). val can be any type, but
coded_value will always be converted to a string.
This method does no encoding in BaseCookie — it exists so it can
be overridden.
In general, it should be the case that value_encode() and
value_decode() are inverses on the range of value_decode."
"BaseCookie.output(attrs=None, header='Set-Cookie:', sep='\r\n')","Return a string representation suitable to be sent as HTTP headers. attrs and
header are sent to each Morsel’s output() method. sep is used
to join the headers together, and is by default the combination '\r\n'
(CRLF)."
BaseCookie.js_output(attrs=None),"Return an embeddable JavaScript snippet, which, if run on a browser which
supports JavaScript, will act the same as if the HTTP headers was sent.
The meaning for attrs is the same as in output()."
BaseCookie.load(rawdata),"If rawdata is a string, parse it as an HTTP_COOKIE and add the values
found there as Morsels. If it is a dictionary, it is equivalent to:
for k, v in rawdata.items():
    cookie[k] = v"
"Morsel.set(key, value, coded_value)","Set the key, value and coded_value attributes."
Morsel.isReservedKey(K),Whether K is a member of the set of keys of a Morsel.
"Morsel.output(attrs=None, header='Set-Cookie:')","Return a string representation of the Morsel, suitable to be sent as an HTTP
header. By default, all the attributes are included, unless attrs is given, in
which case it should be a list of attributes to use. header is by default
""Set-Cookie:""."
Morsel.js_output(attrs=None),"Return an embeddable JavaScript snippet, which, if run on a browser which
supports JavaScript, will act the same as if the HTTP header was sent.
The meaning for attrs is the same as in output()."
Morsel.OutputString(attrs=None),"Return a string representing the Morsel, without any surrounding HTTP or
JavaScript.
The meaning for attrs is the same as in output()."
Morsel.update(values),"Update the values in the Morsel dictionary with the values in the dictionary
values.  Raise an error if any of the keys in the values dict is not a
valid RFC 2109 attribute.

Changed in version 3.5: an error is raised for invalid keys."
Morsel.copy(value),"Return a shallow copy of the Morsel object.

Changed in version 3.5: return a Morsel object instead of a dict."
"Morsel.setdefault(key, value=None)","Raise an error if key is not a valid RFC 2109 attribute, otherwise
behave the same as dict.setdefault()."
CookieJar.add_cookie_header(request),"Add correct Cookie header to request.
If policy allows (ie. the rfc2965 and hide_cookie2 attributes of
the CookieJar’s CookiePolicy instance are true and false
respectively), the Cookie2 header is also added when appropriate.
The request object (usually a urllib.request.Request instance)
must support the methods get_full_url(), get_host(),
get_type(), unverifiable(), has_header(),
get_header(), header_items(), add_unredirected_header()
and origin_req_host attribute as documented by
urllib.request.

Changed in version 3.3: request object needs origin_req_host attribute. Dependency on a
deprecated method get_origin_req_host() has been removed."
"CookieJar.extract_cookies(response, request)","Extract cookies from HTTP response and store them in the CookieJar,
where allowed by policy.
The CookieJar will look for allowable Set-Cookie and
Set-Cookie2 headers in the response argument, and store cookies
as appropriate (subject to the CookiePolicy.set_ok() method’s approval).
The response object (usually the result of a call to
urllib.request.urlopen(), or similar) should support an info()
method, which returns an email.message.Message instance.
The request object (usually a urllib.request.Request instance)
must support the methods get_full_url(), get_host(),
unverifiable(), and origin_req_host attribute, as documented
by urllib.request.  The request is used to set default values for
cookie-attributes as well as for checking that the cookie is allowed to be
set.

Changed in version 3.3: request object needs origin_req_host attribute. Dependency on a
deprecated method get_origin_req_host() has been removed."
CookieJar.set_policy(policy),Set the CookiePolicy instance to be used.
"CookieJar.make_cookies(response, request)","Return sequence of Cookie objects extracted from response object.
See the documentation for extract_cookies() for the interfaces required of
the response and request arguments."
"CookieJar.set_cookie_if_ok(cookie, request)",Set a Cookie if policy says it’s OK to do so.
CookieJar.set_cookie(cookie),"Set a Cookie, without checking with policy to see whether or not it
should be set."
"CookieJar.clear([domain[, path[, name]]])","Clear some cookies.
If invoked without arguments, clear all cookies.  If given a single argument,
only cookies belonging to that domain will be removed. If given two arguments,
cookies belonging to the specified domain and URL path are removed.  If
given three arguments, then the cookie with the specified domain, path and
name is removed.
Raises KeyError if no matching cookie exists."
CookieJar.clear_session_cookies(),"Discard all session cookies.
Discards all contained cookies that have a true discard attribute
(usually because they had either no max-age or expires cookie-attribute,
or an explicit discard cookie-attribute).  For interactive browsers, the end
of a session usually corresponds to closing the browser window.
Note that the save() method won’t save session cookies anyway, unless you
ask otherwise by passing a true ignore_discard argument."
"FileCookieJar.save(filename=None, ignore_discard=False, ignore_expires=False)","Save cookies to a file.
This base class raises NotImplementedError.  Subclasses may leave this
method unimplemented.
filename is the name of file in which to save cookies.  If filename is not
specified, self.filename is used (whose default is the value passed to
the constructor, if any); if self.filename is None,
ValueError is raised.
ignore_discard: save even cookies set to be discarded. ignore_expires: save
even cookies that have expired
The file is overwritten if it already exists, thus wiping all the cookies it
contains.  Saved cookies can be restored later using the load() or
revert() methods."
"FileCookieJar.load(filename=None, ignore_discard=False, ignore_expires=False)","Load cookies from a file.
Old cookies are kept unless overwritten by newly loaded ones.
Arguments are as for save().
The named file must be in the format understood by the class, or
LoadError will be raised.  Also, OSError may be raised, for
example if the file does not exist.

Changed in version 3.3: IOError used to be raised, it is now an alias of OSError."
"FileCookieJar.revert(filename=None, ignore_discard=False, ignore_expires=False)","Clear all cookies and reload cookies from a saved file.
revert() can raise the same exceptions as load(). If there is a
failure, the object’s state will not be altered."
"CookiePolicy.set_ok(cookie, request)","Return boolean value indicating whether cookie should be accepted from server.
cookie is a Cookie instance.  request is an object
implementing the interface defined by the documentation for
CookieJar.extract_cookies()."
"CookiePolicy.return_ok(cookie, request)","Return boolean value indicating whether cookie should be returned to server.
cookie is a Cookie instance.  request is an object
implementing the interface defined by the documentation for
CookieJar.add_cookie_header()."
"CookiePolicy.domain_return_ok(domain, request)","Return False if cookies should not be returned, given cookie domain.
This method is an optimization.  It removes the need for checking every cookie
with a particular domain (which might involve reading many files).  Returning
true from domain_return_ok() and path_return_ok() leaves all the
work to return_ok().
If domain_return_ok() returns true for the cookie domain,
path_return_ok() is called for the cookie path.  Otherwise,
path_return_ok() and return_ok() are never called for that cookie
domain.  If path_return_ok() returns true, return_ok() is called
with the Cookie object itself for a full check.  Otherwise,
return_ok() is never called for that cookie path.
Note that domain_return_ok() is called for every cookie domain, not just
for the request domain.  For example, the function might be called with both
"".example.com"" and ""www.example.com"" if the request domain is
""www.example.com"".  The same goes for path_return_ok().
The request argument is as documented for return_ok()."
"CookiePolicy.path_return_ok(path, request)","Return False if cookies should not be returned, given cookie path.
See the documentation for domain_return_ok()."
DefaultCookiePolicy.blocked_domains(),Return the sequence of blocked domains (as a tuple).
DefaultCookiePolicy.set_blocked_domains(blocked_domains),Set the sequence of blocked domains.
DefaultCookiePolicy.is_blocked(domain),Return whether domain is on the blacklist for setting or receiving cookies.
DefaultCookiePolicy.allowed_domains(),"Return None, or the sequence of allowed domains (as a tuple)."
DefaultCookiePolicy.set_allowed_domains(allowed_domains),"Set the sequence of allowed domains, or None."
DefaultCookiePolicy.is_not_allowed(domain),"Return whether domain is not on the whitelist for setting or receiving
cookies."
Cookie.has_nonstandard_attr(name),Return True if cookie has the named cookie-attribute.
"Cookie.get_nonstandard_attr(name, default=None)","If cookie has the named cookie-attribute, return its value. Otherwise, return
default."
"Cookie.set_nonstandard_attr(name, value)",Set the value of the named cookie-attribute.
Cookie.is_expired(now=None),"True if cookie has passed the time at which the server requested it should
expire.  If now is given (in seconds since the epoch), return whether the
cookie has expired at the specified time."
"xmlrpc.client.dumps(params, methodname=None, methodresponse=None, encoding=None, allow_none=False)","Convert params into an XML-RPC request. or into a response if methodresponse
is true. params can be either a tuple of arguments or an instance of the
Fault exception class.  If methodresponse is true, only a single value
can be returned, meaning that params must be of length 1. encoding, if
supplied, is the encoding to use in the generated XML; the default is UTF-8.
Python’s None value cannot be used in standard XML-RPC; to allow using
it via an extension,  provide a true value for allow_none."
"xmlrpc.client.loads(data, use_datetime=False, use_builtin_types=False)","Convert an XML-RPC request or response into Python objects, a (params,
methodname).  params is a tuple of argument; methodname is a string, or
None if no method name is present in the packet. If the XML-RPC packet
represents a fault condition, this function will raise a Fault exception.
The use_builtin_types flag can be used to cause date/time values to be
presented as datetime.datetime objects and binary data to be
presented as bytes objects; this flag is false by default.
The obsolete use_datetime flag is similar to use_builtin_types but it
applies only to date/time values.

Changed in version 3.3: The use_builtin_types flag was added."
ServerProxy.system.listMethods(),"This method returns a list of strings, one for each (non-system) method
supported by the XML-RPC server."
ServerProxy.system.methodSignature(name),"This method takes one parameter, the name of a method implemented by the XML-RPC
server. It returns an array of possible signatures for this method. A signature
is an array of types. The first of these types is the return type of the method,
the rest are parameters.
Because multiple signatures (ie. overloading) is permitted, this method returns
a list of signatures rather than a singleton.
Signatures themselves are restricted to the top level parameters expected by a
method. For instance if a method expects one array of structs as a parameter,
and it returns a string, its signature is simply “string, array”. If it expects
three integers and returns a string, its signature is “string, int, int, int”.
If no signature is defined for the method, a non-array value is returned. In
Python this means that the type of the returned  value will be something other
than list."
ServerProxy.system.methodHelp(name),"This method takes one parameter, the name of a method implemented by the XML-RPC
server.  It returns a documentation string describing the use of that method. If
no such string is available, an empty string is returned. The documentation
string may contain HTML markup."
decode(string),Accept a string as the instance’s new time value.
encode(out),"Write the XML-RPC encoding of this DateTime item to the out stream
object."
decode(bytes),Accept a base64 bytes object and decode it as the instance’s new data.
encode(out),"Write the XML-RPC base 64 encoding of this binary item to the out stream object.
The encoded data will have newlines every 76 characters as per
RFC 2045 section 6.8,
which was the de facto standard base64 specification when the
XML-RPC spec was written."
"SimpleXMLRPCServer.register_function(function=None, name=None)","Register a function that can respond to XML-RPC requests.  If name is given,
it will be the method name associated with function, otherwise
function.__name__ will be used.  name is a string, and may contain
characters not legal in Python identifiers, including the period character.
This method can also be used as a decorator.  When used as a decorator,
name can only be given as a keyword argument to register function under
name.  If no name is given, function.__name__ will be used.

Changed in version 3.7: register_function() can be used as a decorator."
"SimpleXMLRPCServer.register_instance(instance, allow_dotted_names=False)","Register an object which is used to expose method names which have not been
registered using register_function().  If instance contains a
_dispatch() method, it is called with the requested method name and the
parameters from the request.  Its API is def _dispatch(self, method, params)
(note that params does not represent a variable argument list).  If it calls
an underlying function to perform its task, that function is called as
func(*params), expanding the parameter list. The return value from
_dispatch() is returned to the client as the result.  If instance does
not have a _dispatch() method, it is searched for an attribute matching
the name of the requested method.
If the optional allow_dotted_names argument is true and the instance does not
have a _dispatch() method, then if the requested method name contains
periods, each component of the method name is searched for individually, with
the effect that a simple hierarchical search is performed.  The value found from
this search is then called with the parameters from the request, and the return
value is passed back to the client.

Warning
Enabling the allow_dotted_names option allows intruders to access your
module’s global variables and may allow intruders to execute arbitrary code on
your machine.  Only use this option on a secure, closed network."
SimpleXMLRPCServer.register_introspection_functions(),"Registers the XML-RPC introspection functions system.listMethods,
system.methodHelp and system.methodSignature."
SimpleXMLRPCServer.register_multicall_functions(),Registers the XML-RPC multicall function system.multicall.
"CGIXMLRPCRequestHandler.register_function(function=None, name=None)","Register a function that can respond to XML-RPC requests.  If name is given,
it will be the method name associated with function, otherwise
function.__name__ will be used.  name is a string, and may contain
characters not legal in Python identifiers, including the period character.
This method can also be used as a decorator.  When used as a decorator,
name can only be given as a keyword argument to register function under
name.  If no name is given, function.__name__ will be used.

Changed in version 3.7: register_function() can be used as a decorator."
CGIXMLRPCRequestHandler.register_instance(instance),"Register an object which is used to expose method names  which have not been
registered using register_function(). If  instance contains a
_dispatch() method, it is called with the  requested method name and the
parameters from the  request; the return value is returned to the client as the
result. If instance does not have a _dispatch() method, it is searched
for an attribute matching the name of the requested method; if  the requested
method name contains periods, each  component of the method name is searched for
individually,  with the effect that a simple hierarchical search is performed.
The value found from this search is then called with the  parameters from the
request, and the return value is passed  back to the client."
CGIXMLRPCRequestHandler.register_introspection_functions(),"Register the XML-RPC introspection functions  system.listMethods,
system.methodHelp and  system.methodSignature."
CGIXMLRPCRequestHandler.register_multicall_functions(),Register the XML-RPC multicall function system.multicall.
CGIXMLRPCRequestHandler.handle_request(request_text=None),"Handle an XML-RPC request. If request_text is given, it should be the POST
data provided by the HTTP server,  otherwise the contents of stdin will be used."
DocXMLRPCServer.set_server_title(server_title),"Set the title used in the generated HTML documentation. This title will be used
inside the HTML “title” element."
DocXMLRPCServer.set_server_name(server_name),"Set the name used in the generated HTML documentation. This name will appear at
the top of the generated documentation inside a “h1” element."
DocXMLRPCServer.set_server_documentation(server_documentation),"Set the description used in the generated HTML documentation. This description
will appear as a paragraph, below the server name, in the documentation."
DocCGIXMLRPCRequestHandler.set_server_title(server_title),"Set the title used in the generated HTML documentation. This title will be used
inside the HTML “title” element."
DocCGIXMLRPCRequestHandler.set_server_name(server_name),"Set the name used in the generated HTML documentation. This name will appear at
the top of the generated documentation inside a “h1” element."
DocCGIXMLRPCRequestHandler.set_server_documentation(server_documentation),"Set the description used in the generated HTML documentation. This description
will appear as a paragraph, below the server name, in the documentation."
ipaddress.ip_address(address),"Return an IPv4Address or IPv6Address object depending on
the IP address passed as argument.  Either IPv4 or IPv6 addresses may be
supplied; integers less than 2**32 will be considered to be IPv4 by default.
A ValueError is raised if address does not represent a valid IPv4
or IPv6 address.
>>> ipaddress.ip_address('192.168.0.1')
IPv4Address('192.168.0.1')
>>> ipaddress.ip_address('2001:db8::')
IPv6Address('2001:db8::')"
"ipaddress.ip_network(address, strict=True)","Return an IPv4Network or IPv6Network object depending on
the IP address passed as argument.  address is a string or integer
representing the IP network.  Either IPv4 or IPv6 networks may be supplied;
integers less than 2**32 will be considered to be IPv4 by default.  strict
is passed to IPv4Network or IPv6Network constructor.  A
ValueError is raised if address does not represent a valid IPv4 or
IPv6 address, or if the network has host bits set.
>>> ipaddress.ip_network('192.168.0.0/28')
IPv4Network('192.168.0.0/28')"
ipaddress.ip_interface(address),"Return an IPv4Interface or IPv6Interface object depending
on the IP address passed as argument.  address is a string or integer
representing the IP address.  Either IPv4 or IPv6 addresses may be supplied;
integers less than 2**32 will be considered to be IPv4 by default.  A
ValueError is raised if address does not represent a valid IPv4 or
IPv6 address."
ipaddress.v4_int_to_packed(address),"Represent an address as 4 packed bytes in network (big-endian) order.
address is an integer representation of an IPv4 IP address.  A
ValueError is raised if the integer is negative or too large to be an
IPv4 IP address.
>>> ipaddress.ip_address(3221225985)
IPv4Address('192.0.2.1')
>>> ipaddress.v4_int_to_packed(3221225985)
b'\xc0\x00\x02\x01'"
ipaddress.v6_int_to_packed(address),"Represent an address as 16 packed bytes in network (big-endian) order.
address is an integer representation of an IPv6 IP address.  A
ValueError is raised if the integer is negative or too large to be an
IPv6 IP address."
"ipaddress.summarize_address_range(first, last)","Return an iterator of the summarized network range given the first and last
IP addresses.  first is the first IPv4Address or
IPv6Address in the range and last is the last IPv4Address
or IPv6Address in the range.  A TypeError is raised if
first or last are not IP addresses or are not of the same version.  A
ValueError is raised if last is not greater than first or if
first address version is not 4 or 6.
>>> [ipaddr for ipaddr in ipaddress.summarize_address_range(
...    ipaddress.IPv4Address('192.0.2.0'),
...    ipaddress.IPv4Address('192.0.2.130'))]
[IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/31'), IPv4Network('192.0.2.130/32')]"
ipaddress.collapse_addresses(addresses),"Return an iterator of the collapsed IPv4Network or
IPv6Network objects.  addresses is an iterator of
IPv4Network or IPv6Network objects.  A TypeError is
raised if addresses contains mixed version objects.
>>> [ipaddr for ipaddr in
... ipaddress.collapse_addresses([ipaddress.IPv4Network('192.0.2.0/25'),
... ipaddress.IPv4Network('192.0.2.128/25')])]
[IPv4Network('192.0.2.0/24')]"
ipaddress.get_mixed_type_key(obj),"Return a key suitable for sorting between networks and addresses.  Address
and Network objects are not sortable by default; they’re fundamentally
different, so the expression:
IPv4Address('192.0.2.0') <= IPv4Network('192.0.2.0/24')


doesn’t make sense.  There are some times however, where you may wish to
have ipaddress sort these anyway.  If you need to do this, you can use
this function as the key argument to sorted().
obj is either a network or address object."
hosts(),"Returns an iterator over the usable hosts in the network.  The usable
hosts are all the IP addresses that belong to the network, except the
network address itself and the network broadcast address.  For networks
with a mask length of 31, the network address and network broadcast
address are also included in the result.
>>> list(ip_network('192.0.2.0/29').hosts())  
[IPv4Address('192.0.2.1'), IPv4Address('192.0.2.2'),
 IPv4Address('192.0.2.3'), IPv4Address('192.0.2.4'),
 IPv4Address('192.0.2.5'), IPv4Address('192.0.2.6')]
>>> list(ip_network('192.0.2.0/31').hosts())
[IPv4Address('192.0.2.0'), IPv4Address('192.0.2.1')]"
overlaps(other),"True if this network is partly or wholly contained in other or
other is wholly contained in this network."
address_exclude(network),"Computes the network definitions resulting from removing the given
network from this one.  Returns an iterator of network objects.
Raises ValueError if network is not completely contained in
this network.
>>> n1 = ip_network('192.0.2.0/28')
>>> n2 = ip_network('192.0.2.1/32')
>>> list(n1.address_exclude(n2))  
[IPv4Network('192.0.2.8/29'), IPv4Network('192.0.2.4/30'),
 IPv4Network('192.0.2.2/31'), IPv4Network('192.0.2.0/32')]"
"subnets(prefixlen_diff=1, new_prefix=None)","The subnets that join to make the current network definition, depending
on the argument values.  prefixlen_diff is the amount our prefix
length should be increased by.  new_prefix is the desired new
prefix of the subnets; it must be larger than our prefix.  One and
only one of prefixlen_diff and new_prefix must be set.  Returns an
iterator of network objects.
>>> list(ip_network('192.0.2.0/24').subnets())
[IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/25')]
>>> list(ip_network('192.0.2.0/24').subnets(prefixlen_diff=2))  
[IPv4Network('192.0.2.0/26'), IPv4Network('192.0.2.64/26'),
 IPv4Network('192.0.2.128/26'), IPv4Network('192.0.2.192/26')]
>>> list(ip_network('192.0.2.0/24').subnets(new_prefix=26))  
[IPv4Network('192.0.2.0/26'), IPv4Network('192.0.2.64/26'),
 IPv4Network('192.0.2.128/26'), IPv4Network('192.0.2.192/26')]
>>> list(ip_network('192.0.2.0/24').subnets(new_prefix=23))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
    raise ValueError('new prefix must be longer')
ValueError: new prefix must be longer
>>> list(ip_network('192.0.2.0/24').subnets(new_prefix=25))
[IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/25')]"
"supernet(prefixlen_diff=1, new_prefix=None)","The supernet containing this network definition, depending on the
argument values.  prefixlen_diff is the amount our prefix length
should be decreased by.  new_prefix is the desired new prefix of
the supernet; it must be smaller than our prefix.  One and only one
of prefixlen_diff and new_prefix must be set.  Returns a single
network object.
>>> ip_network('192.0.2.0/24').supernet()
IPv4Network('192.0.2.0/23')
>>> ip_network('192.0.2.0/24').supernet(prefixlen_diff=2)
IPv4Network('192.0.0.0/22')
>>> ip_network('192.0.2.0/24').supernet(new_prefix=20)
IPv4Network('192.0.0.0/20')"
subnet_of(other),"Return True if this network is a subnet of other.
>>> a = ip_network('192.168.1.0/24')
>>> b = ip_network('192.168.1.128/30')
>>> b.subnet_of(a)
True



New in version 3.7."
supernet_of(other),"Return True if this network is a supernet of other.
>>> a = ip_network('192.168.1.0/24')
>>> b = ip_network('192.168.1.128/30')
>>> a.supernet_of(b)
True



New in version 3.7."
compare_networks(other),"Compare this network to other.  In this comparison only the network
addresses are considered; host bits aren’t.  Returns either -1,
0 or 1.
>>> ip_network('192.0.2.1/32').compare_networks(ip_network('192.0.2.2/32'))
-1
>>> ip_network('192.0.2.1/32').compare_networks(ip_network('192.0.2.0/32'))
1
>>> ip_network('192.0.2.1/32').compare_networks(ip_network('192.0.2.1/32'))
0



Deprecated since version 3.7: It uses the same ordering and comparison algorithm as “<”, “==”, and “>”"
hosts(),"Returns an iterator over the usable hosts in the network.  The usable
hosts are all the IP addresses that belong to the network, except the
Subnet-Router anycast address.  For networks with a mask length of 127,
the Subnet-Router anycast address is also included in the result."
overlaps(other),
address_exclude(network),
"subnets(prefixlen_diff=1, new_prefix=None)",
"supernet(prefixlen_diff=1, new_prefix=None)",
subnet_of(other),
supernet_of(other),
compare_networks(other),"Refer to the corresponding attribute documentation in
IPv4Network."
"audioop.add(fragment1, fragment2, width)","Return a fragment which is the addition of the two samples passed as parameters.
width is the sample width in bytes, either 1, 2, 3 or 4.  Both
fragments should have the same length.  Samples are truncated in case of overflow."
"audioop.adpcm2lin(adpcmfragment, width, state)","Decode an Intel/DVI ADPCM coded fragment to a linear fragment.  See the
description of lin2adpcm() for details on ADPCM coding. Return a tuple
(sample, newstate) where the sample has the width specified in width."
"audioop.alaw2lin(fragment, width)","Convert sound fragments in a-LAW encoding to linearly encoded sound fragments.
a-LAW encoding always uses 8 bits samples, so width refers only to the sample
width of the output fragment here."
"audioop.avg(fragment, width)",Return the average over all samples in the fragment.
"audioop.avgpp(fragment, width)","Return the average peak-peak value over all samples in the fragment. No
filtering is done, so the usefulness of this routine is questionable."
"audioop.bias(fragment, width, bias)","Return a fragment that is the original fragment with a bias added to each
sample.  Samples wrap around in case of overflow."
"audioop.byteswap(fragment, width)","“Byteswap” all samples in a fragment and returns the modified fragment.
Converts big-endian samples to little-endian and vice versa.

New in version 3.4."
"audioop.cross(fragment, width)",Return the number of zero crossings in the fragment passed as an argument.
"audioop.findfactor(fragment, reference)","Return a factor F such that rms(add(fragment, mul(reference, -F))) is
minimal, i.e., return the factor with which you should multiply reference to
make it match as well as possible to fragment.  The fragments should both
contain 2-byte samples.
The time taken by this routine is proportional to len(fragment)."
"audioop.findfit(fragment, reference)","Try to match reference as well as possible to a portion of fragment (which
should be the longer fragment).  This is (conceptually) done by taking slices
out of fragment, using findfactor() to compute the best match, and
minimizing the result.  The fragments should both contain 2-byte samples.
Return a tuple (offset, factor) where offset is the (integer) offset into
fragment where the optimal match started and factor is the (floating-point)
factor as per findfactor()."
"audioop.findmax(fragment, length)","Search fragment for a slice of length length samples (not bytes!) with
maximum energy, i.e., return i for which rms(fragment[i*2:(i+length)*2])
is maximal.  The fragments should both contain 2-byte samples.
The routine takes time proportional to len(fragment)."
"audioop.getsample(fragment, width, index)",Return the value of sample index from the fragment.
"audioop.lin2adpcm(fragment, width, state)","Convert samples to 4 bit Intel/DVI ADPCM encoding.  ADPCM coding is an adaptive
coding scheme, whereby each 4 bit number is the difference between one sample
and the next, divided by a (varying) step.  The Intel/DVI ADPCM algorithm has
been selected for use by the IMA, so it may well become a standard.
state is a tuple containing the state of the coder.  The coder returns a tuple
(adpcmfrag, newstate), and the newstate should be passed to the next call
of lin2adpcm().  In the initial call, None can be passed as the state.
adpcmfrag is the ADPCM coded fragment packed 2 4-bit values per byte."
"audioop.lin2alaw(fragment, width)","Convert samples in the audio fragment to a-LAW encoding and return this as a
bytes object.  a-LAW is an audio encoding format whereby you get a dynamic
range of about 13 bits using only 8 bit samples.  It is used by the Sun audio
hardware, among others."
"audioop.lin2lin(fragment, width, newwidth)","Convert samples between 1-, 2-, 3- and 4-byte formats.

Note
In some audio formats, such as .WAV files, 16, 24 and 32 bit samples are
signed, but 8 bit samples are unsigned.  So when converting to 8 bit wide
samples for these formats, you need to also add 128 to the result:
new_frames = audioop.lin2lin(frames, old_width, 1)
new_frames = audioop.bias(new_frames, 1, 128)


The same, in reverse, has to be applied when converting from 8 to 16, 24
or 32 bit width samples."
"audioop.lin2ulaw(fragment, width)","Convert samples in the audio fragment to u-LAW encoding and return this as a
bytes object.  u-LAW is an audio encoding format whereby you get a dynamic
range of about 14 bits using only 8 bit samples.  It is used by the Sun audio
hardware, among others."
"audioop.max(fragment, width)",Return the maximum of the absolute value of all samples in a fragment.
"audioop.maxpp(fragment, width)",Return the maximum peak-peak value in the sound fragment.
"audioop.minmax(fragment, width)","Return a tuple consisting of the minimum and maximum values of all samples in
the sound fragment."
"audioop.mul(fragment, width, factor)","Return a fragment that has all samples in the original fragment multiplied by
the floating-point value factor.  Samples are truncated in case of overflow."
"audioop.ratecv(fragment, width, nchannels, inrate, outrate, state[, weightA[, weightB]])","Convert the frame rate of the input fragment.
state is a tuple containing the state of the converter.  The converter returns
a tuple (newfragment, newstate), and newstate should be passed to the next
call of ratecv().  The initial call should pass None as the state.
The weightA and weightB arguments are parameters for a simple digital filter
and default to 1 and 0 respectively."
"audioop.reverse(fragment, width)",Reverse the samples in a fragment and returns the modified fragment.
"audioop.rms(fragment, width)","Return the root-mean-square of the fragment, i.e. sqrt(sum(S_i^2)/n).
This is a measure of the power in an audio signal."
"audioop.tomono(fragment, width, lfactor, rfactor)","Convert a stereo fragment to a mono fragment.  The left channel is multiplied by
lfactor and the right channel by rfactor before adding the two channels to
give a mono signal."
"audioop.tostereo(fragment, width, lfactor, rfactor)","Generate a stereo fragment from a mono fragment.  Each pair of samples in the
stereo fragment are computed from the mono sample, whereby left channel samples
are multiplied by lfactor and right channel samples by rfactor."
"audioop.ulaw2lin(fragment, width)","Convert sound fragments in u-LAW encoding to linearly encoded sound fragments.
u-LAW encoding always uses 8 bits samples, so width refers only to the sample
width of the output fragment here."
"aifc.open(file, mode=None)","Open an AIFF or AIFF-C file and return an object instance with methods that are
described below.  The argument file is either a string naming a file or a
file object.  mode must be 'r' or 'rb' when the file must be
opened for reading, or 'w'  or 'wb' when the file must be opened for writing.
If omitted, file.mode is used if it exists, otherwise 'rb' is used.  When
used for writing, the file object should be seekable, unless you know ahead of
time how many samples you are going to write in total and use
writeframesraw() and setnframes().
The open() function may be used in a with statement.  When
the with block completes, the close() method is called.

Changed in version 3.4: Support for the with statement was added."
aifc.getnchannels(),"Return the number of audio channels (1 for mono, 2 for stereo)."
aifc.getsampwidth(),Return the size in bytes of individual samples.
aifc.getframerate(),Return the sampling rate (number of audio frames per second).
aifc.getnframes(),Return the number of audio frames in the file.
aifc.getcomptype(),"Return a bytes array of length 4 describing the type of compression
used in the audio file.  For AIFF files, the returned value is
b'NONE'."
aifc.getcompname(),"Return a bytes array convertible to a human-readable description
of the type of compression used in the audio file.  For AIFF files,
the returned value is b'not compressed'."
aifc.getparams(),"Returns a namedtuple() (nchannels, sampwidth,
framerate, nframes, comptype, compname), equivalent to output of the
get*() methods."
aifc.getmarkers(),"Return a list of markers in the audio file.  A marker consists of a tuple of
three elements.  The first is the mark ID (an integer), the second is the mark
position in frames from the beginning of the data (an integer), the third is the
name of the mark (a string)."
aifc.getmark(id),"Return the tuple as described in getmarkers() for the mark with the given
id."
aifc.readframes(nframes),"Read and return the next nframes frames from the audio file.  The returned
data is a string containing for each frame the uncompressed samples of all
channels."
aifc.rewind(),"Rewind the read pointer.  The next readframes() will start from the
beginning."
aifc.setpos(pos),Seek to the specified frame number.
aifc.tell(),Return the current frame number.
aifc.close(),"Close the AIFF file.  After calling this method, the object can no longer be
used."
aifc.aiff(),"Create an AIFF file.  The default is that an AIFF-C file is created, unless the
name of the file ends in '.aiff' in which case the default is an AIFF file."
aifc.aifc(),"Create an AIFF-C file.  The default is that an AIFF-C file is created, unless
the name of the file ends in '.aiff' in which case the default is an AIFF
file."
aifc.setnchannels(nchannels),Specify the number of channels in the audio file.
aifc.setsampwidth(width),Specify the size in bytes of audio samples.
aifc.setframerate(rate),Specify the sampling frequency in frames per second.
aifc.setnframes(nframes),"Specify the number of frames that are to be written to the audio file. If this
parameter is not set, or not set correctly, the file needs to support seeking."
"aifc.setcomptype(type, name)","Specify the compression type.  If not specified, the audio data will
not be compressed.  In AIFF files, compression is not possible.
The name parameter should be a human-readable description of the
compression type as a bytes array, the type parameter should be a
bytes array of length 4.  Currently the following compression types
are supported: b'NONE', b'ULAW', b'ALAW', b'G722'."
"aifc.setparams(nchannels, sampwidth, framerate, comptype, compname)","Set all the above parameters at once.  The argument is a tuple consisting of the
various parameters.  This means that it is possible to use the result of a
getparams() call as argument to setparams()."
"aifc.setmark(id, pos, name)","Add a mark with the given id (larger than 0), and the given name at the given
position.  This method can be called at any time before close()."
aifc.tell(,"Return the current write position in the output file.  Useful in combination
with setmark()."
aifc.writeframes(data),"Write data to the output file.  This method can only be called after the audio
file parameters have been set.

Changed in version 3.4: Any bytes-like object is now accepted."
aifc.writeframesraw(data),"Like writeframes(), except that the header of the audio file is not
updated.

Changed in version 3.4: Any bytes-like object is now accepted."
aifc.close(,"Close the AIFF file.  The header of the file is updated to reflect the actual
size of the audio data. After calling this method, the object can no longer be
used."
"sunau.open(file, mode)","If file is a string, open the file by that name, otherwise treat it as a
seekable file-like object. mode can be any of

'r'Read only mode.

'w'Write only mode.


Note that it does not allow read/write files.
A mode of 'r' returns an AU_read object, while a mode of 'w'
or 'wb' returns an AU_write object."
"sunau.openfp(file, mode)","A synonym for open(), maintained for backwards compatibility.

Deprecated since version 3.7, will be removed in version 3.9."
AU_read.close(),"Close the stream, and make the instance unusable. (This is  called automatically
on deletion.)"
AU_read.getnchannels(),"Returns number of audio channels (1 for mono, 2 for stereo)."
AU_read.getsampwidth(),Returns sample width in bytes.
AU_read.getframerate(),Returns sampling frequency.
AU_read.getnframes(),Returns number of audio frames.
AU_read.getcomptype(),"Returns compression type. Supported compression types are 'ULAW', 'ALAW'
and 'NONE'."
AU_read.getcompname(),"Human-readable version of getcomptype().  The supported types have the
respective names 'CCITT G.711 u-law', 'CCITT G.711 A-law' and 'not
compressed'."
AU_read.getparams(),"Returns a namedtuple() (nchannels, sampwidth,
framerate, nframes, comptype, compname), equivalent to output of the
get*() methods."
AU_read.readframes(n),"Reads and returns at most n frames of audio, as a bytes object.  The data
will be returned in linear format.  If the original data is in u-LAW format, it
will be converted."
AU_read.rewind(),Rewind the file pointer to the beginning of the audio stream.
AU_read.setpos(pos),"Set the file pointer to the specified position.  Only values returned from
tell() should be used for pos."
AU_read.tell(),"Return current file pointer position.  Note that the returned value has nothing
to do with the actual position in the file."
AU_read.getmarkers(),Returns None.
AU_read.getmark(id),Raise an error.
AU_write.setnchannels(n),Set the number of channels.
AU_write.setsampwidth(n),"Set the sample width (in bytes.)

Changed in version 3.4: Added support for 24-bit samples."
AU_write.setframerate(n),Set the frame rate.
AU_write.setnframes(n),"Set the number of frames. This can be later changed, when and if more  frames
are written."
"AU_write.setcomptype(type, name)","Set the compression type and description. Only 'NONE' and 'ULAW' are
supported on output."
AU_write.setparams(tuple),"The tuple should be (nchannels, sampwidth, framerate, nframes, comptype,
compname), with values valid for the set*() methods.  Set all
parameters."
AU_write.tell(),"Return current position in the file, with the same disclaimer for the
AU_read.tell() and AU_read.setpos() methods."
AU_write.writeframesraw(data),"Write audio frames, without correcting nframes.

Changed in version 3.4: Any bytes-like object is now accepted."
AU_write.writeframes(data),"Write audio frames and make sure nframes is correct.

Changed in version 3.4: Any bytes-like object is now accepted."
AU_write.close(),"Make sure nframes is correct, and close the file.
This method is called upon deletion."
"wave.open(file, mode=None)","If file is a string, open the file by that name, otherwise treat it as a
file-like object.  mode can be:

'rb'Read only mode.

'wb'Write only mode.


Note that it does not allow read/write WAV files.
A mode of 'rb' returns a Wave_read object, while a mode of
'wb' returns a Wave_write object.  If mode is omitted and a
file-like object is passed as file, file.mode is used as the default
value for mode.
If you pass in a file-like object, the wave object will not close it when its
close() method is called; it is the caller’s responsibility to close
the file object.
The open() function may be used in a with statement.  When
the with block completes, the Wave_read.close() or Wave_write.close() method is called.

Changed in version 3.4: Added support for unseekable files."
"wave.openfp(file, mode)","A synonym for open(), maintained for backwards compatibility.

Deprecated since version 3.7, will be removed in version 3.9."
Wave_read.close(),"Close the stream if it was opened by wave, and make the instance
unusable.  This is called automatically on object collection."
Wave_read.getnchannels(),"Returns number of audio channels (1 for mono, 2 for stereo)."
Wave_read.getsampwidth(),Returns sample width in bytes.
Wave_read.getframerate(),Returns sampling frequency.
Wave_read.getnframes(),Returns number of audio frames.
Wave_read.getcomptype(),Returns compression type ('NONE' is the only supported type).
Wave_read.getcompname(),"Human-readable version of getcomptype(). Usually 'not compressed'
parallels 'NONE'."
Wave_read.getparams(),"Returns a namedtuple() (nchannels, sampwidth,
framerate, nframes, comptype, compname), equivalent to output of the
get*() methods."
Wave_read.readframes(n),"Reads and returns at most n frames of audio, as a bytes object."
Wave_read.rewind(),Rewind the file pointer to the beginning of the audio stream.
Wave_read.getmarkers(),Returns None.
Wave_read.getmark(id),Raise an error.
Wave_read.setpos(pos),Set the file pointer to the specified position.
Wave_read.tell(),Return current file pointer position.
Wave_write.close(),"Make sure nframes is correct, and close the file if it was opened by
wave.  This method is called upon object collection.  It will raise
an exception if the output stream is not seekable and nframes does not
match the number of frames actually written."
Wave_write.setnchannels(n),Set the number of channels.
Wave_write.setsampwidth(n),Set the sample width to n bytes.
Wave_write.setframerate(n),"Set the frame rate to n.

Changed in version 3.2: A non-integral input to this method is rounded to the nearest
integer."
Wave_write.setnframes(n),"Set the number of frames to n.  This will be changed later if the number
of frames actually written is different (this update attempt will
raise an error if the output stream is not seekable)."
"Wave_write.setcomptype(type, name)","Set the compression type and description. At the moment, only compression type
NONE is supported, meaning no compression."
Wave_write.setparams(tuple),"The tuple should be (nchannels, sampwidth, framerate, nframes, comptype,
compname), with values valid for the set*() methods.  Sets all
parameters."
Wave_write.tell(),"Return current position in the file, with the same disclaimer for the
Wave_read.tell() and Wave_read.setpos() methods."
Wave_write.writeframesraw(data),"Write audio frames, without correcting nframes.

Changed in version 3.4: Any bytes-like object is now accepted."
Wave_write.writeframes(data),"Write audio frames and make sure nframes is correct.  It will raise an
error if the output stream is not seekable and the total number of frames
that have been written after data has been written does not match the
previously set value for nframes.

Changed in version 3.4: Any bytes-like object is now accepted."
getname(),"Returns the name (ID) of the chunk.  This is the first 4 bytes of the
chunk."
getsize(),Returns the size of the chunk.
close(),"Close and skip to the end of the chunk.  This does not close the
underlying file."
isatty(),Returns False.
"seek(pos, whence=0)","Set the chunk’s current position.  The whence argument is optional and
defaults to 0 (absolute file positioning); other values are 1
(seek relative to the current position) and 2 (seek relative to the
file’s end).  There is no return value. If the underlying file does not
allow seek, only forward seeks are allowed."
tell(),Return the current position into the chunk.
read(size=-1),"Read at most size bytes from the chunk (less if the read hits the end of
the chunk before obtaining size bytes).  If the size argument is
negative or omitted, read all data until the end of the chunk.  An empty
bytes object is returned when the end of the chunk is encountered
immediately."
skip(),"Skip to the end of the chunk.  All further calls to read() for the
chunk will return b''.  If you are not interested in the contents of
the chunk, this method should be called so that the file points to the
start of the next chunk."
"colorsys.rgb_to_yiq(r, g, b)",Convert the color from RGB coordinates to YIQ coordinates.
"colorsys.yiq_to_rgb(y, i, q)",Convert the color from YIQ coordinates to RGB coordinates.
"colorsys.rgb_to_hls(r, g, b)",Convert the color from RGB coordinates to HLS coordinates.
"colorsys.hls_to_rgb(h, l, s)",Convert the color from HLS coordinates to RGB coordinates.
"colorsys.rgb_to_hsv(r, g, b)",Convert the color from RGB coordinates to HSV coordinates.
"colorsys.hsv_to_rgb(h, s, v)",Convert the color from HSV coordinates to RGB coordinates.
"imghdr.what(filename, h=None)","Tests the image data contained in the file named by filename, and returns a
string describing the image type.  If optional h is provided, the filename
is ignored and h is assumed to contain the byte stream to test.

Changed in version 3.6: Accepts a path-like object."
sndhdr.what(filename),"Determines the type of sound data stored in the file filename using
whathdr().  If it succeeds, returns a namedtuple as described above, otherwise
None is returned.

Changed in version 3.5: Result changed from a tuple to a namedtuple."
sndhdr.whathdr(filename),"Determines the type of sound data stored in a file based on the file  header.
The name of the file is given by filename.  This function returns a namedtuple as
described above on success, or None.

Changed in version 3.5: Result changed from a tuple to a namedtuple."
ossaudiodev.open(mode),"Open an audio device and return an OSS audio device object.  This object
supports many file-like methods, such as read(), write(), and
fileno() (although there are subtle differences between conventional Unix
read/write semantics and those of OSS audio devices).  It also supports a number
of audio-specific methods; see below for the complete list of methods.
device is the audio device filename to use.  If it is not specified, this
module first looks in the environment variable AUDIODEV for a device
to use.  If not found, it falls back to /dev/dsp.
mode is one of 'r' for read-only (record) access, 'w' for
write-only (playback) access and 'rw' for both. Since many sound cards
only allow one process to have the recorder or player open at a time, it is a
good idea to open the device only for the activity needed.  Further, some
sound cards are half-duplex: they can be opened for reading or writing, but
not both at once.
Note the unusual calling syntax: the first argument is optional, and the
second is required.  This is a historical artifact for compatibility with the
older linuxaudiodev module which ossaudiodev supersedes."
ossaudiodev.openmixer([device]),"Open a mixer device and return an OSS mixer device object.   device is the
mixer device filename to use.  If it is not specified, this module first looks
in the environment variable MIXERDEV for a device to use.  If not
found, it falls back to /dev/mixer."
oss_audio_device.close(),"Explicitly close the audio device.  When you are done writing to or reading from
an audio device, you should explicitly close it.  A closed device cannot be used
again."
oss_audio_device.fileno(),Return the file descriptor associated with the device.
oss_audio_device.read(size),"Read size bytes from the audio input and return them as a Python string.
Unlike most Unix device drivers, OSS audio devices in blocking mode (the
default) will block read() until the entire requested amount of data is
available."
oss_audio_device.write(data),"Write a bytes-like object data to the audio device and return the
number of bytes written.  If the audio device is in blocking mode (the
default), the entire data is always written (again, this is different from
usual Unix device semantics).  If the device is in non-blocking mode, some
data may not be written—see writeall().

Changed in version 3.5: Writable bytes-like object is now accepted."
oss_audio_device.writeall(data),"Write a bytes-like object data to the audio device: waits until
the audio device is able to accept data, writes as much data as it will
accept, and repeats until data has been completely written. If the device
is in blocking mode (the default), this has the same effect as
write(); writeall() is only useful in non-blocking mode.  Has
no return value, since the amount of data written is always equal to the
amount of data supplied.

Changed in version 3.5: Writable bytes-like object is now accepted."
oss_audio_device.nonblock(),"Put the device into non-blocking mode.  Once in non-blocking mode, there is no
way to return it to blocking mode."
oss_audio_device.getfmts(),"Return a bitmask of the audio output formats supported by the soundcard.  Some
of the formats supported by OSS are:






Format
Description



AFMT_MU_LAW
a logarithmic encoding (used by Sun .au
files and /dev/audio)

AFMT_A_LAW
a logarithmic encoding

AFMT_IMA_ADPCM
a 4:1 compressed format defined by the
Interactive Multimedia Association

AFMT_U8
Unsigned, 8-bit audio

AFMT_S16_LE
Signed, 16-bit audio, little-endian byte
order (as used by Intel processors)

AFMT_S16_BE
Signed, 16-bit audio, big-endian byte order
(as used by 68k, PowerPC, Sparc)

AFMT_S8
Signed, 8 bit audio

AFMT_U16_LE
Unsigned, 16-bit little-endian audio

AFMT_U16_BE
Unsigned, 16-bit big-endian audio



Consult the OSS documentation for a full list of audio formats, and note that
most devices support only a subset of these formats.  Some older devices only
support AFMT_U8; the most common format used today is
AFMT_S16_LE."
oss_audio_device.setfmt(format),"Try to set the current audio format to format—see getfmts() for a
list.  Returns the audio format that the device was set to, which may not be the
requested format.  May also be used to return the current audio format—do this
by passing an “audio format” of AFMT_QUERY."
oss_audio_device.channels(nchannels),"Set the number of output channels to nchannels.  A value of 1 indicates
monophonic sound, 2 stereophonic.  Some devices may have more than 2 channels,
and some high-end devices may not support mono. Returns the number of channels
the device was set to."
oss_audio_device.speed(samplerate),"Try to set the audio sampling rate to samplerate samples per second.  Returns
the rate actually set.  Most sound devices don’t support arbitrary sampling
rates.  Common rates are:






Rate
Description



8000
default rate for /dev/audio

11025
speech recording

22050


44100
CD quality audio (at 16 bits/sample and 2
channels)

96000
DVD quality audio (at 24 bits/sample)"
oss_audio_device.sync(),"Wait until the sound device has played every byte in its buffer.  (This happens
implicitly when the device is closed.)  The OSS documentation recommends closing
and re-opening the device rather than using sync()."
oss_audio_device.reset(),"Immediately stop playing or recording and return the device to a state where it
can accept commands.  The OSS documentation recommends closing and re-opening
the device after calling reset()."
oss_audio_device.post(),"Tell the driver that there is likely to be a pause in the output, making it
possible for the device to handle the pause more intelligently.  You might use
this after playing a spot sound effect, before waiting for user input, or before
doing disk I/O."
"oss_audio_device.setparameters(format, nchannels, samplerate[, strict=False])","Set the key audio sampling parameters—sample format, number of channels, and
sampling rate—in one method call.  format,  nchannels, and samplerate
should be as specified in the setfmt(), channels(), and
speed()  methods.  If strict is true, setparameters() checks to
see if each parameter was actually set to the requested value, and raises
OSSAudioError if not.  Returns a tuple (format, nchannels,
samplerate) indicating the parameter values that were actually set by the
device driver (i.e., the same as the return values of setfmt(),
channels(), and speed()).
For example,
(fmt, channels, rate) = dsp.setparameters(fmt, channels, rate)


is equivalent to
fmt = dsp.setfmt(fmt)
channels = dsp.channels(channels)
rate = dsp.rate(rate)"
oss_audio_device.bufsize(),"Returns the size of the hardware buffer, in samples."
oss_audio_device.obufcount(),Returns the number of samples that are in the hardware buffer yet to be played.
oss_audio_device.obuffree(),"Returns the number of samples that could be queued into the hardware buffer to
be played without blocking."
oss_mixer_device.close(),"This method closes the open mixer device file.  Any further attempts to use the
mixer after this file is closed will raise an OSError."
oss_mixer_device.fileno(),Returns the file handle number of the open mixer device file.
oss_mixer_device.controls(),"This method returns a bitmask specifying the available mixer controls (“Control”
being a specific mixable “channel”, such as SOUND_MIXER_PCM or
SOUND_MIXER_SYNTH).  This bitmask indicates a subset of all available
mixer controls—the SOUND_MIXER_* constants defined at module level.
To determine if, for example, the current mixer object supports a PCM mixer, use
the following Python code:
mixer=ossaudiodev.openmixer()
if mixer.controls() & (1 << ossaudiodev.SOUND_MIXER_PCM):
    # PCM is supported
    ... code ...


For most purposes, the SOUND_MIXER_VOLUME (master volume) and
SOUND_MIXER_PCM controls should suffice—but code that uses the mixer
should be flexible when it comes to choosing mixer controls.  On the Gravis
Ultrasound, for example, SOUND_MIXER_VOLUME does not exist."
oss_mixer_device.stereocontrols(),"Returns a bitmask indicating stereo mixer controls.  If a bit is set, the
corresponding control is stereo; if it is unset, the control is either
monophonic or not supported by the mixer (use in combination with
controls() to determine which).
See the code example for the controls() function for an example of getting
data from a bitmask."
oss_mixer_device.reccontrols(),"Returns a bitmask specifying the mixer controls that may be used to record.  See
the code example for controls() for an example of reading from a bitmask."
oss_mixer_device.get(control),"Returns the volume of a given mixer control.  The returned volume is a 2-tuple
(left_volume,right_volume).  Volumes are specified as numbers from 0
(silent) to 100 (full volume).  If the control is monophonic, a 2-tuple is still
returned, but both volumes are the same.
Raises OSSAudioError if an invalid control is specified, or
OSError if an unsupported control is specified."
"oss_mixer_device.set(control, (left, right))","Sets the volume for a given mixer control to (left,right). left and
right must be ints and between 0 (silent) and 100 (full volume).  On
success, the new volume is returned as a 2-tuple. Note that this may not be
exactly the same as the volume specified, because of the limited resolution of
some soundcard’s mixers.
Raises OSSAudioError if an invalid mixer control was specified, or if the
specified volumes were out-of-range."
oss_mixer_device.get_recsrc(),"This method returns a bitmask indicating which control(s) are currently being
used as a recording source."
oss_mixer_device.set_recsrc(bitmask),"Call this function to specify a recording source.  Returns a bitmask indicating
the new recording source (or sources) if successful; raises OSError if an
invalid source was specified.  To set the current recording source to the
microphone input:
mixer.setrecsrc (1 << ossaudiodev.SOUND_MIXER_MIC)"
"gettext.bindtextdomain(domain, localedir=None)","Bind the domain to the locale directory localedir.  More concretely,
gettext will look for binary .mo files for the given domain using
the path (on Unix): localedir/language/LC_MESSAGES/domain.mo, where
language is searched for in the environment variables LANGUAGE,
LC_ALL, LC_MESSAGES, and LANG respectively.
If localedir is omitted or None, then the current binding for domain is
returned. 1"
"gettext.bind_textdomain_codeset(domain, codeset=None)","Bind the domain to codeset, changing the encoding of byte strings
returned by the lgettext(), ldgettext(), lngettext()
and ldngettext() functions.
If codeset is omitted, then the current binding is returned.

Deprecated since version 3.8, will be removed in version 3.10."
gettext.textdomain(domain=None),"Change or query the current global domain.  If domain is None, then the
current global domain is returned, otherwise the global domain is set to
domain, which is returned."
gettext.gettext(message),"Return the localized translation of message, based on the current global
domain, language, and locale directory.  This function is usually aliased as
_() in the local namespace (see examples below)."
"gettext.dgettext(domain, message)","Like gettext(), but look the message up in the specified domain."
"gettext.ngettext(singular, plural, n)","Like gettext(), but consider plural forms. If a translation is found,
apply the plural formula to n, and return the resulting message (some
languages have more than two plural forms). If no translation is found, return
singular if n is 1; return plural otherwise.
The Plural formula is taken from the catalog header. It is a C or Python
expression that has a free variable n; the expression evaluates to the index
of the plural in the catalog. See
the GNU gettext documentation
for the precise syntax to be used in .po files and the
formulas for a variety of languages."
"gettext.dngettext(domain, singular, plural, n)","Like ngettext(), but look the message up in the specified domain."
"gettext.pgettext(context, message)",
"gettext.dpgettext(domain, context, message)",
"gettext.npgettext(context, singular, plural, n)",
"gettext.dnpgettext(domain, context, singular, plural, n)","Similar to the corresponding functions without the p in the prefix (that
is, gettext(), dgettext(), ngettext(), dngettext()),
but the translation is restricted to the given message context.

New in version 3.8."
gettext.lgettext(message),
"gettext.ldgettext(domain, message)",
"gettext.lngettext(singular, plural, n)",
"gettext.ldngettext(domain, singular, plural, n)","Equivalent to the corresponding functions without the l prefix
(gettext(), dgettext(), ngettext() and dngettext()),
but the translation is returned as a byte string encoded in the preferred
system encoding if no other encoding was explicitly set with
bind_textdomain_codeset().

Warning
These functions should be avoided in Python 3, because they return
encoded bytes.  It’s much better to use alternatives which return
Unicode strings instead, since most Python applications will want to
manipulate human readable text as strings instead of bytes.  Further,
it’s possible that you may get unexpected Unicode-related exceptions
if there are encoding problems with the translated strings.


Deprecated since version 3.8, will be removed in version 3.10."
"gettext.find(domain, localedir=None, languages=None, all=False)","This function implements the standard .mo file search algorithm.  It
takes a domain, identical to what textdomain() takes.  Optional
localedir is as in bindtextdomain(). Optional languages is a list of
strings, where each string is a language code.
If localedir is not given, then the default system locale directory is used.
2  If languages is not given, then the following environment variables are
searched: LANGUAGE, LC_ALL, LC_MESSAGES, and
LANG.  The first one returning a non-empty value is used for the
languages variable. The environment variables should contain a colon separated
list of languages, which will be split on the colon to produce the expected list
of language code strings.
find() then expands and normalizes the languages, and then iterates
through them, searching for an existing file built of these components:
localedir/language/LC_MESSAGES/domain.mo
The first such file name that exists is returned by find(). If no such
file is found, then None is returned. If all is given, it returns a list
of all file names, in the order in which they appear in the languages list or
the environment variables."
"gettext.translation(domain, localedir=None, languages=None, class_=None, fallback=False, codeset=None)","Return a *Translations instance based on the domain, localedir,
and languages, which are first passed to find() to get a list of the
associated .mo file paths.  Instances with identical .mo file
names are cached.  The actual class instantiated is class_ if
provided, otherwise GNUTranslations.  The class’s constructor must
take a single file object argument.  If provided, codeset will change
the charset used to encode translated strings in the
lgettext() and lngettext()
methods.
If multiple files are found, later files are used as fallbacks for earlier ones.
To allow setting the fallback, copy.copy() is used to clone each
translation object from the cache; the actual instance data is still shared with
the cache.
If no .mo file is found, this function raises OSError if
fallback is false (which is the default), and returns a
NullTranslations instance if fallback is true.

Changed in version 3.3: IOError used to be raised instead of OSError.


Deprecated since version 3.8, will be removed in version 3.10: The codeset parameter."
"gettext.install(domain, localedir=None, codeset=None, names=None)","This installs the function _() in Python’s builtins namespace, based on
domain, localedir, and codeset which are passed to the function
translation().
For the names parameter, please see the description of the translation
object’s install() method.
As seen below, you usually mark the strings in your application that are
candidates for translation, by wrapping them in a call to the _()
function, like this:
print(_('This string will be translated.'))


For convenience, you want the _() function to be installed in Python’s
builtins namespace, so it is easily accessible in all modules of your
application.

Deprecated since version 3.8, will be removed in version 3.10: The codeset parameter."
_parse(fp),"No-op in the base class, this method takes file object fp, and reads
the data from the file, initializing its message catalog.  If you have an
unsupported message catalog file format, you should override this method
to parse your format."
add_fallback(fallback),"Add fallback as the fallback object for the current translation object.
A translation object should consult the fallback if it cannot provide a
translation for a given message."
gettext(message),"If a fallback has been set, forward gettext() to the fallback.
Otherwise, return message.  Overridden in derived classes."
"ngettext(singular, plural, n)","If a fallback has been set, forward ngettext() to the fallback.
Otherwise, return singular if n is 1; return plural otherwise.
Overridden in derived classes."
"pgettext(context, message)","If a fallback has been set, forward pgettext() to the fallback.
Otherwise, return the translated message.  Overridden in derived classes.

New in version 3.8."
"npgettext(context, singular, plural, n)","If a fallback has been set, forward npgettext() to the fallback.
Otherwise, return the translated message.  Overridden in derived classes.

New in version 3.8."
lgettext(message),
"lngettext(singular, plural, n)","Equivalent to gettext() and ngettext(), but the translation
is returned as a byte string encoded in the preferred system encoding
if no encoding was explicitly set with set_output_charset().
Overridden in derived classes.

Warning
These methods should be avoided in Python 3.  See the warning for the
lgettext() function.


Deprecated since version 3.8, will be removed in version 3.10."
info(),"Return the “protected” _info variable, a dictionary containing
the metadata found in the message catalog file."
charset(),Return the encoding of the message catalog file.
output_charset(),"Return the encoding used to return translated messages in lgettext()
and lngettext().

Deprecated since version 3.8, will be removed in version 3.10."
set_output_charset(charset),"Change the encoding used to return translated messages.

Deprecated since version 3.8, will be removed in version 3.10."
install(names=None),"This method installs gettext() into the built-in namespace,
binding it to _.
If the names parameter is given, it must be a sequence containing the
names of functions you want to install in the builtins namespace in
addition to _().  Supported names are 'gettext', 'ngettext',
'pgettext', 'npgettext', 'lgettext', and 'lngettext'.
Note that this is only one way, albeit the most convenient way, to make
the _() function available to your application.  Because it affects
the entire application globally, and specifically the built-in namespace,
localized modules should never install _(). Instead, they should use
this code to make _() available to their module:
import gettext
t = gettext.translation('mymodule', ...)
_ = t.gettext


This puts _() only in the module’s global namespace and so only
affects calls within this module.

Changed in version 3.8: Added 'pgettext' and 'npgettext'."
gettext(message),"Look up the message id in the catalog and return the corresponding message
string, as a Unicode string.  If there is no entry in the catalog for the
message id, and a fallback has been set, the look up is forwarded to the
fallback’s gettext() method.  Otherwise, the
message id is returned."
"ngettext(singular, plural, n)","Do a plural-forms lookup of a message id.  singular is used as the message id
for purposes of lookup in the catalog, while n is used to determine which
plural form to use.  The returned message string is a Unicode string.
If the message id is not found in the catalog, and a fallback is specified,
the request is forwarded to the fallback’s ngettext()
method.  Otherwise, when n is 1 singular is returned, and plural is
returned in all other cases.
Here is an example:
n = len(os.listdir('.'))
cat = GNUTranslations(somefile)
message = cat.ngettext(
    'There is %(num)d file in this directory',
    'There are %(num)d files in this directory',
    n) % {'num': n}"
"pgettext(context, message)","Look up the context and message id in the catalog and return the
corresponding message string, as a Unicode string.  If there is no
entry in the catalog for the message id and context, and a fallback
has been set, the look up is forwarded to the fallback’s
pgettext() method.  Otherwise, the message id is returned.

New in version 3.8."
"npgettext(context, singular, plural, n)","Do a plural-forms lookup of a message id.  singular is used as the
message id for purposes of lookup in the catalog, while n is used to
determine which plural form to use.
If the message id for context is not found in the catalog, and a
fallback is specified, the request is forwarded to the fallback’s
npgettext() method.  Otherwise, when n is 1 singular is
returned, and plural is returned in all other cases.

New in version 3.8."
lgettext(message),
"lngettext(singular, plural, n)","Equivalent to gettext() and ngettext(), but the translation
is returned as a byte string encoded in the preferred system encoding
if no encoding  was explicitly set with
set_output_charset().

Warning
These methods should be avoided in Python 3.  See the warning for the
lgettext() function.


Deprecated since version 3.8, will be removed in version 3.10."
"locale.setlocale(category, locale=None)","If locale is given and not None, setlocale() modifies the locale
setting for the category. The available categories are listed in the data
description below. locale may be a string, or an iterable of two strings
(language code and encoding). If it’s an iterable, it’s converted to a locale
name using the locale aliasing engine. An empty string specifies the user’s
default settings. If the modification of the locale fails, the exception
Error is raised. If successful, the new locale setting is returned.
If locale is omitted or None, the current setting for category is
returned.
setlocale() is not thread-safe on most systems. Applications typically
start with a call of
import locale
locale.setlocale(locale.LC_ALL, '')


This sets the locale for all categories to the user’s default setting (typically
specified in the LANG environment variable).  If the locale is not
changed thereafter, using multithreading should not cause problems."
locale.localeconv(),"Returns the database of the local conventions as a dictionary. This dictionary
has the following strings as keys:







Category
Key
Meaning



LC_NUMERIC
'decimal_point'
Decimal point character.


'grouping'
Sequence of numbers specifying
which relative positions the
'thousands_sep' is
expected.  If the sequence is
terminated with
CHAR_MAX, no further
grouping is performed. If the
sequence terminates with a
0,  the last group size is
repeatedly used.


'thousands_sep'
Character used between groups.

LC_MONETARY
'int_curr_symbol'
International currency symbol.


'currency_symbol'
Local currency symbol.


'p_cs_precedes/n_cs_precedes'
Whether the currency symbol
precedes the value (for
positive resp. negative
values).


'p_sep_by_space/n_sep_by_space'
Whether the currency symbol is
separated from the value  by a
space (for positive resp.
negative values).


'mon_decimal_point'
Decimal point used for
monetary values.


'frac_digits'
Number of fractional digits
used in local formatting of
monetary values.


'int_frac_digits'
Number of fractional digits
used in international
formatting of monetary values.


'mon_thousands_sep'
Group separator used for
monetary values.


'mon_grouping'
Equivalent to 'grouping',
used for monetary values.


'positive_sign'
Symbol used to annotate a
positive monetary value.


'negative_sign'
Symbol used to annotate a
negative monetary value.


'p_sign_posn/n_sign_posn'
The position of the sign (for
positive resp. negative
values), see below.



All numeric values can be set to CHAR_MAX to indicate that there is no
value specified in this locale.
The possible values for 'p_sign_posn' and 'n_sign_posn' are given below.






Value
Explanation



0
Currency and value are surrounded by
parentheses.

1
The sign should precede the value and
currency symbol.

2
The sign should follow the value and
currency symbol.

3
The sign should immediately precede the
value.

4
The sign should immediately follow the
value.

CHAR_MAX
Nothing is specified in this locale.



The function sets temporarily the LC_CTYPE locale to the LC_NUMERIC
locale or the LC_MONETARY locale if locales are different and numeric or
monetary strings are non-ASCII. This temporary change affects other threads.

Changed in version 3.7: The function now sets temporarily the LC_CTYPE locale to the
LC_NUMERIC locale in some cases."
locale.nl_langinfo(option),"Return some locale-specific information as a string.  This function is not
available on all systems, and the set of possible options might also vary
across platforms.  The possible argument values are numbers, for which
symbolic constants are available in the locale module.
The nl_langinfo() function accepts one of the following keys.  Most
descriptions are taken from the corresponding description in the GNU C
library.


locale.CODESET¶
Get a string with the name of the character encoding used in the
selected locale.



locale.D_T_FMT¶
Get a string that can be used as a format string for time.strftime() to
represent date and time in a locale-specific way.



locale.D_FMT¶
Get a string that can be used as a format string for time.strftime() to
represent a date in a locale-specific way.



locale.T_FMT¶
Get a string that can be used as a format string for time.strftime() to
represent a time in a locale-specific way.



locale.T_FMT_AMPM¶
Get a format string for time.strftime() to represent time in the am/pm
format.



DAY_1 ... DAY_7
Get the name of the n-th day of the week.

Note
This follows the US convention of DAY_1 being Sunday, not the
international convention (ISO 8601) that Monday is the first day of the
week.




ABDAY_1 ... ABDAY_7
Get the abbreviated name of the n-th day of the week.



MON_1 ... MON_12
Get the name of the n-th month.



ABMON_1 ... ABMON_12
Get the abbreviated name of the n-th month.



locale.RADIXCHAR¶
Get the radix character (decimal dot, decimal comma, etc.).



locale.THOUSEP¶
Get the separator character for thousands (groups of three digits).



locale.YESEXPR¶
Get a regular expression that can be used with the regex function to
recognize a positive response to a yes/no question.

Note
The expression is in the syntax suitable for the regex() function
from the C library, which might differ from the syntax used in re.




locale.NOEXPR¶
Get a regular expression that can be used with the regex(3) function to
recognize a negative response to a yes/no question.



locale.CRNCYSTR¶
Get the currency symbol, preceded by “-” if the symbol should appear before
the value, “+” if the symbol should appear after the value, or “.” if the
symbol should replace the radix character.



locale.ERA¶
Get a string that represents the era used in the current locale.
Most locales do not define this value.  An example of a locale which does
define this value is the Japanese one.  In Japan, the traditional
representation of dates includes the name of the era corresponding to the
then-emperor’s reign.
Normally it should not be necessary to use this value directly. Specifying
the E modifier in their format strings causes the time.strftime()
function to use this information.  The format of the returned string is not
specified, and therefore you should not assume knowledge of it on different
systems.



locale.ERA_D_T_FMT¶
Get a format string for time.strftime() to represent date and time in a
locale-specific era-based way.



locale.ERA_D_FMT¶
Get a format string for time.strftime() to represent a date in a
locale-specific era-based way.



locale.ERA_T_FMT¶
Get a format string for time.strftime() to represent a time in a
locale-specific era-based way.



locale.ALT_DIGITS¶
Get a representation of up to 100 values used to represent the values
0 to 99."
locale.getdefaultlocale([envvars]),"Tries to determine the default locale settings and returns them as a tuple of
the form (language code, encoding).
According to POSIX, a program which has not called setlocale(LC_ALL, '')
runs using the portable 'C' locale.  Calling setlocale(LC_ALL, '') lets
it use the default locale as defined by the LANG variable.  Since we
do not want to interfere with the current locale setting we thus emulate the
behavior in the way described above.
To maintain compatibility with other platforms, not only the LANG
variable is tested, but a list of variables given as envvars parameter.  The
first found to be defined will be used.  envvars defaults to the search
path used in GNU gettext; it must always contain the variable name
'LANG'.  The GNU gettext search path contains 'LC_ALL',
'LC_CTYPE', 'LANG' and 'LANGUAGE', in that order.
Except for the code 'C', the language code corresponds to RFC 1766.
language code and encoding may be None if their values cannot be
determined."
locale.getlocale(category=LC_CTYPE),"Returns the current setting for the given locale category as sequence containing
language code, encoding. category may be one of the LC_* values
except LC_ALL.  It defaults to LC_CTYPE.
Except for the code 'C', the language code corresponds to RFC 1766.
language code and encoding may be None if their values cannot be
determined."
locale.getpreferredencoding(do_setlocale=True),"Return the encoding used for text data, according to user preferences.  User
preferences are expressed differently on different systems, and might not be
available programmatically on some systems, so this function only returns a
guess.
On some systems, it is necessary to invoke setlocale() to obtain the user
preferences, so this function is not thread-safe. If invoking setlocale is not
necessary or desired, do_setlocale should be set to False.
On Android or in the UTF-8 mode (-X utf8 option), always
return 'UTF-8', the locale and the do_setlocale argument are ignored.

Changed in version 3.7: The function now always returns UTF-8 on Android or if the UTF-8 mode
is enabled."
locale.normalize(localename),"Returns a normalized locale code for the given locale name.  The returned locale
code is formatted for use with setlocale().  If normalization fails, the
original name is returned unchanged.
If the given encoding is not known, the function defaults to the default
encoding for the locale code just like setlocale()."
locale.resetlocale(category=LC_ALL),"Sets the locale for category to the default setting.
The default setting is determined by calling getdefaultlocale().
category defaults to LC_ALL."
"locale.strcoll(string1, string2)","Compares two strings according to the current LC_COLLATE setting. As
any other compare function, returns a negative, or a positive value, or 0,
depending on whether string1 collates before or after string2 or is equal to
it."
locale.strxfrm(string),"Transforms a string to one that can be used in locale-aware
comparisons.  For example, strxfrm(s1) < strxfrm(s2) is
equivalent to strcoll(s1, s2) < 0.  This function can be used
when the same string is compared repeatedly, e.g. when collating a
sequence of strings."
"locale.format_string(format, val, grouping=False, monetary=False)","Formats a number val according to the current LC_NUMERIC setting.
The format follows the conventions of the % operator.  For floating point
values, the decimal point is modified if appropriate.  If grouping is true,
also takes the grouping into account.
If monetary is true, the conversion uses monetary thousands separator and
grouping strings.
Processes formatting specifiers as in format % val, but takes the current
locale settings into account.

Changed in version 3.7: The monetary keyword parameter was added."
"locale.format(format, val, grouping=False, monetary=False)","Please note that this function works like format_string() but will
only work for exactly one %char specifier.  For example, '%f' and
'%.0f' are both valid specifiers, but '%f KiB' is not.
For whole format strings, use format_string().

Deprecated since version 3.7: Use format_string() instead."
"locale.currency(val, symbol=True, grouping=False, international=False)","Formats a number val according to the current LC_MONETARY settings.
The returned string includes the currency symbol if symbol is true, which is
the default. If grouping is true (which is not the default), grouping is done
with the value. If international is true (which is not the default), the
international currency symbol is used.
Note that this function will not work with the ‘C’ locale, so you have to set a
locale via setlocale() first."
locale.str(float),"Formats a floating point number using the same format as the built-in function
str(float), but takes the decimal point into account."
locale.delocalize(string),"Converts a string into a normalized number string, following the
LC_NUMERIC settings.

New in version 3.5."
locale.atof(string),"Converts a string to a floating point number, following the LC_NUMERIC
settings."
locale.atoi(string),"Converts a string to an integer, following the LC_NUMERIC conventions."
locale.gettext(msg),
"locale.dgettext(domain, msg)",
"locale.dcgettext(domain, msg, category)",
locale.textdomain(domain),
"locale.bindtextdomain(domain, dir)",
turtle.forward(distance),"Parameters
distance – a number (integer or float)


Move the turtle forward by the specified distance, in the direction the
turtle is headed.
>>> turtle.position()
(0.00,0.00)
>>> turtle.forward(25)
>>> turtle.position()
(25.00,0.00)
>>> turtle.forward(-75)
>>> turtle.position()
(-50.00,0.00)"
turtle.back(distance),"Parameters
distance – a number


Move the turtle backward by distance, opposite to the direction the
turtle is headed.  Do not change the turtle’s heading.
>>> turtle.position()
(0.00,0.00)
>>> turtle.backward(30)
>>> turtle.position()
(-30.00,0.00)"
turtle.right(angle),"Parameters
angle – a number (integer or float)


Turn turtle right by angle units.  (Units are by default degrees, but
can be set via the degrees() and radians() functions.)  Angle
orientation depends on the turtle mode, see mode().
>>> turtle.heading()
22.0
>>> turtle.right(45)
>>> turtle.heading()
337.0"
turtle.left(angle),"Parameters
angle – a number (integer or float)


Turn turtle left by angle units.  (Units are by default degrees, but
can be set via the degrees() and radians() functions.)  Angle
orientation depends on the turtle mode, see mode().
>>> turtle.heading()
22.0
>>> turtle.left(45)
>>> turtle.heading()
67.0"
"turtle.goto(x, y=None)","Parameters

x – a number or a pair/vector of numbers
y – a number or None



If y is None, x must be a pair of coordinates or a Vec2D
(e.g. as returned by pos()).
Move turtle to an absolute position.  If the pen is down, draw line.  Do
not change the turtle’s orientation.
 >>> tp = turtle.pos()
 >>> tp
 (0.00,0.00)
 >>> turtle.setpos(60,30)
 >>> turtle.pos()
 (60.00,30.00)
 >>> turtle.setpos((20,80))
 >>> turtle.pos()
 (20.00,80.00)
 >>> turtle.setpos(tp)
 >>> turtle.pos()
 (0.00,0.00)"
turtle.setx(x),"Parameters
x – a number (integer or float)


Set the turtle’s first coordinate to x, leave second coordinate
unchanged.
>>> turtle.position()
(0.00,240.00)
>>> turtle.setx(10)
>>> turtle.position()
(10.00,240.00)"
turtle.sety(y),"Parameters
y – a number (integer or float)


Set the turtle’s second coordinate to y, leave first coordinate unchanged.
>>> turtle.position()
(0.00,40.00)
>>> turtle.sety(-10)
>>> turtle.position()
(0.00,-10.00)"
turtle.setheading(to_angle),"Parameters
to_angle – a number (integer or float)


Set the orientation of the turtle to to_angle.  Here are some common
directions in degrees:






standard mode
logo mode



0 - east
0 - north

90 - north
90 - east

180 - west
180 - south

270 - south
270 - west



>>> turtle.setheading(90)
>>> turtle.heading()
90.0"
turtle.home(),"Move turtle to the origin – coordinates (0,0) – and set its heading to
its start-orientation (which depends on the mode, see mode()).
>>> turtle.heading()
90.0
>>> turtle.position()
(0.00,-10.00)
>>> turtle.home()
>>> turtle.position()
(0.00,0.00)
>>> turtle.heading()
0.0"
"turtle.circle(radius, extent=None, steps=None)","Parameters

radius – a number
extent – a number (or None)
steps – an integer (or None)



Draw a circle with given radius.  The center is radius units left of
the turtle; extent – an angle – determines which part of the circle
is drawn.  If extent is not given, draw the entire circle.  If extent
is not a full circle, one endpoint of the arc is the current pen
position.  Draw the arc in counterclockwise direction if radius is
positive, otherwise in clockwise direction.  Finally the direction of the
turtle is changed by the amount of extent.
As the circle is approximated by an inscribed regular polygon, steps
determines the number of steps to use.  If not given, it will be
calculated automatically.  May be used to draw regular polygons.
>>> turtle.home()
>>> turtle.position()
(0.00,0.00)
>>> turtle.heading()
0.0
>>> turtle.circle(50)
>>> turtle.position()
(-0.00,0.00)
>>> turtle.heading()
0.0
>>> turtle.circle(120, 180)  # draw a semicircle
>>> turtle.position()
(0.00,240.00)
>>> turtle.heading()
180.0"
"turtle.dot(size=None, *color)","Parameters

size – an integer >= 1 (if given)
color – a colorstring or a numeric color tuple



Draw a circular dot with diameter size, using color.  If size is
not given, the maximum of pensize+4 and 2*pensize is used.
>>> turtle.home()
>>> turtle.dot()
>>> turtle.fd(50); turtle.dot(20, ""blue""); turtle.fd(50)
>>> turtle.position()
(100.00,-0.00)
>>> turtle.heading()
0.0"
turtle.stamp(),"Stamp a copy of the turtle shape onto the canvas at the current turtle
position.  Return a stamp_id for that stamp, which can be used to delete
it by calling clearstamp(stamp_id).
>>> turtle.color(""blue"")
>>> turtle.stamp()
11
>>> turtle.fd(50)"
turtle.clearstamp(stampid),"Parameters
stampid – an integer, must be return value of previous
stamp() call


Delete stamp with given stampid.
>>> turtle.position()
(150.00,-0.00)
>>> turtle.color(""blue"")
>>> astamp = turtle.stamp()
>>> turtle.fd(50)
>>> turtle.position()
(200.00,-0.00)
>>> turtle.clearstamp(astamp)
>>> turtle.position()
(200.00,-0.00)"
turtle.clearstamps(n=None),"Parameters
n – an integer (or None)


Delete all or first/last n of turtle’s stamps.  If n is None, delete
all stamps, if n > 0 delete first n stamps, else if n < 0 delete
last n stamps.
>>> for i in range(8):
...     turtle.stamp(); turtle.fd(30)
13
14
15
16
17
18
19
20
>>> turtle.clearstamps(2)
>>> turtle.clearstamps(-2)
>>> turtle.clearstamps()"
turtle.undo(),"Undo (repeatedly) the last turtle action(s).  Number of available
undo actions is determined by the size of the undobuffer.
>>> for i in range(4):
...     turtle.fd(50); turtle.lt(80)
...
>>> for i in range(8):
...     turtle.undo()"
turtle.speed(speed=None),"Parameters
speed – an integer in the range 0..10 or a speedstring (see below)


Set the turtle’s speed to an integer value in the range 0..10.  If no
argument is given, return current speed.
If input is a number greater than 10 or smaller than 0.5, speed is set
to 0.  Speedstrings are mapped to speedvalues as follows:

“fastest”:  0
“fast”:  10
“normal”:  6
“slow”:  3
“slowest”:  1

Speeds from 1 to 10 enforce increasingly faster animation of line drawing
and turtle turning.
Attention: speed = 0 means that no animation takes
place. forward/back makes turtle jump and likewise left/right make the
turtle turn instantly.
>>> turtle.speed()
3
>>> turtle.speed('normal')
>>> turtle.speed()
6
>>> turtle.speed(9)
>>> turtle.speed()
9"
turtle.position(),"Return the turtle’s current location (x,y) (as a Vec2D vector).
>>> turtle.pos()
(440.00,-0.00)"
"turtle.towards(x, y=None)","Parameters

x – a number or a pair/vector of numbers or a turtle instance
y – a number if x is a number, else None



Return the angle between the line from turtle position to position specified
by (x,y), the vector or the other turtle.  This depends on the turtle’s start
orientation which depends on the mode - “standard”/”world” or “logo”).
>>> turtle.goto(10, 10)
>>> turtle.towards(0,0)
225.0"
turtle.xcor(),"Return the turtle’s x coordinate.
>>> turtle.home()
>>> turtle.left(50)
>>> turtle.forward(100)
>>> turtle.pos()
(64.28,76.60)
>>> print(round(turtle.xcor(), 5))
64.27876"
turtle.ycor(),"Return the turtle’s y coordinate.
>>> turtle.home()
>>> turtle.left(60)
>>> turtle.forward(100)
>>> print(turtle.pos())
(50.00,86.60)
>>> print(round(turtle.ycor(), 5))
86.60254"
turtle.heading(),"Return the turtle’s current heading (value depends on the turtle mode, see
mode()).
>>> turtle.home()
>>> turtle.left(67)
>>> turtle.heading()
67.0"
"turtle.distance(x, y=None)","Parameters

x – a number or a pair/vector of numbers or a turtle instance
y – a number if x is a number, else None



Return the distance from the turtle to (x,y), the given vector, or the given
other turtle, in turtle step units.
>>> turtle.home()
>>> turtle.distance(30,40)
50.0
>>> turtle.distance((30,40))
50.0
>>> joe = Turtle()
>>> joe.forward(77)
>>> turtle.distance(joe)
77.0"
turtle.degrees(fullcircle=360.0),"Parameters
fullcircle – a number


Set angle measurement units, i.e. set number of “degrees” for a full circle.
Default value is 360 degrees.
>>> turtle.home()
>>> turtle.left(90)
>>> turtle.heading()
90.0

Change angle measurement unit to grad (also known as gon,
grade, or gradian and equals 1/100-th of the right angle.)
>>> turtle.degrees(400.0)
>>> turtle.heading()
100.0
>>> turtle.degrees(360)
>>> turtle.heading()
90.0"
turtle.radians(),"Set the angle measurement units to radians.  Equivalent to
degrees(2*math.pi).
>>> turtle.home()
>>> turtle.left(90)
>>> turtle.heading()
90.0
>>> turtle.radians()
>>> turtle.heading()
1.5707963267948966"
turtle.pendown(),Pull the pen down – drawing when moving.
turtle.penup(),Pull the pen up – no drawing when moving.
turtle.pensize(width=None),"Parameters
width – a positive number


Set the line thickness to width or return it.  If resizemode is set to
“auto” and turtleshape is a polygon, that polygon is drawn with the same line
thickness.  If no argument is given, the current pensize is returned.
>>> turtle.pensize()
1
>>> turtle.pensize(10)   # from here on lines of width 10 are drawn"
"turtle.pen(pen=None, **pendict)","Parameters

pen – a dictionary with some or all of the below listed keys
pendict – one or more keyword-arguments with the below listed keys as keywords



Return or set the pen’s attributes in a “pen-dictionary” with the following
key/value pairs:

“shown”: True/False
“pendown”: True/False
“pencolor”: color-string or color-tuple
“fillcolor”: color-string or color-tuple
“pensize”: positive number
“speed”: number in range 0..10
“resizemode”: “auto” or “user” or “noresize”
“stretchfactor”: (positive number, positive number)
“outline”: positive number
“tilt”: number

This dictionary can be used as argument for a subsequent call to pen()
to restore the former pen-state.  Moreover one or more of these attributes
can be provided as keyword-arguments.  This can be used to set several pen
attributes in one statement.
>>> turtle.pen(fillcolor=""black"", pencolor=""red"", pensize=10)
>>> sorted(turtle.pen().items())
[('fillcolor', 'black'), ('outline', 1), ('pencolor', 'red'),
 ('pendown', True), ('pensize', 10), ('resizemode', 'noresize'),
 ('shearfactor', 0.0), ('shown', True), ('speed', 9),
 ('stretchfactor', (1.0, 1.0)), ('tilt', 0.0)]
>>> penstate=turtle.pen()
>>> turtle.color(""yellow"", """")
>>> turtle.penup()
>>> sorted(turtle.pen().items())[:3]
[('fillcolor', ''), ('outline', 1), ('pencolor', 'yellow')]
>>> turtle.pen(penstate, fillcolor=""green"")
>>> sorted(turtle.pen().items())[:3]
[('fillcolor', 'green'), ('outline', 1), ('pencolor', 'red')]"
turtle.isdown(),"Return True if pen is down, False if it’s up.
>>> turtle.penup()
>>> turtle.isdown()
False
>>> turtle.pendown()
>>> turtle.isdown()
True"
turtle.pencolor(*args),"Return or set the pencolor.
Four input formats are allowed:

pencolor()Return the current pencolor as color specification string or
as a tuple (see example).  May be used as input to another
color/pencolor/fillcolor call.

pencolor(colorstring)Set pencolor to colorstring, which is a Tk color specification string,
such as ""red"", ""yellow"", or ""#33cc8c"".

pencolor((r, g, b))Set pencolor to the RGB color represented by the tuple of r, g, and
b.  Each of r, g, and b must be in the range 0..colormode, where
colormode is either 1.0 or 255 (see colormode()).

pencolor(r, g, b)
Set pencolor to the RGB color represented by r, g, and b.  Each of
r, g, and b must be in the range 0..colormode.

If turtleshape is a polygon, the outline of that polygon is drawn with the
newly set pencolor.


 >>> colormode()
 1.0
 >>> turtle.pencolor()
 'red'
 >>> turtle.pencolor(""brown"")
 >>> turtle.pencolor()
 'brown'
 >>> tup = (0.2, 0.8, 0.55)
 >>> turtle.pencolor(tup)
 >>> turtle.pencolor()
 (0.2, 0.8, 0.5490196078431373)
 >>> colormode(255)
 >>> turtle.pencolor()
 (51.0, 204.0, 140.0)
 >>> turtle.pencolor('#32c18f')
 >>> turtle.pencolor()
 (50.0, 193.0, 143.0)"
turtle.fillcolor(*args),"Return or set the fillcolor.
Four input formats are allowed:

fillcolor()Return the current fillcolor as color specification string, possibly
in tuple format (see example).  May be used as input to another
color/pencolor/fillcolor call.

fillcolor(colorstring)Set fillcolor to colorstring, which is a Tk color specification string,
such as ""red"", ""yellow"", or ""#33cc8c"".

fillcolor((r, g, b))Set fillcolor to the RGB color represented by the tuple of r, g, and
b.  Each of r, g, and b must be in the range 0..colormode, where
colormode is either 1.0 or 255 (see colormode()).

fillcolor(r, g, b)
Set fillcolor to the RGB color represented by r, g, and b.  Each of
r, g, and b must be in the range 0..colormode.

If turtleshape is a polygon, the interior of that polygon is drawn
with the newly set fillcolor.


 >>> turtle.fillcolor(""violet"")
 >>> turtle.fillcolor()
 'violet'
 >>> turtle.pencolor()
 (50.0, 193.0, 143.0)
 >>> turtle.fillcolor((50, 193, 143))  # Integers, not floats
 >>> turtle.fillcolor()
 (50.0, 193.0, 143.0)
 >>> turtle.fillcolor('#ffffff')
 >>> turtle.fillcolor()
 (255.0, 255.0, 255.0)"
turtle.color(*args),"Return or set pencolor and fillcolor.
Several input formats are allowed.  They use 0 to 3 arguments as
follows:

color()Return the current pencolor and the current fillcolor as a pair of color
specification strings or tuples as returned by pencolor() and
fillcolor().

color(colorstring), color((r,g,b)), color(r,g,b)Inputs as in pencolor(), set both, fillcolor and pencolor, to the
given value.

color(colorstring1, colorstring2), color((r1,g1,b1), (r2,g2,b2))
Equivalent to pencolor(colorstring1) and fillcolor(colorstring2)
and analogously if the other input format is used.

If turtleshape is a polygon, outline and interior of that polygon is drawn
with the newly set colors.


 >>> turtle.color(""red"", ""green"")
 >>> turtle.color()
 ('red', 'green')
 >>> color(""#285078"", ""#a0c8f0"")
 >>> color()
 ((40.0, 80.0, 120.0), (160.0, 200.0, 240.0))"
turtle.filling(),"Return fillstate (True if filling, False else).
 >>> turtle.begin_fill()
 >>> if turtle.filling():
 ...    turtle.pensize(5)
 ... else:
 ...    turtle.pensize(3)"
turtle.begin_fill(),To be called just before drawing a shape to be filled.
turtle.end_fill(),"Fill the shape drawn after the last call to begin_fill().
Whether or not overlap regions for self-intersecting polygons
or multiple shapes are filled depends on the operating system graphics,
type of overlap, and number of overlaps.  For example, the Turtle star
above may be either all yellow or have some white regions.
>>> turtle.color(""black"", ""red"")
>>> turtle.begin_fill()
>>> turtle.circle(80)
>>> turtle.end_fill()"
turtle.reset(),"Delete the turtle’s drawings from the screen, re-center the turtle and set
variables to the default values.
>>> turtle.goto(0,-22)
>>> turtle.left(100)
>>> turtle.position()
(0.00,-22.00)
>>> turtle.heading()
100.0
>>> turtle.reset()
>>> turtle.position()
(0.00,0.00)
>>> turtle.heading()
0.0"
turtle.clear(),"Delete the turtle’s drawings from the screen.  Do not move turtle.  State and
position of the turtle as well as drawings of other turtles are not affected."
"turtle.write(arg, move=False, align=""left"", font=(""Arial"", 8, ""normal""))","Parameters

arg – object to be written to the TurtleScreen
move – True/False
align – one of the strings “left”, “center” or right”
font – a triple (fontname, fontsize, fonttype)



Write text - the string representation of arg - at the current turtle
position according to align (“left”, “center” or right”) and with the given
font.  If move is true, the pen is moved to the bottom-right corner of the
text.  By default, move is False.
>>> turtle.write(""Home = "", True, align=""center"")
>>> turtle.write((0,0), True)"
turtle.hideturtle(),"Make the turtle invisible.  It’s a good idea to do this while you’re in the
middle of doing some complex drawing, because hiding the turtle speeds up the
drawing observably.
>>> turtle.hideturtle()"
turtle.showturtle(),"Make the turtle visible.
>>> turtle.showturtle()"
turtle.isvisible(),"Return True if the Turtle is shown, False if it’s hidden.
>>> turtle.hideturtle()
>>> turtle.isvisible()
False
>>> turtle.showturtle()
>>> turtle.isvisible()
True"
turtle.shape(name=None),"Parameters
name – a string which is a valid shapename


Set turtle shape to shape with given name or, if name is not given, return
name of current shape.  Shape with name must exist in the TurtleScreen’s
shape dictionary.  Initially there are the following polygon shapes: “arrow”,
“turtle”, “circle”, “square”, “triangle”, “classic”.  To learn about how to
deal with shapes see Screen method register_shape().
>>> turtle.shape()
'classic'
>>> turtle.shape(""turtle"")
>>> turtle.shape()
'turtle'"
turtle.resizemode(rmode=None),"Parameters
rmode – one of the strings “auto”, “user”, “noresize”


Set resizemode to one of the values: “auto”, “user”, “noresize”.  If rmode
is not given, return current resizemode.  Different resizemodes have the
following effects:

“auto”: adapts the appearance of the turtle corresponding to the value of pensize.
“user”: adapts the appearance of the turtle according to the values of
stretchfactor and outlinewidth (outline), which are set by
shapesize().
“noresize”: no adaption of the turtle’s appearance takes place.

resizemode(“user”) is called by shapesize() when used with arguments.
>>> turtle.resizemode()
'noresize'
>>> turtle.resizemode(""auto"")
>>> turtle.resizemode()
'auto'"
"turtle.shapesize(stretch_wid=None, stretch_len=None, outline=None)","Parameters

stretch_wid – positive number
stretch_len – positive number
outline – positive number



Return or set the pen’s attributes x/y-stretchfactors and/or outline.  Set
resizemode to “user”.  If and only if resizemode is set to “user”, the turtle
will be displayed stretched according to its stretchfactors: stretch_wid is
stretchfactor perpendicular to its orientation, stretch_len is
stretchfactor in direction of its orientation, outline determines the width
of the shapes’s outline.
>>> turtle.shapesize()
(1.0, 1.0, 1)
>>> turtle.resizemode(""user"")
>>> turtle.shapesize(5, 5, 12)
>>> turtle.shapesize()
(5, 5, 12)
>>> turtle.shapesize(outline=8)
>>> turtle.shapesize()
(5, 5, 8)"
turtle.shearfactor(shear=None),"Parameters
shear – number (optional)


Set or return the current shearfactor. Shear the turtleshape according to
the given shearfactor shear, which is the tangent of the shear angle.
Do not change the turtle’s heading (direction of movement).
If shear is not given: return the current shearfactor, i. e. the
tangent of the shear angle, by which lines parallel to the
heading of the turtle are sheared.
 >>> turtle.shape(""circle"")
 >>> turtle.shapesize(5,2)
 >>> turtle.shearfactor(0.5)
 >>> turtle.shearfactor()
 0.5"
turtle.tilt(angle),"Parameters
angle – a number


Rotate the turtleshape by angle from its current tilt-angle, but do not
change the turtle’s heading (direction of movement).
>>> turtle.reset()
>>> turtle.shape(""circle"")
>>> turtle.shapesize(5,2)
>>> turtle.tilt(30)
>>> turtle.fd(50)
>>> turtle.tilt(30)
>>> turtle.fd(50)"
turtle.settiltangle(angle),"Parameters
angle – a number


Rotate the turtleshape to point in the direction specified by angle,
regardless of its current tilt-angle.  Do not change the turtle’s heading
(direction of movement).
>>> turtle.reset()
>>> turtle.shape(""circle"")
>>> turtle.shapesize(5,2)
>>> turtle.settiltangle(45)
>>> turtle.fd(50)
>>> turtle.settiltangle(-45)
>>> turtle.fd(50)



Deprecated since version 3.1."
turtle.tiltangle(angle=None),"Parameters
angle – a number (optional)


Set or return the current tilt-angle. If angle is given, rotate the
turtleshape to point in the direction specified by angle,
regardless of its current tilt-angle. Do not change the turtle’s
heading (direction of movement).
If angle is not given: return the current tilt-angle, i. e. the angle
between the orientation of the turtleshape and the heading of the
turtle (its direction of movement).
>>> turtle.reset()
>>> turtle.shape(""circle"")
>>> turtle.shapesize(5,2)
>>> turtle.tilt(45)
>>> turtle.tiltangle()
45.0"
"turtle.shapetransform(t11=None, t12=None, t21=None, t22=None)","Parameters

t11 – a number (optional)
t12 – a number (optional)
t21 – a number (optional)
t12 – a number (optional)



Set or return the current transformation matrix of the turtle shape.
If none of the matrix elements are given, return the transformation
matrix as a tuple of 4 elements.
Otherwise set the given elements and transform the turtleshape
according to the matrix consisting of first row t11, t12 and
second row t21, 22. The determinant t11 * t22 - t12 * t21 must not be
zero, otherwise an error is raised.
Modify stretchfactor, shearfactor and tiltangle according to the
given matrix.
>>> turtle = Turtle()
>>> turtle.shape(""square"")
>>> turtle.shapesize(4,2)
>>> turtle.shearfactor(-0.5)
>>> turtle.shapetransform()
(4.0, -1.0, -0.0, 2.0)"
turtle.get_shapepoly(),"Return the current shape polygon as tuple of coordinate pairs. This
can be used to define a new shape or components of a compound shape.
>>> turtle.shape(""square"")
>>> turtle.shapetransform(4, -1, 0, 2)
>>> turtle.get_shapepoly()
((50, -20), (30, 20), (-50, 20), (-30, -20))"
"turtle.onclick(fun, btn=1, add=None)","Parameters

fun – a function with two arguments which will be called with the
coordinates of the clicked point on the canvas
btn – number of the mouse-button, defaults to 1 (left mouse button)
add – True or False – if True, a new binding will be
added, otherwise it will replace a former binding



Bind fun to mouse-click events on this turtle.  If fun is None,
existing bindings are removed.  Example for the anonymous turtle, i.e. the
procedural way:
>>> def turn(x, y):
...     left(180)
...
>>> onclick(turn)  # Now clicking into the turtle will turn it.
>>> onclick(None)  # event-binding will be removed"
"turtle.onrelease(fun, btn=1, add=None)","Parameters

fun – a function with two arguments which will be called with the
coordinates of the clicked point on the canvas
btn – number of the mouse-button, defaults to 1 (left mouse button)
add – True or False – if True, a new binding will be
added, otherwise it will replace a former binding



Bind fun to mouse-button-release events on this turtle.  If fun is
None, existing bindings are removed.
>>> class MyTurtle(Turtle):
...     def glow(self,x,y):
...         self.fillcolor(""red"")
...     def unglow(self,x,y):
...         self.fillcolor("""")
...
>>> turtle = MyTurtle()
>>> turtle.onclick(turtle.glow)     # clicking on turtle turns fillcolor red,
>>> turtle.onrelease(turtle.unglow) # releasing turns it to transparent."
"turtle.ondrag(fun, btn=1, add=None)","Parameters

fun – a function with two arguments which will be called with the
coordinates of the clicked point on the canvas
btn – number of the mouse-button, defaults to 1 (left mouse button)
add – True or False – if True, a new binding will be
added, otherwise it will replace a former binding



Bind fun to mouse-move events on this turtle.  If fun is None,
existing bindings are removed.
Remark: Every sequence of mouse-move-events on a turtle is preceded by a
mouse-click event on that turtle.
>>> turtle.ondrag(turtle.goto)


Subsequently, clicking and dragging the Turtle will move it across
the screen thereby producing handdrawings (if pen is down)."
turtle.begin_poly(),"Start recording the vertices of a polygon.  Current turtle position is first
vertex of polygon."
turtle.end_poly(),"Stop recording the vertices of a polygon.  Current turtle position is last
vertex of polygon.  This will be connected with the first vertex."
turtle.get_poly(),"Return the last recorded polygon.
>>> turtle.home()
>>> turtle.begin_poly()
>>> turtle.fd(100)
>>> turtle.left(20)
>>> turtle.fd(30)
>>> turtle.left(60)
>>> turtle.fd(50)
>>> turtle.end_poly()
>>> p = turtle.get_poly()
>>> register_shape(""myFavouriteShape"", p)"
turtle.clone(),"Create and return a clone of the turtle with same position, heading and
turtle properties.
>>> mick = Turtle()
>>> joe = mick.clone()"
turtle.getturtle(),"Return the Turtle object itself.  Only reasonable use: as a function to
return the “anonymous turtle”:
>>> pet = getturtle()
>>> pet.fd(50)
>>> pet
<turtle.Turtle object at 0x...>"
turtle.getscreen(),"Return the TurtleScreen object the turtle is drawing on.
TurtleScreen methods can then be called for that object.
>>> ts = turtle.getscreen()
>>> ts
<turtle._Screen object at 0x...>
>>> ts.bgcolor(""pink"")"
turtle.setundobuffer(size),"Parameters
size – an integer or None


Set or disable undobuffer.  If size is an integer an empty undobuffer of
given size is installed.  size gives the maximum number of turtle actions
that can be undone by the undo() method/function.  If size is
None, the undobuffer is disabled.
>>> turtle.setundobuffer(42)"
turtle.undobufferentries(),"Return number of entries in the undobuffer.
>>> while undobufferentries():
...     undo()"
turtle.bgcolor(*args),"Parameters
args – a color string or three numbers in the range 0..colormode or a
3-tuple of such numbers


Set or return background color of the TurtleScreen.
>>> screen.bgcolor(""orange"")
>>> screen.bgcolor()
'orange'
>>> screen.bgcolor(""#800080"")
>>> screen.bgcolor()
(128.0, 0.0, 128.0)"
turtle.bgpic(picname=None),"Parameters
picname – a string, name of a gif-file or ""nopic"", or None


Set background image or return name of current backgroundimage.  If picname
is a filename, set the corresponding image as background.  If picname is
""nopic"", delete background image, if present.  If picname is None,
return the filename of the current backgroundimage.
>>> screen.bgpic()
'nopic'
>>> screen.bgpic(""landscape.gif"")
>>> screen.bgpic()
""landscape.gif"""
turtle.clear(,"Delete all drawings and all turtles from the TurtleScreen.  Reset the now
empty TurtleScreen to its initial state: white background, no background
image, no event bindings and tracing on.

Note
This TurtleScreen method is available as a global function only under the
name clearscreen.  The global function clear is a different one
derived from the Turtle method clear."
turtle.reset(,"Reset all Turtles on the Screen to their initial state.

Note
This TurtleScreen method is available as a global function only under the
name resetscreen.  The global function reset is another one
derived from the Turtle method reset."
"turtle.screensize(canvwidth=None, canvheight=None, bg=None)","Parameters

canvwidth – positive integer, new width of canvas in pixels
canvheight – positive integer, new height of canvas in pixels
bg – colorstring or color-tuple, new background color



If no arguments are given, return current (canvaswidth, canvasheight).  Else
resize the canvas the turtles are drawing on.  Do not alter the drawing
window.  To observe hidden parts of the canvas, use the scrollbars. With this
method, one can make visible those parts of a drawing which were outside the
canvas before.
>>> screen.screensize()
(400, 300)
>>> screen.screensize(2000,1500)
>>> screen.screensize()
(2000, 1500)


e.g. to search for an erroneously escaped turtle ;-)"
"turtle.setworldcoordinates(llx, lly, urx, ury)","Parameters

llx – a number, x-coordinate of lower left corner of canvas
lly – a number, y-coordinate of lower left corner of canvas
urx – a number, x-coordinate of upper right corner of canvas
ury – a number, y-coordinate of upper right corner of canvas



Set up user-defined coordinate system and switch to mode “world” if
necessary.  This performs a screen.reset().  If mode “world” is already
active, all drawings are redrawn according to the new coordinates.
ATTENTION: in user-defined coordinate systems angles may appear
distorted.
>>> screen.reset()
>>> screen.setworldcoordinates(-50,-7.5,50,7.5)
>>> for _ in range(72):
...     left(10)
...
>>> for _ in range(8):
...     left(45); fd(2)   # a regular octagon"
turtle.delay(delay=None),"Parameters
delay – positive integer


Set or return the drawing delay in milliseconds.  (This is approximately
the time interval between two consecutive canvas updates.)  The longer the
drawing delay, the slower the animation.
Optional argument:
>>> screen.delay()
10
>>> screen.delay(5)
>>> screen.delay()
5"
"turtle.tracer(n=None, delay=None)","Parameters

n – nonnegative integer
delay – nonnegative integer



Turn turtle animation on/off and set delay for update drawings.  If
n is given, only each n-th regular screen update is really
performed.  (Can be used to accelerate the drawing of complex
graphics.)  When called without arguments, returns the currently
stored value of n. Second argument sets delay value (see
delay()).
>>> screen.tracer(8, 25)
>>> dist = 2
>>> for i in range(200):
...     fd(dist)
...     rt(90)
...     dist += 2"
turtle.update(),Perform a TurtleScreen update. To be used when tracer is turned off.
"turtle.listen(xdummy=None, ydummy=None)","Set focus on TurtleScreen (in order to collect key-events).  Dummy arguments
are provided in order to be able to pass listen() to the onclick method."
"turtle.onkey(fun, key)","Parameters

fun – a function with no arguments or None
key – a string: key (e.g. “a”) or key-symbol (e.g. “space”)



Bind fun to key-release event of key.  If fun is None, event bindings
are removed. Remark: in order to be able to register key-events, TurtleScreen
must have the focus. (See method listen().)
>>> def f():
...     fd(50)
...     lt(60)
...
>>> screen.onkey(f, ""Up"")
>>> screen.listen()"
"turtle.onkeypress(fun, key=None)","Parameters

fun – a function with no arguments or None
key – a string: key (e.g. “a”) or key-symbol (e.g. “space”)



Bind fun to key-press event of key if key is given,
or to any key-press-event if no key is given.
Remark: in order to be able to register key-events, TurtleScreen
must have focus. (See method listen().)
>>> def f():
...     fd(50)
...
>>> screen.onkey(f, ""Up"")
>>> screen.listen()"
"turtle.onclick(fun, btn=1, add=None","Parameters

fun – a function with two arguments which will be called with the
coordinates of the clicked point on the canvas
btn – number of the mouse-button, defaults to 1 (left mouse button)
add – True or False – if True, a new binding will be
added, otherwise it will replace a former binding



Bind fun to mouse-click events on this screen.  If fun is None,
existing bindings are removed.
Example for a TurtleScreen instance named screen and a Turtle instance
named turtle:
>>> screen.onclick(turtle.goto) # Subsequently clicking into the TurtleScreen will
>>>                             # make the turtle move to the clicked point.
>>> screen.onclick(None)        # remove event binding again



Note
This TurtleScreen method is available as a global function only under the
name onscreenclick.  The global function onclick is another one
derived from the Turtle method onclick."
"turtle.ontimer(fun, t=0)","Parameters

fun – a function with no arguments
t – a number >= 0



Install a timer that calls fun after t milliseconds.
>>> running = True
>>> def f():
...     if running:
...         fd(50)
...         lt(60)
...         screen.ontimer(f, 250)
>>> f()   ### makes the turtle march around
>>> running = False"
turtle.mainloop(),"Starts event loop - calling Tkinter’s mainloop function.
Must be the last statement in a turtle graphics program.
Must not be used if a script is run from within IDLE in -n mode
(No subprocess) - for interactive use of turtle graphics.
>>> screen.mainloop()"
"turtle.textinput(title, prompt)","Parameters

title – string
prompt – string



Pop up a dialog window for input of a string. Parameter title is
the title of the dialog window, prompt is a text mostly describing
what information to input.
Return the string input. If the dialog is canceled, return None.
>>> screen.textinput(""NIM"", ""Name of first player:"")"
"turtle.numinput(title, prompt, default=None, minval=None, maxval=None)","Parameters

title – string
prompt – string
default – number (optional)
minval – number (optional)
maxval – number (optional)



Pop up a dialog window for input of a number. title is the title of the
dialog window, prompt is a text mostly describing what numerical information
to input. default: default value, minval: minimum value for input,
maxval: maximum value for input
The number input must be in the range minval .. maxval if these are
given. If not, a hint is issued and the dialog remains open for
correction.
Return the number input. If the dialog is canceled,  return None.
>>> screen.numinput(""Poker"", ""Your stakes:"", 1000, minval=10, maxval=10000)"
turtle.mode(mode=None),"Parameters
mode – one of the strings “standard”, “logo” or “world”


Set turtle mode (“standard”, “logo” or “world”) and perform reset.  If mode
is not given, current mode is returned.
Mode “standard” is compatible with old turtle.  Mode “logo” is
compatible with most Logo turtle graphics.  Mode “world” uses user-defined
“world coordinates”. Attention: in this mode angles appear distorted if
x/y unit-ratio doesn’t equal 1.







Mode
Initial turtle heading
positive angles



“standard”
to the right (east)
counterclockwise

“logo”
upward    (north)
clockwise



>>> mode(""logo"")   # resets turtle heading to north
>>> mode()
'logo'"
turtle.colormode(cmode=None),"Parameters
cmode – one of the values 1.0 or 255


Return the colormode or set it to 1.0 or 255.  Subsequently r, g, b
values of color triples have to be in the range 0..cmode.
>>> screen.colormode(1)
>>> turtle.pencolor(240, 160, 80)
Traceback (most recent call last):
     ...
TurtleGraphicsError: bad color sequence: (240, 160, 80)
>>> screen.colormode()
1.0
>>> screen.colormode(255)
>>> screen.colormode()
255
>>> turtle.pencolor(240,160,80)"
turtle.getcanvas(),"Return the Canvas of this TurtleScreen.  Useful for insiders who know what to
do with a Tkinter Canvas.
>>> cv = screen.getcanvas()
>>> cv
<turtle.ScrolledCanvas object ...>"
turtle.getshapes(),"Return a list of names of all currently available turtle shapes.
>>> screen.getshapes()
['arrow', 'blank', 'circle', ..., 'turtle']"
"turtle.register_shape(name, shape=None)","There are three different ways to call this function:

name is the name of a gif-file and shape is None: Install the
corresponding image shape.
>>> screen.register_shape(""turtle.gif"")



Note
Image shapes do not rotate when turning the turtle, so they do not
display the heading of the turtle!


name is an arbitrary string and shape is a tuple of pairs of
coordinates: Install the corresponding polygon shape.
>>> screen.register_shape(""triangle"", ((5,-3), (0,5), (-5,-3)))



name is an arbitrary string and shape is a (compound) Shape
object: Install the corresponding compound shape.

Add a turtle shape to TurtleScreen’s shapelist.  Only thusly registered
shapes can be used by issuing the command shape(shapename)."
turtle.turtles(),"Return the list of turtles on the screen.
>>> for turtle in screen.turtles():
...     turtle.color(""red"")"
turtle.window_height(),"Return the height of the turtle window.
>>> screen.window_height()
480"
turtle.window_width(),"Return the width of the turtle window.
>>> screen.window_width()
640"
turtle.bye(),Shut the turtlegraphics window.
turtle.exitonclick(),"Bind bye() method to mouse clicks on the Screen.
If the value “using_IDLE” in the configuration dictionary is False
(default value), also enter mainloop.  Remark: If IDLE with the -n switch
(no subprocess) is used, this value should be set to True in
turtle.cfg.  In this case IDLE’s own mainloop is active also for the
client script."
"turtle.setup(width=_CFG[""width""], height=_CFG[""height""], startx=_CFG[""leftright""], starty=_CFG[""topbottom""])","Set the size and position of the main window.  Default values of arguments
are stored in the configuration dictionary and can be changed via a
turtle.cfg file.

Parameters

width – if an integer, a size in pixels, if a float, a fraction of the
screen; default is 50% of screen
height – if an integer, the height in pixels, if a float, a fraction of
the screen; default is 75% of screen
startx – if positive, starting position in pixels from the left
edge of the screen, if negative from the right edge, if None,
center window horizontally
starty – if positive, starting position in pixels from the top
edge of the screen, if negative from the bottom edge, if None,
center window vertically



>>> screen.setup (width=200, height=200, startx=0, starty=0)
>>>              # sets window to 200x200 pixels, in upper left of screen
>>> screen.setup(width=.75, height=0.5, startx=None, starty=None)
>>>              # sets window to 75% of screen by 50% of screen and centers"
turtle.title(titlestring),"Parameters
titlestring – a string that is shown in the titlebar of the turtle
graphics window


Set title of turtle window to titlestring.
>>> screen.title(""Welcome to the turtle zoo!"")"
"turtle.write_docstringdict(filename=""turtle_docstringdict"")","Parameters
filename – a string, used as filename


Create and write docstring-dictionary to a Python script with the given
filename.  This function has to be called explicitly (it is not used by the
turtle graphics classes).  The docstring dictionary will be written to the
Python script filename.py.  It is intended to serve as a template
for translation of the docstrings into different languages."
"addcomponent(poly, fill, outline=None)","Parameters

poly – a polygon, i.e. a tuple of pairs of numbers
fill – a color the poly will be filled with
outline – a color for the poly’s outline (if given)



Example:
>>> poly = ((0,0),(10,-5),(0,10),(-10,-5))
>>> s = Shape(""compound"")
>>> s.addcomponent(poly, ""red"", ""blue"")
>>> # ... add more components and then use register_shape()


See Compound shapes."
Cmd.cmdloop(intro=None),"Repeatedly issue a prompt, accept input, parse an initial prefix off the
received input, and dispatch to action methods, passing them the remainder of
the line as argument.
The optional argument is a banner or intro string to be issued before the first
prompt (this overrides the intro class attribute).
If the readline module is loaded, input will automatically inherit
bash-like history-list editing (e.g. Control-P scrolls back
to the last command, Control-N forward to the next one, Control-F
moves the cursor to the right non-destructively, Control-B moves the
cursor to the left non-destructively, etc.).
An end-of-file on input is passed back as the string 'EOF'.
An interpreter instance will recognize a command name foo if and only if it
has a method do_foo().  As a special case, a line beginning with the
character '?' is dispatched to the method do_help().  As another
special case, a line beginning with the character '!' is dispatched to the
method do_shell() (if such a method is defined).
This method will return when the postcmd() method returns a true value.
The stop argument to postcmd() is the return value from the command’s
corresponding do_*() method.
If completion is enabled, completing commands will be done automatically, and
completing of commands args is done by calling complete_foo() with
arguments text, line, begidx, and endidx.  text is the string prefix
we are attempting to match: all returned matches must begin with it. line is
the current input line with leading whitespace removed, begidx and endidx
are the beginning and ending indexes of the prefix text, which could be used to
provide different completion depending upon which position the argument is in.
All subclasses of Cmd inherit a predefined do_help().  This
method, called with an argument 'bar', invokes the corresponding method
help_bar(), and if that is not present, prints the docstring of
do_bar(), if available.  With no argument, do_help() lists all
available help topics (that is, all commands with corresponding
help_*() methods or commands that have docstrings), and also lists any
undocumented commands."
Cmd.onecmd(str),"Interpret the argument as though it had been typed in response to the prompt.
This may be overridden, but should not normally need to be; see the
precmd() and postcmd() methods for useful execution hooks.  The
return value is a flag indicating whether interpretation of commands by the
interpreter should stop.  If there is a do_*() method for the command
str, the return value of that method is returned, otherwise the return value
from the default() method is returned."
Cmd.emptyline(),"Method called when an empty line is entered in response to the prompt. If this
method is not overridden, it repeats the last nonempty command entered."
Cmd.default(line),"Method called on an input line when the command prefix is not recognized. If
this method is not overridden, it prints an error message and returns."
"Cmd.completedefault(text, line, begidx, endidx)","Method called to complete an input line when no command-specific
complete_*() method is available.  By default, it returns an empty list."
Cmd.precmd(line),"Hook method executed just before the command line line is interpreted, but
after the input prompt is generated and issued.  This method is a stub in
Cmd; it exists to be overridden by subclasses.  The return value is
used as the command which will be executed by the onecmd() method; the
precmd() implementation may re-write the command or simply return line
unchanged."
"Cmd.postcmd(stop, line)","Hook method executed just after a command dispatch is finished.  This method is
a stub in Cmd; it exists to be overridden by subclasses.  line is the
command line which was executed, and stop is a flag which indicates whether
execution will be terminated after the call to postcmd(); this will be the
return value of the onecmd() method.  The return value of this method will
be used as the new value for the internal flag which corresponds to stop;
returning false will cause interpretation to continue."
Cmd.preloop(),"Hook method executed once when cmdloop() is called.  This method is a stub
in Cmd; it exists to be overridden by subclasses."
Cmd.postloop(),"Hook method executed once when cmdloop() is about to return. This method
is a stub in Cmd; it exists to be overridden by subclasses."
"shlex.split(s, comments=False, posix=True)","Split the string s using shell-like syntax. If comments is False
(the default), the parsing of comments in the given string will be disabled
(setting the commenters attribute of the
shlex instance to the empty string).  This function operates
in POSIX mode by default, but uses non-POSIX mode if the posix argument is
false.

Note
Since the split() function instantiates a shlex
instance, passing None for s will read the string to split from
standard input."
shlex.join(split_command),"Concatenate the tokens of the list split_command and return a string.
This function is the inverse of split().
>>> from shlex import join
>>> print(join(['echo', '-n', 'Multiple words']))
echo -n 'Multiple words'


The returned value is shell-escaped to protect against injection
vulnerabilities (see quote()).

New in version 3.8."
shlex.quote(s),"Return a shell-escaped version of the string s.  The returned value is a
string that can safely be used as one token in a shell command line, for
cases where you cannot use a list.
This idiom would be unsafe:
>>> filename = 'somefile; rm -rf ~'
>>> command = 'ls -l {}'.format(filename)
>>> print(command)  # executed by a shell: boom!
ls -l somefile; rm -rf ~


quote() lets you plug the security hole:
>>> from shlex import quote
>>> command = 'ls -l {}'.format(quote(filename))
>>> print(command)
ls -l 'somefile; rm -rf ~'
>>> remote_command = 'ssh home {}'.format(quote(command))
>>> print(remote_command)
ssh home 'ls -l '""'""'somefile; rm -rf ~'""'""''


The quoting is compatible with UNIX shells and with split():
>>> from shlex import split
>>> remote_command = split(remote_command)
>>> remote_command
['ssh', 'home', ""ls -l 'somefile; rm -rf ~'""]
>>> command = split(remote_command[-1])
>>> command
['ls', '-l', 'somefile; rm -rf ~']



New in version 3.3."
shlex.get_token(),"Return a token.  If tokens have been stacked using push_token(), pop a
token off the stack.  Otherwise, read one from the input stream.  If reading
encounters an immediate end-of-file, eof is returned (the empty
string ('') in non-POSIX mode, and None in POSIX mode)."
shlex.push_token(str),Push the argument onto the token stack.
shlex.read_token(),"Read a raw token.  Ignore the pushback stack, and do not interpret source
requests.  (This is not ordinarily a useful entry point, and is documented here
only for the sake of completeness.)"
shlex.sourcehook(filename),"When shlex detects a source request (see source
below) this method is given the following token as argument, and expected
to return a tuple consisting of a filename and an open file-like object.
Normally, this method first strips any quotes off the argument.  If the result
is an absolute pathname, or there was no previous source request in effect, or
the previous source was a stream (such as sys.stdin), the result is left
alone.  Otherwise, if the result is a relative pathname, the directory part of
the name of the file immediately before it on the source inclusion stack is
prepended (this behavior is like the way the C preprocessor handles #include
""file.h"").
The result of the manipulations is treated as a filename, and returned as the
first component of the tuple, with open() called on it to yield the second
component. (Note: this is the reverse of the order of arguments in instance
initialization!)
This hook is exposed so that you can use it to implement directory search paths,
addition of file extensions, and other namespace hacks. There is no
corresponding ‘close’ hook, but a shlex instance will call the
close() method of the sourced input stream when it returns
EOF.
For more explicit control of source stacking, use the push_source() and
pop_source() methods."
"shlex.push_source(newstream, newfile=None)","Push an input source stream onto the input stack.  If the filename argument is
specified it will later be available for use in error messages.  This is the
same method used internally by the sourcehook() method."
shlex.pop_source(),"Pop the last-pushed input source from the input stack. This is the same method
used internally when the lexer reaches EOF on a stacked input stream."
"shlex.error_leader(infile=None, lineno=None)","This method generates an error message leader in the format of a Unix C compiler
error label; the format is '""%s"", line %d: ', where the %s is replaced
with the name of the current source file and the %d with the current input
line number (the optional arguments can be used to override these).
This convenience is provided to encourage shlex users to generate error
messages in the standard, parseable format understood by Emacs and other Unix
tools."
"tkinter.Tcl(screenName=None, baseName=None, className='Tk', useTk=0)","The Tcl() function is a factory function which creates an object much like
that created by the Tk class, except that it does not initialize the Tk
subsystem.  This is most often useful when driving the Tcl interpreter in an
environment where one doesn’t want to create extraneous toplevel windows, or
where one cannot (such as Unix/Linux systems without an X server).  An object
created by the Tcl() object can have a Toplevel window created (and the Tk
subsystem initialized) by calling its loadtk() method."
"Widget.tk.createfilehandler(file, mask, func)","Registers the file handler callback function func. The file argument
may either be an object with a fileno() method (such as
a file or socket object), or an integer file descriptor. The mask
argument is an ORed combination of any of the three constants below.
The callback is called as follows:
callback(file, mask)"
Widget.tk.deletefilehandler(file),Unregisters a file handler.
"identify(x, y)","Returns the name of the element at position x y, or the empty string
if the point does not lie within any element.
x and y are pixel coordinates relative to the widget."
"instate(statespec, callback=None, *args, **kw)","Test the widget’s state. If a callback is not specified, returns True
if the widget state matches statespec and False otherwise. If callback
is specified then it is called with args if widget state matches
statespec."
state(statespec=None),"Modify or inquire widget state. If statespec is specified, sets the
widget state according to it and return a new statespec indicating
which flags were changed. If statespec is not specified, returns
the currently-enabled state flags."
current(newindex=None),"If newindex is specified, sets the combobox value to the element
position newindex. Otherwise, returns the index of the current value or
-1 if the current value is not in the values list."
get(),Returns the current value of the combobox.
set(value),Sets the value of the combobox to value.
get(),Returns the current value of the spinbox.
set(value),Sets the value of the spinbox to value.
"add(child, **kw)","Adds a new tab to the notebook.
If window is currently managed by the notebook but hidden, it is
restored to its previous position.
See Tab Options for the list of available options."
forget(tab_id),"Removes the tab specified by tab_id, unmaps and unmanages the
associated window."
hide(tab_id),"Hides the tab specified by tab_id.
The tab will not be displayed, but the associated window remains
managed by the notebook and its configuration remembered. Hidden tabs
may be restored with the add() command."
"identify(x, y)","Returns the name of the tab element at position x, y, or the empty
string if none."
index(tab_id),"Returns the numeric index of the tab specified by tab_id, or the total
number of tabs if tab_id is the string “end”."
"insert(pos, child, **kw)","Inserts a pane at the specified position.
pos is either the string “end”, an integer index, or the name of a
managed child. If child is already managed by the notebook, moves it to
the specified position.
See Tab Options for the list of available options."
select(tab_id=None),"Selects the specified tab_id.
The associated child window will be displayed, and the
previously-selected window (if different) is unmapped. If tab_id is
omitted, returns the widget name of the currently selected pane."
"tab(tab_id, option=None, **kw)","Query or modify the options of the specific tab_id.
If kw is not given, returns a dictionary of the tab option values. If
option is specified, returns the value of that option. Otherwise,
sets the options to the corresponding values."
tabs(),Returns a list of windows managed by the notebook.
enable_traversal(),"Enable keyboard traversal for a toplevel window containing this notebook.
This will extend the bindings for the toplevel window containing the
notebook as follows:

Control-Tab: selects the tab following the currently selected one.
Shift-Control-Tab: selects the tab preceding the currently selected one.
Alt-K: where K is the mnemonic (underlined) character of any tab, will
select that tab.

Multiple notebooks in a single toplevel may be enabled for traversal,
including nested notebooks. However, notebook traversal only works
properly if all panes have the notebook they are in as master."
start(interval=None),"Begin autoincrement mode: schedules a recurring timer event that calls
Progressbar.step() every interval milliseconds. If omitted,
interval defaults to 50 milliseconds."
step(amount=None),"Increments the progress bar’s value by amount.
amount defaults to 1.0 if omitted."
stop(),"Stop autoincrement mode: cancels any recurring timer event initiated by
Progressbar.start() for this progress bar."
"bbox(item, column=None)","Returns the bounding box (relative to the treeview widget’s window) of
the specified item in the form (x, y, width, height).
If column is specified, returns the bounding box of that cell. If the
item is not visible (i.e., if it is a descendant of a closed item or is
scrolled offscreen), returns an empty string."
get_children(item=None),"Returns the list of children belonging to item.
If item is not specified, returns root children."
"set_children(item, *newchildren)","Replaces item’s child with newchildren.
Children present in item that are not present in newchildren are
detached from the tree. No items in newchildren may be an ancestor of
item. Note that not specifying newchildren results in detaching
item’s children."
"column(column, option=None, **kw)","Query or modify the options for the specified column.
If kw is not given, returns a dict of the column option values. If
option is specified then the value for that option is returned.
Otherwise, sets the options to the corresponding values.
The valid options/values are:


idReturns the column name. This is a read-only option.




anchor: One of the standard Tk anchor values.Specifies how the text in this column should be aligned with respect
to the cell.




minwidth: widthThe minimum width of the column in pixels. The treeview widget will
not make the column any smaller than specified by this option when
the widget is resized or the user drags a column.




stretch: True/FalseSpecifies whether the column’s width should be adjusted when
the widget is resized.




width: widthThe width of the column in pixels.




To configure the tree column, call this with column = “#0”"
delete(*items),"Delete all specified items and all their descendants.
The root item may not be deleted."
detach(*items),"Unlinks all of the specified items from the tree.
The items and all of their descendants are still present, and may be
reinserted at another point in the tree, but will not be displayed.
The root item may not be detached."
exists(item),Returns True if the specified item is present in the tree.
focus(item=None),"If item is specified, sets the focus item to item. Otherwise, returns
the current focus item, or ‘’ if there is none."
"heading(column, option=None, **kw)","Query or modify the heading options for the specified column.
If kw is not given, returns a dict of the heading option values. If
option is specified then the value for that option is returned.
Otherwise, sets the options to the corresponding values.
The valid options/values are:


text: textThe text to display in the column heading.




image: imageNameSpecifies an image to display to the right of the column heading.




anchor: anchorSpecifies how the heading text should be aligned. One of the standard
Tk anchor values.




command: callbackA callback to be invoked when the heading label is pressed.




To configure the tree column heading, call this with column = “#0”."
"identify(component, x, y)","Returns a description of the specified component under the point given
by x and y, or the empty string if no such component is present at
that position."
identify_row(y),Returns the item ID of the item at position y.
identify_column(x),"Returns the data column identifier of the cell at position x.
The tree column has ID #0."
"identify_region(x, y)","Returns one of:






region
meaning



heading
Tree heading area.

separator
Space between two columns headings.

tree
The tree area.

cell
A data cell.



Availability: Tk 8.6."
"identify_element(x, y)","Returns the element at position x, y.
Availability: Tk 8.6."
index(item),Returns the integer index of item within its parent’s list of children.
"insert(parent, index, iid=None, **kw)","Creates a new item and returns the item identifier of the newly created
item.
parent is the item ID of the parent item, or the empty string to create
a new top-level item. index is an integer, or the value “end”,
specifying where in the list of parent’s children to insert the new item.
If index is less than or equal to zero, the new node is inserted at
the beginning; if index is greater than or equal to the current number
of children, it is inserted at the end. If iid is specified, it is used
as the item identifier; iid must not already exist in the tree.
Otherwise, a new unique identifier is generated.
See Item Options for the list of available points."
"item(item, option=None, **kw)","Query or modify the options for the specified item.
If no options are given, a dict with options/values for the item is
returned.
If option is specified then the value for that option is returned.
Otherwise, sets the options to the corresponding values as given by kw."
"move(item, parent, index)","Moves item to position index in parent’s list of children.
It is illegal to move an item under one of its descendants. If index is
less than or equal to zero, item is moved to the beginning; if greater
than or equal to the number of children, it is moved to the end. If item
was detached it is reattached."
next(item),"Returns the identifier of item’s next sibling, or ‘’ if item is the
last child of its parent."
parent(item),"Returns the ID of the parent of item, or ‘’ if item is at the top
level of the hierarchy."
prev(item),"Returns the identifier of item’s previous sibling, or ‘’ if item is
the first child of its parent."
"reattach(item, parent, index)",An alias for Treeview.move().
see(item),"Ensure that item is visible.
Sets all of item’s ancestors open option to True, and scrolls the
widget if necessary so that item is within the visible portion of
the tree."
selection(),"Returns a tuple of selected items.

Changed in version 3.8: selection() no longer takes arguments.  For changing the selection
state use the following selection methods."
selection_set(*items),"items becomes the new selection.

Changed in version 3.6: items can be passed as separate arguments, not just as a single tuple."
selection_add(*items),"Add items to the selection.

Changed in version 3.6: items can be passed as separate arguments, not just as a single tuple."
selection_remove(*items),"Remove items from the selection.

Changed in version 3.6: items can be passed as separate arguments, not just as a single tuple."
selection_toggle(*items),"Toggle the selection state of each item in items.

Changed in version 3.6: items can be passed as separate arguments, not just as a single tuple."
"set(item, column=None, value=None)","With one argument, returns a dictionary of column/value pairs for the
specified item. With two arguments, returns the current value of the
specified column. With three arguments, sets the value of given
column in given item to the specified value."
"tag_bind(tagname, sequence=None, callback=None)","Bind a callback for the given event sequence to the tag tagname.
When an event is delivered to an item, the callbacks for each of the
item’s tags option are called."
"tag_configure(tagname, option=None, **kw)","Query or modify the options for the specified tagname.
If kw is not given, returns a dict of the option settings for
tagname. If option is specified, returns the value for that option
for the specified tagname. Otherwise, sets the options to the
corresponding values for the given tagname."
"tag_has(tagname, item=None)","If item is specified, returns 1 or 0 depending on whether the specified
item has the given tagname. Otherwise, returns a list of all items
that have the specified tag.
Availability: Tk 8.6"
xview(*args),Query or modify horizontal position of the treeview.
yview(*args),Query or modify vertical position of the treeview.
"configure(style, query_opt=None, **kw)","Query or set the default value of the specified option(s) in style.
Each key in kw is an option and each value is a string identifying
the value for that option.
For example, to change every default button to be a flat button with
some padding and a different background color:
from tkinter import ttk
import tkinter

root = tkinter.Tk()

ttk.Style().configure(""TButton"", padding=6, relief=""flat"",
   background=""#ccc"")

btn = ttk.Button(text=""Sample"")
btn.pack()

root.mainloop()"
"map(style, query_opt=None, **kw)","Query or sets dynamic values of the specified option(s) in style.
Each key in kw is an option and each value should be a list or a
tuple (usually) containing statespecs grouped in tuples, lists, or
some other preference. A statespec is a compound of one
or more states and then a value.
An example may make it more understandable:
import tkinter
from tkinter import ttk

root = tkinter.Tk()

style = ttk.Style()
style.map(""C.TButton"",
    foreground=[('pressed', 'red'), ('active', 'blue')],
    background=[('pressed', '!disabled', 'black'), ('active', 'white')]
    )

colored_btn = ttk.Button(text=""Test"", style=""C.TButton"").pack()

root.mainloop()


Note that the order of the (states, value) sequences for an option does
matter, if the order is changed to [('active', 'blue'), ('pressed',
'red')] in the foreground option, for example, the result would be a
blue foreground when the widget were in active or pressed states."
"lookup(style, option, state=None, default=None)","Returns the value specified for option in style.
If state is specified, it is expected to be a sequence of one or more
states. If the default argument is set, it is used as a fallback value
in case no specification for option is found.
To check what font a Button uses by default:
from tkinter import ttk

print(ttk.Style().lookup(""TButton"", ""font""))"
"layout(style, layoutspec=None)","Define the widget layout for given style. If layoutspec is omitted,
return the layout specification for given style.
layoutspec, if specified, is expected to be a list or some other
sequence type (excluding strings), where each item should be a tuple and
the first item is the layout name and the second item should have the
format described in Layouts.
To understand the format, see the following example (it is not
intended to do anything useful):
from tkinter import ttk
import tkinter

root = tkinter.Tk()

style = ttk.Style()
style.layout(""TMenubutton"", [
   (""Menubutton.background"", None),
   (""Menubutton.button"", {""children"":
       [(""Menubutton.focus"", {""children"":
           [(""Menubutton.padding"", {""children"":
               [(""Menubutton.label"", {""side"": ""left"", ""expand"": 1})]
           })]
       })]
   }),
])

mbtn = ttk.Menubutton(text='Text')
mbtn.pack()
root.mainloop()"
"element_create(elementname, etype, *args, **kw)","Create a new element in the current theme, of the given etype which is
expected to be either “image”, “from” or “vsapi”. The latter is only
available in Tk 8.6a for Windows XP and Vista and is not described here.
If “image” is used, args should contain the default image name followed
by statespec/value pairs (this is the imagespec), and kw may have the
following options:



border=paddingpadding is a list of up to four integers, specifying the left, top,
right, and bottom borders, respectively.




height=heightSpecifies a minimum height for the element. If less than zero, the
base image’s height is used as a default.




padding=paddingSpecifies the element’s interior padding. Defaults to border’s value
if not specified.




sticky=specSpecifies how the image is placed within the final parcel. spec
contains zero or more characters “n”, “s”, “w”, or “e”.




width=widthSpecifies a minimum width for the element. If less than zero, the
base image’s width is used as a default.





If “from” is used as the value of etype,
element_create() will clone an existing
element. args is expected to contain a themename, from which
the element will be cloned, and optionally an element to clone from.
If this element to clone from is not specified, an empty element will
be used. kw is discarded."
element_names(),Returns the list of elements defined in the current theme.
element_options(elementname),Returns the list of elementname’s options.
"theme_create(themename, parent=None, settings=None)","Create a new theme.
It is an error if themename already exists. If parent is specified,
the new theme will inherit styles, elements and layouts from the parent
theme. If settings are present they are expected to have the same
syntax used for theme_settings()."
"theme_settings(themename, settings)","Temporarily sets the current theme to themename, apply specified
settings and then restore the previous theme.
Each key in settings is a style and each value may contain the keys
‘configure’, ‘map’, ‘layout’ and ‘element create’ and they are expected
to have the same format as specified by the methods
Style.configure(), Style.map(), Style.layout() and
Style.element_create() respectively.
As an example, let’s change the Combobox for the default theme a bit:
from tkinter import ttk
import tkinter

root = tkinter.Tk()

style = ttk.Style()
style.theme_settings(""default"", {
   ""TCombobox"": {
       ""configure"": {""padding"": 5},
       ""map"": {
           ""background"": [(""active"", ""green2""),
                          (""!disabled"", ""green4"")],
           ""fieldbackground"": [(""!disabled"", ""green3"")],
           ""foreground"": [(""focus"", ""OliveDrab1""),
                          (""!disabled"", ""OliveDrab2"")]
       }
   }
})

combo = ttk.Combobox().pack()

root.mainloop()"
theme_names(),Returns a list of all known themes.
theme_use(themename=None),"If themename is not given, returns the theme in use.  Otherwise, sets
the current theme to themename, refreshes all widgets and emits a
<<ThemeChanged>> event."
"tixCommand.tix_configure(cnf=None, **kw)","Query or modify the configuration options of the Tix application context. If no
option is specified, returns a dictionary all of the available options.  If
option is specified with no value, then the method returns a list describing the
one named option (this list will be identical to the corresponding sublist of
the value returned if no option is specified).  If one or more option-value
pairs are specified, then the method modifies the given option(s) to have the
given value(s); in this case the method returns an empty string. Option may be
any of the configuration options."
tixCommand.tix_cget(option),"Returns the current value of the configuration option given by option. Option
may be any of the configuration options."
tixCommand.tix_getbitmap(name),"Locates a bitmap file of the name name.xpm or name in one of the bitmap
directories (see the tix_addbitmapdir() method).  By using
tix_getbitmap(), you can avoid hard coding the pathnames of the bitmap
files in your application. When successful, it returns the complete pathname of
the bitmap file, prefixed with the character @.  The returned value can be
used to configure the bitmap option of the Tk and Tix widgets."
tixCommand.tix_addbitmapdir(directory),"Tix maintains a list of directories under which the tix_getimage() and
tix_getbitmap() methods will search for image files.  The standard bitmap
directory is $TIX_LIBRARY/bitmaps. The tix_addbitmapdir() method
adds directory into this list. By using this method, the image files of an
applications can also be located using the tix_getimage() or
tix_getbitmap() method."
tixCommand.tix_filedialog([dlgclass]),"Returns the file selection dialog that may be shared among different calls from
this application.  This method will create a file selection dialog widget when
it is called the first time. This dialog will be returned by all subsequent
calls to tix_filedialog().  An optional dlgclass parameter can be passed
as a string to specified what type of file selection dialog widget is desired.
Possible options are tix, FileSelectDialog or tixExFileSelectDialog."
"tixCommand.tix_getimage(self, name)","Locates an image file of the name name.xpm, name.xbm or
name.ppm in one of the bitmap directories (see the
tix_addbitmapdir() method above). If more than one file with the same name
(but different extensions) exist, then the image type is chosen according to the
depth of the X display: xbm images are chosen on monochrome displays and color
images are chosen on color displays. By using tix_getimage(), you can
avoid hard coding the pathnames of the image files in your application. When
successful, this method returns the name of the newly created image, which can
be used to configure the image option of the Tk and Tix widgets."
tixCommand.tix_option_get(name),Gets the options maintained by the Tix scheme mechanism.
"tixCommand.tix_resetoptions(newScheme, newFontSet[, newScmPrio])","Resets the scheme and fontset of the Tix application to newScheme and
newFontSet, respectively.  This affects only those widgets created after this
call.  Therefore, it is best to call the resetoptions method before the creation
of any widgets in a Tix application.
The optional parameter newScmPrio can be given to reset the priority level of
the Tk options set by the Tix schemes.
Because of the way Tk handles the X option database, after Tix has been has
imported and inited, it is not possible to reset the color schemes and font sets
using the tix_config() method. Instead, the tix_resetoptions()
method must be used."
typing.NewType(typ),"A helper function to indicate a distinct types to a typechecker,
see NewType. At runtime it returns a function that returns
its argument. Usage:
UserId = NewType('UserId', int)
first_user = UserId(1)



New in version 3.5.2."
"typing.cast(typ, val)","Cast a value to a type.
This returns the value unchanged.  To the type checker this
signals that the return value has the designated type, but at
runtime we intentionally don’t check anything (we want this
to be as fast as possible)."
"typing.get_type_hints(obj[, globals[, locals]])","Return a dictionary containing type hints for a function, method, module
or class object.
This is often the same as obj.__annotations__. In addition,
forward references encoded as string literals are handled by evaluating
them in globals and locals namespaces. If necessary,
Optional[t] is added for function and method annotations if a default
value equal to None is set. For a class C, return
a dictionary constructed by merging all the __annotations__ along
C.__mro__ in reverse order."
typing.get_origin(tp),
typing.get_args(tp),"Provide basic introspection for generic types and special typing forms.
For a typing object of the form X[Y, Z, ...] these functions return
X and (Y, Z, ...). If X is a generic alias for a builtin or
collections class, it gets normalized to the original class.
For unsupported objects return None and () correspondingly.
Examples:
assert get_origin(Dict[str, int]) is dict
assert get_args(Dict[int, str]) == (int, str)

assert get_origin(Union[int, str]) is Union
assert get_args(Union[int, str]) == (int, str)



New in version 3.8."
@typing.overload,"The @overload decorator allows describing functions and methods
that support multiple different combinations of argument types. A series
of @overload-decorated definitions must be followed by exactly one
non-@overload-decorated definition (for the same function/method).
The @overload-decorated definitions are for the benefit of the
type checker only, since they will be overwritten by the
non-@overload-decorated definition, while the latter is used at
runtime but should be ignored by a type checker.  At runtime, calling
a @overload-decorated function directly will raise
NotImplementedError. An example of overload that gives a more
precise type than can be expressed using a union or a type variable:
@overload
def process(response: None) -> None:
    ...
@overload
def process(response: int) -> Tuple[int, str]:
    ...
@overload
def process(response: bytes) -> str:
    ...
def process(response):
    <actual implementation>


See PEP 484 for details and comparison with other typing semantics."
@typing.final,"A decorator to indicate to type checkers that the decorated method
cannot be overridden, and the decorated class cannot be subclassed.
For example:
class Base:
    @final
    def done(self) -> None:
        ...
class Sub(Base):
    def done(self) -> None:  # Error reported by type checker
          ...

@final
class Leaf:
    ...
class Other(Leaf):  # Error reported by type checker
    ...


There is no runtime checking of these properties. See PEP 591 for
more details.

New in version 3.8."
@typing.no_type_check,"Decorator to indicate that annotations are not type hints.
This works as class or function decorator.  With a class, it
applies recursively to all methods defined in that class (but not
to methods defined in its superclasses or subclasses).
This mutates the function(s) in place."
@typing.no_type_check_decorator,"Decorator to give another decorator the no_type_check() effect.
This wraps the decorator with something that wraps the decorated
function in no_type_check()."
@typing.type_check_only,"Decorator to mark a class or function to be unavailable at runtime.
This decorator is itself not available at runtime. It is mainly
intended to mark classes that are defined in type stub files if
an implementation returns an instance of a private class:
@type_check_only
class Response:  # private or not available at runtime
    code: int
    def get_header(self, name: str) -> str: ...

def fetch_response() -> Response: ...


Note that returning instances of private classes is not recommended.
It is usually preferable to make such classes public."
@typing.runtime_checkable,"Mark a protocol class as a runtime protocol.
Such a protocol can be used with isinstance() and issubclass().
This raises TypeError when applied to a non-protocol class.  This
allows a simple-minded structural check, very similar to “one trick ponies”
in collections.abc such as Iterable.  For example:
@runtime_checkable
class Closable(Protocol):
    def close(self): ...

assert isinstance(open('/some/file'), Closable)


Warning: this will check only the presence of the required methods,
not their type signatures!

New in version 3.8."
doctest.register_optionflag(name),"Create a new option flag with a given name, and return the new flag’s integer
value.  register_optionflag() can be used when subclassing
OutputChecker or DocTestRunner to create new options that are
supported by your subclasses.  register_optionflag() should always be
called using the following idiom:
MY_FLAG = register_optionflag('MY_FLAG')"
"doctest.testfile(filename, module_relative=True, name=None, package=None, globs=None, verbose=None, report=True, optionflags=0, extraglobs=None, raise_on_error=False, parser=DocTestParser(), encoding=None)","All arguments except filename are optional, and should be specified in keyword
form.
Test examples in the file named filename.  Return (failure_count,
test_count).
Optional argument module_relative specifies how the filename should be
interpreted:

If module_relative is True (the default), then filename specifies an
OS-independent module-relative path.  By default, this path is relative to the
calling module’s directory; but if the package argument is specified, then it
is relative to that package.  To ensure OS-independence, filename should use
/ characters to separate path segments, and may not be an absolute path
(i.e., it may not begin with /).
If module_relative is False, then filename specifies an OS-specific
path.  The path may be absolute or relative; relative paths are resolved with
respect to the current working directory.

Optional argument name gives the name of the test; by default, or if None,
os.path.basename(filename) is used.
Optional argument package is a Python package or the name of a Python package
whose directory should be used as the base directory for a module-relative
filename.  If no package is specified, then the calling module’s directory is
used as the base directory for module-relative filenames.  It is an error to
specify package if module_relative is False.
Optional argument globs gives a dict to be used as the globals when executing
examples.  A new shallow copy of this dict is created for the doctest, so its
examples start with a clean slate. By default, or if None, a new empty dict
is used.
Optional argument extraglobs gives a dict merged into the globals used to
execute examples.  This works like dict.update():  if globs and
extraglobs have a common key, the associated value in extraglobs appears in
the combined dict.  By default, or if None, no extra globals are used.  This
is an advanced feature that allows parameterization of doctests.  For example, a
doctest can be written for a base class, using a generic name for the class,
then reused to test any number of subclasses by passing an extraglobs dict
mapping the generic name to the subclass to be tested.
Optional argument verbose prints lots of stuff if true, and prints only
failures if false; by default, or if None, it’s true if and only if '-v'
is in sys.argv.
Optional argument report prints a summary at the end when true, else prints
nothing at the end.  In verbose mode, the summary is detailed, else the summary
is very brief (in fact, empty if all tests passed).
Optional argument optionflags (default value 0) takes the
bitwise OR of option flags.
See section Option Flags.
Optional argument raise_on_error defaults to false.  If true, an exception is
raised upon the first failure or unexpected exception in an example.  This
allows failures to be post-mortem debugged. Default behavior is to continue
running examples.
Optional argument parser specifies a DocTestParser (or subclass) that
should be used to extract tests from the files.  It defaults to a normal parser
(i.e., DocTestParser()).
Optional argument encoding specifies an encoding that should be used to
convert the file to unicode."
"doctest.testmod(m=None, name=None, globs=None, verbose=None, report=True, optionflags=0, extraglobs=None, raise_on_error=False, exclude_empty=False)","All arguments are optional, and all except for m should be specified in
keyword form.
Test examples in docstrings in functions and classes reachable from module m
(or module __main__ if m is not supplied or is None), starting with
m.__doc__.
Also test examples reachable from dict m.__test__, if it exists and is not
None.  m.__test__ maps names (strings) to functions, classes and
strings; function and class docstrings are searched for examples; strings are
searched directly, as if they were docstrings.
Only docstrings attached to objects belonging to module m are searched.
Return (failure_count, test_count).
Optional argument name gives the name of the module; by default, or if
None, m.__name__ is used.
Optional argument exclude_empty defaults to false.  If true, objects for which
no doctests are found are excluded from consideration. The default is a backward
compatibility hack, so that code still using doctest.master.summarize() in
conjunction with testmod() continues to get output for objects with no
tests. The exclude_empty argument to the newer DocTestFinder
constructor defaults to true.
Optional arguments extraglobs, verbose, report, optionflags,
raise_on_error, and globs are the same as for function testfile()
above, except that globs defaults to m.__dict__."
"doctest.run_docstring_examples(f, globs, verbose=False, name=""NoName"", compileflags=None, optionflags=0)","Test examples associated with object f; for example, f may be a string,
a module, a function, or a class object.
A shallow copy of dictionary argument globs is used for the execution context.
Optional argument name is used in failure messages, and defaults to
""NoName"".
If optional argument verbose is true, output is generated even if there are no
failures.  By default, output is generated only in case of an example failure.
Optional argument compileflags gives the set of flags that should be used by
the Python compiler when running the examples.  By default, or if None,
flags are deduced corresponding to the set of future features found in globs.
Optional argument optionflags works as for function testfile() above."
"doctest.DocFileSuite(*paths, module_relative=True, package=None, setUp=None, tearDown=None, globs=None, optionflags=0, parser=DocTestParser(), encoding=None)","Convert doctest tests from one or more text files to a
unittest.TestSuite.
The returned unittest.TestSuite is to be run by the unittest framework
and runs the interactive examples in each file.  If an example in any file
fails, then the synthesized unit test fails, and a failureException
exception is raised showing the name of the file containing the test and a
(sometimes approximate) line number.
Pass one or more paths (as strings) to text files to be examined.
Options may be provided as keyword arguments:
Optional argument module_relative specifies how the filenames in paths
should be interpreted:

If module_relative is True (the default), then each filename in
paths specifies an OS-independent module-relative path.  By default, this
path is relative to the calling module’s directory; but if the package
argument is specified, then it is relative to that package.  To ensure
OS-independence, each filename should use / characters to separate path
segments, and may not be an absolute path (i.e., it may not begin with
/).
If module_relative is False, then each filename in paths specifies
an OS-specific path.  The path may be absolute or relative; relative paths
are resolved with respect to the current working directory.

Optional argument package is a Python package or the name of a Python
package whose directory should be used as the base directory for
module-relative filenames in paths.  If no package is specified, then the
calling module’s directory is used as the base directory for module-relative
filenames.  It is an error to specify package if module_relative is
False.
Optional argument setUp specifies a set-up function for the test suite.
This is called before running the tests in each file.  The setUp function
will be passed a DocTest object.  The setUp function can access the
test globals as the globs attribute of the test passed.
Optional argument tearDown specifies a tear-down function for the test
suite.  This is called after running the tests in each file.  The tearDown
function will be passed a DocTest object.  The setUp function can
access the test globals as the globs attribute of the test passed.
Optional argument globs is a dictionary containing the initial global
variables for the tests.  A new copy of this dictionary is created for each
test.  By default, globs is a new empty dictionary.
Optional argument optionflags specifies the default doctest options for the
tests, created by or-ing together individual option flags.  See section
Option Flags. See function set_unittest_reportflags() below
for a better way to set reporting options.
Optional argument parser specifies a DocTestParser (or subclass)
that should be used to extract tests from the files.  It defaults to a normal
parser (i.e., DocTestParser()).
Optional argument encoding specifies an encoding that should be used to
convert the file to unicode.
The global __file__ is added to the globals provided to doctests loaded
from a text file using DocFileSuite()."
"doctest.DocTestSuite(module=None, globs=None, extraglobs=None, test_finder=None, setUp=None, tearDown=None, checker=None)","Convert doctest tests for a module to a unittest.TestSuite.
The returned unittest.TestSuite is to be run by the unittest framework
and runs each doctest in the module.  If any of the doctests fail, then the
synthesized unit test fails, and a failureException exception is raised
showing the name of the file containing the test and a (sometimes approximate)
line number.
Optional argument module provides the module to be tested.  It can be a module
object or a (possibly dotted) module name.  If not specified, the module calling
this function is used.
Optional argument globs is a dictionary containing the initial global
variables for the tests.  A new copy of this dictionary is created for each
test.  By default, globs is a new empty dictionary.
Optional argument extraglobs specifies an extra set of global variables, which
is merged into globs.  By default, no extra globals are used.
Optional argument test_finder is the DocTestFinder object (or a
drop-in replacement) that is used to extract doctests from the module.
Optional arguments setUp, tearDown, and optionflags are the same as for
function DocFileSuite() above.
This function uses the same search technique as testmod().

Changed in version 3.5: DocTestSuite() returns an empty unittest.TestSuite if module
contains no docstrings instead of raising ValueError."
doctest.set_unittest_reportflags(flags),"Set the doctest reporting flags to use.
Argument flags takes the bitwise OR of option flags.  See
section Option Flags.  Only “reporting flags” can be used.
This is a module-global setting, and affects all future doctests run by module
unittest:  the runTest() method of DocTestCase looks at
the option flags specified for the test case when the DocTestCase
instance was constructed.  If no reporting flags were specified (which is the
typical and expected case), doctest’s unittest reporting flags are
bitwise ORed into the option flags, and the option flags
so augmented are passed to the DocTestRunner instance created to
run the doctest.  If any reporting flags were specified when the
DocTestCase instance was constructed, doctest’s
unittest reporting flags are ignored.
The value of the unittest reporting flags in effect before the function
was called is returned by the function."
doctest.script_from_examples(s),"Convert text with examples to a script.
Argument s is a string containing doctest examples.  The string is converted
to a Python script, where doctest examples in s are converted to regular code,
and everything else is converted to Python comments.  The generated script is
returned as a string. For example,
import doctest
print(doctest.script_from_examples(r""""""
    Set x and y to 1 and 2.
    >>> x, y = 1, 2

    Print their sum:
    >>> print(x+y)
    3
""""""))


displays:
# Set x and y to 1 and 2.
x, y = 1, 2
#
# Print their sum:
print(x+y)
# Expected:
## 3


This function is used internally by other functions (see below), but can also be
useful when you want to transform an interactive Python session into a Python
script."
"doctest.testsource(module, name)","Convert the doctest for an object to a script.
Argument module is a module object, or dotted name of a module, containing the
object whose doctests are of interest.  Argument name is the name (within the
module) of the object with the doctests of interest.  The result is a string,
containing the object’s docstring converted to a Python script, as described for
script_from_examples() above.  For example, if module a.py
contains a top-level function f(), then
import a, doctest
print(doctest.testsource(a, ""a.f""))


prints a script version of function f()’s docstring, with doctests
converted to code, and the rest placed in comments."
"doctest.debug(module, name, pm=False)","Debug the doctests for an object.
The module and name arguments are the same as for function
testsource() above.  The synthesized Python script for the named object’s
docstring is written to a temporary file, and then that file is run under the
control of the Python debugger, pdb.
A shallow copy of module.__dict__ is used for both local and global
execution context.
Optional argument pm controls whether post-mortem debugging is used.  If pm
has a true value, the script file is run directly, and the debugger gets
involved only if the script terminates via raising an unhandled exception.  If
it does, then post-mortem debugging is invoked, via pdb.post_mortem(),
passing the traceback object from the unhandled exception.  If pm is not
specified, or is false, the script is run under the debugger from the start, via
passing an appropriate exec() call to pdb.run()."
"doctest.debug_src(src, pm=False, globs=None)","Debug the doctests in a string.
This is like function debug() above, except that a string containing
doctest examples is specified directly, via the src argument.
Optional argument pm has the same meaning as in function debug() above.
Optional argument globs gives a dictionary to use as both local and global
execution context.  If not specified, or None, an empty dictionary is used.
If specified, a shallow copy of the dictionary is used."
"find(obj[, name][, module][, globs][, extraglobs])","Return a list of the DocTests that are defined by obj’s
docstring, or by any of its contained objects’ docstrings.
The optional argument name specifies the object’s name; this name will be
used to construct names for the returned DocTests.  If name is
not specified, then obj.__name__ is used.
The optional parameter module is the module that contains the given object.
If the module is not specified or is None, then the test finder will attempt
to automatically determine the correct module.  The object’s module is used:

As a default namespace, if globs is not specified.
To prevent the DocTestFinder from extracting DocTests from objects that are
imported from other modules.  (Contained objects with modules other than
module are ignored.)
To find the name of the file containing the object.
To help find the line number of the object within its file.

If module is False, no attempt to find the module will be made.  This is
obscure, of use mostly in testing doctest itself: if module is False, or
is None but cannot be found automatically, then all objects are considered
to belong to the (non-existent) module, so all contained objects will
(recursively) be searched for doctests.
The globals for each DocTest is formed by combining globs and
extraglobs (bindings in extraglobs override bindings in globs).  A new
shallow copy of the globals dictionary is created for each DocTest.
If globs is not specified, then it defaults to the module’s __dict__, if
specified, or {} otherwise.  If extraglobs is not specified, then it
defaults to {}."
"get_doctest(string, globs, name, filename, lineno)","Extract all doctest examples from the given string, and collect them into a
DocTest object.
globs, name, filename, and lineno are attributes for the new
DocTest object.  See the documentation for DocTest for more
information."
"get_examples(string, name='<string>')","Extract all doctest examples from the given string, and return them as a list
of Example objects.  Line numbers are 0-based.  The optional argument
name is a name identifying this string, and is only used for error messages."
"parse(string, name='<string>')","Divide the given string into examples and intervening text, and return them as
a list of alternating Examples and strings. Line numbers for the
Examples are 0-based.  The optional argument name is a name
identifying this string, and is only used for error messages."
"report_start(out, test, example)","Report that the test runner is about to process the given example. This method
is provided to allow subclasses of DocTestRunner to customize their
output; it should not be called directly.
example is the example about to be processed.  test is the test
containing example.  out is the output function that was passed to
DocTestRunner.run()."
"report_success(out, test, example, got)","Report that the given example ran successfully.  This method is provided to
allow subclasses of DocTestRunner to customize their output; it
should not be called directly.
example is the example about to be processed.  got is the actual output
from the example.  test is the test containing example.  out is the
output function that was passed to DocTestRunner.run()."
"report_failure(out, test, example, got)","Report that the given example failed.  This method is provided to allow
subclasses of DocTestRunner to customize their output; it should not
be called directly.
example is the example about to be processed.  got is the actual output
from the example.  test is the test containing example.  out is the
output function that was passed to DocTestRunner.run()."
"report_unexpected_exception(out, test, example, exc_info)","Report that the given example raised an unexpected exception. This method is
provided to allow subclasses of DocTestRunner to customize their
output; it should not be called directly.
example is the example about to be processed. exc_info is a tuple
containing information about the unexpected exception (as returned by
sys.exc_info()). test is the test containing example.  out is the
output function that was passed to DocTestRunner.run()."
"run(test, compileflags=None, out=None, clear_globs=True)","Run the examples in test (a DocTest object), and display the
results using the writer function out.
The examples are run in the namespace test.globs.  If clear_globs is
true (the default), then this namespace will be cleared after the test runs,
to help with garbage collection. If you would like to examine the namespace
after the test completes, then use clear_globs=False.
compileflags gives the set of flags that should be used by the Python
compiler when running the examples.  If not specified, then it will default to
the set of future-import flags that apply to globs.
The output of each example is checked using the DocTestRunner’s
output checker, and the results are formatted by the
DocTestRunner.report_*() methods."
summarize(verbose=None),"Print a summary of all the test cases that have been run by this DocTestRunner,
and return a named tuple TestResults(failed, attempted).
The optional verbose argument controls how detailed the summary is.  If the
verbosity is not specified, then the DocTestRunner’s verbosity is
used."
"check_output(want, got, optionflags)","Return True iff the actual output from an example (got) matches the
expected output (want).  These strings are always considered to match if
they are identical; but depending on what option flags the test runner is
using, several non-exact match types are also possible.  See section
Option Flags for more information about option flags."
"output_difference(example, got, optionflags)","Return a string describing the differences between the expected output for a
given example (example) and the actual output (got).  optionflags is the
set of option flags used to compare want and got."
@unittest.skip(reason),"Unconditionally skip the decorated test.  reason should describe why the
test is being skipped."
"@unittest.skipIf(condition, reason)",Skip the decorated test if condition is true.
"@unittest.skipUnless(condition, reason)",Skip the decorated test unless condition is true.
@unittest.expectedFailure,"Mark the test as an expected failure.  If the test fails it will be
considered a success.  If the test passes, it will be considered a failure."
"unittest.main(module='__main__', defaultTest=None, argv=None, testRunner=None, testLoader=unittest.defaultTestLoader, exit=True, verbosity=1, failfast=None, catchbreak=None, buffer=None, warnings=None)","A command-line program that loads a set of tests from module and runs them;
this is primarily for making test modules conveniently executable.
The simplest use for this function is to include the following line at the
end of a test script:
if __name__ == '__main__':
    unittest.main()


You can run tests with more detailed information by passing in the verbosity
argument:
if __name__ == '__main__':
    unittest.main(verbosity=2)


The defaultTest argument is either the name of a single test or an
iterable of test names to run if no test names are specified via argv.  If
not specified or None and no test names are provided via argv, all
tests found in module are run.
The argv argument can be a list of options passed to the program, with the
first element being the program name.  If not specified or None,
the values of sys.argv are used.
The testRunner argument can either be a test runner class or an already
created instance of it. By default main calls sys.exit() with
an exit code indicating success or failure of the tests run.
The testLoader argument has to be a TestLoader instance,
and defaults to defaultTestLoader.
main supports being used from the interactive interpreter by passing in the
argument exit=False. This displays the result on standard output without
calling sys.exit():
>>> from unittest import main
>>> main(module='test_module', exit=False)


The failfast, catchbreak and buffer parameters have the same
effect as the same-name command-line options.
The warnings argument specifies the warning filter
that should be used while running the tests.  If it’s not specified, it will
remain None if a -W option is passed to python
(see Warning control),
otherwise it will be set to 'default'.
Calling main actually returns an instance of the TestProgram class.
This stores the result of the tests run as the result attribute.

Changed in version 3.1: The exit parameter was added.


Changed in version 3.2: The verbosity, failfast, catchbreak, buffer
and warnings parameters were added.


Changed in version 3.4: The defaultTest parameter was changed to also accept an iterable of
test names."
"unittest.addModuleCleanup(function, /, *args, **kwargs)","Add a function to be called after tearDownModule() to cleanup
resources used during the test class. Functions will be called in reverse
order to the order they are added (LIFO).
They are called with any arguments and keyword arguments passed into
addModuleCleanup() when they are added.
If setUpModule() fails, meaning that tearDownModule() is not
called, then any cleanup functions added will still be called.

New in version 3.8."
unittest.doModuleCleanups(),"This function is called unconditionally after tearDownModule(), or
after setUpModule() if setUpModule() raises an exception.
It is responsible for calling all the cleanup functions added by
addCleanupModule(). If you need cleanup functions to be called
prior to tearDownModule() then you can call
doModuleCleanups() yourself.
doModuleCleanups() pops methods off the stack of cleanup
functions one at a time, so it can be called at any time.

New in version 3.8."
unittest.installHandler(),"Install the control-c handler. When a signal.SIGINT is received
(usually in response to the user pressing control-c) all registered results
have stop() called."
unittest.registerResult(result),"Register a TestResult object for control-c handling. Registering a
result stores a weak reference to it, so it doesn’t prevent the result from
being garbage collected.
Registering a TestResult object has no side-effects if control-c
handling is not enabled, so test frameworks can unconditionally register
all results they create independently of whether or not handling is enabled."
unittest.removeResult(result),"Remove a registered result. Once a result has been removed then
stop() will no longer be called on that result object in
response to a control-c."
unittest.removeHandler(function=None),"When called without arguments this function removes the control-c handler
if it has been installed. This function can also be used as a test decorator
to temporarily remove the handler while the test is being executed:
@unittest.removeHandler
def test_signal_handling(self):
    ..."
setUp(),"Method called to prepare the test fixture.  This is called immediately
before calling the test method; other than AssertionError or SkipTest,
any exception raised by this method will be considered an error rather than
a test failure. The default implementation does nothing."
tearDown(),"Method called immediately after the test method has been called and the
result recorded.  This is called even if the test method raised an
exception, so the implementation in subclasses may need to be particularly
careful about checking internal state.  Any exception, other than
AssertionError or SkipTest, raised by this method will be
considered an additional error rather than a test failure (thus increasing
the total number of reported errors). This method will only be called if
the setUp() succeeds, regardless of the outcome of the test method.
The default implementation does nothing."
setUpClass(),"A class method called before tests in an individual class are run.
setUpClass is called with the class as the only argument
and must be decorated as a classmethod():
@classmethod
def setUpClass(cls):
    ...


See Class and Module Fixtures for more details.

New in version 3.2."
tearDownClass(),"A class method called after tests in an individual class have run.
tearDownClass is called with the class as the only argument
and must be decorated as a classmethod():
@classmethod
def tearDownClass(cls):
    ...


See Class and Module Fixtures for more details.

New in version 3.2."
run(result=None),"Run the test, collecting the result into the TestResult object
passed as result.  If result is omitted or None, a temporary
result object is created (by calling the defaultTestResult()
method) and used. The result object is returned to run()’s
caller.
The same effect may be had by simply calling the TestCase
instance.

Changed in version 3.3: Previous versions of run did not return the result. Neither did
calling an instance."
skipTest(reason),"Calling this during a test method or setUp() skips the current
test.  See Skipping tests and expected failures for more information.

New in version 3.1."
"subTest(msg=None, **params)","Return a context manager which executes the enclosed code block as a
subtest.  msg and params are optional, arbitrary values which are
displayed whenever a subtest fails, allowing you to identify them
clearly.
A test case can contain any number of subtest declarations, and
they can be arbitrarily nested.
See Distinguishing test iterations using subtests for more information.

New in version 3.4."
debug(),"Run the test without collecting the result.  This allows exceptions raised
by the test to be propagated to the caller, and can be used to support
running tests under a debugger."
"assertEqual(first, second, msg=None)","Test that first and second are equal.  If the values do not
compare equal, the test will fail.
In addition, if first and second are the exact same type and one of
list, tuple, dict, set, frozenset or str or any type that a subclass
registers with addTypeEqualityFunc() the type-specific equality
function will be called in order to generate a more useful default
error message (see also the list of type-specific methods).

Changed in version 3.1: Added the automatic calling of type-specific equality function.


Changed in version 3.2: assertMultiLineEqual() added as the default type equality
function for comparing strings."
"assertNotEqual(first, second, msg=None)","Test that first and second are not equal.  If the values do
compare equal, the test will fail."
"assertTrue(expr, msg=None)","Test that expr is true (or false).
Note that this is equivalent to bool(expr) is True and not to expr
is True (use assertIs(expr, True) for the latter).  This method
should also be avoided when more specific methods are available (e.g.
assertEqual(a, b) instead of assertTrue(a == b)), because they
provide a better error message in case of failure."
"assertIs(first, second, msg=None)","Test that first and second evaluate (or don’t evaluate) to the
same object.

New in version 3.1."
"assertIsNone(expr, msg=None)","Test that expr is (or is not) None.

New in version 3.1."
"assertIn(first, second, msg=None)","Test that first is (or is not) in second.

New in version 3.1."
"assertIsInstance(obj, cls, msg=None)","Test that obj is (or is not) an instance of cls (which can be a
class or a tuple of classes, as supported by isinstance()).
To check for the exact type, use assertIs(type(obj), cls).

New in version 3.2."
"assertRaises(exception, callable, *args, **kwds)","Test that an exception is raised when callable is called with any
positional or keyword arguments that are also passed to
assertRaises().  The test passes if exception is raised, is an
error if another exception is raised, or fails if no exception is raised.
To catch any of a group of exceptions, a tuple containing the exception
classes may be passed as exception.
If only the exception and possibly the msg arguments are given,
return a context manager so that the code under test can be written
inline rather than as a function:
with self.assertRaises(SomeException):
    do_something()


When used as a context manager, assertRaises() accepts the
additional keyword argument msg.
The context manager will store the caught exception object in its
exception attribute.  This can be useful if the intention
is to perform additional checks on the exception raised:
with self.assertRaises(SomeException) as cm:
    do_something()

the_exception = cm.exception
self.assertEqual(the_exception.error_code, 3)



Changed in version 3.1: Added the ability to use assertRaises() as a context manager.


Changed in version 3.2: Added the exception attribute.


Changed in version 3.3: Added the msg keyword argument when used as a context manager."
"assertRaisesRegex(exception, regex, callable, *args, **kwds)","Like assertRaises() but also tests that regex matches
on the string representation of the raised exception.  regex may be
a regular expression object or a string containing a regular expression
suitable for use by re.search().  Examples:
self.assertRaisesRegex(ValueError, ""invalid literal for.*XYZ'$"",
                       int, 'XYZ')


or:
with self.assertRaisesRegex(ValueError, 'literal'):
   int('XYZ')



New in version 3.1: Added under the name assertRaisesRegexp.


Changed in version 3.2: Renamed to assertRaisesRegex().


Changed in version 3.3: Added the msg keyword argument when used as a context manager."
"assertWarns(warning, callable, *args, **kwds)","Test that a warning is triggered when callable is called with any
positional or keyword arguments that are also passed to
assertWarns().  The test passes if warning is triggered and
fails if it isn’t.  Any exception is an error.
To catch any of a group of warnings, a tuple containing the warning
classes may be passed as warnings.
If only the warning and possibly the msg arguments are given,
return a context manager so that the code under test can be written
inline rather than as a function:
with self.assertWarns(SomeWarning):
    do_something()


When used as a context manager, assertWarns() accepts the
additional keyword argument msg.
The context manager will store the caught warning object in its
warning attribute, and the source line which triggered the
warnings in the filename and lineno attributes.
This can be useful if the intention is to perform additional checks
on the warning caught:
with self.assertWarns(SomeWarning) as cm:
    do_something()

self.assertIn('myfile.py', cm.filename)
self.assertEqual(320, cm.lineno)


This method works regardless of the warning filters in place when it
is called.

New in version 3.2.


Changed in version 3.3: Added the msg keyword argument when used as a context manager."
"assertWarnsRegex(warning, regex, callable, *args, **kwds)","Like assertWarns() but also tests that regex matches on the
message of the triggered warning.  regex may be a regular expression
object or a string containing a regular expression suitable for use
by re.search().  Example:
self.assertWarnsRegex(DeprecationWarning,
                      r'legacy_function\(\) is deprecated',
                      legacy_function, 'XYZ')


or:
with self.assertWarnsRegex(RuntimeWarning, 'unsafe frobnicating'):
    frobnicate('/etc/passwd')



New in version 3.2.


Changed in version 3.3: Added the msg keyword argument when used as a context manager."
"assertLogs(logger=None, level=None)","A context manager to test that at least one message is logged on
the logger or one of its children, with at least the given
level.
If given, logger should be a logging.Logger object or a
str giving the name of a logger.  The default is the root
logger, which will catch all messages.
If given, level should be either a numeric logging level or
its string equivalent (for example either ""ERROR"" or
logging.ERROR).  The default is logging.INFO.
The test passes if at least one message emitted inside the with
block matches the logger and level conditions, otherwise it fails.
The object returned by the context manager is a recording helper
which keeps tracks of the matching log messages.  It has two
attributes:


records¶
A list of logging.LogRecord objects of the matching
log messages.



output¶
A list of str objects with the formatted output of
matching messages.

Example:
with self.assertLogs('foo', level='INFO') as cm:
   logging.getLogger('foo').info('first message')
   logging.getLogger('foo.bar').error('second message')
self.assertEqual(cm.output, ['INFO:foo:first message',
                             'ERROR:foo.bar:second message'])



New in version 3.4."
"assertAlmostEqual(first, second, places=7, msg=None, delta=None)","Test that first and second are approximately (or not approximately)
equal by computing the difference, rounding to the given number of
decimal places (default 7), and comparing to zero.  Note that these
methods round the values to the given number of decimal places (i.e.
like the round() function) and not significant digits.
If delta is supplied instead of places then the difference
between first and second must be less or equal to (or greater than) delta.
Supplying both delta and places raises a TypeError.

Changed in version 3.2: assertAlmostEqual() automatically considers almost equal objects
that compare equal.  assertNotAlmostEqual() automatically fails
if the objects compare equal.  Added the delta keyword argument."
"assertGreater(first, second, msg=None)","Test that first is respectively >, >=, < or <= than second depending
on the method name.  If not, the test will fail:
>>> self.assertGreaterEqual(3, 4)
AssertionError: ""3"" unexpectedly not greater than or equal to ""4""



New in version 3.1."
"assertRegex(text, regex, msg=None)","Test that a regex search matches (or does not match) text.  In case
of failure, the error message will include the pattern and the text (or
the pattern and the part of text that unexpectedly matched).  regex
may be a regular expression object or a string containing a regular
expression suitable for use by re.search().

New in version 3.1: Added under the name assertRegexpMatches.


Changed in version 3.2: The method assertRegexpMatches() has been renamed to
assertRegex().


New in version 3.2: assertNotRegex().


New in version 3.5: The name assertNotRegexpMatches is a deprecated alias
for assertNotRegex()."
"assertCountEqual(first, second, msg=None)","Test that sequence first contains the same elements as second,
regardless of their order. When they don’t, an error message listing the
differences between the sequences will be generated.
Duplicate elements are not ignored when comparing first and
second. It verifies whether each element has the same count in both
sequences. Equivalent to:
assertEqual(Counter(list(first)), Counter(list(second)))
but works with sequences of unhashable objects as well.

New in version 3.2."
"addTypeEqualityFunc(typeobj, function)","Registers a type-specific method called by assertEqual() to check
if two objects of exactly the same typeobj (not subclasses) compare
equal.  function must take two positional arguments and a third msg=None
keyword argument just as assertEqual() does.  It must raise
self.failureException(msg) when inequality
between the first two parameters is detected – possibly providing useful
information and explaining the inequalities in details in the error
message.

New in version 3.1."
"assertMultiLineEqual(first, second, msg=None)","Test that the multiline string first is equal to the string second.
When not equal a diff of the two strings highlighting the differences
will be included in the error message. This method is used by default
when comparing strings with assertEqual().

New in version 3.1."
"assertSequenceEqual(first, second, msg=None, seq_type=None)","Tests that two sequences are equal.  If a seq_type is supplied, both
first and second must be instances of seq_type or a failure will
be raised.  If the sequences are different an error message is
constructed that shows the difference between the two.
This method is not called directly by assertEqual(), but
it’s used to implement assertListEqual() and
assertTupleEqual().

New in version 3.1."
"assertListEqual(first, second, msg=None)","Tests that two lists or tuples are equal.  If not, an error message is
constructed that shows only the differences between the two.  An error
is also raised if either of the parameters are of the wrong type.
These methods are used by default when comparing lists or tuples with
assertEqual().

New in version 3.1."
"assertSetEqual(first, second, msg=None)","Tests that two sets are equal.  If not, an error message is constructed
that lists the differences between the sets.  This method is used by
default when comparing sets or frozensets with assertEqual().
Fails if either of first or second does not have a set.difference()
method.

New in version 3.1."
"assertDictEqual(first, second, msg=None)","Test that two dictionaries are equal.  If not, an error message is
constructed that shows the differences in the dictionaries. This
method will be used by default to compare dictionaries in
calls to assertEqual().

New in version 3.1."
fail(msg=None),"Signals a test failure unconditionally, with msg or None for
the error message."
countTestCases(),"Return the number of tests represented by this test object.  For
TestCase instances, this will always be 1."
defaultTestResult(),"Return an instance of the test result class that should be used for this
test case class (if no other result instance is provided to the
run() method).
For TestCase instances, this will always be an instance of
TestResult; subclasses of TestCase should override this
as necessary."
id(),"Return a string identifying the specific test case.  This is usually the
full name of the test method, including the module and class name."
shortDescription(),"Returns a description of the test, or None if no description
has been provided.  The default implementation of this method
returns the first line of the test method’s docstring, if available,
or None.

Changed in version 3.1: In 3.1 this was changed to add the test name to the short description
even in the presence of a docstring.  This caused compatibility issues
with unittest extensions and adding the test name was moved to the
TextTestResult in Python 3.2."
"addCleanup(function, *args, **kwargs)","Add a function to be called after tearDown() to cleanup resources
used during the test. Functions will be called in reverse order to the
order they are added (LIFO).  They
are called with any arguments and keyword arguments passed into
addCleanup() when they are added.
If setUp() fails, meaning that tearDown() is not called,
then any cleanup functions added will still be called.

New in version 3.1."
doCleanups(),"This method is called unconditionally after tearDown(), or
after setUp() if setUp() raises an exception.
It is responsible for calling all the cleanup functions added by
addCleanup(). If you need cleanup functions to be called
prior to tearDown() then you can call doCleanups()
yourself.
doCleanups() pops methods off the stack of cleanup
functions one at a time, so it can be called at any time.

New in version 3.1."
"classmethod addClassCleanup(function, /, *args, **kwargs)","Add a function to be called after tearDownClass() to cleanup
resources used during the test class. Functions will be called in reverse
order to the order they are added (LIFO).
They are called with any arguments and keyword arguments passed into
addClassCleanup() when they are added.
If setUpClass() fails, meaning that tearDownClass() is not
called, then any cleanup functions added will still be called.

New in version 3.8."
classmethod doClassCleanups(),"This method is called unconditionally after tearDownClass(), or
after setUpClass() if setUpClass() raises an exception.
It is responsible for calling all the cleanup functions added by
addCleanupClass(). If you need cleanup functions to be called
prior to tearDownClass() then you can call
doCleanupsClass() yourself.
doCleanupsClass() pops methods off the stack of cleanup
functions one at a time, so it can be called at any time.

New in version 3.8."
coroutine asyncSetUp(),"Method called to prepare the test fixture. This is called after setUp().
This is called immediately before calling the test method; other than
AssertionError or SkipTest, any exception raised by this method
will be considered an error rather than a test failure. The default implementation
does nothing."
coroutine asyncTearDown(),"Method called immediately after the test method has been called and the
result recorded.  This is called before tearDown(). This is called even if
the test method raised an exception, so the implementation in subclasses may need
to be particularly careful about checking internal state.  Any exception, other than
AssertionError or SkipTest, raised by this method will be
considered an additional error rather than a test failure (thus increasing
the total number of reported errors). This method will only be called if
the asyncSetUp() succeeds, regardless of the outcome of the test method.
The default implementation does nothing."
"addAsyncCleanup(function, /, *args, **kwargs)",This method accepts a coroutine that can be used as a cleanup function.
run(result=None),"Sets up a new event loop to run the test, collecting the result into
the TestResult object passed as result.  If result is
omitted or None, a temporary result object is created (by calling
the defaultTestResult() method) and used. The result object is
returned to run()’s caller. At the end of the test all the tasks
in the event loop are cancelled."
addTest(test),Add a TestCase or TestSuite to the suite.
addTests(tests),"Add all the tests from an iterable of TestCase and TestSuite
instances to this test suite.
This is equivalent to iterating over tests, calling addTest() for
each element."
run(result),"Run the tests associated with this suite, collecting the result into the
test result object passed as result.  Note that unlike
TestCase.run(), TestSuite.run() requires the result object to
be passed in."
debug(),"Run the tests associated with this suite without collecting the
result. This allows exceptions raised by the test to be propagated to the
caller and can be used to support running tests under a debugger."
countTestCases(),"Return the number of tests represented by this test object, including all
individual tests and sub-suites."
__iter__(),"Tests grouped by a TestSuite are always accessed by iteration.
Subclasses can lazily provide tests by overriding __iter__(). Note
that this method may be called several times on a single suite (for
example when counting tests or comparing for equality) so the tests
returned by repeated iterations before TestSuite.run() must be the
same for each call iteration. After TestSuite.run(), callers should
not rely on the tests returned by this method unless the caller uses a
subclass that overrides TestSuite._removeTestAtIndex() to preserve
test references.

Changed in version 3.2: In earlier versions the TestSuite accessed tests directly rather
than through iteration, so overriding __iter__() wasn’t sufficient
for providing tests.


Changed in version 3.4: In earlier versions the TestSuite held references to each
TestCase after TestSuite.run(). Subclasses can restore
that behavior by overriding TestSuite._removeTestAtIndex()."
loadTestsFromTestCase(testCaseClass),"Return a suite of all test cases contained in the TestCase-derived
testCaseClass.
A test case instance is created for each method named by
getTestCaseNames(). By default these are the method names
beginning with test. If getTestCaseNames() returns no
methods, but the runTest() method is implemented, a single test
case is created for that method instead."
"loadTestsFromModule(module, pattern=None)","Return a suite of all test cases contained in the given module. This
method searches module for classes derived from TestCase and
creates an instance of the class for each test method defined for the
class.

Note
While using a hierarchy of TestCase-derived classes can be
convenient in sharing fixtures and helper functions, defining test
methods on base classes that are not intended to be instantiated
directly does not play well with this method.  Doing so, however, can
be useful when the fixtures are different and defined in subclasses.

If a module provides a load_tests function it will be called to
load the tests. This allows modules to customize test loading.
This is the load_tests protocol.  The pattern argument is passed as
the third argument to load_tests.

Changed in version 3.2: Support for load_tests added.


Changed in version 3.5: The undocumented and unofficial use_load_tests default argument is
deprecated and ignored, although it is still accepted for backward
compatibility.  The method also now accepts a keyword-only argument
pattern which is passed to load_tests as the third argument."
"loadTestsFromName(name, module=None)","Return a suite of all test cases given a string specifier.
The specifier name is a “dotted name” that may resolve either to a
module, a test case class, a test method within a test case class, a
TestSuite instance, or a callable object which returns a
TestCase or TestSuite instance.  These checks are
applied in the order listed here; that is, a method on a possible test
case class will be picked up as “a test method within a test case class”,
rather than “a callable object”.
For example, if you have a module SampleTests containing a
TestCase-derived class SampleTestCase with three test
methods (test_one(), test_two(), and test_three()), the
specifier 'SampleTests.SampleTestCase' would cause this method to
return a suite which will run all three test methods. Using the specifier
'SampleTests.SampleTestCase.test_two' would cause it to return a test
suite which will run only the test_two() test method. The specifier
can refer to modules and packages which have not been imported; they will
be imported as a side-effect.
The method optionally resolves name relative to the given module.

Changed in version 3.5: If an ImportError or AttributeError occurs while traversing
name then a synthetic test that raises that error when run will be
returned. These errors are included in the errors accumulated by
self.errors."
"loadTestsFromNames(names, module=None)","Similar to loadTestsFromName(), but takes a sequence of names rather
than a single name.  The return value is a test suite which supports all
the tests defined for each name."
getTestCaseNames(testCaseClass),"Return a sorted sequence of method names found within testCaseClass;
this should be a subclass of TestCase."
"discover(start_dir, pattern='test*.py', top_level_dir=None)","Find all the test modules by recursing into subdirectories from the
specified start directory, and return a TestSuite object containing them.
Only test files that match pattern will be loaded. (Using shell style
pattern matching.) Only module names that are importable (i.e. are valid
Python identifiers) will be loaded.
All test modules must be importable from the top level of the project. If
the start directory is not the top level directory then the top level
directory must be specified separately.
If importing a module fails, for example due to a syntax error, then
this will be recorded as a single error and discovery will continue.  If
the import failure is due to SkipTest being raised, it will be
recorded as a skip instead of an error.
If a package (a directory containing a file named __init__.py) is
found, the package will be checked for a load_tests function. If this
exists then it will be called
package.load_tests(loader, tests, pattern). Test discovery takes care
to ensure that a package is only checked for tests once during an
invocation, even if the load_tests function itself calls
loader.discover.
If load_tests exists then discovery does not recurse into the
package, load_tests is responsible for loading all tests in the
package.
The pattern is deliberately not stored as a loader attribute so that
packages can continue discovery themselves. top_level_dir is stored so
load_tests does not need to pass this argument in to
loader.discover().
start_dir can be a dotted module name as well as a directory.

New in version 3.2.


Changed in version 3.4: Modules that raise SkipTest on import are recorded as skips,
  not errors.
Discovery works for namespace packages.
Paths are sorted before being imported so that execution order is
  the same even if the underlying file system’s ordering is not
  dependent on file name.


Changed in version 3.5: Found packages are now checked for load_tests regardless of
whether their path matches pattern, because it is impossible for
a package name to match the default pattern."
wasSuccessful(),"Return True if all tests run so far have passed, otherwise returns
False.

Changed in version 3.4: Returns False if there were any unexpectedSuccesses
from tests marked with the expectedFailure() decorator."
stop(),"This method can be called to signal that the set of tests being run should
be aborted by setting the shouldStop attribute to True.
TestRunner objects should respect this flag and return without
running any additional tests.
For example, this feature is used by the TextTestRunner class to
stop the test framework when the user signals an interrupt from the
keyboard.  Interactive tools which provide TestRunner
implementations can use this in a similar manner."
startTest(test),Called when the test case test is about to be run.
stopTest(test),"Called after the test case test has been executed, regardless of the
outcome."
startTestRun(),"Called once before any tests are executed.

New in version 3.1."
stopTestRun(),"Called once after all tests are executed.

New in version 3.1."
"addError(test, err)","Called when the test case test raises an unexpected exception. err is a
tuple of the form returned by sys.exc_info(): (type, value,
traceback).
The default implementation appends a tuple (test, formatted_err) to
the instance’s errors attribute, where formatted_err is a
formatted traceback derived from err."
"addFailure(test, err)","Called when the test case test signals a failure. err is a tuple of
the form returned by sys.exc_info(): (type, value, traceback).
The default implementation appends a tuple (test, formatted_err) to
the instance’s failures attribute, where formatted_err is a
formatted traceback derived from err."
addSuccess(test),"Called when the test case test succeeds.
The default implementation does nothing."
"addSkip(test, reason)","Called when the test case test is skipped.  reason is the reason the
test gave for skipping.
The default implementation appends a tuple (test, reason) to the
instance’s skipped attribute."
"addExpectedFailure(test, err)","Called when the test case test fails, but was marked with the
expectedFailure() decorator.
The default implementation appends a tuple (test, formatted_err) to
the instance’s expectedFailures attribute, where formatted_err
is a formatted traceback derived from err."
addUnexpectedSuccess(test),"Called when the test case test was marked with the
expectedFailure() decorator, but succeeded.
The default implementation appends the test to the instance’s
unexpectedSuccesses attribute."
"addSubTest(test, subtest, outcome)","Called when a subtest finishes.  test is the test case
corresponding to the test method.  subtest is a custom
TestCase instance describing the subtest.
If outcome is None, the subtest succeeded.  Otherwise,
it failed with an exception where outcome is a tuple of the form
returned by sys.exc_info(): (type, value, traceback).
The default implementation does nothing when the outcome is a
success, and records subtest failures as normal failures.

New in version 3.4."
_makeResult(),"This method returns the instance of TestResult used by run().
It is not intended to be called directly, but can be overridden in
subclasses to provide a custom TestResult.
_makeResult() instantiates the class or callable passed in the
TextTestRunner constructor as the resultclass argument. It
defaults to TextTestResult if no resultclass is provided.
The result class is instantiated with the following arguments:
stream, descriptions, verbosity"
run(test),"This method is the main public interface to the TextTestRunner. This
method takes a TestSuite or TestCase instance. A
TestResult is created by calling
_makeResult() and the test(s) are run and the
results printed to stdout."
"unittest.mock.patch(target, new=DEFAULT, spec=None, create=False, spec_set=None, autospec=None, new_callable=None, **kwargs)","patch() acts as a function decorator, class decorator or a context
manager. Inside the body of the function or with statement, the target
is patched with a new object. When the function/with statement exits
the patch is undone.
If new is omitted, then the target is replaced with an
AsyncMock if the patched object is an async function or
a MagicMock otherwise.
If patch() is used as a decorator and new is
omitted, the created mock is passed in as an extra argument to the
decorated function. If patch() is used as a context manager the created
mock is returned by the context manager.
target should be a string in the form 'package.module.ClassName'. The
target is imported and the specified object replaced with the new
object, so the target must be importable from the environment you are
calling patch() from. The target is imported when the decorated function
is executed, not at decoration time.
The spec and spec_set keyword arguments are passed to the MagicMock
if patch is creating one for you.
In addition you can pass spec=True or spec_set=True, which causes
patch to pass in the object being mocked as the spec/spec_set object.
new_callable allows you to specify a different class, or callable object,
that will be called to create the new object. By default AsyncMock
is used for async functions and MagicMock for the rest.
A more powerful form of spec is autospec. If you set autospec=True
then the mock will be created with a spec from the object being replaced.
All attributes of the mock will also have the spec of the corresponding
attribute of the object being replaced. Methods and functions being mocked
will have their arguments checked and will raise a TypeError if they are
called with the wrong signature. For mocks
replacing a class, their return value (the ‘instance’) will have the same
spec as the class. See the create_autospec() function and
Autospeccing.
Instead of autospec=True you can pass autospec=some_object to use an
arbitrary object as the spec instead of the one being replaced.
By default patch() will fail to replace attributes that don’t exist.
If you pass in create=True, and the attribute doesn’t exist, patch will
create the attribute for you when the patched function is called, and delete
it again after the patched function has exited. This is useful for writing
tests against attributes that your production code creates at runtime. It is
off by default because it can be dangerous. With it switched on you can
write passing tests against APIs that don’t actually exist!

Note

Changed in version 3.5: If you are patching builtins in a module then you don’t
need to pass create=True, it will be added by default.


Patch can be used as a TestCase class decorator. It works by
decorating each test method in the class. This reduces the boilerplate
code when your test methods share a common patchings set. patch() finds
tests by looking for method names that start with patch.TEST_PREFIX.
By default this is 'test', which matches the way unittest finds tests.
You can specify an alternative prefix by setting patch.TEST_PREFIX.
Patch can be used as a context manager, with the with statement. Here the
patching applies to the indented block after the with statement. If you
use “as” then the patched object will be bound to the name after the
“as”; very useful if patch() is creating a mock object for you.
patch() takes arbitrary keyword arguments. These will be passed to
the Mock (or new_callable) on construction.
patch.dict(...), patch.multiple(...) and patch.object(...) are
available for alternate use-cases."
"patch.object(target, attribute, new=DEFAULT, spec=None, create=False, spec_set=None, autospec=None, new_callable=None, **kwargs)","patch the named member (attribute) on an object (target) with a mock
object.
patch.object() can be used as a decorator, class decorator or a context
manager. Arguments new, spec, create, spec_set, autospec and
new_callable have the same meaning as for patch(). Like patch(),
patch.object() takes arbitrary keyword arguments for configuring the mock
object it creates.
When used as a class decorator patch.object() honours patch.TEST_PREFIX
for choosing which methods to wrap."
"patch.dict(in_dict, values=(), clear=False, **kwargs)","Patch a dictionary, or dictionary like object, and restore the dictionary
to its original state after the test.
in_dict can be a dictionary or a mapping like container. If it is a
mapping then it must at least support getting, setting and deleting items
plus iterating over keys.
in_dict can also be a string specifying the name of the dictionary, which
will then be fetched by importing it.
values can be a dictionary of values to set in the dictionary. values
can also be an iterable of (key, value) pairs.
If clear is true then the dictionary will be cleared before the new
values are set.
patch.dict() can also be called with arbitrary keyword arguments to set
values in the dictionary.

Changed in version 3.8: patch.dict() now returns the patched dictionary when used as a context
manager."
"patch.multiple(target, spec=None, create=False, spec_set=None, autospec=None, new_callable=None, **kwargs)","Perform multiple patches in a single call. It takes the object to be
patched (either as an object or a string to fetch the object by importing)
and keyword arguments for the patches:
with patch.multiple(settings, FIRST_PATCH='one', SECOND_PATCH='two'):
    ...


Use DEFAULT as the value if you want patch.multiple() to create
mocks for you. In this case the created mocks are passed into a decorated
function by keyword, and a dictionary is returned when patch.multiple() is
used as a context manager.
patch.multiple() can be used as a decorator, class decorator or a context
manager. The arguments spec, spec_set, create, autospec and
new_callable have the same meaning as for patch(). These arguments will
be applied to all patches done by patch.multiple().
When used as a class decorator patch.multiple() honours patch.TEST_PREFIX
for choosing which methods to wrap."
patch.stopall(),Stop all active patches. Only stops patches started with start.
"unittest.mock.call(*args, **kwargs)","call() is a helper object for making simpler assertions, for comparing with
call_args, call_args_list,
mock_calls and method_calls. call() can also be
used with assert_has_calls().
>>> m = MagicMock(return_value=None)
>>> m(1, 2, a='foo', b='bar')
>>> m()
>>> m.call_args_list == [call(1, 2, a='foo', b='bar'), call()]
True"
"unittest.mock.create_autospec(spec, spec_set=False, instance=False, **kwargs)","Create a mock object using another object as a spec. Attributes on the
mock will use the corresponding attribute on the spec object as their
spec.
Functions or methods being mocked will have their arguments checked to
ensure that they are called with the correct signature.
If spec_set is True then attempting to set attributes that don’t exist
on the spec object will raise an AttributeError.
If a class is used as a spec then the return value of the mock (the
instance of the class) will have the same spec. You can use a class as the
spec for an instance object by passing instance=True. The returned mock
will only be callable if instances of the mock are callable.
create_autospec() also takes arbitrary keyword arguments that are passed to
the constructor of the created mock."
"unittest.mock.mock_open(mock=None, read_data=None)","A helper function to create a mock to replace the use of open(). It works
for open() called directly or used as a context manager.
The mock argument is the mock object to configure. If None (the
default) then a MagicMock will be created for you, with the API limited
to methods or attributes available on standard file handles.
read_data is a string for the read(),
readline(), and readlines() methods
of the file handle to return.  Calls to those methods will take data from
read_data until it is depleted.  The mock of these methods is pretty
simplistic: every time the mock is called, the read_data is rewound to
the start.  If you need more control over the data that you are feeding to
the tested code you will need to customize this mock for yourself.  When that
is insufficient, one of the in-memory filesystem packages on PyPI can offer a realistic filesystem for testing.

Changed in version 3.4: Added readline() and readlines() support.
The mock of read() changed to consume read_data rather
than returning it on each call.


Changed in version 3.5: read_data is now reset on each call to the mock.


Changed in version 3.8: Added __iter__() to implementation so that iteration (such as in for
loops) correctly consumes read_data."
unittest.mock.seal(mock),"Seal will disable the automatic creation of mocks when accessing an attribute of
the mock being sealed or any of its attributes that are already mocks recursively.
If a mock instance with a name or a spec is assigned to an attribute
it won’t be considered in the sealing chain. This allows one to prevent seal from
fixing part of the mock object.
>>> mock = Mock()
>>> mock.submock.attribute1 = 2
>>> mock.not_submock = mock.Mock(name=""sample_name"")
>>> seal(mock)
>>> mock.new_attribute  # This will raise AttributeError.
>>> mock.submock.attribute2  # This will raise AttributeError.
>>> mock.not_submock.attribute2  # This won't raise.



New in version 3.7."
assert_called(),"Assert that the mock was called at least once.
>>> mock = Mock()
>>> mock.method()
<Mock name='mock.method()' id='...'>
>>> mock.method.assert_called()



New in version 3.6."
assert_called_once(),"Assert that the mock was called exactly once.
>>> mock = Mock()
>>> mock.method()
<Mock name='mock.method()' id='...'>
>>> mock.method.assert_called_once()
>>> mock.method()
<Mock name='mock.method()' id='...'>
>>> mock.method.assert_called_once()
Traceback (most recent call last):
...
AssertionError: Expected 'method' to have been called once. Called 2 times.



New in version 3.6."
"assert_called_with(*args, **kwargs)","This method is a convenient way of asserting that the last call has been
made in a particular way:
>>> mock = Mock()
>>> mock.method(1, 2, 3, test='wow')
<Mock name='mock.method()' id='...'>
>>> mock.method.assert_called_with(1, 2, 3, test='wow')"
"assert_called_once_with(*args, **kwargs)","Assert that the mock was called exactly once and that that call was
with the specified arguments.
>>> mock = Mock(return_value=None)
>>> mock('foo', bar='baz')
>>> mock.assert_called_once_with('foo', bar='baz')
>>> mock('other', bar='values')
>>> mock.assert_called_once_with('other', bar='values')
Traceback (most recent call last):
  ...
AssertionError: Expected 'mock' to be called once. Called 2 times."
"assert_any_call(*args, **kwargs)","assert the mock has been called with the specified arguments.
The assert passes if the mock has ever been called, unlike
assert_called_with() and assert_called_once_with() that
only pass if the call is the most recent one, and in the case of
assert_called_once_with() it must also be the only call.
>>> mock = Mock(return_value=None)
>>> mock(1, 2, arg='thing')
>>> mock('some', 'thing', 'else')
>>> mock.assert_any_call(1, 2, arg='thing')"
"assert_has_calls(calls, any_order=False)","assert the mock has been called with the specified calls.
The mock_calls list is checked for the calls.
If any_order is false then the calls must be
sequential. There can be extra calls before or after the
specified calls.
If any_order is true then the calls can be in any order, but
they must all appear in mock_calls.
>>> mock = Mock(return_value=None)
>>> mock(1)
>>> mock(2)
>>> mock(3)
>>> mock(4)
>>> calls = [call(2), call(3)]
>>> mock.assert_has_calls(calls)
>>> calls = [call(4), call(2), call(3)]
>>> mock.assert_has_calls(calls, any_order=True)"
assert_not_called(),"Assert the mock was never called.
>>> m = Mock()
>>> m.hello.assert_not_called()
>>> obj = m.hello()
>>> m.hello.assert_not_called()
Traceback (most recent call last):
  ...
AssertionError: Expected 'hello' to not have been called. Called 1 times.



New in version 3.5."
"reset_mock(*, return_value=False, side_effect=False)","The reset_mock method resets all the call attributes on a mock object:
>>> mock = Mock(return_value=None)
>>> mock('hello')
>>> mock.called
True
>>> mock.reset_mock()
>>> mock.called
False



Changed in version 3.6: Added two keyword only argument to the reset_mock function.

This can be useful where you want to make a series of assertions that
reuse the same object. Note that reset_mock() doesn’t clear the
return value, side_effect or any child attributes you have
set using normal assignment by default. In case you want to reset
return_value or side_effect, then pass the corresponding
parameter as True. Child mocks and the return value mock
(if any) are reset as well.

Note
return_value, and side_effect are keyword only
argument."
"mock_add_spec(spec, spec_set=False)","Add a spec to a mock. spec can either be an object or a
list of strings. Only attributes on the spec can be fetched as
attributes from the mock.
If spec_set is true then only attributes on the spec can be set."
"attach_mock(mock, attribute)","Attach a mock as an attribute of this one, replacing its name and
parent. Calls to the attached mock will be recorded in the
method_calls and mock_calls attributes of this one."
configure_mock(**kwargs),"Set attributes on the mock through keyword arguments.
Attributes plus return values and side effects can be set on child
mocks using standard dot notation and unpacking a dictionary in the
method call:
>>> mock = Mock()
>>> attrs = {'method.return_value': 3, 'other.side_effect': KeyError}
>>> mock.configure_mock(**attrs)
>>> mock.method()
3
>>> mock.other()
Traceback (most recent call last):
  ...
KeyError


The same thing can be achieved in the constructor call to mocks:
>>> attrs = {'method.return_value': 3, 'other.side_effect': KeyError}
>>> mock = Mock(some_attribute='eggs', **attrs)
>>> mock.some_attribute
'eggs'
>>> mock.method()
3
>>> mock.other()
Traceback (most recent call last):
  ...
KeyError


configure_mock() exists to make it easier to do configuration
after the mock has been created."
__dir__(),"Mock objects limit the results of dir(some_mock) to useful results.
For mocks with a spec this includes all the permitted attributes
for the mock.
See FILTER_DIR for what this filtering does, and how to
switch it off."
_get_child_mock(**kw),"Create the child mocks for attributes and return value.
By default child mocks will be the same type as the parent.
Subclasses of Mock may want to override this to customize the way
child mocks are made.
For non-callable mocks the callable variant will be used (rather than
any custom subclass)."
assert_awaited(),"Assert that the mock was awaited at least once. Note that this is separate
from the object having been called, the await keyword must be used:
>>> mock = AsyncMock()
>>> async def main(coroutine_mock):
...     await coroutine_mock
...
>>> coroutine_mock = mock()
>>> mock.called
True
>>> mock.assert_awaited()
Traceback (most recent call last):
...
AssertionError: Expected mock to have been awaited.
>>> asyncio.run(main(coroutine_mock))
>>> mock.assert_awaited()"
assert_awaited_once(),"Assert that the mock was awaited exactly once.
>>> mock = AsyncMock()
>>> async def main():
...     await mock()
...
>>> asyncio.run(main())
>>> mock.assert_awaited_once()
>>> asyncio.run(main())
>>> mock.method.assert_awaited_once()
Traceback (most recent call last):
...
AssertionError: Expected mock to have been awaited once. Awaited 2 times."
"assert_awaited_with(*args, **kwargs)","Assert that the last await was with the specified arguments.
>>> mock = AsyncMock()
>>> async def main(*args, **kwargs):
...     await mock(*args, **kwargs)
...
>>> asyncio.run(main('foo', bar='bar'))
>>> mock.assert_awaited_with('foo', bar='bar')
>>> mock.assert_awaited_with('other')
Traceback (most recent call last):
...
AssertionError: expected call not found.
Expected: mock('other')
Actual: mock('foo', bar='bar')"
"assert_awaited_once_with(*args, **kwargs)","Assert that the mock was awaited exactly once and with the specified
arguments.
>>> mock = AsyncMock()
>>> async def main(*args, **kwargs):
...     await mock(*args, **kwargs)
...
>>> asyncio.run(main('foo', bar='bar'))
>>> mock.assert_awaited_once_with('foo', bar='bar')
>>> asyncio.run(main('foo', bar='bar'))
>>> mock.assert_awaited_once_with('foo', bar='bar')
Traceback (most recent call last):
...
AssertionError: Expected mock to have been awaited once. Awaited 2 times."
"assert_any_await(*args, **kwargs)","Assert the mock has ever been awaited with the specified arguments.
>>> mock = AsyncMock()
>>> async def main(*args, **kwargs):
...     await mock(*args, **kwargs)
...
>>> asyncio.run(main('foo', bar='bar'))
>>> asyncio.run(main('hello'))
>>> mock.assert_any_await('foo', bar='bar')
>>> mock.assert_any_await('other')
Traceback (most recent call last):
...
AssertionError: mock('other') await not found"
"assert_has_awaits(calls, any_order=False)","Assert the mock has been awaited with the specified calls.
The await_args_list list is checked for the awaits.
If any_order is false then the awaits must be
sequential. There can be extra calls before or after the
specified awaits.
If any_order is true then the awaits can be in any order, but
they must all appear in await_args_list.
>>> mock = AsyncMock()
>>> async def main(*args, **kwargs):
...     await mock(*args, **kwargs)
...
>>> calls = [call(""foo""), call(""bar"")]
>>> mock.assert_has_awaits(calls)
Traceback (most recent call last):
...
AssertionError: Awaits not found.
Expected: [call('foo'), call('bar')]
Actual: []
>>> asyncio.run(main('foo'))
>>> asyncio.run(main('bar'))
>>> mock.assert_has_awaits(calls)"
assert_not_awaited(),"Assert that the mock was never awaited.
>>> mock = AsyncMock()
>>> mock.assert_not_awaited()"
"reset_mock(*args, **kwargs)","See Mock.reset_mock(). Also sets await_count to 0,
await_args to None, and clears the await_args_list."
call.call_list(),"For a call object that represents multiple calls, call_list()
returns a list of all the intermediate calls as well as the
final call."
test.support.forget(module_name),"Remove the module named module_name from sys.modules and delete any
byte-compiled files of the module."
test.support.unload(name),Delete name from sys.modules.
test.support.unlink(filename),"Call os.unlink() on filename.  On Windows platforms, this is
wrapped with a wait loop that checks for the existence fo the file."
test.support.rmdir(filename),"Call os.rmdir() on filename.  On Windows platforms, this is
wrapped with a wait loop that checks for the existence of the file."
test.support.rmtree(path),"Call shutil.rmtree() on path or call os.lstat() and
os.rmdir() to remove a path and its contents.  On Windows platforms,
this is wrapped with a wait loop that checks for the existence of the files."
test.support.make_legacy_pyc(source),"Move a PEP 3147/PEP 488 pyc file to its legacy pyc location and return the file
system path to the legacy pyc file.  The source value is the file system
path to the source file.  It does not need to exist, however the PEP
3147/488 pyc file must exist."
test.support.is_resource_enabled(resource),"Return True if resource is enabled and available. The list of
available resources is only set when test.regrtest is executing the
tests."
test.support.python_is_optimized(),Return True if Python was not built with -O0 or -Og.
test.support.with_pymalloc(),Return _testcapi.WITH_PYMALLOC.
"test.support.requires(resource, msg=None)","Raise ResourceDenied if resource is not available. msg is the
argument to ResourceDenied if it is raised. Always returns
True if called by a function whose __name__ is '__main__'.
Used when tests are executed by test.regrtest."
test.support.system_must_validate_cert(f),Raise unittest.SkipTest on TLS certification validation failures.
test.support.sortdict(dict),Return a repr of dict with keys sorted.
"test.support.findfile(filename, subdir=None)","Return the path to the file named filename. If no match is found
filename is returned. This does not equal a failure since it could be the
path to the file.
Setting subdir indicates a relative path to use to find the file
rather than looking directly in the path directories."
test.support.create_empty_file(filename),"Create an empty file with filename.  If it already exists, truncate it."
test.support.fd_count(),Count the number of open file descriptors.
test.support.match_test(test),Match test to patterns set in set_match_tests().
test.support.set_match_tests(patterns),Define match test with regular expression patterns.
test.support.run_unittest(*classes),"Execute unittest.TestCase subclasses passed to the function. The
function scans the classes for methods starting with the prefix test_
and executes the tests individually.
It is also legal to pass strings as parameters; these should be keys in
sys.modules. Each associated module will be scanned by
unittest.TestLoader.loadTestsFromModule(). This is usually seen in the
following test_main() function:
def test_main():
    support.run_unittest(__name__)


This will run all tests defined in the named module."
"test.support.run_doctest(module, verbosity=None, optionflags=0)","Run doctest.testmod() on the given module.  Return
(failure_count, test_count).
If verbosity is None, doctest.testmod() is run with verbosity
set to verbose.  Otherwise, it is run with verbosity set to
None.  optionflags is passed as optionflags to
doctest.testmod()."
test.support.setswitchinterval(interval),"Set the sys.setswitchinterval() to the given interval.  Defines
a minimum interval for Android systems to prevent the system from hanging."
test.support.check_impl_detail(**guards),"Use this check to guard CPython’s implementation-specific tests or to
run them only on the implementations guarded by the arguments:
check_impl_detail()               # Only on CPython (default).
check_impl_detail(jython=True)    # Only on Jython.
check_impl_detail(cpython=False)  # Everywhere except CPython."
"test.support.check_warnings(*filters, quiet=True)","A convenience wrapper for warnings.catch_warnings() that makes it
easier to test that a warning was correctly raised.  It is approximately
equivalent to calling warnings.catch_warnings(record=True) with
warnings.simplefilter() set to always and with the option to
automatically validate the results that are recorded.
check_warnings accepts 2-tuples of the form (""message regexp"",
WarningCategory) as positional arguments. If one or more filters are
provided, or if the optional keyword argument quiet is False,
it checks to make sure the warnings are as expected:  each specified filter
must match at least one of the warnings raised by the enclosed code or the
test fails, and if any warnings are raised that do not match any of the
specified filters the test fails.  To disable the first of these checks,
set quiet to True.
If no arguments are specified, it defaults to:
check_warnings(("""", Warning), quiet=True)


In this case all warnings are caught and no errors are raised.
On entry to the context manager, a WarningRecorder instance is
returned. The underlying warnings list from
catch_warnings() is available via the recorder object’s
warnings attribute.  As a convenience, the attributes of the object
representing the most recent warning can also be accessed directly through
the recorder object (see example below).  If no warning has been raised,
then any of the attributes that would otherwise be expected on an object
representing a warning will return None.
The recorder object also has a reset() method, which clears the
warnings list.
The context manager is designed to be used like this:
with check_warnings((""assertion is always true"", SyntaxWarning),
                    ("""", UserWarning)):
    exec('assert(False, ""Hey!"")')
    warnings.warn(UserWarning(""Hide me!""))


In this case if either warning was not raised, or some other warning was
raised, check_warnings() would raise an error.
When a test needs to look more deeply into the warnings, rather than
just checking whether or not they occurred, code like this can be used:
with check_warnings(quiet=True) as w:
    warnings.warn(""foo"")
    assert str(w.args[0]) == ""foo""
    warnings.warn(""bar"")
    assert str(w.args[0]) == ""bar""
    assert str(w.warnings[0].args[0]) == ""foo""
    assert str(w.warnings[1].args[0]) == ""bar""
    w.reset()
    assert len(w.warnings) == 0


Here all warnings will be caught, and the test code tests the captured
warnings directly.

Changed in version 3.2: New optional arguments filters and quiet."
test.support.check_no_resource_warning(testcase),"Context manager to check that no ResourceWarning was raised.  You
must remove the object which may emit ResourceWarning before the
end of the context manager."
test.support.set_memlimit(limit),"Set the values for max_memuse and real_max_memuse for big
memory tests."
test.support.record_original_stdout(stdout),"Store the value from stdout.  It is meant to hold the stdout at the
time the regrtest began."
test.support.get_original_stdout(),"Return the original stdout set by record_original_stdout() or
sys.stdout if it’s not set."
test.support.strip_python_strerr(stderr),"Strip the stderr of a Python process from potential debug output
emitted by the interpreter.  This will typically be run on the result of
subprocess.Popen.communicate()."
test.support.args_from_interpreter_flags(),"Return a list of command line arguments reproducing the current settings
in sys.flags and sys.warnoptions."
test.support.optim_args_from_interpreter_flags(),"Return a list of command line arguments reproducing the current
optimization settings in sys.flags."
test.support.captured_stdin(),"A context managers that temporarily replaces the named stream with
io.StringIO object.
Example use with output streams:
with captured_stdout() as stdout, captured_stderr() as stderr:
    print(""hello"")
    print(""error"", file=sys.stderr)
assert stdout.getvalue() == ""hello\n""
assert stderr.getvalue() == ""error\n""


Example use with input stream:
with captured_stdin() as stdin:
    stdin.write('hello\n')
    stdin.seek(0)
    # call test code that consumes from sys.stdin
    captured = input()
self.assertEqual(captured, ""hello"")"
"test.support.temp_dir(path=None, quiet=False)","A context manager that creates a temporary directory at path and
yields the directory.
If path is None, the temporary directory is created using
tempfile.mkdtemp().  If quiet is False, the context manager
raises an exception on error.  Otherwise, if path is specified and
cannot be created, only a warning is issued."
"test.support.change_cwd(path, quiet=False)","A context manager that temporarily changes the current working
directory to path and yields the directory.
If quiet is False, the context manager raises an exception
on error.  Otherwise, it issues only a warning and keeps the current
working directory the same."
"test.support.temp_cwd(name='tempcwd', quiet=False)","A context manager that temporarily creates a new directory and
changes the current working directory (CWD).
The context manager creates a temporary directory in the current
directory with name name before temporarily changing the current
working directory.  If name is None, the temporary directory is
created using tempfile.mkdtemp().
If quiet is False and it is not possible to create or change
the CWD, an error is raised.  Otherwise, only a warning is raised
and the original CWD is used."
test.support.temp_umask(umask),A context manager that temporarily sets the process umask.
"test.support.transient_internet(resource_name, *, timeout=30.0, errnos=())","A context manager that raises ResourceDenied when various issues
with the internet connection manifest themselves as exceptions."
test.support.disable_faulthandler(),A context manager that replaces sys.stderr with sys.__stderr__.
test.support.gc_collect(),"Force as many objects as possible to be collected.  This is needed because
timely deallocation is not guaranteed by the garbage collector.  This means
that __del__ methods may be called later than expected and weakrefs
may remain alive for longer than expected."
test.support.disable_gc(),"A context manager that disables the garbage collector upon entry and
reenables it upon exit."
"test.support.swap_attr(obj, attr, new_val)","Context manager to swap out an attribute with a new object.
Usage:
with swap_attr(obj, ""attr"", 5):
    ...


This will set obj.attr to 5 for the duration of the with block,
restoring the old value at the end of the block.  If attr doesn’t
exist on obj, it will be created and then deleted at the end of the
block.
The old value (or None if it doesn’t exist) will be assigned to the
target of the “as” clause, if there is one."
"test.support.swap_item(obj, attr, new_val)","Context manager to swap out an item with a new object.
Usage:
with swap_item(obj, ""item"", 5):
    ...


This will set obj[""item""] to 5 for the duration of the with block,
restoring the old value at the end of the block. If item doesn’t
exist on obj, it will be created and then deleted at the end of the
block.
The old value (or None if it doesn’t exist) will be assigned to the
target of the “as” clause, if there is one."
test.support.wait_threads_exit(timeout=60.0),"Context manager to wait until all threads created in the with statement
exit."
"test.support.start_threads(threads, unlock=None)","Context manager to start threads.  It attempts to join the threads upon
exit."
test.support.calcobjsize(fmt),"Return struct.calcsize() for nP{fmt}0n or, if gettotalrefcount
exists, 2PnP{fmt}0P."
test.support.calcvobjsize(fmt),"Return struct.calcsize() for nPn{fmt}0n or, if gettotalrefcount
exists, 2PnPn{fmt}0P."
"test.support.checksizeof(test, o, size)","For testcase test, assert that the sys.getsizeof for o plus the GC
header size equals size."
test.support.can_symlink(),"Return True if the OS supports symbolic links, False
otherwise."
test.support.can_xattr(),"Return True if the OS supports xattr, False
otherwise."
@test.support.skip_unless_symlink,A decorator for running tests that require support for symbolic links.
@test.support.skip_unless_xattr,A decorator for running tests that require support for xattr.
@test.support.skip_unless_bind_unix_socket,"A decorator for running tests that require a functional bind() for Unix
sockets."
@test.support.anticipate_failure(condition),"A decorator to conditionally mark tests with
unittest.expectedFailure(). Any use of this decorator should
have an associated comment identifying the relevant tracker issue."
"@test.support.run_with_locale(catstr, *locales)","A decorator for running a function in a different locale, correctly
resetting it after it has finished.  catstr is the locale category as
a string (for example ""LC_ALL"").  The locales passed will be tried
sequentially, and the first valid locale will be used."
@test.support.run_with_tz(tz),"A decorator for running a function in a specific timezone, correctly
resetting it after it has finished."
@test.support.requires_freebsd_version(*min_version),"Decorator for the minimum version when running test on FreeBSD.  If the
FreeBSD version is less than the minimum, raise unittest.SkipTest."
@test.support.requires_linux_version(*min_version),"Decorator for the minimum version when running test on Linux.  If the
Linux version is less than the minimum, raise unittest.SkipTest."
@test.support.requires_mac_version(*min_version),"Decorator for the minimum version when running test on Mac OS X.  If the
MAC OS X version is less than the minimum, raise unittest.SkipTest."
@test.support.requires_IEEE_754,Decorator for skipping tests on non-IEEE 754 platforms.
@test.support.requires_zlib,Decorator for skipping tests if zlib doesn’t exist.
@test.support.requires_gzip,Decorator for skipping tests if gzip doesn’t exist.
@test.support.requires_bz2,Decorator for skipping tests if bz2 doesn’t exist.
@test.support.requires_lzma,Decorator for skipping tests if lzma doesn’t exist.
@test.support.requires_resource(resource),Decorator for skipping tests if resource is not available.
@test.support.requires_docstrings,Decorator for only running the test if HAVE_DOCSTRINGS.
@test.support.cpython_only(test),Decorator for tests only applicable to CPython.
"@test.support.impl_detail(msg=None, **guards)","Decorator for invoking check_impl_detail() on guards.  If that
returns False, then uses msg as the reason for skipping the test."
@test.support.no_tracing(func),Decorator to temporarily turn off tracing for the duration of the test.
@test.support.refcount_test(test),"Decorator for tests which involve reference counting.  The decorator does
not run the test if it is not run by CPython.  Any trace function is unset
for the duration of the test to prevent unexpected refcounts caused by
the trace function."
@test.support.reap_threads(func),Decorator to ensure the threads are cleaned up even if the test fails.
"@test.support.bigmemtest(size, memuse, dry_run=True)","Decorator for bigmem tests.
size is a requested size for the test (in arbitrary, test-interpreted
units.)  memuse is the number of bytes per unit for the test, or a good
estimate of it.  For example, a test that needs two byte buffers, of 4 GiB
each, could be decorated with @bigmemtest(size=_4G, memuse=2).
The size argument is normally passed to the decorated test method as an
extra argument.  If dry_run is True, the value passed to the test
method may be less than the requested value.  If dry_run is False, it
means the test doesn’t support dummy runs when -M is not specified."
@test.support.bigaddrspacetest(f),"Decorator for tests that fill the address space.  f is the function to
wrap."
test.support.make_bad_fd(),"Create an invalid file descriptor by opening and closing a temporary file,
and returning its descriptor."
"test.support.check_syntax_error(testcase, statement, errtext='', *, lineno=None, offset=None)","Test for syntax errors in statement by attempting to compile statement.
testcase is the unittest instance for the test.  errtext is the
regular expression which should match the string representation of the
raised SyntaxError.  If lineno is not None, compares to
the line of the exception.  If offset is not None, compares to
the offset of the exception."
"test.support.check_syntax_warning(testcase, statement, errtext='', *, lineno=1, offset=None)","Test for syntax warning in statement by attempting to compile statement.
Test also that the SyntaxWarning is emitted only once, and that it
will be converted to a SyntaxError when turned into error.
testcase is the unittest instance for the test.  errtext is the
regular expression which should match the string representation of the
emitted SyntaxWarning and raised SyntaxError.  If lineno
is not None, compares to the line of the warning and exception.
If offset is not None, compares to the offset of the exception.

New in version 3.8."
"test.support.open_urlresource(url, *args, **kw)","Open url.  If open fails, raises TestFailed."
"test.support.import_module(name, deprecated=False, *, required_on())","This function imports and returns the named module. Unlike a normal
import, this function raises unittest.SkipTest if the module
cannot be imported.
Module and package deprecation messages are suppressed during this import
if deprecated is True.  If a module is required on a platform but
optional for others, set required_on to an iterable of platform prefixes
which will be compared against sys.platform.

New in version 3.1."
"test.support.import_fresh_module(name, fresh=(), blocked=(), deprecated=False)","This function imports and returns a fresh copy of the named Python module
by removing the named module from sys.modules before doing the import.
Note that unlike reload(), the original module is not affected by
this operation.
fresh is an iterable of additional module names that are also removed
from the sys.modules cache before doing the import.
blocked is an iterable of module names that are replaced with None
in the module cache during the import to ensure that attempts to import
them raise ImportError.
The named module and any modules named in the fresh and blocked
parameters are saved before starting the import and then reinserted into
sys.modules when the fresh import is complete.
Module and package deprecation messages are suppressed during this import
if deprecated is True.
This function will raise ImportError if the named module cannot be
imported.
Example use:
# Get copies of the warnings module for testing without affecting the
# version being used by the rest of the test suite. One copy uses the
# C implementation, the other is forced to use the pure Python fallback
# implementation
py_warnings = import_fresh_module('warnings', blocked=['_warnings'])
c_warnings = import_fresh_module('warnings', fresh=['_warnings'])



New in version 3.1."
test.support.modules_setup(),Return a copy of sys.modules.
test.support.modules_cleanup(oldmodules),"Remove modules except for oldmodules and encodings in order to
preserve internal cache."
test.support.threading_setup(),Return current thread count and copy of dangling threads.
test.support.threading_cleanup(*original_values),"Cleanup up threads not specified in original_values.  Designed to emit
a warning if a test leaves running threads in the background."
"test.support.join_thread(thread, timeout=30.0)","Join a thread within timeout.  Raise an AssertionError if thread
is still alive after timeout seconds."
test.support.reap_children(),"Use this at the end of test_main whenever sub-processes are started.
This will help ensure that no extra children (zombies) stick around to
hog resources and create problems when looking for refleaks."
"test.support.get_attribute(obj, name)","Get an attribute, raising unittest.SkipTest if AttributeError
is raised."
"test.support.bind_port(sock, host=HOST)","Bind the socket to a free port and return the port number.  Relies on
ephemeral ports in order to ensure we are using an unbound port.  This is
important as many tests may be running simultaneously, especially in a
buildbot environment.  This method raises an exception if the
sock.family is AF_INET and sock.type is
SOCK_STREAM, and the socket has
SO_REUSEADDR or SO_REUSEPORT set on it.
Tests should never set these socket options for TCP/IP sockets.
The only case for setting these options is testing multicasting via
multiple UDP sockets.
Additionally, if the SO_EXCLUSIVEADDRUSE socket option is
available (i.e. on Windows), it will be set on the socket.  This will
prevent anyone else from binding to our host/port for the duration of the
test."
"test.support.bind_unix_socket(sock, addr)","Bind a unix socket, raising unittest.SkipTest if
PermissionError is raised."
test.support.catch_threading_exception(),"Context manager catching threading.Thread exception using
threading.excepthook().
Attributes set when an exception is catched:

exc_type
exc_value
exc_traceback
thread

See threading.excepthook() documentation.
These attributes are deleted at the context manager exit.
Usage:
with support.catch_threading_exception() as cm:
    # code spawning a thread which raises an exception
    ...

    # check the thread exception, use cm attributes:
    # exc_type, exc_value, exc_traceback, thread
    ...

# exc_type, exc_value, exc_traceback, thread attributes of cm no longer
# exists at this point
# (to avoid reference cycles)



New in version 3.8."
test.support.catch_unraisable_exception(),"Context manager catching unraisable exception using
sys.unraisablehook().
Storing the exception value (cm.unraisable.exc_value) creates a
reference cycle. The reference cycle is broken explicitly when the context
manager exits.
Storing the object (cm.unraisable.object) can resurrect it if it is set
to an object which is being finalized. Exiting the context manager clears
the stored object.
Usage:
with support.catch_unraisable_exception() as cm:
    # code creating an ""unraisable exception""
    ...

    # check the unraisable exception: use cm.unraisable
    ...

# cm.unraisable attribute no longer exists at this point
# (to break a reference cycle)



New in version 3.8."
"test.support.find_unused_port(family=socket.AF_INET, socktype=socket.SOCK_STREAM)","Returns an unused port that should be suitable for binding.  This is
achieved by creating a temporary socket with the same family and type as
the sock parameter (default is AF_INET,
SOCK_STREAM),
and binding it to the specified host address (defaults to 0.0.0.0)
with the port set to 0, eliciting an unused ephemeral port from the OS.
The temporary socket is then closed and deleted, and the ephemeral port is
returned.
Either this method or bind_port() should be used for any tests
where a server socket needs to be bound to a particular port for the
duration of the test.
Which one to use depends on whether the calling code is creating a Python
socket, or if an unused port needs to be provided in a constructor
or passed to an external program (i.e. the -accept argument to
openssl’s s_server mode).  Always prefer bind_port() over
find_unused_port() where possible.  Using a hard coded port is
discouraged since it can make multiple instances of the test impossible to
run simultaneously, which is a problem for buildbots."
"test.support.load_package_tests(pkg_dir, loader, standard_tests, pattern)","Generic implementation of the unittest load_tests protocol for
use in test packages.  pkg_dir is the root directory of the package;
loader, standard_tests, and pattern are the arguments expected by
load_tests.  In simple cases, the test package’s __init__.py
can be the following:
import os
from test.support import load_package_tests

def load_tests(*args):
    return load_package_tests(os.path.dirname(__file__), *args)"
test.support.fs_is_case_insensitive(directory),Return True if the file system for directory is case-insensitive.
"test.support.detect_api_mismatch(ref_api, other_api, *, ignore=())","Returns the set of attributes, functions or methods of ref_api not
found on other_api, except for a defined list of items to be
ignored in this check specified in ignore.
By default this skips private attributes beginning with ‘_’ but
includes all magic methods, i.e. those starting and ending in ‘__’.

New in version 3.5."
"test.support.patch(test_instance, object_to_patch, attr_name, new_value)","Override object_to_patch.attr_name with new_value.  Also add
cleanup procedure to test_instance to restore object_to_patch for
attr_name.  The attr_name should be a valid attribute for
object_to_patch."
test.support.run_in_subinterp(code),"Run code in subinterpreter.  Raise unittest.SkipTest if
tracemalloc is enabled."
"test.support.check_free_after_iterating(test, iter, cls, args=())",Assert that iter is deallocated after iterating.
test.support.missing_compiler_executable(cmd_names=[]),"Check for the existence of the compiler executables whose names are listed
in cmd_names or all the compiler executables when cmd_names is empty
and return the first missing executable or None when none is found
missing."
"test.support.check__all__(test_case, module, name_of_module=None, extra=(), blacklist=())","Assert that the __all__ variable of module contains all public names.
The module’s public names (its API) are detected automatically
based on whether they match the public name convention and were defined in
module.
The name_of_module argument can specify (as a string or tuple thereof) what
module(s) an API could be defined in order to be detected as a public
API. One case for this is when module imports part of its public API from
other modules, possibly a C backend (like csv and its _csv).
The extra argument can be a set of names that wouldn’t otherwise be automatically
detected as “public”, like objects without a proper __module__
attribute. If provided, it will be added to the automatically detected ones.
The blacklist argument can be a set of names that must not be treated as part of
the public API even though their names indicate otherwise.
Example use:
import bar
import foo
import unittest
from test import support

class MiscTestCase(unittest.TestCase):
    def test__all__(self):
        support.check__all__(self, foo)

class OtherTestCase(unittest.TestCase):
    def test__all__(self):
        extra = {'BAR_CONST', 'FOO_CONST'}
        blacklist = {'baz'}  # Undocumented name.
        # bar imports part of its API from _bar.
        support.check__all__(self, bar, ('bar', '_bar'),
                             extra=extra, blacklist=blacklist)



New in version 3.6."
test.support.script_helper.interpreter_requires_environment(),"Return True if sys.executable interpreter requires environment
variables in order to be able to run at all.
This is designed to be used with @unittest.skipIf() to annotate tests
that need to use an assert_python*() function to launch an isolated
mode (-I) or no environment mode (-E) sub-interpreter process.
A normal build & test does not run into this situation but it can happen
when trying to run the standard library test suite from an interpreter that
doesn’t have an obvious home with Python’s current home finding logic.
Setting PYTHONHOME is one way to get most of the testsuite to run
in that situation.  PYTHONPATH or PYTHONUSERSITE are
other common environment variables that might impact whether or not the
interpreter can start."
"test.support.script_helper.run_python_until_end(*args, **env_vars)","Set up the environment based on env_vars for running the interpreter
in a subprocess.  The values can include __isolated, __cleanenv,
__cwd, and TERM."
"test.support.script_helper.assert_python_ok(*args, **env_vars)","Assert that running the interpreter with args and optional environment
variables env_vars succeeds (rc == 0) and return a (return code,
stdout, stderr) tuple.
If the __cleanenv keyword is set, env_vars is used as a fresh
environment.
Python is started in isolated mode (command line option -I),
except if the __isolated keyword is set to False."
"test.support.script_helper.assert_python_failure(*args, **env_vars)","Assert that running the interpreter with args and optional environment
variables env_vars fails (rc != 0) and return a (return code,
stdout, stderr) tuple.
See assert_python_ok() for more options."
"test.support.script_helper.spawn_python(*args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, **kw)","Run a Python subprocess with the given arguments.
kw is extra keyword args to pass to subprocess.Popen(). Returns a
subprocess.Popen object."
test.support.script_helper.kill_python(p),"Run the given subprocess.Popen process until completion and return
stdout."
"test.support.script_helper.make_script(script_dir, script_basename, source, omit_suffix=False)","Create script containing source in path script_dir and script_basename.
If omit_suffix is False, append .py to the name.  Return the full
script path."
"test.support.script_helper.make_zip_script(zip_dir, zip_basename, script_name, name_in_zip=None)","Create zip file at zip_dir and zip_basename with extension zip which
contains the files in script_name. name_in_zip is the archive name.
Return a tuple containing (full path, full path of archive name)."
"test.support.script_helper.make_pkg(pkg_dir, init_source='')","Create a directory named pkg_dir containing an __init__ file with
init_source as its contents."
"test.support.script_helper.make_zip_pkg(zip_dir, zip_basename, pkg_name, script_basename, source, depth=1, compiled=False)","Create a zip package directory with a path of zip_dir and zip_basename
containing an empty __init__ file and a file script_basename
containing the source.  If compiled is True, both source files will
be compiled and added to the zip package.  Return a tuple of the full zip
path and the archive name for the zip file."
"EnvironmentVarGuard.set(envvar, value)","Temporarily set the environment variable envvar to the value of
value."
EnvironmentVarGuard.unset(envvar),Temporarily unset the environment variable envvar.
"matches(self, d, **kwargs)",Try to match a single dict with the supplied arguments.
"match_value(self, k, dv, v)",Try to match a single stored value (dv) with a supplied value (v).
run(test),Run test and return the result.
test.support.forget(module_name),"Remove the module named module_name from sys.modules and delete any
byte-compiled files of the module."
test.support.unload(name),Delete name from sys.modules.
test.support.unlink(filename),"Call os.unlink() on filename.  On Windows platforms, this is
wrapped with a wait loop that checks for the existence fo the file."
test.support.rmdir(filename),"Call os.rmdir() on filename.  On Windows platforms, this is
wrapped with a wait loop that checks for the existence of the file."
test.support.rmtree(path),"Call shutil.rmtree() on path or call os.lstat() and
os.rmdir() to remove a path and its contents.  On Windows platforms,
this is wrapped with a wait loop that checks for the existence of the files."
test.support.make_legacy_pyc(source),"Move a PEP 3147/PEP 488 pyc file to its legacy pyc location and return the file
system path to the legacy pyc file.  The source value is the file system
path to the source file.  It does not need to exist, however the PEP
3147/488 pyc file must exist."
test.support.is_resource_enabled(resource),"Return True if resource is enabled and available. The list of
available resources is only set when test.regrtest is executing the
tests."
test.support.python_is_optimized(),Return True if Python was not built with -O0 or -Og.
test.support.with_pymalloc(),Return _testcapi.WITH_PYMALLOC.
"test.support.requires(resource, msg=None)","Raise ResourceDenied if resource is not available. msg is the
argument to ResourceDenied if it is raised. Always returns
True if called by a function whose __name__ is '__main__'.
Used when tests are executed by test.regrtest."
test.support.system_must_validate_cert(f),Raise unittest.SkipTest on TLS certification validation failures.
test.support.sortdict(dict),Return a repr of dict with keys sorted.
"test.support.findfile(filename, subdir=None)","Return the path to the file named filename. If no match is found
filename is returned. This does not equal a failure since it could be the
path to the file.
Setting subdir indicates a relative path to use to find the file
rather than looking directly in the path directories."
test.support.create_empty_file(filename),"Create an empty file with filename.  If it already exists, truncate it."
test.support.fd_count(),Count the number of open file descriptors.
test.support.match_test(test),Match test to patterns set in set_match_tests().
test.support.set_match_tests(patterns),Define match test with regular expression patterns.
test.support.run_unittest(*classes),"Execute unittest.TestCase subclasses passed to the function. The
function scans the classes for methods starting with the prefix test_
and executes the tests individually.
It is also legal to pass strings as parameters; these should be keys in
sys.modules. Each associated module will be scanned by
unittest.TestLoader.loadTestsFromModule(). This is usually seen in the
following test_main() function:
def test_main():
    support.run_unittest(__name__)


This will run all tests defined in the named module."
"test.support.run_doctest(module, verbosity=None, optionflags=0)","Run doctest.testmod() on the given module.  Return
(failure_count, test_count).
If verbosity is None, doctest.testmod() is run with verbosity
set to verbose.  Otherwise, it is run with verbosity set to
None.  optionflags is passed as optionflags to
doctest.testmod()."
test.support.setswitchinterval(interval),"Set the sys.setswitchinterval() to the given interval.  Defines
a minimum interval for Android systems to prevent the system from hanging."
test.support.check_impl_detail(**guards),"Use this check to guard CPython’s implementation-specific tests or to
run them only on the implementations guarded by the arguments:
check_impl_detail()               # Only on CPython (default).
check_impl_detail(jython=True)    # Only on Jython.
check_impl_detail(cpython=False)  # Everywhere except CPython."
"test.support.check_warnings(*filters, quiet=True)","A convenience wrapper for warnings.catch_warnings() that makes it
easier to test that a warning was correctly raised.  It is approximately
equivalent to calling warnings.catch_warnings(record=True) with
warnings.simplefilter() set to always and with the option to
automatically validate the results that are recorded.
check_warnings accepts 2-tuples of the form (""message regexp"",
WarningCategory) as positional arguments. If one or more filters are
provided, or if the optional keyword argument quiet is False,
it checks to make sure the warnings are as expected:  each specified filter
must match at least one of the warnings raised by the enclosed code or the
test fails, and if any warnings are raised that do not match any of the
specified filters the test fails.  To disable the first of these checks,
set quiet to True.
If no arguments are specified, it defaults to:
check_warnings(("""", Warning), quiet=True)


In this case all warnings are caught and no errors are raised.
On entry to the context manager, a WarningRecorder instance is
returned. The underlying warnings list from
catch_warnings() is available via the recorder object’s
warnings attribute.  As a convenience, the attributes of the object
representing the most recent warning can also be accessed directly through
the recorder object (see example below).  If no warning has been raised,
then any of the attributes that would otherwise be expected on an object
representing a warning will return None.
The recorder object also has a reset() method, which clears the
warnings list.
The context manager is designed to be used like this:
with check_warnings((""assertion is always true"", SyntaxWarning),
                    ("""", UserWarning)):
    exec('assert(False, ""Hey!"")')
    warnings.warn(UserWarning(""Hide me!""))


In this case if either warning was not raised, or some other warning was
raised, check_warnings() would raise an error.
When a test needs to look more deeply into the warnings, rather than
just checking whether or not they occurred, code like this can be used:
with check_warnings(quiet=True) as w:
    warnings.warn(""foo"")
    assert str(w.args[0]) == ""foo""
    warnings.warn(""bar"")
    assert str(w.args[0]) == ""bar""
    assert str(w.warnings[0].args[0]) == ""foo""
    assert str(w.warnings[1].args[0]) == ""bar""
    w.reset()
    assert len(w.warnings) == 0


Here all warnings will be caught, and the test code tests the captured
warnings directly.

Changed in version 3.2: New optional arguments filters and quiet."
test.support.check_no_resource_warning(testcase),"Context manager to check that no ResourceWarning was raised.  You
must remove the object which may emit ResourceWarning before the
end of the context manager."
test.support.set_memlimit(limit),"Set the values for max_memuse and real_max_memuse for big
memory tests."
test.support.record_original_stdout(stdout),"Store the value from stdout.  It is meant to hold the stdout at the
time the regrtest began."
test.support.get_original_stdout(),"Return the original stdout set by record_original_stdout() or
sys.stdout if it’s not set."
test.support.strip_python_strerr(stderr),"Strip the stderr of a Python process from potential debug output
emitted by the interpreter.  This will typically be run on the result of
subprocess.Popen.communicate()."
test.support.args_from_interpreter_flags(),"Return a list of command line arguments reproducing the current settings
in sys.flags and sys.warnoptions."
test.support.optim_args_from_interpreter_flags(),"Return a list of command line arguments reproducing the current
optimization settings in sys.flags."
test.support.captured_stdin(),"A context managers that temporarily replaces the named stream with
io.StringIO object.
Example use with output streams:
with captured_stdout() as stdout, captured_stderr() as stderr:
    print(""hello"")
    print(""error"", file=sys.stderr)
assert stdout.getvalue() == ""hello\n""
assert stderr.getvalue() == ""error\n""


Example use with input stream:
with captured_stdin() as stdin:
    stdin.write('hello\n')
    stdin.seek(0)
    # call test code that consumes from sys.stdin
    captured = input()
self.assertEqual(captured, ""hello"")"
"test.support.temp_dir(path=None, quiet=False)","A context manager that creates a temporary directory at path and
yields the directory.
If path is None, the temporary directory is created using
tempfile.mkdtemp().  If quiet is False, the context manager
raises an exception on error.  Otherwise, if path is specified and
cannot be created, only a warning is issued."
"test.support.change_cwd(path, quiet=False)","A context manager that temporarily changes the current working
directory to path and yields the directory.
If quiet is False, the context manager raises an exception
on error.  Otherwise, it issues only a warning and keeps the current
working directory the same."
"test.support.temp_cwd(name='tempcwd', quiet=False)","A context manager that temporarily creates a new directory and
changes the current working directory (CWD).
The context manager creates a temporary directory in the current
directory with name name before temporarily changing the current
working directory.  If name is None, the temporary directory is
created using tempfile.mkdtemp().
If quiet is False and it is not possible to create or change
the CWD, an error is raised.  Otherwise, only a warning is raised
and the original CWD is used."
test.support.temp_umask(umask),A context manager that temporarily sets the process umask.
"test.support.transient_internet(resource_name, *, timeout=30.0, errnos=())","A context manager that raises ResourceDenied when various issues
with the internet connection manifest themselves as exceptions."
test.support.disable_faulthandler(),A context manager that replaces sys.stderr with sys.__stderr__.
test.support.gc_collect(),"Force as many objects as possible to be collected.  This is needed because
timely deallocation is not guaranteed by the garbage collector.  This means
that __del__ methods may be called later than expected and weakrefs
may remain alive for longer than expected."
test.support.disable_gc(),"A context manager that disables the garbage collector upon entry and
reenables it upon exit."
"test.support.swap_attr(obj, attr, new_val)","Context manager to swap out an attribute with a new object.
Usage:
with swap_attr(obj, ""attr"", 5):
    ...


This will set obj.attr to 5 for the duration of the with block,
restoring the old value at the end of the block.  If attr doesn’t
exist on obj, it will be created and then deleted at the end of the
block.
The old value (or None if it doesn’t exist) will be assigned to the
target of the “as” clause, if there is one."
"test.support.swap_item(obj, attr, new_val)","Context manager to swap out an item with a new object.
Usage:
with swap_item(obj, ""item"", 5):
    ...


This will set obj[""item""] to 5 for the duration of the with block,
restoring the old value at the end of the block. If item doesn’t
exist on obj, it will be created and then deleted at the end of the
block.
The old value (or None if it doesn’t exist) will be assigned to the
target of the “as” clause, if there is one."
test.support.wait_threads_exit(timeout=60.0),"Context manager to wait until all threads created in the with statement
exit."
"test.support.start_threads(threads, unlock=None)","Context manager to start threads.  It attempts to join the threads upon
exit."
test.support.calcobjsize(fmt),"Return struct.calcsize() for nP{fmt}0n or, if gettotalrefcount
exists, 2PnP{fmt}0P."
test.support.calcvobjsize(fmt),"Return struct.calcsize() for nPn{fmt}0n or, if gettotalrefcount
exists, 2PnPn{fmt}0P."
"test.support.checksizeof(test, o, size)","For testcase test, assert that the sys.getsizeof for o plus the GC
header size equals size."
test.support.can_symlink(),"Return True if the OS supports symbolic links, False
otherwise."
test.support.can_xattr(),"Return True if the OS supports xattr, False
otherwise."
@test.support.skip_unless_symlink,A decorator for running tests that require support for symbolic links.
@test.support.skip_unless_xattr,A decorator for running tests that require support for xattr.
@test.support.skip_unless_bind_unix_socket,"A decorator for running tests that require a functional bind() for Unix
sockets."
@test.support.anticipate_failure(condition),"A decorator to conditionally mark tests with
unittest.expectedFailure(). Any use of this decorator should
have an associated comment identifying the relevant tracker issue."
"@test.support.run_with_locale(catstr, *locales)","A decorator for running a function in a different locale, correctly
resetting it after it has finished.  catstr is the locale category as
a string (for example ""LC_ALL"").  The locales passed will be tried
sequentially, and the first valid locale will be used."
@test.support.run_with_tz(tz),"A decorator for running a function in a specific timezone, correctly
resetting it after it has finished."
@test.support.requires_freebsd_version(*min_version),"Decorator for the minimum version when running test on FreeBSD.  If the
FreeBSD version is less than the minimum, raise unittest.SkipTest."
@test.support.requires_linux_version(*min_version),"Decorator for the minimum version when running test on Linux.  If the
Linux version is less than the minimum, raise unittest.SkipTest."
@test.support.requires_mac_version(*min_version),"Decorator for the minimum version when running test on Mac OS X.  If the
MAC OS X version is less than the minimum, raise unittest.SkipTest."
@test.support.requires_IEEE_754,Decorator for skipping tests on non-IEEE 754 platforms.
@test.support.requires_zlib,Decorator for skipping tests if zlib doesn’t exist.
@test.support.requires_gzip,Decorator for skipping tests if gzip doesn’t exist.
@test.support.requires_bz2,Decorator for skipping tests if bz2 doesn’t exist.
@test.support.requires_lzma,Decorator for skipping tests if lzma doesn’t exist.
@test.support.requires_resource(resource),Decorator for skipping tests if resource is not available.
@test.support.requires_docstrings,Decorator for only running the test if HAVE_DOCSTRINGS.
@test.support.cpython_only(test),Decorator for tests only applicable to CPython.
"@test.support.impl_detail(msg=None, **guards)","Decorator for invoking check_impl_detail() on guards.  If that
returns False, then uses msg as the reason for skipping the test."
@test.support.no_tracing(func),Decorator to temporarily turn off tracing for the duration of the test.
@test.support.refcount_test(test),"Decorator for tests which involve reference counting.  The decorator does
not run the test if it is not run by CPython.  Any trace function is unset
for the duration of the test to prevent unexpected refcounts caused by
the trace function."
@test.support.reap_threads(func),Decorator to ensure the threads are cleaned up even if the test fails.
"@test.support.bigmemtest(size, memuse, dry_run=True)","Decorator for bigmem tests.
size is a requested size for the test (in arbitrary, test-interpreted
units.)  memuse is the number of bytes per unit for the test, or a good
estimate of it.  For example, a test that needs two byte buffers, of 4 GiB
each, could be decorated with @bigmemtest(size=_4G, memuse=2).
The size argument is normally passed to the decorated test method as an
extra argument.  If dry_run is True, the value passed to the test
method may be less than the requested value.  If dry_run is False, it
means the test doesn’t support dummy runs when -M is not specified."
@test.support.bigaddrspacetest(f),"Decorator for tests that fill the address space.  f is the function to
wrap."
test.support.make_bad_fd(),"Create an invalid file descriptor by opening and closing a temporary file,
and returning its descriptor."
"test.support.check_syntax_error(testcase, statement, errtext='', *, lineno=None, offset=None)","Test for syntax errors in statement by attempting to compile statement.
testcase is the unittest instance for the test.  errtext is the
regular expression which should match the string representation of the
raised SyntaxError.  If lineno is not None, compares to
the line of the exception.  If offset is not None, compares to
the offset of the exception."
"test.support.check_syntax_warning(testcase, statement, errtext='', *, lineno=1, offset=None)","Test for syntax warning in statement by attempting to compile statement.
Test also that the SyntaxWarning is emitted only once, and that it
will be converted to a SyntaxError when turned into error.
testcase is the unittest instance for the test.  errtext is the
regular expression which should match the string representation of the
emitted SyntaxWarning and raised SyntaxError.  If lineno
is not None, compares to the line of the warning and exception.
If offset is not None, compares to the offset of the exception.

New in version 3.8."
"test.support.open_urlresource(url, *args, **kw)","Open url.  If open fails, raises TestFailed."
"test.support.import_module(name, deprecated=False, *, required_on())","This function imports and returns the named module. Unlike a normal
import, this function raises unittest.SkipTest if the module
cannot be imported.
Module and package deprecation messages are suppressed during this import
if deprecated is True.  If a module is required on a platform but
optional for others, set required_on to an iterable of platform prefixes
which will be compared against sys.platform.

New in version 3.1."
"test.support.import_fresh_module(name, fresh=(), blocked=(), deprecated=False)","This function imports and returns a fresh copy of the named Python module
by removing the named module from sys.modules before doing the import.
Note that unlike reload(), the original module is not affected by
this operation.
fresh is an iterable of additional module names that are also removed
from the sys.modules cache before doing the import.
blocked is an iterable of module names that are replaced with None
in the module cache during the import to ensure that attempts to import
them raise ImportError.
The named module and any modules named in the fresh and blocked
parameters are saved before starting the import and then reinserted into
sys.modules when the fresh import is complete.
Module and package deprecation messages are suppressed during this import
if deprecated is True.
This function will raise ImportError if the named module cannot be
imported.
Example use:
# Get copies of the warnings module for testing without affecting the
# version being used by the rest of the test suite. One copy uses the
# C implementation, the other is forced to use the pure Python fallback
# implementation
py_warnings = import_fresh_module('warnings', blocked=['_warnings'])
c_warnings = import_fresh_module('warnings', fresh=['_warnings'])



New in version 3.1."
test.support.modules_setup(),Return a copy of sys.modules.
test.support.modules_cleanup(oldmodules),"Remove modules except for oldmodules and encodings in order to
preserve internal cache."
test.support.threading_setup(),Return current thread count and copy of dangling threads.
test.support.threading_cleanup(*original_values),"Cleanup up threads not specified in original_values.  Designed to emit
a warning if a test leaves running threads in the background."
"test.support.join_thread(thread, timeout=30.0)","Join a thread within timeout.  Raise an AssertionError if thread
is still alive after timeout seconds."
test.support.reap_children(),"Use this at the end of test_main whenever sub-processes are started.
This will help ensure that no extra children (zombies) stick around to
hog resources and create problems when looking for refleaks."
"test.support.get_attribute(obj, name)","Get an attribute, raising unittest.SkipTest if AttributeError
is raised."
"test.support.bind_port(sock, host=HOST)","Bind the socket to a free port and return the port number.  Relies on
ephemeral ports in order to ensure we are using an unbound port.  This is
important as many tests may be running simultaneously, especially in a
buildbot environment.  This method raises an exception if the
sock.family is AF_INET and sock.type is
SOCK_STREAM, and the socket has
SO_REUSEADDR or SO_REUSEPORT set on it.
Tests should never set these socket options for TCP/IP sockets.
The only case for setting these options is testing multicasting via
multiple UDP sockets.
Additionally, if the SO_EXCLUSIVEADDRUSE socket option is
available (i.e. on Windows), it will be set on the socket.  This will
prevent anyone else from binding to our host/port for the duration of the
test."
"test.support.bind_unix_socket(sock, addr)","Bind a unix socket, raising unittest.SkipTest if
PermissionError is raised."
test.support.catch_threading_exception(),"Context manager catching threading.Thread exception using
threading.excepthook().
Attributes set when an exception is catched:

exc_type
exc_value
exc_traceback
thread

See threading.excepthook() documentation.
These attributes are deleted at the context manager exit.
Usage:
with support.catch_threading_exception() as cm:
    # code spawning a thread which raises an exception
    ...

    # check the thread exception, use cm attributes:
    # exc_type, exc_value, exc_traceback, thread
    ...

# exc_type, exc_value, exc_traceback, thread attributes of cm no longer
# exists at this point
# (to avoid reference cycles)



New in version 3.8."
test.support.catch_unraisable_exception(),"Context manager catching unraisable exception using
sys.unraisablehook().
Storing the exception value (cm.unraisable.exc_value) creates a
reference cycle. The reference cycle is broken explicitly when the context
manager exits.
Storing the object (cm.unraisable.object) can resurrect it if it is set
to an object which is being finalized. Exiting the context manager clears
the stored object.
Usage:
with support.catch_unraisable_exception() as cm:
    # code creating an ""unraisable exception""
    ...

    # check the unraisable exception: use cm.unraisable
    ...

# cm.unraisable attribute no longer exists at this point
# (to break a reference cycle)



New in version 3.8."
"test.support.find_unused_port(family=socket.AF_INET, socktype=socket.SOCK_STREAM)","Returns an unused port that should be suitable for binding.  This is
achieved by creating a temporary socket with the same family and type as
the sock parameter (default is AF_INET,
SOCK_STREAM),
and binding it to the specified host address (defaults to 0.0.0.0)
with the port set to 0, eliciting an unused ephemeral port from the OS.
The temporary socket is then closed and deleted, and the ephemeral port is
returned.
Either this method or bind_port() should be used for any tests
where a server socket needs to be bound to a particular port for the
duration of the test.
Which one to use depends on whether the calling code is creating a Python
socket, or if an unused port needs to be provided in a constructor
or passed to an external program (i.e. the -accept argument to
openssl’s s_server mode).  Always prefer bind_port() over
find_unused_port() where possible.  Using a hard coded port is
discouraged since it can make multiple instances of the test impossible to
run simultaneously, which is a problem for buildbots."
"test.support.load_package_tests(pkg_dir, loader, standard_tests, pattern)","Generic implementation of the unittest load_tests protocol for
use in test packages.  pkg_dir is the root directory of the package;
loader, standard_tests, and pattern are the arguments expected by
load_tests.  In simple cases, the test package’s __init__.py
can be the following:
import os
from test.support import load_package_tests

def load_tests(*args):
    return load_package_tests(os.path.dirname(__file__), *args)"
test.support.fs_is_case_insensitive(directory),Return True if the file system for directory is case-insensitive.
"test.support.detect_api_mismatch(ref_api, other_api, *, ignore=())","Returns the set of attributes, functions or methods of ref_api not
found on other_api, except for a defined list of items to be
ignored in this check specified in ignore.
By default this skips private attributes beginning with ‘_’ but
includes all magic methods, i.e. those starting and ending in ‘__’.

New in version 3.5."
"test.support.patch(test_instance, object_to_patch, attr_name, new_value)","Override object_to_patch.attr_name with new_value.  Also add
cleanup procedure to test_instance to restore object_to_patch for
attr_name.  The attr_name should be a valid attribute for
object_to_patch."
test.support.run_in_subinterp(code),"Run code in subinterpreter.  Raise unittest.SkipTest if
tracemalloc is enabled."
"test.support.check_free_after_iterating(test, iter, cls, args=())",Assert that iter is deallocated after iterating.
test.support.missing_compiler_executable(cmd_names=[]),"Check for the existence of the compiler executables whose names are listed
in cmd_names or all the compiler executables when cmd_names is empty
and return the first missing executable or None when none is found
missing."
"test.support.check__all__(test_case, module, name_of_module=None, extra=(), blacklist=())","Assert that the __all__ variable of module contains all public names.
The module’s public names (its API) are detected automatically
based on whether they match the public name convention and were defined in
module.
The name_of_module argument can specify (as a string or tuple thereof) what
module(s) an API could be defined in order to be detected as a public
API. One case for this is when module imports part of its public API from
other modules, possibly a C backend (like csv and its _csv).
The extra argument can be a set of names that wouldn’t otherwise be automatically
detected as “public”, like objects without a proper __module__
attribute. If provided, it will be added to the automatically detected ones.
The blacklist argument can be a set of names that must not be treated as part of
the public API even though their names indicate otherwise.
Example use:
import bar
import foo
import unittest
from test import support

class MiscTestCase(unittest.TestCase):
    def test__all__(self):
        support.check__all__(self, foo)

class OtherTestCase(unittest.TestCase):
    def test__all__(self):
        extra = {'BAR_CONST', 'FOO_CONST'}
        blacklist = {'baz'}  # Undocumented name.
        # bar imports part of its API from _bar.
        support.check__all__(self, bar, ('bar', '_bar'),
                             extra=extra, blacklist=blacklist)



New in version 3.6."
test.support.script_helper.interpreter_requires_environment(),"Return True if sys.executable interpreter requires environment
variables in order to be able to run at all.
This is designed to be used with @unittest.skipIf() to annotate tests
that need to use an assert_python*() function to launch an isolated
mode (-I) or no environment mode (-E) sub-interpreter process.
A normal build & test does not run into this situation but it can happen
when trying to run the standard library test suite from an interpreter that
doesn’t have an obvious home with Python’s current home finding logic.
Setting PYTHONHOME is one way to get most of the testsuite to run
in that situation.  PYTHONPATH or PYTHONUSERSITE are
other common environment variables that might impact whether or not the
interpreter can start."
"test.support.script_helper.run_python_until_end(*args, **env_vars)","Set up the environment based on env_vars for running the interpreter
in a subprocess.  The values can include __isolated, __cleanenv,
__cwd, and TERM."
"test.support.script_helper.assert_python_ok(*args, **env_vars)","Assert that running the interpreter with args and optional environment
variables env_vars succeeds (rc == 0) and return a (return code,
stdout, stderr) tuple.
If the __cleanenv keyword is set, env_vars is used as a fresh
environment.
Python is started in isolated mode (command line option -I),
except if the __isolated keyword is set to False."
"test.support.script_helper.assert_python_failure(*args, **env_vars)","Assert that running the interpreter with args and optional environment
variables env_vars fails (rc != 0) and return a (return code,
stdout, stderr) tuple.
See assert_python_ok() for more options."
"test.support.script_helper.spawn_python(*args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, **kw)","Run a Python subprocess with the given arguments.
kw is extra keyword args to pass to subprocess.Popen(). Returns a
subprocess.Popen object."
test.support.script_helper.kill_python(p),"Run the given subprocess.Popen process until completion and return
stdout."
"test.support.script_helper.make_script(script_dir, script_basename, source, omit_suffix=False)","Create script containing source in path script_dir and script_basename.
If omit_suffix is False, append .py to the name.  Return the full
script path."
"test.support.script_helper.make_zip_script(zip_dir, zip_basename, script_name, name_in_zip=None)","Create zip file at zip_dir and zip_basename with extension zip which
contains the files in script_name. name_in_zip is the archive name.
Return a tuple containing (full path, full path of archive name)."
"test.support.script_helper.make_pkg(pkg_dir, init_source='')","Create a directory named pkg_dir containing an __init__ file with
init_source as its contents."
"test.support.script_helper.make_zip_pkg(zip_dir, zip_basename, pkg_name, script_basename, source, depth=1, compiled=False)","Create a zip package directory with a path of zip_dir and zip_basename
containing an empty __init__ file and a file script_basename
containing the source.  If compiled is True, both source files will
be compiled and added to the zip package.  Return a tuple of the full zip
path and the archive name for the zip file."
"EnvironmentVarGuard.set(envvar, value)","Temporarily set the environment variable envvar to the value of
value."
EnvironmentVarGuard.unset(envvar),Temporarily unset the environment variable envvar.
"matches(self, d, **kwargs)",Try to match a single dict with the supplied arguments.
"match_value(self, k, dv, v)",Try to match a single stored value (dv) with a supplied value (v).
run(test),Run test and return the result.
test.support.forget(module_name),"Remove the module named module_name from sys.modules and delete any
byte-compiled files of the module."
test.support.unload(name),Delete name from sys.modules.
test.support.unlink(filename),"Call os.unlink() on filename.  On Windows platforms, this is
wrapped with a wait loop that checks for the existence fo the file."
test.support.rmdir(filename),"Call os.rmdir() on filename.  On Windows platforms, this is
wrapped with a wait loop that checks for the existence of the file."
test.support.rmtree(path),"Call shutil.rmtree() on path or call os.lstat() and
os.rmdir() to remove a path and its contents.  On Windows platforms,
this is wrapped with a wait loop that checks for the existence of the files."
test.support.make_legacy_pyc(source),"Move a PEP 3147/PEP 488 pyc file to its legacy pyc location and return the file
system path to the legacy pyc file.  The source value is the file system
path to the source file.  It does not need to exist, however the PEP
3147/488 pyc file must exist."
test.support.is_resource_enabled(resource),"Return True if resource is enabled and available. The list of
available resources is only set when test.regrtest is executing the
tests."
test.support.python_is_optimized(),Return True if Python was not built with -O0 or -Og.
test.support.with_pymalloc(),Return _testcapi.WITH_PYMALLOC.
"test.support.requires(resource, msg=None)","Raise ResourceDenied if resource is not available. msg is the
argument to ResourceDenied if it is raised. Always returns
True if called by a function whose __name__ is '__main__'.
Used when tests are executed by test.regrtest."
test.support.system_must_validate_cert(f),Raise unittest.SkipTest on TLS certification validation failures.
test.support.sortdict(dict),Return a repr of dict with keys sorted.
"test.support.findfile(filename, subdir=None)","Return the path to the file named filename. If no match is found
filename is returned. This does not equal a failure since it could be the
path to the file.
Setting subdir indicates a relative path to use to find the file
rather than looking directly in the path directories."
test.support.create_empty_file(filename),"Create an empty file with filename.  If it already exists, truncate it."
test.support.fd_count(),Count the number of open file descriptors.
test.support.match_test(test),Match test to patterns set in set_match_tests().
test.support.set_match_tests(patterns),Define match test with regular expression patterns.
test.support.run_unittest(*classes),"Execute unittest.TestCase subclasses passed to the function. The
function scans the classes for methods starting with the prefix test_
and executes the tests individually.
It is also legal to pass strings as parameters; these should be keys in
sys.modules. Each associated module will be scanned by
unittest.TestLoader.loadTestsFromModule(). This is usually seen in the
following test_main() function:
def test_main():
    support.run_unittest(__name__)


This will run all tests defined in the named module."
"test.support.run_doctest(module, verbosity=None, optionflags=0)","Run doctest.testmod() on the given module.  Return
(failure_count, test_count).
If verbosity is None, doctest.testmod() is run with verbosity
set to verbose.  Otherwise, it is run with verbosity set to
None.  optionflags is passed as optionflags to
doctest.testmod()."
test.support.setswitchinterval(interval),"Set the sys.setswitchinterval() to the given interval.  Defines
a minimum interval for Android systems to prevent the system from hanging."
test.support.check_impl_detail(**guards),"Use this check to guard CPython’s implementation-specific tests or to
run them only on the implementations guarded by the arguments:
check_impl_detail()               # Only on CPython (default).
check_impl_detail(jython=True)    # Only on Jython.
check_impl_detail(cpython=False)  # Everywhere except CPython."
"test.support.check_warnings(*filters, quiet=True)","A convenience wrapper for warnings.catch_warnings() that makes it
easier to test that a warning was correctly raised.  It is approximately
equivalent to calling warnings.catch_warnings(record=True) with
warnings.simplefilter() set to always and with the option to
automatically validate the results that are recorded.
check_warnings accepts 2-tuples of the form (""message regexp"",
WarningCategory) as positional arguments. If one or more filters are
provided, or if the optional keyword argument quiet is False,
it checks to make sure the warnings are as expected:  each specified filter
must match at least one of the warnings raised by the enclosed code or the
test fails, and if any warnings are raised that do not match any of the
specified filters the test fails.  To disable the first of these checks,
set quiet to True.
If no arguments are specified, it defaults to:
check_warnings(("""", Warning), quiet=True)


In this case all warnings are caught and no errors are raised.
On entry to the context manager, a WarningRecorder instance is
returned. The underlying warnings list from
catch_warnings() is available via the recorder object’s
warnings attribute.  As a convenience, the attributes of the object
representing the most recent warning can also be accessed directly through
the recorder object (see example below).  If no warning has been raised,
then any of the attributes that would otherwise be expected on an object
representing a warning will return None.
The recorder object also has a reset() method, which clears the
warnings list.
The context manager is designed to be used like this:
with check_warnings((""assertion is always true"", SyntaxWarning),
                    ("""", UserWarning)):
    exec('assert(False, ""Hey!"")')
    warnings.warn(UserWarning(""Hide me!""))


In this case if either warning was not raised, or some other warning was
raised, check_warnings() would raise an error.
When a test needs to look more deeply into the warnings, rather than
just checking whether or not they occurred, code like this can be used:
with check_warnings(quiet=True) as w:
    warnings.warn(""foo"")
    assert str(w.args[0]) == ""foo""
    warnings.warn(""bar"")
    assert str(w.args[0]) == ""bar""
    assert str(w.warnings[0].args[0]) == ""foo""
    assert str(w.warnings[1].args[0]) == ""bar""
    w.reset()
    assert len(w.warnings) == 0


Here all warnings will be caught, and the test code tests the captured
warnings directly.

Changed in version 3.2: New optional arguments filters and quiet."
test.support.check_no_resource_warning(testcase),"Context manager to check that no ResourceWarning was raised.  You
must remove the object which may emit ResourceWarning before the
end of the context manager."
test.support.set_memlimit(limit),"Set the values for max_memuse and real_max_memuse for big
memory tests."
test.support.record_original_stdout(stdout),"Store the value from stdout.  It is meant to hold the stdout at the
time the regrtest began."
test.support.get_original_stdout(),"Return the original stdout set by record_original_stdout() or
sys.stdout if it’s not set."
test.support.strip_python_strerr(stderr),"Strip the stderr of a Python process from potential debug output
emitted by the interpreter.  This will typically be run on the result of
subprocess.Popen.communicate()."
test.support.args_from_interpreter_flags(),"Return a list of command line arguments reproducing the current settings
in sys.flags and sys.warnoptions."
test.support.optim_args_from_interpreter_flags(),"Return a list of command line arguments reproducing the current
optimization settings in sys.flags."
test.support.captured_stdin(),"A context managers that temporarily replaces the named stream with
io.StringIO object.
Example use with output streams:
with captured_stdout() as stdout, captured_stderr() as stderr:
    print(""hello"")
    print(""error"", file=sys.stderr)
assert stdout.getvalue() == ""hello\n""
assert stderr.getvalue() == ""error\n""


Example use with input stream:
with captured_stdin() as stdin:
    stdin.write('hello\n')
    stdin.seek(0)
    # call test code that consumes from sys.stdin
    captured = input()
self.assertEqual(captured, ""hello"")"
"test.support.temp_dir(path=None, quiet=False)","A context manager that creates a temporary directory at path and
yields the directory.
If path is None, the temporary directory is created using
tempfile.mkdtemp().  If quiet is False, the context manager
raises an exception on error.  Otherwise, if path is specified and
cannot be created, only a warning is issued."
"test.support.change_cwd(path, quiet=False)","A context manager that temporarily changes the current working
directory to path and yields the directory.
If quiet is False, the context manager raises an exception
on error.  Otherwise, it issues only a warning and keeps the current
working directory the same."
"test.support.temp_cwd(name='tempcwd', quiet=False)","A context manager that temporarily creates a new directory and
changes the current working directory (CWD).
The context manager creates a temporary directory in the current
directory with name name before temporarily changing the current
working directory.  If name is None, the temporary directory is
created using tempfile.mkdtemp().
If quiet is False and it is not possible to create or change
the CWD, an error is raised.  Otherwise, only a warning is raised
and the original CWD is used."
test.support.temp_umask(umask),A context manager that temporarily sets the process umask.
"test.support.transient_internet(resource_name, *, timeout=30.0, errnos=())","A context manager that raises ResourceDenied when various issues
with the internet connection manifest themselves as exceptions."
test.support.disable_faulthandler(),A context manager that replaces sys.stderr with sys.__stderr__.
test.support.gc_collect(),"Force as many objects as possible to be collected.  This is needed because
timely deallocation is not guaranteed by the garbage collector.  This means
that __del__ methods may be called later than expected and weakrefs
may remain alive for longer than expected."
test.support.disable_gc(),"A context manager that disables the garbage collector upon entry and
reenables it upon exit."
"test.support.swap_attr(obj, attr, new_val)","Context manager to swap out an attribute with a new object.
Usage:
with swap_attr(obj, ""attr"", 5):
    ...


This will set obj.attr to 5 for the duration of the with block,
restoring the old value at the end of the block.  If attr doesn’t
exist on obj, it will be created and then deleted at the end of the
block.
The old value (or None if it doesn’t exist) will be assigned to the
target of the “as” clause, if there is one."
"test.support.swap_item(obj, attr, new_val)","Context manager to swap out an item with a new object.
Usage:
with swap_item(obj, ""item"", 5):
    ...


This will set obj[""item""] to 5 for the duration of the with block,
restoring the old value at the end of the block. If item doesn’t
exist on obj, it will be created and then deleted at the end of the
block.
The old value (or None if it doesn’t exist) will be assigned to the
target of the “as” clause, if there is one."
test.support.wait_threads_exit(timeout=60.0),"Context manager to wait until all threads created in the with statement
exit."
"test.support.start_threads(threads, unlock=None)","Context manager to start threads.  It attempts to join the threads upon
exit."
test.support.calcobjsize(fmt),"Return struct.calcsize() for nP{fmt}0n or, if gettotalrefcount
exists, 2PnP{fmt}0P."
test.support.calcvobjsize(fmt),"Return struct.calcsize() for nPn{fmt}0n or, if gettotalrefcount
exists, 2PnPn{fmt}0P."
"test.support.checksizeof(test, o, size)","For testcase test, assert that the sys.getsizeof for o plus the GC
header size equals size."
test.support.can_symlink(),"Return True if the OS supports symbolic links, False
otherwise."
test.support.can_xattr(),"Return True if the OS supports xattr, False
otherwise."
@test.support.skip_unless_symlink,A decorator for running tests that require support for symbolic links.
@test.support.skip_unless_xattr,A decorator for running tests that require support for xattr.
@test.support.skip_unless_bind_unix_socket,"A decorator for running tests that require a functional bind() for Unix
sockets."
@test.support.anticipate_failure(condition),"A decorator to conditionally mark tests with
unittest.expectedFailure(). Any use of this decorator should
have an associated comment identifying the relevant tracker issue."
"@test.support.run_with_locale(catstr, *locales)","A decorator for running a function in a different locale, correctly
resetting it after it has finished.  catstr is the locale category as
a string (for example ""LC_ALL"").  The locales passed will be tried
sequentially, and the first valid locale will be used."
@test.support.run_with_tz(tz),"A decorator for running a function in a specific timezone, correctly
resetting it after it has finished."
@test.support.requires_freebsd_version(*min_version),"Decorator for the minimum version when running test on FreeBSD.  If the
FreeBSD version is less than the minimum, raise unittest.SkipTest."
@test.support.requires_linux_version(*min_version),"Decorator for the minimum version when running test on Linux.  If the
Linux version is less than the minimum, raise unittest.SkipTest."
@test.support.requires_mac_version(*min_version),"Decorator for the minimum version when running test on Mac OS X.  If the
MAC OS X version is less than the minimum, raise unittest.SkipTest."
@test.support.requires_IEEE_754,Decorator for skipping tests on non-IEEE 754 platforms.
@test.support.requires_zlib,Decorator for skipping tests if zlib doesn’t exist.
@test.support.requires_gzip,Decorator for skipping tests if gzip doesn’t exist.
@test.support.requires_bz2,Decorator for skipping tests if bz2 doesn’t exist.
@test.support.requires_lzma,Decorator for skipping tests if lzma doesn’t exist.
@test.support.requires_resource(resource),Decorator for skipping tests if resource is not available.
@test.support.requires_docstrings,Decorator for only running the test if HAVE_DOCSTRINGS.
@test.support.cpython_only(test),Decorator for tests only applicable to CPython.
"@test.support.impl_detail(msg=None, **guards)","Decorator for invoking check_impl_detail() on guards.  If that
returns False, then uses msg as the reason for skipping the test."
@test.support.no_tracing(func),Decorator to temporarily turn off tracing for the duration of the test.
@test.support.refcount_test(test),"Decorator for tests which involve reference counting.  The decorator does
not run the test if it is not run by CPython.  Any trace function is unset
for the duration of the test to prevent unexpected refcounts caused by
the trace function."
@test.support.reap_threads(func),Decorator to ensure the threads are cleaned up even if the test fails.
"@test.support.bigmemtest(size, memuse, dry_run=True)","Decorator for bigmem tests.
size is a requested size for the test (in arbitrary, test-interpreted
units.)  memuse is the number of bytes per unit for the test, or a good
estimate of it.  For example, a test that needs two byte buffers, of 4 GiB
each, could be decorated with @bigmemtest(size=_4G, memuse=2).
The size argument is normally passed to the decorated test method as an
extra argument.  If dry_run is True, the value passed to the test
method may be less than the requested value.  If dry_run is False, it
means the test doesn’t support dummy runs when -M is not specified."
@test.support.bigaddrspacetest(f),"Decorator for tests that fill the address space.  f is the function to
wrap."
test.support.make_bad_fd(),"Create an invalid file descriptor by opening and closing a temporary file,
and returning its descriptor."
"test.support.check_syntax_error(testcase, statement, errtext='', *, lineno=None, offset=None)","Test for syntax errors in statement by attempting to compile statement.
testcase is the unittest instance for the test.  errtext is the
regular expression which should match the string representation of the
raised SyntaxError.  If lineno is not None, compares to
the line of the exception.  If offset is not None, compares to
the offset of the exception."
"test.support.check_syntax_warning(testcase, statement, errtext='', *, lineno=1, offset=None)","Test for syntax warning in statement by attempting to compile statement.
Test also that the SyntaxWarning is emitted only once, and that it
will be converted to a SyntaxError when turned into error.
testcase is the unittest instance for the test.  errtext is the
regular expression which should match the string representation of the
emitted SyntaxWarning and raised SyntaxError.  If lineno
is not None, compares to the line of the warning and exception.
If offset is not None, compares to the offset of the exception.

New in version 3.8."
"test.support.open_urlresource(url, *args, **kw)","Open url.  If open fails, raises TestFailed."
"test.support.import_module(name, deprecated=False, *, required_on())","This function imports and returns the named module. Unlike a normal
import, this function raises unittest.SkipTest if the module
cannot be imported.
Module and package deprecation messages are suppressed during this import
if deprecated is True.  If a module is required on a platform but
optional for others, set required_on to an iterable of platform prefixes
which will be compared against sys.platform.

New in version 3.1."
"test.support.import_fresh_module(name, fresh=(), blocked=(), deprecated=False)","This function imports and returns a fresh copy of the named Python module
by removing the named module from sys.modules before doing the import.
Note that unlike reload(), the original module is not affected by
this operation.
fresh is an iterable of additional module names that are also removed
from the sys.modules cache before doing the import.
blocked is an iterable of module names that are replaced with None
in the module cache during the import to ensure that attempts to import
them raise ImportError.
The named module and any modules named in the fresh and blocked
parameters are saved before starting the import and then reinserted into
sys.modules when the fresh import is complete.
Module and package deprecation messages are suppressed during this import
if deprecated is True.
This function will raise ImportError if the named module cannot be
imported.
Example use:
# Get copies of the warnings module for testing without affecting the
# version being used by the rest of the test suite. One copy uses the
# C implementation, the other is forced to use the pure Python fallback
# implementation
py_warnings = import_fresh_module('warnings', blocked=['_warnings'])
c_warnings = import_fresh_module('warnings', fresh=['_warnings'])



New in version 3.1."
test.support.modules_setup(),Return a copy of sys.modules.
test.support.modules_cleanup(oldmodules),"Remove modules except for oldmodules and encodings in order to
preserve internal cache."
test.support.threading_setup(),Return current thread count and copy of dangling threads.
test.support.threading_cleanup(*original_values),"Cleanup up threads not specified in original_values.  Designed to emit
a warning if a test leaves running threads in the background."
"test.support.join_thread(thread, timeout=30.0)","Join a thread within timeout.  Raise an AssertionError if thread
is still alive after timeout seconds."
test.support.reap_children(),"Use this at the end of test_main whenever sub-processes are started.
This will help ensure that no extra children (zombies) stick around to
hog resources and create problems when looking for refleaks."
"test.support.get_attribute(obj, name)","Get an attribute, raising unittest.SkipTest if AttributeError
is raised."
"test.support.bind_port(sock, host=HOST)","Bind the socket to a free port and return the port number.  Relies on
ephemeral ports in order to ensure we are using an unbound port.  This is
important as many tests may be running simultaneously, especially in a
buildbot environment.  This method raises an exception if the
sock.family is AF_INET and sock.type is
SOCK_STREAM, and the socket has
SO_REUSEADDR or SO_REUSEPORT set on it.
Tests should never set these socket options for TCP/IP sockets.
The only case for setting these options is testing multicasting via
multiple UDP sockets.
Additionally, if the SO_EXCLUSIVEADDRUSE socket option is
available (i.e. on Windows), it will be set on the socket.  This will
prevent anyone else from binding to our host/port for the duration of the
test."
"test.support.bind_unix_socket(sock, addr)","Bind a unix socket, raising unittest.SkipTest if
PermissionError is raised."
test.support.catch_threading_exception(),"Context manager catching threading.Thread exception using
threading.excepthook().
Attributes set when an exception is catched:

exc_type
exc_value
exc_traceback
thread

See threading.excepthook() documentation.
These attributes are deleted at the context manager exit.
Usage:
with support.catch_threading_exception() as cm:
    # code spawning a thread which raises an exception
    ...

    # check the thread exception, use cm attributes:
    # exc_type, exc_value, exc_traceback, thread
    ...

# exc_type, exc_value, exc_traceback, thread attributes of cm no longer
# exists at this point
# (to avoid reference cycles)



New in version 3.8."
test.support.catch_unraisable_exception(),"Context manager catching unraisable exception using
sys.unraisablehook().
Storing the exception value (cm.unraisable.exc_value) creates a
reference cycle. The reference cycle is broken explicitly when the context
manager exits.
Storing the object (cm.unraisable.object) can resurrect it if it is set
to an object which is being finalized. Exiting the context manager clears
the stored object.
Usage:
with support.catch_unraisable_exception() as cm:
    # code creating an ""unraisable exception""
    ...

    # check the unraisable exception: use cm.unraisable
    ...

# cm.unraisable attribute no longer exists at this point
# (to break a reference cycle)



New in version 3.8."
"test.support.find_unused_port(family=socket.AF_INET, socktype=socket.SOCK_STREAM)","Returns an unused port that should be suitable for binding.  This is
achieved by creating a temporary socket with the same family and type as
the sock parameter (default is AF_INET,
SOCK_STREAM),
and binding it to the specified host address (defaults to 0.0.0.0)
with the port set to 0, eliciting an unused ephemeral port from the OS.
The temporary socket is then closed and deleted, and the ephemeral port is
returned.
Either this method or bind_port() should be used for any tests
where a server socket needs to be bound to a particular port for the
duration of the test.
Which one to use depends on whether the calling code is creating a Python
socket, or if an unused port needs to be provided in a constructor
or passed to an external program (i.e. the -accept argument to
openssl’s s_server mode).  Always prefer bind_port() over
find_unused_port() where possible.  Using a hard coded port is
discouraged since it can make multiple instances of the test impossible to
run simultaneously, which is a problem for buildbots."
"test.support.load_package_tests(pkg_dir, loader, standard_tests, pattern)","Generic implementation of the unittest load_tests protocol for
use in test packages.  pkg_dir is the root directory of the package;
loader, standard_tests, and pattern are the arguments expected by
load_tests.  In simple cases, the test package’s __init__.py
can be the following:
import os
from test.support import load_package_tests

def load_tests(*args):
    return load_package_tests(os.path.dirname(__file__), *args)"
test.support.fs_is_case_insensitive(directory),Return True if the file system for directory is case-insensitive.
"test.support.detect_api_mismatch(ref_api, other_api, *, ignore=())","Returns the set of attributes, functions or methods of ref_api not
found on other_api, except for a defined list of items to be
ignored in this check specified in ignore.
By default this skips private attributes beginning with ‘_’ but
includes all magic methods, i.e. those starting and ending in ‘__’.

New in version 3.5."
"test.support.patch(test_instance, object_to_patch, attr_name, new_value)","Override object_to_patch.attr_name with new_value.  Also add
cleanup procedure to test_instance to restore object_to_patch for
attr_name.  The attr_name should be a valid attribute for
object_to_patch."
test.support.run_in_subinterp(code),"Run code in subinterpreter.  Raise unittest.SkipTest if
tracemalloc is enabled."
"test.support.check_free_after_iterating(test, iter, cls, args=())",Assert that iter is deallocated after iterating.
test.support.missing_compiler_executable(cmd_names=[]),"Check for the existence of the compiler executables whose names are listed
in cmd_names or all the compiler executables when cmd_names is empty
and return the first missing executable or None when none is found
missing."
"test.support.check__all__(test_case, module, name_of_module=None, extra=(), blacklist=())","Assert that the __all__ variable of module contains all public names.
The module’s public names (its API) are detected automatically
based on whether they match the public name convention and were defined in
module.
The name_of_module argument can specify (as a string or tuple thereof) what
module(s) an API could be defined in order to be detected as a public
API. One case for this is when module imports part of its public API from
other modules, possibly a C backend (like csv and its _csv).
The extra argument can be a set of names that wouldn’t otherwise be automatically
detected as “public”, like objects without a proper __module__
attribute. If provided, it will be added to the automatically detected ones.
The blacklist argument can be a set of names that must not be treated as part of
the public API even though their names indicate otherwise.
Example use:
import bar
import foo
import unittest
from test import support

class MiscTestCase(unittest.TestCase):
    def test__all__(self):
        support.check__all__(self, foo)

class OtherTestCase(unittest.TestCase):
    def test__all__(self):
        extra = {'BAR_CONST', 'FOO_CONST'}
        blacklist = {'baz'}  # Undocumented name.
        # bar imports part of its API from _bar.
        support.check__all__(self, bar, ('bar', '_bar'),
                             extra=extra, blacklist=blacklist)



New in version 3.6."
test.support.script_helper.interpreter_requires_environment(),"Return True if sys.executable interpreter requires environment
variables in order to be able to run at all.
This is designed to be used with @unittest.skipIf() to annotate tests
that need to use an assert_python*() function to launch an isolated
mode (-I) or no environment mode (-E) sub-interpreter process.
A normal build & test does not run into this situation but it can happen
when trying to run the standard library test suite from an interpreter that
doesn’t have an obvious home with Python’s current home finding logic.
Setting PYTHONHOME is one way to get most of the testsuite to run
in that situation.  PYTHONPATH or PYTHONUSERSITE are
other common environment variables that might impact whether or not the
interpreter can start."
"test.support.script_helper.run_python_until_end(*args, **env_vars)","Set up the environment based on env_vars for running the interpreter
in a subprocess.  The values can include __isolated, __cleanenv,
__cwd, and TERM."
"test.support.script_helper.assert_python_ok(*args, **env_vars)","Assert that running the interpreter with args and optional environment
variables env_vars succeeds (rc == 0) and return a (return code,
stdout, stderr) tuple.
If the __cleanenv keyword is set, env_vars is used as a fresh
environment.
Python is started in isolated mode (command line option -I),
except if the __isolated keyword is set to False."
"test.support.script_helper.assert_python_failure(*args, **env_vars)","Assert that running the interpreter with args and optional environment
variables env_vars fails (rc != 0) and return a (return code,
stdout, stderr) tuple.
See assert_python_ok() for more options."
"test.support.script_helper.spawn_python(*args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, **kw)","Run a Python subprocess with the given arguments.
kw is extra keyword args to pass to subprocess.Popen(). Returns a
subprocess.Popen object."
test.support.script_helper.kill_python(p),"Run the given subprocess.Popen process until completion and return
stdout."
"test.support.script_helper.make_script(script_dir, script_basename, source, omit_suffix=False)","Create script containing source in path script_dir and script_basename.
If omit_suffix is False, append .py to the name.  Return the full
script path."
"test.support.script_helper.make_zip_script(zip_dir, zip_basename, script_name, name_in_zip=None)","Create zip file at zip_dir and zip_basename with extension zip which
contains the files in script_name. name_in_zip is the archive name.
Return a tuple containing (full path, full path of archive name)."
"test.support.script_helper.make_pkg(pkg_dir, init_source='')","Create a directory named pkg_dir containing an __init__ file with
init_source as its contents."
"test.support.script_helper.make_zip_pkg(zip_dir, zip_basename, pkg_name, script_basename, source, depth=1, compiled=False)","Create a zip package directory with a path of zip_dir and zip_basename
containing an empty __init__ file and a file script_basename
containing the source.  If compiled is True, both source files will
be compiled and added to the zip package.  Return a tuple of the full zip
path and the archive name for the zip file."
"EnvironmentVarGuard.set(envvar, value)","Temporarily set the environment variable envvar to the value of
value."
EnvironmentVarGuard.unset(envvar),Temporarily unset the environment variable envvar.
"matches(self, d, **kwargs)",Try to match a single dict with the supplied arguments.
"match_value(self, k, dv, v)",Try to match a single stored value (dv) with a supplied value (v).
run(test),Run test and return the result.
"bdb.checkfuncname(b, frame)","Check whether we should break here, depending on the way the breakpoint b
was set.
If it was set via line number, it checks if b.line is the same as the one
in the frame also passed as argument.  If the breakpoint was set via function
name, we have to check we are in the right frame (the right function) and if
we are in its first executable line."
"bdb.effective(file, line, frame)","Determine if there is an effective (active) breakpoint at this line of code.
Return a tuple of the breakpoint and a boolean that indicates if it is ok
to delete a temporary breakpoint.  Return (None, None) if there is no
matching breakpoint."
bdb.set_trace(),Start debugging with a Bdb instance from caller’s frame.
deleteMe(),"Delete the breakpoint from the list associated to a file/line.  If it is
the last breakpoint in that position, it also deletes the entry for the
file/line."
enable(),Mark the breakpoint as enabled.
disable(),Mark the breakpoint as disabled.
bpformat(),"Return a string with all the information about the breakpoint, nicely
formatted:

The breakpoint number.
If it is temporary or not.
Its file,line position.
The condition that causes a break.
If it must be ignored the next N times.
The breakpoint hit count.


New in version 3.2."
bpprint(out=None),"Print the output of bpformat() to the file out, or if it is
None, to standard output."
canonic(filename),"Auxiliary method for getting a filename in a canonical form, that is, as a
case-normalized (on case-insensitive filesystems) absolute path, stripped
of surrounding angle brackets."
reset(),"Set the botframe, stopframe, returnframe and
quitting attributes with values ready to start debugging."
"trace_dispatch(frame, event, arg)","This function is installed as the trace function of debugged frames.  Its
return value is the new trace function (in most cases, that is, itself).
The default implementation decides how to dispatch a frame, depending on
the type of event (passed as a string) that is about to be executed.
event can be one of the following:

""line"": A new line of code is going to be executed.
""call"": A function is about to be called, or another code block
entered.
""return"": A function or other code block is about to return.
""exception"": An exception has occurred.
""c_call"": A C function is about to be called.
""c_return"": A C function has returned.
""c_exception"": A C function has raised an exception.

For the Python events, specialized functions (see below) are called.  For
the C events, no action is taken.
The arg parameter depends on the previous event.
See the documentation for sys.settrace() for more information on the
trace function.  For more information on code and frame objects, refer to
The standard type hierarchy."
dispatch_line(frame),"If the debugger should stop on the current line, invoke the
user_line() method (which should be overridden in subclasses).
Raise a BdbQuit exception if the Bdb.quitting flag is set
(which can be set from user_line()).  Return a reference to the
trace_dispatch() method for further tracing in that scope."
"dispatch_call(frame, arg)","If the debugger should stop on this function call, invoke the
user_call() method (which should be overridden in subclasses).
Raise a BdbQuit exception if the Bdb.quitting flag is set
(which can be set from user_call()).  Return a reference to the
trace_dispatch() method for further tracing in that scope."
"dispatch_return(frame, arg)","If the debugger should stop on this function return, invoke the
user_return() method (which should be overridden in subclasses).
Raise a BdbQuit exception if the Bdb.quitting flag is set
(which can be set from user_return()).  Return a reference to the
trace_dispatch() method for further tracing in that scope."
"dispatch_exception(frame, arg)","If the debugger should stop at this exception, invokes the
user_exception() method (which should be overridden in subclasses).
Raise a BdbQuit exception if the Bdb.quitting flag is set
(which can be set from user_exception()).  Return a reference to the
trace_dispatch() method for further tracing in that scope."
stop_here(frame),"This method checks if the frame is somewhere below botframe in
the call stack.  botframe is the frame in which debugging started."
break_here(frame),"This method checks if there is a breakpoint in the filename and line
belonging to frame or, at least, in the current function.  If the
breakpoint is a temporary one, this method deletes it."
break_anywhere(frame),"This method checks if there is a breakpoint in the filename of the current
frame."
"user_call(frame, argument_list)","This method is called from dispatch_call() when there is the
possibility that a break might be necessary anywhere inside the called
function."
user_line(frame),"This method is called from dispatch_line() when either
stop_here() or break_here() yields True."
"user_return(frame, return_value)","This method is called from dispatch_return() when stop_here()
yields True."
"user_exception(frame, exc_info)","This method is called from dispatch_exception() when
stop_here() yields True."
do_clear(arg),"Handle how a breakpoint must be removed when it is a temporary one.
This method must be implemented by derived classes."
set_step(),Stop after one line of code.
set_next(frame),Stop on the next line in or below the given frame.
set_return(frame),Stop when returning from the given frame.
set_until(frame),"Stop when the line with the line no greater than the current one is
reached or when returning from current frame."
set_trace([frame]),"Start debugging from frame.  If frame is not specified, debugging
starts from caller’s frame."
set_continue(),"Stop only at breakpoints or when finished.  If there are no breakpoints,
set the system trace function to None."
set_quit(),"Set the quitting attribute to True.  This raises BdbQuit in
the next call to one of the dispatch_*() methods."
"set_break(filename, lineno, temporary=0, cond, funcname)","Set a new breakpoint.  If the lineno line doesn’t exist for the
filename passed as argument, return an error message.  The filename
should be in canonical form, as described in the canonic() method."
"clear_break(filename, lineno)","Delete the breakpoints in filename and lineno.  If none were set, an
error message is returned."
clear_bpbynumber(arg),"Delete the breakpoint which has the index arg in the
Breakpoint.bpbynumber.  If arg is not numeric or out of range,
return an error message."
clear_all_file_breaks(filename),"Delete all breakpoints in filename.  If none were set, an error message
is returned."
clear_all_breaks(),Delete all existing breakpoints.
get_bpbynumber(arg),"Return a breakpoint specified by the given number.  If arg is a string,
it will be converted to a number.  If arg is a non-numeric string, if
the given breakpoint never existed or has been deleted, a
ValueError is raised.

New in version 3.2."
"get_break(filename, lineno)",Check if there is a breakpoint for lineno of filename.
"get_breaks(filename, lineno)","Return all breakpoints for lineno in filename, or an empty list if
none are set."
get_file_breaks(filename),"Return all breakpoints in filename, or an empty list if none are set."
get_all_breaks(),Return all breakpoints that are set.
"get_stack(f, t)","Get a list of records for a frame and all higher (calling) and lower
frames, and the size of the higher part."
"format_stack_entry(frame_lineno, lprefix=': ')","Return a string with information about a stack entry, identified by a
(frame, lineno) tuple:

The canonical form of the filename which contains the frame.
The function name, or ""<lambda>"".
The input arguments.
The return value.
The line of code (if it exists)."
"run(cmd, globals=None, locals=None)","Debug a statement executed via the exec() function.  globals
defaults to __main__.__dict__, locals defaults to globals."
"runeval(expr, globals=None, locals=None)","Debug an expression executed via the eval() function.  globals and
locals have the same meaning as in run()."
"runctx(cmd, globals, locals)",For backwards compatibility.  Calls the run() method.
"runcall(func, *args, **kwds)","Debug a single function call, and return its result."
"faulthandler.dump_traceback(file=sys.stderr, all_threads=True)","Dump the tracebacks of all threads into file. If all_threads is
False, dump only the current thread.

Changed in version 3.5: Added support for passing file descriptor to this function."
"faulthandler.enable(file=sys.stderr, all_threads=True)","Enable the fault handler: install handlers for the SIGSEGV,
SIGFPE, SIGABRT, SIGBUS and SIGILL
signals to dump the Python traceback. If all_threads is True,
produce tracebacks for every running thread. Otherwise, dump only the current
thread.
The file must be kept open until the fault handler is disabled: see
issue with file descriptors.

Changed in version 3.5: Added support for passing file descriptor to this function.


Changed in version 3.6: On Windows, a handler for Windows exception is also installed."
faulthandler.disable(),"Disable the fault handler: uninstall the signal handlers installed by
enable()."
faulthandler.is_enabled(),Check if the fault handler is enabled.
"faulthandler.dump_traceback_later(timeout, repeat=False, file=sys.stderr, exit=False)","Dump the tracebacks of all threads, after a timeout of timeout seconds, or
every timeout seconds if repeat is True.  If exit is True, call
_exit() with status=1 after dumping the tracebacks.  (Note
_exit() exits the process immediately, which means it doesn’t do any
cleanup like flushing file buffers.) If the function is called twice, the new
call replaces previous parameters and resets the timeout. The timer has a
sub-second resolution.
The file must be kept open until the traceback is dumped or
cancel_dump_traceback_later() is called: see issue with file
descriptors.
This function is implemented using a watchdog thread.

Changed in version 3.7: This function is now always available.


Changed in version 3.5: Added support for passing file descriptor to this function."
faulthandler.cancel_dump_traceback_later(),Cancel the last call to dump_traceback_later().
"faulthandler.register(signum, file=sys.stderr, all_threads=True, chain=False)","Register a user signal: install a handler for the signum signal to dump
the traceback of all threads, or of the current thread if all_threads is
False, into file. Call the previous handler if chain is True.
The file must be kept open until the signal is unregistered by
unregister(): see issue with file descriptors.
Not available on Windows.

Changed in version 3.5: Added support for passing file descriptor to this function."
faulthandler.unregister(signum),"Unregister a user signal: uninstall the handler of the signum signal
installed by register(). Return True if the signal was registered,
False otherwise.
Not available on Windows."
"pdb.run(statement, globals=None, locals=None)","Execute the statement (given as a string or a code object) under debugger
control.  The debugger prompt appears before any code is executed; you can
set breakpoints and type continue, or you can step through the
statement using step or next (all these commands are
explained below).  The optional globals and locals arguments specify the
environment in which the code is executed; by default the dictionary of the
module __main__ is used.  (See the explanation of the built-in
exec() or eval() functions.)"
"pdb.runeval(expression, globals=None, locals=None)","Evaluate the expression (given as a string or a code object) under debugger
control.  When runeval() returns, it returns the value of the
expression.  Otherwise this function is similar to run()."
"pdb.runcall(function, *args, **kwds)","Call the function (a function or method object, not a string) with the
given arguments.  When runcall() returns, it returns whatever the
function call returned.  The debugger prompt appears as soon as the function
is entered."
"pdb.set_trace(*, header=None)","Enter the debugger at the calling stack frame.  This is useful to hard-code
a breakpoint at a given point in a program, even if the code is not
otherwise being debugged (e.g. when an assertion fails).  If given,
header is printed to the console just before debugging begins.

Changed in version 3.7: The keyword-only argument header."
pdb.post_mortem(traceback=None),"Enter post-mortem debugging of the given traceback object.  If no
traceback is given, it uses the one of the exception that is currently
being handled (an exception must be being handled if the default is to be
used)."
pdb.pm(),"Enter post-mortem debugging of the traceback found in
sys.last_traceback."
"run(statement, globals=None, locals=None)",See the documentation for the functions explained above.
"profile.run(command, filename=None, sort=-1)","This function takes a single argument that can be passed to the exec()
function, and an optional file name.  In all cases this routine executes:
exec(command, __main__.__dict__, __main__.__dict__)


and gathers profiling statistics from the execution. If no file name is
present, then this function automatically creates a Stats
instance and prints a simple profiling report. If the sort value is specified,
it is passed to this Stats instance to control how the
results are sorted."
"profile.runctx(command, globals, locals, filename=None, sort=-1)","This function is similar to run(), with added arguments to supply the
globals and locals dictionaries for the command string. This routine
executes:
exec(command, globals, locals)


and gathers profiling statistics as in the run() function above."
enable(),Start collecting profiling data. Only in cProfile.
disable(),Stop collecting profiling data. Only in cProfile.
create_stats(),"Stop collecting profiling data and record the results internally
as the current profile."
print_stats(sort=-1),"Create a Stats object based on the current
profile and print the results to stdout."
dump_stats(filename),Write the results of the current profile to filename.
run(cmd),Profile the cmd via exec().
"runctx(cmd, globals, locals)","Profile the cmd via exec() with the specified global and
local environment."
"runcall(func, *args, **kwargs)","Profile func(*args, **kwargs)"
strip_dirs(),"This method for the Stats class removes all leading path
information from file names.  It is very useful in reducing the size of
the printout to fit within (close to) 80 columns.  This method modifies
the object, and the stripped information is lost.  After performing a
strip operation, the object is considered to have its entries in a
“random” order, as it was just after object initialization and loading.
If strip_dirs() causes two function names to be
indistinguishable (they are on the same line of the same filename, and
have the same function name), then the statistics for these two entries
are accumulated into a single entry."
add(*filenames),"This method of the Stats class accumulates additional profiling
information into the current profiling object.  Its arguments should refer
to filenames created by the corresponding version of profile.run()
or cProfile.run(). Statistics for identically named (re: file, line,
name) functions are automatically accumulated into single function
statistics."
dump_stats(filename),"Save the data loaded into the Stats object to a file named
filename.  The file is created if it does not exist, and is overwritten
if it already exists.  This is equivalent to the method of the same name
on the profile.Profile and cProfile.Profile classes."
sort_stats(*keys),"This method modifies the Stats object by sorting it according to
the supplied criteria.  The argument can be either a string or a SortKey
enum identifying the basis of a sort (example: 'time', 'name',
SortKey.TIME or SortKey.NAME). The SortKey enums argument have
advantage over the string argument in that it is more robust and less
error prone.
When more than one key is provided, then additional keys are used as
secondary criteria when there is equality in all keys selected before
them.  For example, sort_stats(SortKey.NAME, SortKey.FILE) will sort
all the entries according to their function name, and resolve all ties
(identical function names) by sorting by file name.
For the string argument, abbreviations can be used for any key names, as
long as the abbreviation is unambiguous.
The following are the valid string and SortKey:







Valid String Arg
Valid enum Arg
Meaning



'calls'
SortKey.CALLS
call count

'cumulative'
SortKey.CUMULATIVE
cumulative time

'cumtime'
N/A
cumulative time

'file'
N/A
file name

'filename'
SortKey.FILENAME
file name

'module'
N/A
file name

'ncalls'
N/A
call count

'pcalls'
SortKey.PCALLS
primitive call count

'line'
SortKey.LINE
line number

'name'
SortKey.NAME
function name

'nfl'
SortKey.NFL
name/file/line

'stdname'
SortKey.STDNAME
standard name

'time'
SortKey.TIME
internal time

'tottime'
N/A
internal time



Note that all sorts on statistics are in descending order (placing most
time consuming items first), where as name, file, and line number searches
are in ascending order (alphabetical). The subtle distinction between
SortKey.NFL and SortKey.STDNAME is that the standard name is a
sort of the name as printed, which means that the embedded line numbers
get compared in an odd way.  For example, lines 3, 20, and 40 would (if
the file names were the same) appear in the string order 20, 3 and 40.
In contrast, SortKey.NFL does a numeric compare of the line numbers.
In fact, sort_stats(SortKey.NFL) is the same as
sort_stats(SortKey.NAME, SortKey.FILENAME, SortKey.LINE).
For backward-compatibility reasons, the numeric arguments -1, 0,
1, and 2 are permitted.  They are interpreted as 'stdname',
'calls', 'time', and 'cumulative' respectively.  If this old
style format (numeric) is used, only one sort key (the numeric key) will
be used, and additional arguments will be silently ignored.

New in version 3.7: Added the SortKey enum."
reverse_order(),"This method for the Stats class reverses the ordering of the
basic list within the object.  Note that by default ascending vs
descending order is properly selected based on the sort key of choice."
print_stats(*restrictions),"This method for the Stats class prints out a report as described
in the profile.run() definition.
The order of the printing is based on the last
sort_stats() operation done on the object (subject to
caveats in add() and
strip_dirs()).
The arguments provided (if any) can be used to limit the list down to the
significant entries.  Initially, the list is taken to be the complete set
of profiled functions.  Each restriction is either an integer (to select a
count of lines), or a decimal fraction between 0.0 and 1.0 inclusive (to
select a percentage of lines), or a string that will interpreted as a
regular expression (to pattern match the standard name that is printed).
If several restrictions are provided, then they are applied sequentially.
For example:
print_stats(.1, 'foo:')


would first limit the printing to first 10% of list, and then only print
functions that were part of filename .*foo:.  In contrast, the
command:
print_stats('foo:', .1)


would limit the list to all functions having file names .*foo:,
and then proceed to only print the first 10% of them."
print_callers(*restrictions),"This method for the Stats class prints a list of all functions
that called each function in the profiled database.  The ordering is
identical to that provided by print_stats(), and the
definition of the restricting argument is also identical.  Each caller is
reported on its own line.  The format differs slightly depending on the
profiler that produced the stats:

With profile, a number is shown in parentheses after each caller
to show how many times this specific call was made.  For convenience, a
second non-parenthesized number repeats the cumulative time spent in the
function at the right.
With cProfile, each caller is preceded by three numbers: the
number of times this specific call was made, and the total and
cumulative times spent in the current function while it was invoked by
this specific caller."
print_callees(*restrictions),"This method for the Stats class prints a list of all function
that were called by the indicated function.  Aside from this reversal of
direction of calls (re: called vs was called by), the arguments and
ordering are identical to the print_callers() method."
"timeit.timeit(stmt='pass', setup='pass', timer=<default timer>, number=1000000, globals=None)","Create a Timer instance with the given statement, setup code and
timer function and run its timeit() method with number executions.
The optional globals argument specifies a namespace in which to execute the
code.

Changed in version 3.5: The optional globals parameter was added."
"timeit.repeat(stmt='pass', setup='pass', timer=<default timer>, repeat=5, number=1000000, globals=None)","Create a Timer instance with the given statement, setup code and
timer function and run its repeat() method with the given repeat
count and number executions.  The optional globals argument specifies a
namespace in which to execute the code.

Changed in version 3.5: The optional globals parameter was added.


Changed in version 3.7: Default value of repeat changed from 3 to 5."
timeit.default_timer(),"The default timer, which is always time.perf_counter().

Changed in version 3.3: time.perf_counter() is now the default timer."
timeit(number=1000000),"Time number executions of the main statement.  This executes the setup
statement once, and then returns the time it takes to execute the main
statement a number of times, measured in seconds as a float.
The argument is the number of times through the loop, defaulting to one
million.  The main statement, the setup statement and the timer function
to be used are passed to the constructor.

Note
By default, timeit() temporarily turns off garbage
collection during the timing.  The advantage of this approach is that
it makes independent timings more comparable.  The disadvantage is
that GC may be an important component of the performance of the
function being measured.  If so, GC can be re-enabled as the first
statement in the setup string.  For example:
timeit.Timer('for i in range(10): oct(i)', 'gc.enable()').timeit()"
autorange(callback=None),"Automatically determine how many times to call timeit().
This is a convenience function that calls timeit() repeatedly
so that the total time >= 0.2 second, returning the eventual
(number of loops, time taken for that number of loops). It calls
timeit() with increasing numbers from the sequence 1, 2, 5,
10, 20, 50, … until the time taken is at least 0.2 second.
If callback is given and is not None, it will be called after
each trial with two arguments: callback(number, time_taken).

New in version 3.6."
"repeat(repeat=5, number=1000000)","Call timeit() a few times.
This is a convenience function that calls the timeit() repeatedly,
returning a list of results.  The first argument specifies how many times
to call timeit().  The second argument specifies the number
argument for timeit().

Note
It’s tempting to calculate mean and standard deviation from the result
vector and report these.  However, this is not very useful.
In a typical case, the lowest value gives a lower bound for how fast
your machine can run the given code snippet; higher values in the
result vector are typically not caused by variability in Python’s
speed, but by other processes interfering with your timing accuracy.
So the min() of the result is probably the only number you
should be interested in.  After that, you should look at the entire
vector and apply common sense rather than statistics.


Changed in version 3.7: Default value of repeat changed from 3 to 5."
print_exc(file=None),"Helper to print a traceback from the timed code.
Typical use:
t = Timer(...)       # outside the try/except
try:
    t.timeit(...)    # or t.repeat(...)
except Exception:
    t.print_exc()


The advantage over the standard traceback is that source lines in the
compiled template will be displayed.  The optional file argument directs
where the traceback is sent; it defaults to sys.stderr."
run(cmd),"Execute the command and gather statistics from the execution with
the current tracing parameters.  cmd must be a string or code object,
suitable for passing into exec()."
"runctx(cmd, globals=None, locals=None)","Execute the command and gather statistics from the execution with the
current tracing parameters, in the defined global and local
environments.  If not defined, globals and locals default to empty
dictionaries."
"runfunc(func, *args, **kwds)","Call func with the given arguments under control of the Trace
object with the current tracing parameters."
results(),"Return a CoverageResults object that contains the cumulative
results of all previous calls to run, runctx and runfunc
for the given Trace instance.  Does not reset the accumulated
trace results."
update(other),Merge in data from another CoverageResults object.
"write_results(show_missing=True, summary=False, coverdir=None)","Write coverage results.  Set show_missing to show lines that had no
hits.  Set summary to include in the output the coverage summary per
module.  coverdir specifies the directory into which the coverage
result files will be output.  If None, the results for each source
file are placed in its directory."
tracemalloc.clear_traces(),"Clear traces of memory blocks allocated by Python.
See also stop()."
tracemalloc.get_object_traceback(obj),"Get the traceback where the Python object obj was allocated.
Return a Traceback instance, or None if the tracemalloc
module is not tracing memory allocations or did not trace the allocation of
the object.
See also gc.get_referrers() and sys.getsizeof() functions."
tracemalloc.get_traceback_limit(),"Get the maximum number of frames stored in the traceback of a trace.
The tracemalloc module must be tracing memory allocations to
get the limit, otherwise an exception is raised.
The limit is set by the start() function."
tracemalloc.get_traced_memory(),"Get the current size and peak size of memory blocks traced by the
tracemalloc module as a tuple: (current: int, peak: int)."
tracemalloc.get_tracemalloc_memory(),"Get the memory usage in bytes of the tracemalloc module used to store
traces of memory blocks.
Return an int."
tracemalloc.is_tracing(),"True if the tracemalloc module is tracing Python memory
allocations, False otherwise.
See also start() and stop() functions."
tracemalloc.start(nframe: int=1),"Start tracing Python memory allocations: install hooks on Python memory
allocators. Collected tracebacks of traces will be limited to nframe
frames. By default, a trace of a memory block only stores the most recent
frame: the limit is 1. nframe must be greater or equal to 1.
Storing more than 1 frame is only useful to compute statistics grouped
by 'traceback' or to compute cumulative statistics: see the
Snapshot.compare_to() and Snapshot.statistics() methods.
Storing more frames increases the memory and CPU overhead of the
tracemalloc module. Use the get_tracemalloc_memory() function
to measure how much memory is used by the tracemalloc module.
The PYTHONTRACEMALLOC environment variable
(PYTHONTRACEMALLOC=NFRAME) and the -X tracemalloc=NFRAME
command line option can be used to start tracing at startup.
See also stop(), is_tracing() and get_traceback_limit()
functions."
tracemalloc.stop(),"Stop tracing Python memory allocations: uninstall hooks on Python memory
allocators. Also clears all previously collected traces of memory blocks
allocated by Python.
Call take_snapshot() function to take a snapshot of traces before
clearing them.
See also start(), is_tracing() and clear_traces()
functions."
tracemalloc.take_snapshot(),"Take a snapshot of traces of memory blocks allocated by Python. Return a new
Snapshot instance.
The snapshot does not include memory blocks allocated before the
tracemalloc module started to trace memory allocations.
Tracebacks of traces are limited to get_traceback_limit() frames. Use
the nframe parameter of the start() function to store more frames.
The tracemalloc module must be tracing memory allocations to take a
snapshot, see the start() function.
See also the get_object_traceback() function."
"compare_to(old_snapshot: Snapshot, key_type: str, cumulative: bool=False)","Compute the differences with an old snapshot. Get statistics as a sorted
list of StatisticDiff instances grouped by key_type.
See the Snapshot.statistics() method for key_type and cumulative
parameters.
The result is sorted from the biggest to the smallest by: absolute value
of StatisticDiff.size_diff, StatisticDiff.size, absolute
value of StatisticDiff.count_diff, Statistic.count and
then by StatisticDiff.traceback."
dump(filename),"Write the snapshot into a file.
Use load() to reload the snapshot."
filter_traces(filters),"Create a new Snapshot instance with a filtered traces
sequence, filters is a list of DomainFilter and
Filter instances.  If filters is an empty list, return a new
Snapshot instance with a copy of the traces.
All inclusive filters are applied at once, a trace is ignored if no
inclusive filters match it. A trace is ignored if at least one exclusive
filter matches it.

Changed in version 3.6: DomainFilter instances are now also accepted in filters."
classmethod load(filename),"Load a snapshot from a file.
See also dump()."
"statistics(key_type: str, cumulative: bool=False)","Get statistics as a sorted list of Statistic instances grouped
by key_type:






key_type
description



'filename'
filename

'lineno'
filename and line number

'traceback'
traceback



If cumulative is True, cumulate size and count of memory blocks of
all frames of the traceback of a trace, not only the most recent frame.
The cumulative mode can only be used with key_type equals to
'filename' and 'lineno'.
The result is sorted from the biggest to the smallest by:
Statistic.size, Statistic.count and then by
Statistic.traceback."
"format(limit=None, most_recent_first=False)","Format the traceback as a list of lines with newlines. Use the
linecache module to retrieve lines from the source code.
If limit is set, format the limit most recent frames if limit
is positive. Otherwise, format the abs(limit) oldest frames.
If most_recent_first is True, the order of the formatted frames
is reversed, returning the most recent frame first instead of last.
Similar to the traceback.format_tb() function, except that
format() does not include newlines.
Example:
print(""Traceback (most recent call first):"")
for line in traceback:
    print(line)


Output:
Traceback (most recent call first):
  File ""test.py"", line 9
    obj = Object()
  File ""test.py"", line 12
    tb = tracemalloc.get_object_traceback(f())"
ensurepip.version(),"Returns a string specifying the bundled version of pip that will be
installed when bootstrapping an environment."
"ensurepip.bootstrap(root=None, upgrade=False, user=False, altinstall=False, default_pip=False, verbosity=0)","Bootstraps pip into the current or designated environment.
root specifies an alternative root directory to install relative to.
If root is None, then installation uses the default install location
for the current environment.
upgrade indicates whether or not to upgrade an existing installation
of an earlier version of pip to the bundled version.
user indicates whether to use the user scheme rather than installing
globally.
By default, the scripts pipX and pipX.Y will be installed (where
X.Y stands for the current version of Python).
If altinstall is set, then pipX will not be installed.
If default_pip is set, then pip will be installed in addition to
the two regular scripts.
Setting both altinstall and default_pip will trigger
ValueError.
verbosity controls the level of output to sys.stdout from the
bootstrapping operation.
Raises an auditing event ensurepip.bootstrap with argument root.

Note
The bootstrapping process has side effects on both sys.path and
os.environ. Invoking the command line interface in a subprocess
instead allows these side effects to be avoided.


Note
The bootstrapping process may install additional modules required by
pip, but other software should not assume those dependencies will
always be present by default (as the dependencies may be removed in a
future version of pip)."
"venv.create(env_dir, system_site_packages=False, clear=False, symlinks=False, with_pip=False, prompt=None)","Create an EnvBuilder with the given keyword arguments, and call its
create() method with the env_dir argument.

New in version 3.3.


Changed in version 3.4: Added the with_pip parameter


Changed in version 3.6: Added the prompt parameter"
create(env_dir),"Create a virtual environment by specifying the target directory
(absolute or relative to the current directory) which is to contain the
virtual environment.  The create method will either create the
environment in the specified directory, or raise an appropriate
exception.
The create method of the EnvBuilder class illustrates the
hooks available for subclass customization:
def create(self, env_dir):
    """"""
    Create a virtualized Python environment in a directory.
    env_dir is the target directory to create an environment in.
    """"""
    env_dir = os.path.abspath(env_dir)
    context = self.ensure_directories(env_dir)
    self.create_configuration(context)
    self.setup_python(context)
    self.setup_scripts(context)
    self.post_setup(context)


Each of the methods ensure_directories(),
create_configuration(), setup_python(),
setup_scripts() and post_setup() can be overridden."
ensure_directories(env_dir),"Creates the environment directory and all necessary directories, and
returns a context object.  This is just a holder for attributes (such as
paths), for use by the other methods. The directories are allowed to
exist already, as long as either clear or upgrade were
specified to allow operating on an existing environment directory."
create_configuration(context),Creates the pyvenv.cfg configuration file in the environment.
setup_python(context),"Creates a copy or symlink to the Python executable in the environment.
On POSIX systems, if a specific executable python3.x was used,
symlinks to python and python3 will be created pointing to that
executable, unless files with those names already exist."
setup_scripts(context),"Installs activation scripts appropriate to the platform into the virtual
environment."
post_setup(context),"A placeholder method which can be overridden in third party
implementations to pre-install packages in the virtual environment or
perform other post-creation steps."
"install_scripts(context, path)","path is the path to a directory that should contain subdirectories
“common”, “posix”, “nt”, each containing scripts destined for the bin
directory in the environment.  The contents of “common” and the
directory corresponding to os.name are copied after some text
replacement of placeholders:

__VENV_DIR__ is replaced with the absolute path of the environment
directory.
__VENV_NAME__ is replaced with the environment name (final path
segment of environment directory).
__VENV_PROMPT__ is replaced with the prompt (the environment
name surrounded by parentheses and with a following space)
__VENV_BIN_NAME__ is replaced with the name of the bin directory
(either bin or Scripts).
__VENV_PYTHON__ is replaced with the absolute path of the
environment’s executable.

The directories are allowed to exist (for when an existing environment
is being upgraded)."
"zipapp.create_archive(source, target=None, interpreter=None, main=None, filter=None, compressed=False)","Create an application archive from source.  The source can be any
of the following:

The name of a directory, or a path-like object referring
to a directory, in which case a new application archive will be
created from the content of that directory.
The name of an existing application archive file, or a path-like object
referring to such a file, in which case the file is copied to
the target (modifying it to reflect the value given for the interpreter
argument).  The file name should include the .pyz extension, if required.
A file object open for reading in bytes mode.  The content of the
file should be an application archive, and the file object is
assumed to be positioned at the start of the archive.

The target argument determines where the resulting archive will be
written:

If it is the name of a file, or a path-like object,
the archive will be written to that file.
If it is an open file object, the archive will be written to that
file object, which must be open for writing in bytes mode.
If the target is omitted (or None), the source must be a directory
and the target will be a file with the same name as the source, with
a .pyz extension added.

The interpreter argument specifies the name of the Python
interpreter with which the archive will be executed.  It is written as
a “shebang” line at the start of the archive.  On POSIX, this will be
interpreted by the OS, and on Windows it will be handled by the Python
launcher.  Omitting the interpreter results in no shebang line being
written.  If an interpreter is specified, and the target is a
filename, the executable bit of the target file will be set.
The main argument specifies the name of a callable which will be
used as the main program for the archive.  It can only be specified if
the source is a directory, and the source does not already contain a
__main__.py file.  The main argument should take the form
“pkg.module:callable” and the archive will be run by importing
“pkg.module” and executing the given callable with no arguments.  It
is an error to omit main if the source is a directory and does not
contain a __main__.py file, as otherwise the resulting archive
would not be executable.
The optional filter argument specifies a callback function that
is passed a Path object representing the path to the file being added
(relative to the source directory).  It should return True if the
file is to be added.
The optional compressed argument determines whether files are
compressed.  If set to True, files in the archive are compressed
with the deflate method; otherwise, files are stored uncompressed.
This argument has no effect when copying an existing archive.
If a file object is specified for source or target, it is the
caller’s responsibility to close it after calling create_archive.
When copying an existing archive, file objects supplied only need
read and readline, or write methods.  When creating an
archive from a directory, if the target is a file object it will be
passed to the zipfile.ZipFile class, and must supply the methods
needed by that class.

New in version 3.7: Added the filter and compressed arguments."
zipapp.get_interpreter(archive),"Return the interpreter specified in the #! line at the start of the
archive.  If there is no #! line, return None.
The archive argument can be a filename or a file-like object open
for reading in bytes mode.  It is assumed to be at the start of the archive."
sys.addaudithook(hook),"Append the callable hook to the list of active auditing hooks for the
current interpreter.
When an auditing event is raised through the sys.audit() function, each
hook will be called in the order it was added with the event name and the
tuple of arguments. Native hooks added by PySys_AddAuditHook() are
called first, followed by hooks added in the current interpreter.
Raise an auditing event sys.addaudithook with no arguments. If any
existing hooks raise an exception derived from RuntimeError, the
new hook will not be added and the exception suppressed. As a result,
callers cannot assume that their hook has been added unless they control
all existing hooks.

New in version 3.8.


Changed in version 3.8.1: Exceptions derived from Exception but not RuntimeError
are no longer suppressed.


CPython implementation detail: When tracing is enabled (see settrace()), Python hooks are only
traced if the callable has a __cantrace__ member that is set to a
true value. Otherwise, trace functions will skip the hook."
"sys.audit(event, *args)","Raise an auditing event with any active hooks. The event name is a string
identifying the event and its associated schema, which is the number and
types of arguments. The schema for a given event is considered public and
stable API and should not be modified between releases.
This function will raise the first exception raised by any hook. In general,
these errors should not be handled and should terminate the process as
quickly as possible.
Hooks are added using the sys.addaudithook() or
PySys_AddAuditHook() functions.
The native equivalent of this function is PySys_Audit(). Using the
native function is preferred when possible.
See the audit events table for all events raised by
CPython.

New in version 3.8."
"sys.call_tracing(func, args)","Call func(*args), while tracing is enabled.  The tracing state is saved,
and restored afterwards.  This is intended to be called from a debugger from
a checkpoint, to recursively debug some other code."
sys._clear_type_cache(),"Clear the internal type cache. The type cache is used to speed up attribute
and method lookups. Use the function only to drop unnecessary references
during reference leak debugging.
This function should be used for internal and specialized purposes only."
sys._current_frames(),"Return a dictionary mapping each thread’s identifier to the topmost stack frame
currently active in that thread at the time the function is called. Note that
functions in the traceback module can build the call stack given such a
frame.
This is most useful for debugging deadlock:  this function does not require the
deadlocked threads’ cooperation, and such threads’ call stacks are frozen for as
long as they remain deadlocked.  The frame returned for a non-deadlocked thread
may bear no relationship to that thread’s current activity by the time calling
code examines the frame.
This function should be used for internal and specialized purposes only.
Raises an auditing event sys._current_frames with no arguments."
sys.breakpointhook(),"This hook function is called by built-in breakpoint().  By default,
it drops you into the pdb debugger, but it can be set to any other
function so that you can choose which debugger gets used.
The signature of this function is dependent on what it calls.  For example,
the default binding (e.g. pdb.set_trace()) expects no arguments, but
you might bind it to a function that expects additional arguments
(positional and/or keyword).  The built-in breakpoint() function passes
its *args and **kws straight through.  Whatever
breakpointhooks() returns is returned from breakpoint().
The default implementation first consults the environment variable
PYTHONBREAKPOINT.  If that is set to ""0"" then this function
returns immediately; i.e. it is a no-op.  If the environment variable is
not set, or is set to the empty string, pdb.set_trace() is called.
Otherwise this variable should name a function to run, using Python’s
dotted-import nomenclature, e.g. package.subpackage.module.function.
In this case, package.subpackage.module would be imported and the
resulting module must have a callable named function().  This is run,
passing in *args and **kws, and whatever function() returns,
sys.breakpointhook() returns to the built-in breakpoint()
function.
Note that if anything goes wrong while importing the callable named by
PYTHONBREAKPOINT, a RuntimeWarning is reported and the
breakpoint is ignored.
Also note that if sys.breakpointhook() is overridden programmatically,
PYTHONBREAKPOINT is not consulted.

New in version 3.7."
sys._debugmallocstats(),"Print low-level information to stderr about the state of CPython’s memory
allocator.
If Python is configured –with-pydebug, it also performs some expensive
internal consistency checks.

New in version 3.3.


CPython implementation detail: This function is specific to CPython.  The exact output format is not
defined here, and may change."
sys.displayhook(value),"If value is not None, this function prints repr(value) to
sys.stdout, and saves value in builtins._. If repr(value) is
not encodable to sys.stdout.encoding with sys.stdout.errors error
handler (which is probably 'strict'), encode it to
sys.stdout.encoding with 'backslashreplace' error handler.
sys.displayhook is called on the result of evaluating an expression
entered in an interactive Python session.  The display of these values can be
customized by assigning another one-argument function to sys.displayhook.
Pseudo-code:
def displayhook(value):
    if value is None:
        return
    # Set '_' to None to avoid recursion
    builtins._ = None
    text = repr(value)
    try:
        sys.stdout.write(text)
    except UnicodeEncodeError:
        bytes = text.encode(sys.stdout.encoding, 'backslashreplace')
        if hasattr(sys.stdout, 'buffer'):
            sys.stdout.buffer.write(bytes)
        else:
            text = bytes.decode(sys.stdout.encoding, 'strict')
            sys.stdout.write(text)
    sys.stdout.write(""\n"")
    builtins._ = value



Changed in version 3.2: Use 'backslashreplace' error handler on UnicodeEncodeError."
"sys.excepthook(type, value, traceback)","This function prints out a given traceback and exception to sys.stderr.
When an exception is raised and uncaught, the interpreter calls
sys.excepthook with three arguments, the exception class, exception
instance, and a traceback object.  In an interactive session this happens just
before control is returned to the prompt; in a Python program this happens just
before the program exits.  The handling of such top-level exceptions can be
customized by assigning another three-argument function to sys.excepthook.
Raise an auditing event sys.excepthook with arguments hook,
type, value, traceback when an uncaught exception occurs.
If no hook has been set, hook may be None. If any hook raises
an exception derived from RuntimeError the call to the hook will
be suppressed. Otherwise, the audit hook exception will be reported as
unraisable and sys.excepthook will be called.

See also
The sys.unraisablehook() function handles unraisable exceptions
and the threading.excepthook() function handles exception raised
by threading.Thread.run()."
sys.exc_info(),"This function returns a tuple of three values that give information about the
exception that is currently being handled.  The information returned is specific
both to the current thread and to the current stack frame.  If the current stack
frame is not handling an exception, the information is taken from the calling
stack frame, or its caller, and so on until a stack frame is found that is
handling an exception.  Here, “handling an exception” is defined as “executing
an except clause.”  For any stack frame, only information about the exception
being currently handled is accessible.
If no exception is being handled anywhere on the stack, a tuple containing
three None values is returned.  Otherwise, the values returned are
(type, value, traceback).  Their meaning is: type gets the type of the
exception being handled (a subclass of BaseException); value gets
the exception instance (an instance of the exception type); traceback gets
a traceback object which encapsulates the call
stack at the point where the exception originally occurred."
sys.exit([arg]),"Exit from Python.  This is implemented by raising the SystemExit
exception, so cleanup actions specified by finally clauses of try
statements are honored, and it is possible to intercept the exit attempt at
an outer level.
The optional argument arg can be an integer giving the exit status
(defaulting to zero), or another type of object.  If it is an integer, zero
is considered “successful termination” and any nonzero value is considered
“abnormal termination” by shells and the like.  Most systems require it to be
in the range 0–127, and produce undefined results otherwise.  Some systems
have a convention for assigning specific meanings to specific exit codes, but
these are generally underdeveloped; Unix programs generally use 2 for command
line syntax errors and 1 for all other kind of errors.  If another type of
object is passed, None is equivalent to passing zero, and any other
object is printed to stderr and results in an exit code of 1.  In
particular, sys.exit(""some error message"") is a quick way to exit a
program when an error occurs.
Since exit() ultimately “only” raises an exception, it will only exit
the process when called from the main thread, and the exception is not
intercepted.

Changed in version 3.6: If an error occurs in the cleanup after the Python interpreter
has caught SystemExit (such as an error flushing buffered data
in the standard streams), the exit status is changed to 120."
sys.getallocatedblocks(),"Return the number of memory blocks currently allocated by the interpreter,
regardless of their size.  This function is mainly useful for tracking
and debugging memory leaks.  Because of the interpreter’s internal
caches, the result can vary from call to call; you may have to call
_clear_type_cache() and gc.collect() to get more
predictable results.
If a Python build or implementation cannot reasonably compute this
information, getallocatedblocks() is allowed to return 0 instead.

New in version 3.4."
sys.getandroidapilevel(),"Return the build time API version of Android as an integer.
Availability: Android.

New in version 3.7."
sys.getcheckinterval(),"Return the interpreter’s “check interval”; see setcheckinterval().

Deprecated since version 3.2: Use getswitchinterval() instead."
sys.getdefaultencoding(),"Return the name of the current default string encoding used by the Unicode
implementation."
sys.getdlopenflags(),"Return the current value of the flags that are used for
dlopen() calls.  Symbolic names for the flag values can be
found in the os module (RTLD_xxx constants, e.g.
os.RTLD_LAZY).
Availability: Unix."
sys.getfilesystemencoding(),"Return the name of the encoding used to convert between Unicode
filenames and bytes filenames. For best compatibility, str should be
used for filenames in all cases, although representing filenames as bytes
is also supported. Functions accepting or returning filenames should support
either str or bytes and internally convert to the system’s preferred
representation.
This encoding is always ASCII-compatible.
os.fsencode() and os.fsdecode() should be used to ensure that
the correct encoding and errors mode are used.

In the UTF-8 mode, the encoding is utf-8 on any platform.
On macOS, the encoding is 'utf-8'.
On Unix, the encoding is the locale encoding.
On Windows, the encoding may be 'utf-8' or 'mbcs', depending
on user configuration.
On Android, the encoding is 'utf-8'.
On VxWorks, the encoding is 'utf-8'.


Changed in version 3.2: getfilesystemencoding() result cannot be None anymore.


Changed in version 3.6: Windows is no longer guaranteed to return 'mbcs'. See PEP 529
and _enablelegacywindowsfsencoding() for more information.


Changed in version 3.7: Return ‘utf-8’ in the UTF-8 mode."
sys.getfilesystemencodeerrors(),"Return the name of the error mode used to convert between Unicode filenames
and bytes filenames. The encoding name is returned from
getfilesystemencoding().
os.fsencode() and os.fsdecode() should be used to ensure that
the correct encoding and errors mode are used.

New in version 3.6."
sys.getrefcount(object),"Return the reference count of the object.  The count returned is generally one
higher than you might expect, because it includes the (temporary) reference as
an argument to getrefcount()."
sys.getrecursionlimit(),"Return the current value of the recursion limit, the maximum depth of the Python
interpreter stack.  This limit prevents infinite recursion from causing an
overflow of the C stack and crashing Python.  It can be set by
setrecursionlimit()."
"sys.getsizeof(object[, default])","Return the size of an object in bytes. The object can be any type of
object. All built-in objects will return correct results, but this
does not have to hold true for third-party extensions as it is implementation
specific.
Only the memory consumption directly attributed to the object is
accounted for, not the memory consumption of objects it refers to.
If given, default will be returned if the object does not provide means to
retrieve the size.  Otherwise a TypeError will be raised.
getsizeof() calls the object’s __sizeof__ method and adds an
additional garbage collector overhead if the object is managed by the garbage
collector.
See recursive sizeof recipe
for an example of using getsizeof() recursively to find the size of
containers and all their contents."
sys.getswitchinterval(),"Return the interpreter’s “thread switch interval”; see
setswitchinterval().

New in version 3.2."
sys._getframe([depth]),"Return a frame object from the call stack.  If optional integer depth is
given, return the frame object that many calls below the top of the stack.  If
that is deeper than the call stack, ValueError is raised.  The default
for depth is zero, returning the frame at the top of the call stack.
Raises an auditing event sys._getframe with no arguments.

CPython implementation detail: This function should be used for internal and specialized purposes only.
It is not guaranteed to exist in all implementations of Python."
sys.getprofile(),Get the profiler function as set by setprofile().
sys.gettrace(),"Get the trace function as set by settrace().

CPython implementation detail: The gettrace() function is intended only for implementing debuggers,
profilers, coverage tools and the like.  Its behavior is part of the
implementation platform, rather than part of the language definition, and
thus may not be available in all Python implementations."
sys.getwindowsversion(),"Return a named tuple describing the Windows version
currently running.  The named elements are major, minor,
build, platform, service_pack, service_pack_minor,
service_pack_major, suite_mask, product_type and
platform_version. service_pack contains a string,
platform_version a 3-tuple and all other values are
integers. The components can also be accessed by name, so
sys.getwindowsversion()[0] is equivalent to
sys.getwindowsversion().major. For compatibility with prior
versions, only the first 5 elements are retrievable by indexing.
platform will be 2 (VER_PLATFORM_WIN32_NT).
product_type may be one of the following values:






Constant
Meaning



1 (VER_NT_WORKSTATION)
The system is a workstation.

2 (VER_NT_DOMAIN_CONTROLLER)
The system is a domain
controller.

3 (VER_NT_SERVER)
The system is a server, but not
a domain controller.



This function wraps the Win32 GetVersionEx() function; see the
Microsoft documentation on OSVERSIONINFOEX() for more information
about these fields.
platform_version returns the accurate major version, minor version and
build number of the current operating system, rather than the version that
is being emulated for the process. It is intended for use in logging rather
than for feature detection.
Availability: Windows.

Changed in version 3.2: Changed to a named tuple and added service_pack_minor,
service_pack_major, suite_mask, and product_type.


Changed in version 3.6: Added platform_version"
sys.get_asyncgen_hooks(),"Returns an asyncgen_hooks object, which is similar to a
namedtuple of the form (firstiter, finalizer),
where firstiter and finalizer are expected to be either None or
functions which take an asynchronous generator iterator as an
argument, and are used to schedule finalization of an asynchronous
generator by an event loop.

New in version 3.6: See PEP 525 for more details.


Note
This function has been added on a provisional basis (see PEP 411
for details.)"
sys.get_coroutine_origin_tracking_depth(),"Get the current coroutine origin tracking depth, as set by
set_coroutine_origin_tracking_depth().

New in version 3.7.


Note
This function has been added on a provisional basis (see PEP 411
for details.)  Use it only for debugging purposes."
sys.intern(string),"Enter string in the table of “interned” strings and return the interned string
– which is string itself or a copy. Interning strings is useful to gain a
little performance on dictionary lookup – if the keys in a dictionary are
interned, and the lookup key is interned, the key comparisons (after hashing)
can be done by a pointer compare instead of a string compare.  Normally, the
names used in Python programs are automatically interned, and the dictionaries
used to hold module, class or instance attributes have interned keys.
Interned strings are not immortal; you must keep a reference to the return
value of intern() around to benefit from it."
sys.is_finalizing(),"Return True if the Python interpreter is
shutting down, False otherwise.

New in version 3.5."
sys.setcheckinterval(interval),"Set the interpreter’s “check interval”.  This integer value determines how often
the interpreter checks for periodic things such as thread switches and signal
handlers.  The default is 100, meaning the check is performed every 100
Python virtual instructions. Setting it to a larger value may increase
performance for programs using threads.  Setting it to a value <= 0 checks
every virtual instruction, maximizing responsiveness as well as overhead.

Deprecated since version 3.2: This function doesn’t have an effect anymore, as the internal logic for
thread switching and asynchronous tasks has been rewritten.  Use
setswitchinterval() instead."
sys.setdlopenflags(n),"Set the flags used by the interpreter for dlopen() calls, such as when
the interpreter loads extension modules.  Among other things, this will enable a
lazy resolving of symbols when importing a module, if called as
sys.setdlopenflags(0).  To share symbols across extension modules, call as
sys.setdlopenflags(os.RTLD_GLOBAL).  Symbolic names for the flag values
can be found in the os module (RTLD_xxx constants, e.g.
os.RTLD_LAZY).
Availability: Unix."
sys.setprofile(profilefunc),"Set the system’s profile function, which allows you to implement a Python source
code profiler in Python.  See chapter The Python Profilers for more information on the
Python profiler.  The system’s profile function is called similarly to the
system’s trace function (see settrace()), but it is called with different events,
for example it isn’t called for each executed line of code (only on call and return,
but the return event is reported even when an exception has been set). The function is
thread-specific, but there is no way for the profiler to know about context switches between
threads, so it does not make sense to use this in the presence of multiple threads. Also,
its return value is not used, so it can simply return None.  Error in the profile
function will cause itself unset.
Profile functions should have three arguments: frame, event, and
arg. frame is the current stack frame.  event is a string: 'call',
'return', 'c_call', 'c_return', or 'c_exception'. arg depends
on the event type.
Raises an auditing event sys.setprofile with no arguments.
The events have the following meaning:

'call'A function is called (or some other code block entered).  The
profile function is called; arg is None.

'return'A function (or other code block) is about to return.  The profile
function is called; arg is the value that will be returned, or None
if the event is caused by an exception being raised.

'c_call'A C function is about to be called.  This may be an extension function or
a built-in.  arg is the C function object.

'c_return'A C function has returned. arg is the C function object.

'c_exception'A C function has raised an exception.  arg is the C function object."
sys.setrecursionlimit(limit),"Set the maximum depth of the Python interpreter stack to limit.  This limit
prevents infinite recursion from causing an overflow of the C stack and crashing
Python.
The highest possible limit is platform-dependent.  A user may need to set the
limit higher when they have a program that requires deep recursion and a platform
that supports a higher limit.  This should be done with care, because a too-high
limit can lead to a crash.
If the new limit is too low at the current recursion depth, a
RecursionError exception is raised.

Changed in version 3.5.1: A RecursionError exception is now raised if the new limit is too
low at the current recursion depth."
sys.setswitchinterval(interval),"Set the interpreter’s thread switch interval (in seconds).  This floating-point
value determines the ideal duration of the “timeslices” allocated to
concurrently running Python threads.  Please note that the actual value
can be higher, especially if long-running internal functions or methods
are used.  Also, which thread becomes scheduled at the end of the interval
is the operating system’s decision.  The interpreter doesn’t have its
own scheduler.

New in version 3.2."
sys.settrace(tracefunc),"Set the system’s trace function, which allows you to implement a Python
source code debugger in Python.  The function is thread-specific; for a
debugger to support multiple threads, it must register a trace function using
settrace() for each thread being debugged or use threading.settrace().
Trace functions should have three arguments: frame, event, and
arg. frame is the current stack frame.  event is a string: 'call',
'line', 'return', 'exception' or 'opcode'.  arg depends on
the event type.
The trace function is invoked (with event set to 'call') whenever a new
local scope is entered; it should return a reference to a local trace
function to be used for the new scope, or None if the scope shouldn’t be
traced.
The local trace function should return a reference to itself (or to another
function for further tracing in that scope), or None to turn off tracing
in that scope.
If there is any error occurred in the trace function, it will be unset, just
like settrace(None) is called.
The events have the following meaning:

'call'A function is called (or some other code block entered).  The
global trace function is called; arg is None; the return value
specifies the local trace function.

'line'The interpreter is about to execute a new line of code or re-execute the
condition of a loop.  The local trace function is called; arg is
None; the return value specifies the new local trace function.  See
Objects/lnotab_notes.txt for a detailed explanation of how this
works.
Per-line events may be disabled for a frame by setting
f_trace_lines to False on that frame.

'return'A function (or other code block) is about to return.  The local trace
function is called; arg is the value that will be returned, or None
if the event is caused by an exception being raised.  The trace function’s
return value is ignored.

'exception'An exception has occurred.  The local trace function is called; arg is a
tuple (exception, value, traceback); the return value specifies the
new local trace function.

'opcode'The interpreter is about to execute a new opcode (see dis for
opcode details).  The local trace function is called; arg is
None; the return value specifies the new local trace function.
Per-opcode events are not emitted by default: they must be explicitly
requested by setting f_trace_opcodes to True on the
frame.


Note that as an exception is propagated down the chain of callers, an
'exception' event is generated at each level.
For more fine-grained usage, it’s possible to set a trace function by
assigning frame.f_trace = tracefunc explicitly, rather than relying on
it being set indirectly via the return value from an already installed
trace function. This is also required for activating the trace function on
the current frame, which settrace() doesn’t do. Note that in order
for this to work, a global tracing function must have been installed
with settrace() in order to enable the runtime tracing machinery,
but it doesn’t need to be the same tracing function (e.g. it could be a
low overhead tracing function that simply returns None to disable
itself immediately on each frame).
For more information on code and frame objects, refer to The standard type hierarchy.
Raises an auditing event sys.settrace with no arguments.

CPython implementation detail: The settrace() function is intended only for implementing debuggers,
profilers, coverage tools and the like.  Its behavior is part of the
implementation platform, rather than part of the language definition, and
thus may not be available in all Python implementations.


Changed in version 3.7: 'opcode' event type added; f_trace_lines and
f_trace_opcodes attributes added to frames"
"sys.set_asyncgen_hooks(firstiter, finalizer)","Accepts two optional keyword arguments which are callables that accept an
asynchronous generator iterator as an argument. The firstiter
callable will be called when an asynchronous generator is iterated for the
first time. The finalizer will be called when an asynchronous generator
is about to be garbage collected.
Raises an auditing event sys.set_asyncgen_hooks_firstiter with no arguments.
Raises an auditing event sys.set_asyncgen_hooks_finalizer with no arguments.
Two auditing events are raised because the underlying API consists of two
calls, each of which must raise its own event.

New in version 3.6: See PEP 525 for more details, and for a reference example of a
finalizer method see the implementation of
asyncio.Loop.shutdown_asyncgens in
Lib/asyncio/base_events.py


Note
This function has been added on a provisional basis (see PEP 411
for details.)"
sys.set_coroutine_origin_tracking_depth(depth),"Allows enabling or disabling coroutine origin tracking. When
enabled, the cr_origin attribute on coroutine objects will
contain a tuple of (filename, line number, function name) tuples
describing the traceback where the coroutine object was created,
with the most recent call first. When disabled, cr_origin will
be None.
To enable, pass a depth value greater than zero; this sets the
number of frames whose information will be captured. To disable,
pass set depth to zero.
This setting is thread-specific.

New in version 3.7.


Note
This function has been added on a provisional basis (see PEP 411
for details.)  Use it only for debugging purposes."
sys._enablelegacywindowsfsencoding(),"Changes the default filesystem encoding and errors mode to ‘mbcs’ and
‘replace’ respectively, for consistency with versions of Python prior to 3.6.
This is equivalent to defining the PYTHONLEGACYWINDOWSFSENCODING
environment variable before launching Python.
Availability: Windows.

New in version 3.6: See PEP 529 for more details."
"sys.unraisablehook(unraisable, /)","Handle an unraisable exception.
Called when an exception has occurred but there is no way for Python to
handle it. For example, when a destructor raises an exception or during
garbage collection (gc.collect()).
The unraisable argument has the following attributes:

exc_type: Exception type.
exc_value: Exception value, can be None.
exc_traceback: Exception traceback, can be None.
err_msg: Error message, can be None.
object: Object causing the exception, can be None.

The default hook formats err_msg and object as:
f'{err_msg}: {object!r}'; use “Exception ignored in” error message
if err_msg is None.
sys.unraisablehook() can be overridden to control how unraisable
exceptions are handled.
Storing exc_value using a custom hook can create a reference cycle. It
should be cleared explicitly to break the reference cycle when the
exception is no longer needed.
Storing object using a custom hook can resurrect it if it is set to an
object which is being finalized. Avoid storing object after the custom
hook completes to avoid resurrecting objects.
See also excepthook() which handles uncaught exceptions.
Raise an auditing event sys.unraisablehook with arguments
hook, unraisable when an exception that cannot be handled occurs.
The unraisable object is the same as what will be passed to the hook.
If no hook has been set, hook may be None.

New in version 3.8."
sysconfig.get_config_vars(*args),"With no arguments, return a dictionary of all configuration variables
relevant for the current platform.
With arguments, return a list of values that result from looking up each
argument in the configuration variable dictionary.
For each argument, if the value is not found, return None."
sysconfig.get_config_var(name),"Return the value of a single variable name. Equivalent to
get_config_vars().get(name).
If name is not found, return None."
sysconfig.get_scheme_names(),"Return a tuple containing all schemes currently supported in
sysconfig."
sysconfig.get_path_names(),"Return a tuple containing all path names currently supported in
sysconfig."
"sysconfig.get_path(name[, scheme[, vars[, expand]]])","Return an installation path corresponding to the path name, from the
install scheme named scheme.
name has to be a value from the list returned by get_path_names().
sysconfig stores installation paths corresponding to each path name,
for each platform, with variables to be expanded.  For instance the stdlib
path for the nt scheme is: {base}/Lib.
get_path() will use the variables returned by get_config_vars()
to expand the path.  All variables have default values for each platform so
one may call this function and get the default value.
If scheme is provided, it must be a value from the list returned by
get_scheme_names().  Otherwise, the default scheme for the current
platform is used.
If vars is provided, it must be a dictionary of variables that will update
the dictionary return by get_config_vars().
If expand is set to False, the path will not be expanded using the
variables.
If name is not found, return None."
"sysconfig.get_paths([scheme[, vars[, expand]]])","Return a dictionary containing all installation paths corresponding to an
installation scheme. See get_path() for more information.
If scheme is not provided, will use the default scheme for the current
platform.
If vars is provided, it must be a dictionary of variables that will
update the dictionary used to expand the paths.
If expand is set to false, the paths will not be expanded.
If scheme is not an existing scheme, get_paths() will raise a
KeyError."
sysconfig.get_python_version(),"Return the MAJOR.MINOR Python version number as a string.  Similar to
'%d.%d' % sys.version_info[:2]."
sysconfig.get_platform(),"Return a string that identifies the current platform.
This is used mainly to distinguish platform-specific build directories and
platform-specific built distributions.  Typically includes the OS name and
version and the architecture (as supplied by ‘os.uname()’), although the
exact information included depends on the OS; e.g., on Linux, the kernel
version isn’t particularly important.
Examples of returned values:

linux-i586
linux-alpha (?)
solaris-2.6-sun4u

Windows will return one of:

win-amd64 (64bit Windows on AMD64, aka x86_64, Intel64, and EM64T)
win32 (all others - specifically, sys.platform is returned)

Mac OS X can return:

macosx-10.6-ppc
macosx-10.4-ppc64
macosx-10.3-i386
macosx-10.4-fat

For other non-POSIX platforms, currently just returns sys.platform."
sysconfig.is_python_build(),"Return True if the running Python interpreter was built from source and
is being run from its built location, and not from a location resulting from
e.g. running make install or installing via a binary installer."
"sysconfig.parse_config_h(fp[, vars])","Parse a config.h-style file.
fp is a file-like object pointing to the config.h-like file.
A dictionary containing name/value pairs is returned.  If an optional
dictionary is passed in as the second argument, it is used instead of a new
dictionary, and updated with the values read in the file."
sysconfig.get_config_h_filename(),Return the path of pyconfig.h.
sysconfig.get_makefile_filename(),Return the path of Makefile.
"warnings.warn(message, category=None, stacklevel=1, source=None)","Issue a warning, or maybe ignore it or raise an exception.  The category
argument, if given, must be a warning category class; it
defaults to UserWarning.  Alternatively, message can be a Warning instance,
in which case category will be ignored and message.__class__ will be used.
In this case, the message text will be str(message). This function raises an
exception if the particular warning issued is changed into an error by the
warnings filter.  The stacklevel argument can be used by wrapper
functions written in Python, like this:
def deprecation(message):
    warnings.warn(message, DeprecationWarning, stacklevel=2)


This makes the warning refer to deprecation()’s caller, rather than to the
source of deprecation() itself (since the latter would defeat the purpose
of the warning message).
source, if supplied, is the destroyed object which emitted a
ResourceWarning.

Changed in version 3.6: Added source parameter."
"warnings.warn_explicit(message, category, filename, lineno, module=None, registry=None, module_globals=None, source=None)","This is a low-level interface to the functionality of warn(), passing in
explicitly the message, category, filename and line number, and optionally the
module name and the registry (which should be the __warningregistry__
dictionary of the module).  The module name defaults to the filename with
.py stripped; if no registry is passed, the warning is never suppressed.
message must be a string and category a subclass of Warning or
message may be a Warning instance, in which case category will be
ignored.
module_globals, if supplied, should be the global namespace in use by the code
for which the warning is issued.  (This argument is used to support displaying
source for modules found in zipfiles or other non-filesystem import
sources).
source, if supplied, is the destroyed object which emitted a
ResourceWarning.

Changed in version 3.6: Add the source parameter."
"warnings.showwarning(message, category, filename, lineno, file=None, line=None)","Write a warning to a file.  The default implementation calls
formatwarning(message, category, filename, lineno, line) and writes the
resulting string to file, which defaults to sys.stderr.  You may replace
this function with any callable by assigning to warnings.showwarning.
line is a line of source code to be included in the warning
message; if line is not supplied, showwarning() will
try to read the line specified by filename and lineno."
"warnings.formatwarning(message, category, filename, lineno, line=None)","Format a warning the standard way.  This returns a string which may contain
embedded newlines and ends in a newline.  line is a line of source code to
be included in the warning message; if line is not supplied,
formatwarning() will try to read the line specified by filename and
lineno."
"warnings.filterwarnings(action, message='', category=Warning, module='', lineno=0, append=False)","Insert an entry into the list of warnings filter specifications.  The entry is inserted at the front by default; if
append is true, it is inserted at the end.  This checks the types of the
arguments, compiles the message and module regular expressions, and
inserts them as a tuple in the list of warnings filters.  Entries closer to
the front of the list override entries later in the list, if both match a
particular warning.  Omitted arguments default to a value that matches
everything."
"warnings.simplefilter(action, category=Warning, lineno=0, append=False)","Insert a simple entry into the list of warnings filter specifications.  The meaning of the function parameters is as for
filterwarnings(), but regular expressions are not needed as the filter
inserted always matches any message in any module as long as the category and
line number match."
warnings.resetwarnings(),"Reset the warnings filter.  This discards the effect of all previous calls to
filterwarnings(), including that of the -W command line options
and calls to simplefilter()."
"@dataclasses.dataclass(*, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False)","This function is a decorator that is used to add generated
special methods to classes, as described below.
The dataclass() decorator examines the class to find
fields.  A field is defined as class variable that has a
type annotation.  With two
exceptions described below, nothing in dataclass()
examines the type specified in the variable annotation.
The order of the fields in all of the generated methods is the
order in which they appear in the class definition.
The dataclass() decorator will add various “dunder” methods to
the class, described below.  If any of the added methods already
exist on the class, the behavior depends on the parameter, as documented
below. The decorator returns the same class that is called on; no new
class is created.
If dataclass() is used just as a simple decorator with no parameters,
it acts as if it has the default values documented in this
signature.  That is, these three uses of dataclass() are
equivalent:
@dataclass
class C:
    ...

@dataclass()
class C:
    ...

@dataclass(init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False)
class C:
   ...


The parameters to dataclass() are:

init: If true (the default), a __init__() method will be
generated.
If the class already defines __init__(), this parameter is
ignored.

repr: If true (the default), a __repr__() method will be
generated.  The generated repr string will have the class name and
the name and repr of each field, in the order they are defined in
the class.  Fields that are marked as being excluded from the repr
are not included.  For example:
InventoryItem(name='widget', unit_price=3.0, quantity_on_hand=10).
If the class already defines __repr__(), this parameter is
ignored.

eq: If true (the default), an __eq__() method will be
generated.  This method compares the class as if it were a tuple
of its fields, in order.  Both instances in the comparison must
be of the identical type.
If the class already defines __eq__(), this parameter is
ignored.

order: If true (the default is False), __lt__(),
__le__(), __gt__(), and __ge__() methods will be
generated.  These compare the class as if it were a tuple of its
fields, in order.  Both instances in the comparison must be of the
identical type.  If order is true and eq is false, a
ValueError is raised.
If the class already defines any of __lt__(),
__le__(), __gt__(), or __ge__(), then
TypeError is raised.

unsafe_hash: If False (the default), a __hash__() method
is generated according to how eq and frozen are set.
__hash__() is used by built-in hash(), and when objects are
added to hashed collections such as dictionaries and sets.  Having a
__hash__() implies that instances of the class are immutable.
Mutability is a complicated property that depends on the programmer’s
intent, the existence and behavior of __eq__(), and the values of
the eq and frozen flags in the dataclass() decorator.
By default, dataclass() will not implicitly add a __hash__()
method unless it is safe to do so.  Neither will it add or change an
existing explicitly defined __hash__() method.  Setting the class
attribute __hash__ = None has a specific meaning to Python, as
described in the __hash__() documentation.
If __hash__() is not explicit defined, or if it is set to None,
then dataclass() may add an implicit __hash__() method.
Although not recommended, you can force dataclass() to create a
__hash__() method with unsafe_hash=True. This might be the case
if your class is logically immutable but can nonetheless be mutated.
This is a specialized use case and should be considered carefully.
Here are the rules governing implicit creation of a __hash__()
method.  Note that you cannot both have an explicit __hash__()
method in your dataclass and set unsafe_hash=True; this will result
in a TypeError.
If eq and frozen are both true, by default dataclass() will
generate a __hash__() method for you.  If eq is true and
frozen is false, __hash__() will be set to None, marking it
unhashable (which it is, since it is mutable).  If eq is false,
__hash__() will be left untouched meaning the __hash__()
method of the superclass will be used (if the superclass is
object, this means it will fall back to id-based hashing).

frozen: If true (the default is False), assigning to fields will
generate an exception.  This emulates read-only frozen instances.  If
__setattr__() or __delattr__() is defined in the class, then
TypeError is raised.  See the discussion below.

fields may optionally specify a default value, using normal
Python syntax:
@dataclass
class C:
    a: int       # 'a' has no default value
    b: int = 0   # assign a default value for 'b'


In this example, both a and b will be included in the added
__init__() method, which will be defined as:
def __init__(self, a: int, b: int = 0):


TypeError will be raised if a field without a default value
follows a field with a default value.  This is true either when this
occurs in a single class, or as a result of class inheritance."
"dataclasses.field(*, default=MISSING, default_factory=MISSING, repr=True, hash=None, init=True, compare=True, metadata=None)","For common and simple use cases, no other functionality is
required.  There are, however, some dataclass features that
require additional per-field information.  To satisfy this need for
additional information, you can replace the default field value
with a call to the provided field() function.  For example:
@dataclass
class C:
    mylist: List[int] = field(default_factory=list)

c = C()
c.mylist += [1, 2, 3]


As shown above, the MISSING value is a sentinel object used to
detect if the default and default_factory parameters are
provided.  This sentinel is used because None is a valid value
for default.  No code should directly use the MISSING
value.
The parameters to field() are:

default: If provided, this will be the default value for this
field.  This is needed because the field() call itself
replaces the normal position of the default value.
default_factory: If provided, it must be a zero-argument
callable that will be called when a default value is needed for
this field.  Among other purposes, this can be used to specify
fields with mutable default values, as discussed below.  It is an
error to specify both default and default_factory.
init: If true (the default), this field is included as a
parameter to the generated __init__() method.
repr: If true (the default), this field is included in the
string returned by the generated __repr__() method.
compare: If true (the default), this field is included in the
generated equality and comparison methods (__eq__(),
__gt__(), et al.).
hash: This can be a bool or None.  If true, this field is
included in the generated __hash__() method.  If None (the
default), use the value of compare: this would normally be
the expected behavior.  A field should be considered in the hash
if it’s used for comparisons.  Setting this value to anything
other than None is discouraged.
One possible reason to set hash=False but compare=True
would be if a field is expensive to compute a hash value for,
that field is needed for equality testing, and there are other
fields that contribute to the type’s hash value.  Even if a field
is excluded from the hash, it will still be used for comparisons.

metadata: This can be a mapping or None. None is treated as
an empty dict.  This value is wrapped in
MappingProxyType() to make it read-only, and exposed
on the Field object. It is not used at all by Data
Classes, and is provided as a third-party extension mechanism.
Multiple third-parties can each have their own key, to use as a
namespace in the metadata.

If the default value of a field is specified by a call to
field(), then the class attribute for this field will be
replaced by the specified default value.  If no default is
provided, then the class attribute will be deleted.  The intent is
that after the dataclass() decorator runs, the class
attributes will all contain the default values for the fields, just
as if the default value itself were specified.  For example,
after:
@dataclass
class C:
    x: int
    y: int = field(repr=False)
    z: int = field(repr=False, default=10)
    t: int = 20


The class attribute C.z will be 10, the class attribute
C.t will be 20, and the class attributes C.x and
C.y will not be set."
dataclasses.fields(class_or_instance),"Returns a tuple of Field objects that define the fields for this
dataclass.  Accepts either a dataclass, or an instance of a dataclass.
Raises TypeError if not passed a dataclass or instance of one.
Does not return pseudo-fields which are ClassVar or InitVar."
"dataclasses.asdict(instance, *, dict_factory=dict)","Converts the dataclass instance to a dict (by using the
factory function dict_factory).  Each dataclass is converted
to a dict of its fields, as name: value pairs.  dataclasses, dicts,
lists, and tuples are recursed into.  For example:
@dataclass
class Point:
     x: int
     y: int

@dataclass
class C:
     mylist: List[Point]

p = Point(10, 20)
assert asdict(p) == {'x': 10, 'y': 20}

c = C([Point(0, 0), Point(10, 4)])
assert asdict(c) == {'mylist': [{'x': 0, 'y': 0}, {'x': 10, 'y': 4}]}


Raises TypeError if instance is not a dataclass instance."
"dataclasses.astuple(instance, *, tuple_factory=tuple)","Converts the dataclass instance to a tuple (by using the
factory function tuple_factory).  Each dataclass is converted
to a tuple of its field values.  dataclasses, dicts, lists, and
tuples are recursed into.
Continuing from the previous example:
assert astuple(p) == (10, 20)
assert astuple(c) == ([(0, 0), (10, 4)],)


Raises TypeError if instance is not a dataclass instance."
"dataclasses.make_dataclass(cls_name, fields, *, bases=(), namespace=None, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False)","Creates a new dataclass with name cls_name, fields as defined
in fields, base classes as given in bases, and initialized
with a namespace as given in namespace.  fields is an
iterable whose elements are each either name, (name, type),
or (name, type, Field).  If just name is supplied,
typing.Any is used for type.  The values of init,
repr, eq, order, unsafe_hash, and frozen have
the same meaning as they do in dataclass().
This function is not strictly required, because any Python
mechanism for creating a new class with __annotations__ can
then apply the dataclass() function to convert that class to
a dataclass.  This function is provided as a convenience.  For
example:
C = make_dataclass('C',
                   [('x', int),
                     'y',
                    ('z', int, field(default=5))],
                   namespace={'add_one': lambda self: self.x + 1})


Is equivalent to:
@dataclass
class C:
    x: int
    y: 'typing.Any'
    z: int = 5

    def add_one(self):
        return self.x + 1"
"dataclasses.replace(instance, **changes)","Creates a new object of the same type of instance, replacing
fields with values from changes.  If instance is not a Data
Class, raises TypeError.  If values in changes do not
specify fields, raises TypeError.
The newly returned object is created by calling the __init__()
method of the dataclass.  This ensures that
__post_init__(), if present, is also called.
Init-only variables without default values, if any exist, must be
specified on the call to replace() so that they can be passed to
__init__() and __post_init__().
It is an error for changes to contain any fields that are
defined as having init=False.  A ValueError will be raised
in this case.
Be forewarned about how init=False fields work during a call to
replace().  They are not copied from the source object, but
rather are initialized in __post_init__(), if they’re
initialized at all.  It is expected that init=False fields will
be rarely and judiciously used.  If they are used, it might be wise
to have alternate class constructors, or perhaps a custom
replace() (or similarly named) method which handles instance
copying."
dataclasses.is_dataclass(class_or_instance),"Return True if its parameter is a dataclass or an instance of one,
otherwise return False.
If you need to know if a class is an instance of a dataclass (and
not a dataclass itself), then add a further check for not
isinstance(obj, type):
def is_dataclass_instance(obj):
    return is_dataclass(obj) and not isinstance(obj, type)"
@contextlib.contextmanager,"This function is a decorator that can be used to define a factory
function for with statement context managers, without needing to
create a class or separate __enter__() and __exit__() methods.
While many objects natively support use in with statements, sometimes a
resource needs to be managed that isn’t a context manager in its own right,
and doesn’t implement a close() method for use with contextlib.closing
An abstract example would be the following to ensure correct resource
management:
from contextlib import contextmanager

@contextmanager
def managed_resource(*args, **kwds):
    # Code to acquire resource, e.g.:
    resource = acquire_resource(*args, **kwds)
    try:
        yield resource
    finally:
        # Code to release resource, e.g.:
        release_resource(resource)

>>> with managed_resource(timeout=3600) as resource:
...     # Resource is released at the end of this block,
...     # even if code in the block raises an exception


The function being decorated must return a generator-iterator when
called. This iterator must yield exactly one value, which will be bound to
the targets in the with statement’s as clause, if any.
At the point where the generator yields, the block nested in the with
statement is executed.  The generator is then resumed after the block is exited.
If an unhandled exception occurs in the block, it is reraised inside the
generator at the point where the yield occurred.  Thus, you can use a
try…except…finally statement to trap
the error (if any), or ensure that some cleanup takes place. If an exception is
trapped merely in order to log it or to perform some action (rather than to
suppress it entirely), the generator must reraise that exception. Otherwise the
generator context manager will indicate to the with statement that
the exception has been handled, and execution will resume with the statement
immediately following the with statement.
contextmanager() uses ContextDecorator so the context managers
it creates can be used as decorators as well as in with statements.
When used as a decorator, a new generator instance is implicitly created on
each function call (this allows the otherwise “one-shot” context managers
created by contextmanager() to meet the requirement that context
managers support multiple invocations in order to be used as decorators).

Changed in version 3.2: Use of ContextDecorator."
@contextlib.asynccontextmanager,"Similar to contextmanager(), but creates an
asynchronous context manager.
This function is a decorator that can be used to define a factory
function for async with statement asynchronous context managers,
without needing to create a class or separate __aenter__() and
__aexit__() methods. It must be applied to an asynchronous
generator function.
A simple example:
from contextlib import asynccontextmanager

@asynccontextmanager
async def get_connection():
    conn = await acquire_db_connection()
    try:
        yield conn
    finally:
        await release_db_connection(conn)

async def get_all_users():
    async with get_connection() as conn:
        return conn.query('SELECT ...')



New in version 3.7."
contextlib.closing(thing),"Return a context manager that closes thing upon completion of the block.  This
is basically equivalent to:
from contextlib import contextmanager

@contextmanager
def closing(thing):
    try:
        yield thing
    finally:
        thing.close()


And lets you write code like this:
from contextlib import closing
from urllib.request import urlopen

with closing(urlopen('http://www.python.org')) as page:
    for line in page:
        print(line)


without needing to explicitly close page.  Even if an error occurs,
page.close() will be called when the with block is exited."
contextlib.nullcontext(enter_result=None),"Return a context manager that returns enter_result from __enter__, but
otherwise does nothing. It is intended to be used as a stand-in for an
optional context manager, for example:
def myfunction(arg, ignore_exceptions=False):
    if ignore_exceptions:
        # Use suppress to ignore all exceptions.
        cm = contextlib.suppress(Exception)
    else:
        # Do not ignore any exceptions, cm has no effect.
        cm = contextlib.nullcontext()
    with cm:
        # Do something


An example using enter_result:
def process_file(file_or_path):
    if isinstance(file_or_path, str):
        # If string, open file
        cm = open(file_or_path)
    else:
        # Caller is responsible for closing file
        cm = nullcontext(file_or_path)

    with cm as file:
        # Perform processing on the file



New in version 3.7."
contextlib.suppress(*exceptions),"Return a context manager that suppresses any of the specified exceptions
if they occur in the body of a with statement and then resumes execution
with the first statement following the end of the with statement.
As with any other mechanism that completely suppresses exceptions, this
context manager should be used only to cover very specific errors where
silently continuing with program execution is known to be the right
thing to do.
For example:
from contextlib import suppress

with suppress(FileNotFoundError):
    os.remove('somefile.tmp')

with suppress(FileNotFoundError):
    os.remove('someotherfile.tmp')


This code is equivalent to:
try:
    os.remove('somefile.tmp')
except FileNotFoundError:
    pass

try:
    os.remove('someotherfile.tmp')
except FileNotFoundError:
    pass


This context manager is reentrant.

New in version 3.4."
contextlib.redirect_stdout(new_target),"Context manager for temporarily redirecting sys.stdout to
another file or file-like object.
This tool adds flexibility to existing functions or classes whose output
is hardwired to stdout.
For example, the output of help() normally is sent to sys.stdout.
You can capture that output in a string by redirecting the output to an
io.StringIO object:
f = io.StringIO()
with redirect_stdout(f):
    help(pow)
s = f.getvalue()


To send the output of help() to a file on disk, redirect the output
to a regular file:
with open('help.txt', 'w') as f:
    with redirect_stdout(f):
        help(pow)


To send the output of help() to sys.stderr:
with redirect_stdout(sys.stderr):
    help(pow)


Note that the global side effect on sys.stdout means that this
context manager is not suitable for use in library code and most threaded
applications. It also has no effect on the output of subprocesses.
However, it is still a useful approach for many utility scripts.
This context manager is reentrant.

New in version 3.4."
contextlib.redirect_stderr(new_target),"Similar to redirect_stdout() but redirecting
sys.stderr to another file or file-like object.
This context manager is reentrant.

New in version 3.5."
enter_context(cm),"Enters a new context manager and adds its __exit__() method to
the callback stack. The return value is the result of the context
manager’s own __enter__() method.
These context managers may suppress exceptions just as they normally
would if used directly as part of a with statement."
push(exit),"Adds a context manager’s __exit__() method to the callback stack.
As __enter__ is not invoked, this method can be used to cover
part of an __enter__() implementation with a context manager’s own
__exit__() method.
If passed an object that is not a context manager, this method assumes
it is a callback with the same signature as a context manager’s
__exit__() method and adds it directly to the callback stack.
By returning true values, these callbacks can suppress exceptions the
same way context manager __exit__() methods can.
The passed in object is returned from the function, allowing this
method to be used as a function decorator."
"callback(callback, *args, **kwds)","Accepts an arbitrary callback function and arguments and adds it to
the callback stack.
Unlike the other methods, callbacks added this way cannot suppress
exceptions (as they are never passed the exception details).
The passed in callback is returned from the function, allowing this
method to be used as a function decorator."
pop_all(),"Transfers the callback stack to a fresh ExitStack instance
and returns it. No callbacks are invoked by this operation - instead,
they will now be invoked when the new stack is closed (either
explicitly or implicitly at the end of a with statement).
For example, a group of files can be opened as an “all or nothing”
operation as follows:
with ExitStack() as stack:
    files = [stack.enter_context(open(fname)) for fname in filenames]
    # Hold onto the close method, but don't call it yet.
    close_files = stack.pop_all().close
    # If opening any file fails, all previously opened files will be
    # closed automatically. If all files are opened successfully,
    # they will remain open even after the with statement ends.
    # close_files() can then be invoked explicitly to close them all."
close(),"Immediately unwinds the callback stack, invoking callbacks in the
reverse order of registration. For any context managers and exit
callbacks registered, the arguments passed in will indicate that no
exception occurred."
enter_async_context(cm),"Similar to enter_context() but expects an asynchronous context
manager."
push_async_exit(exit),"Similar to push() but expects either an asynchronous context manager
or a coroutine function."
"push_async_callback(callback, *args, **kwds)",Similar to callback() but expects a coroutine function.
aclose(),Similar to close() but properly handles awaitables.
@abc.abstractmethod,"A decorator indicating abstract methods.
Using this decorator requires that the class’s metaclass is ABCMeta
or is derived from it.  A class that has a metaclass derived from
ABCMeta cannot be instantiated unless all of its abstract methods
and properties are overridden.  The abstract methods can be called using any
of the normal ‘super’ call mechanisms.  abstractmethod() may be used
to declare abstract methods for properties and descriptors.
Dynamically adding abstract methods to a class, or attempting to modify the
abstraction status of a method or class once it is created, are not
supported.  The abstractmethod() only affects subclasses derived using
regular inheritance; “virtual subclasses” registered with the ABC’s
register() method are not affected.
When abstractmethod() is applied in combination with other method
descriptors, it should be applied as the innermost decorator, as shown in
the following usage examples:
class C(ABC):
    @abstractmethod
    def my_abstract_method(self, ...):
        ...
    @classmethod
    @abstractmethod
    def my_abstract_classmethod(cls, ...):
        ...
    @staticmethod
    @abstractmethod
    def my_abstract_staticmethod(...):
        ...

    @property
    @abstractmethod
    def my_abstract_property(self):
        ...
    @my_abstract_property.setter
    @abstractmethod
    def my_abstract_property(self, val):
        ...

    @abstractmethod
    def _get_x(self):
        ...
    @abstractmethod
    def _set_x(self, val):
        ...
    x = property(_get_x, _set_x)


In order to correctly interoperate with the abstract base class machinery,
the descriptor must identify itself as abstract using
__isabstractmethod__. In general, this attribute should be True
if any of the methods used to compose the descriptor are abstract. For
example, Python’s built-in property does the equivalent of:
class Descriptor:
    ...
    @property
    def __isabstractmethod__(self):
        return any(getattr(f, '__isabstractmethod__', False) for
                   f in (self._fget, self._fset, self._fdel))



Note
Unlike Java abstract methods, these abstract
methods may have an implementation. This implementation can be
called via the super() mechanism from the class that
overrides it.  This could be useful as an end-point for a
super-call in a framework that uses cooperative
multiple-inheritance."
@abc.abstractclassmethod,"New in version 3.2.


Deprecated since version 3.3: It is now possible to use classmethod with
abstractmethod(), making this decorator redundant.

A subclass of the built-in classmethod(), indicating an abstract
classmethod. Otherwise it is similar to abstractmethod().
This special case is deprecated, as the classmethod() decorator
is now correctly identified as abstract when applied to an abstract
method:
class C(ABC):
    @classmethod
    @abstractmethod
    def my_abstract_classmethod(cls, ...):
        ..."
@abc.abstractstaticmethod,"New in version 3.2.


Deprecated since version 3.3: It is now possible to use staticmethod with
abstractmethod(), making this decorator redundant.

A subclass of the built-in staticmethod(), indicating an abstract
staticmethod. Otherwise it is similar to abstractmethod().
This special case is deprecated, as the staticmethod() decorator
is now correctly identified as abstract when applied to an abstract
method:
class C(ABC):
    @staticmethod
    @abstractmethod
    def my_abstract_staticmethod(...):
        ..."
@abc.abstractproperty,"Deprecated since version 3.3: It is now possible to use property, property.getter(),
property.setter() and property.deleter() with
abstractmethod(), making this decorator redundant.

A subclass of the built-in property(), indicating an abstract
property.
This special case is deprecated, as the property() decorator
is now correctly identified as abstract when applied to an abstract
method:
class C(ABC):
    @property
    @abstractmethod
    def my_abstract_property(self):
        ...


The above example defines a read-only property; you can also define a
read-write abstract property by appropriately marking one or more of the
underlying methods as abstract:
class C(ABC):
    @property
    def x(self):
        ...

    @x.setter
    @abstractmethod
    def x(self, val):
        ...


If only some components are abstract, only those components need to be
updated to create a concrete property in a subclass:
class D(C):
    @C.x.setter
    def x(self, val):
        ..."
abc.get_cache_token(),"Returns the current abstract base class cache token.
The token is an opaque object (that supports equality testing) identifying
the current version of the abstract base class cache for virtual subclasses.
The token changes with every call to ABCMeta.register() on any ABC.

New in version 3.4."
register(subclass),"Register subclass as a “virtual subclass” of this ABC. For
example:
from abc import ABC

class MyABC(ABC):
    pass

MyABC.register(tuple)

assert issubclass(tuple, MyABC)
assert isinstance((), MyABC)



Changed in version 3.3: Returns the registered subclass, to allow usage as a class decorator.


Changed in version 3.4: To detect calls to register(), you can use the
get_cache_token() function."
__subclasshook__(subclass),"(Must be defined as a class method.)
Check whether subclass is considered a subclass of this ABC.  This means
that you can customize the behavior of issubclass further without the
need to call register() on every class you want to consider a
subclass of the ABC.  (This class method is called from the
__subclasscheck__() method of the ABC.)
This method should return True, False or NotImplemented.  If
it returns True, the subclass is considered a subclass of this ABC.
If it returns False, the subclass is not considered a subclass of
this ABC, even if it would normally be one.  If it returns
NotImplemented, the subclass check is continued with the usual
mechanism."
"atexit.register(func, *args, **kwargs)","Register func as a function to be executed at termination.  Any optional
arguments that are to be passed to func must be passed as arguments to
register().  It is possible to register the same function and arguments
more than once.
At normal program termination (for instance, if sys.exit() is called or
the main module’s execution completes), all functions registered are called in
last in, first out order.  The assumption is that lower level modules will
normally be imported before higher level modules and thus must be cleaned up
later.
If an exception is raised during execution of the exit handlers, a traceback is
printed (unless SystemExit is raised) and the exception information is
saved.  After all exit handlers have had a chance to run the last exception to
be raised is re-raised.
This function returns func, which makes it possible to use it as a
decorator."
atexit.unregister(func),"Remove func from the list of functions to be run at interpreter
shutdown.  After calling unregister(), func is guaranteed not to be
called when the interpreter shuts down, even if it was registered more than
once.  unregister() silently does nothing if func was not previously
registered."
"traceback.print_tb(tb, limit=None, file=None)","Print up to limit stack trace entries from traceback object tb (starting
from the caller’s frame) if limit is positive.  Otherwise, print the last
abs(limit) entries.  If limit is omitted or None, all entries are
printed.  If file is omitted or None, the output goes to
sys.stderr; otherwise it should be an open file or file-like object to
receive the output.

Changed in version 3.5: Added negative limit support."
"traceback.print_exception(etype, value, tb, limit=None, file=None, chain=True)","Print exception information and stack trace entries from traceback object
tb to file. This differs from print_tb() in the following
ways:

if tb is not None, it prints a header Traceback (most recent
call last):
it prints the exception etype and value after the stack trace


if type(value) is SyntaxError and value has the appropriate
format, it prints the line where the syntax error occurred with a caret
indicating the approximate position of the error.

The optional limit argument has the same meaning as for print_tb().
If chain is true (the default), then chained exceptions (the
__cause__ or __context__ attributes of the exception) will be
printed as well, like the interpreter itself does when printing an unhandled
exception.

Changed in version 3.5: The etype argument is ignored and inferred from the type of value."
"traceback.print_exc(limit=None, file=None, chain=True)","This is a shorthand for print_exception(*sys.exc_info(), limit, file,
chain)."
"traceback.print_last(limit=None, file=None, chain=True)","This is a shorthand for print_exception(sys.last_type, sys.last_value,
sys.last_traceback, limit, file, chain).  In general it will work only
after an exception has reached an interactive prompt (see
sys.last_type)."
"traceback.print_stack(f=None, limit=None, file=None)","Print up to limit stack trace entries (starting from the invocation
point) if limit is positive.  Otherwise, print the last abs(limit)
entries.  If limit is omitted or None, all entries are printed.
The optional f argument can be used to specify an alternate stack frame
to start.  The optional file argument has the same meaning as for
print_tb().

Changed in version 3.5: Added negative limit support."
"traceback.extract_tb(tb, limit=None)","Return a StackSummary object representing a list of “pre-processed”
stack trace entries extracted from the traceback object tb.  It is useful
for alternate formatting of stack traces.  The optional limit argument has
the same meaning as for print_tb().  A “pre-processed” stack trace
entry is a FrameSummary object containing attributes
filename, lineno,
name, and line representing the
information that is usually printed for a stack trace.  The
line is a string with leading and trailing
whitespace stripped; if the source is not available it is None."
"traceback.extract_stack(f=None, limit=None)","Extract the raw traceback from the current stack frame.  The return value has
the same format as for extract_tb().  The optional f and limit
arguments have the same meaning as for print_stack()."
traceback.format_list(extracted_list),"Given a list of tuples or FrameSummary objects as returned by
extract_tb() or extract_stack(), return a list of strings ready
for printing.  Each string in the resulting list corresponds to the item with
the same index in the argument list.  Each string ends in a newline; the
strings may contain internal newlines as well, for those items whose source
text line is not None."
"traceback.format_exception_only(etype, value)","Format the exception part of a traceback.  The arguments are the exception
type and value such as given by sys.last_type and sys.last_value.
The return value is a list of strings, each ending in a newline.  Normally,
the list contains a single string; however, for SyntaxError
exceptions, it contains several lines that (when printed) display detailed
information about where the syntax error occurred.  The message indicating
which exception occurred is the always last string in the list."
"traceback.format_exception(etype, value, tb, limit=None, chain=True)","Format a stack trace and the exception information.  The arguments  have the
same meaning as the corresponding arguments to print_exception().  The
return value is a list of strings, each ending in a newline and some
containing internal newlines.  When these lines are concatenated and printed,
exactly the same text is printed as does print_exception().

Changed in version 3.5: The etype argument is ignored and inferred from the type of value."
"traceback.format_exc(limit=None, chain=True)","This is like print_exc(limit) but returns a string instead of printing to
a file."
"traceback.format_tb(tb, limit=None)","A shorthand for format_list(extract_tb(tb, limit))."
"traceback.format_stack(f=None, limit=None)","A shorthand for format_list(extract_stack(f, limit))."
traceback.clear_frames(tb),"Clears the local variables of all the stack frames in a traceback tb
by calling the clear() method of each frame object.

New in version 3.4."
traceback.walk_stack(f),"Walk a stack following f.f_back from the given frame, yielding the frame
and line number for each frame. If f is None, the current stack is
used. This helper is used with StackSummary.extract().

New in version 3.5."
traceback.walk_tb(tb),"Walk a traceback following tb_next yielding the frame and line number
for each frame. This helper is used with StackSummary.extract().

New in version 3.5."
"classmethod from_exception(exc, *, limit=None, lookup_lines=True, capture_locals=False)","Capture an exception for later rendering. limit, lookup_lines and
capture_locals are as for the StackSummary class.
Note that when locals are captured, they are also shown in the traceback."
"format(*, chain=True)","Format the exception.
If chain is not True, __cause__ and __context__ will not
be formatted.
The return value is a generator of strings, each ending in a newline and
some containing internal newlines. print_exception()
is a wrapper around this method which just prints the lines to a file.
The message indicating which exception occurred is always the last
string in the output."
format_exception_only(),"Format the exception part of the traceback.
The return value is a generator of strings, each ending in a newline.
Normally, the generator emits a single string; however, for
SyntaxError exceptions, it emits several lines that (when
printed) display detailed information about where the syntax
error occurred.
The message indicating which exception occurred is always the last
string in the output."
"classmethod extract(frame_gen, *, limit=None, lookup_lines=True, capture_locals=False)","Construct a StackSummary object from a frame generator (such as
is returned by walk_stack() or
walk_tb()).
If limit is supplied, only this many frames are taken from frame_gen.
If lookup_lines is False, the returned FrameSummary
objects will not have read their lines in yet, making the cost of
creating the StackSummary cheaper (which may be valuable if it
may not actually get formatted). If capture_locals is True the
local variables in each FrameSummary are captured as object
representations."
classmethod from_list(a_list),"Construct a StackSummary object from a supplied list of
FrameSummary objects or old-style list of tuples.  Each tuple
should be a 4-tuple with filename, lineno, name, line as the elements."
format(),"Returns a list of strings ready for printing.  Each string in the
resulting list corresponds to a single frame from the stack.
Each string ends in a newline; the strings may contain internal
newlines as well, for those items with source text lines.
For long sequences of the same frame and line, the first few
repetitions are shown, followed by a summary line stating the exact
number of further repetitions.

Changed in version 3.6: Long sequences of repeated frames are now abbreviated."
gc.enable(),Enable automatic garbage collection.
gc.disable(),Disable automatic garbage collection.
gc.isenabled(),Return True if automatic collection is enabled.
gc.collect(generation=2),"With no arguments, run a full collection.  The optional argument generation
may be an integer specifying which generation to collect (from 0 to 2).  A
ValueError is raised if the generation number  is invalid. The number of
unreachable objects found is returned.
The free lists maintained for a number of built-in types are cleared
whenever a full collection or collection of the highest generation (2)
is run.  Not all items in some free lists may be freed due to the
particular implementation, in particular float."
gc.set_debug(flags),"Set the garbage collection debugging flags. Debugging information will be
written to sys.stderr.  See below for a list of debugging flags which can be
combined using bit operations to control debugging."
gc.get_debug(),Return the debugging flags currently set.
gc.get_objects(generation=None),"Returns a list of all objects tracked by the collector, excluding the list
returned. If generation is not None, return only the objects tracked by
the collector that are in that generation.

Changed in version 3.8: New generation parameter."
gc.get_stats(),"Return a list of three per-generation dictionaries containing collection
statistics since interpreter start.  The number of keys may change
in the future, but currently each dictionary will contain the following
items:

collections is the number of times this generation was collected;
collected is the total number of objects collected inside this
generation;
uncollectable is the total number of objects which were found
to be uncollectable (and were therefore moved to the garbage
list) inside this generation.


New in version 3.4."
"gc.set_threshold(threshold0[, threshold1[, threshold2]])","Set the garbage collection thresholds (the collection frequency). Setting
threshold0 to zero disables collection.
The GC classifies objects into three generations depending on how many
collection sweeps they have survived.  New objects are placed in the youngest
generation (generation 0).  If an object survives a collection it is moved
into the next older generation.  Since generation 2 is the oldest
generation, objects in that generation remain there after a collection.  In
order to decide when to run, the collector keeps track of the number object
allocations and deallocations since the last collection.  When the number of
allocations minus the number of deallocations exceeds threshold0, collection
starts.  Initially only generation 0 is examined.  If generation 0 has
been examined more than threshold1 times since generation 1 has been
examined, then generation 1 is examined as well.  Similarly, threshold2
controls the number of collections of generation 1 before collecting
generation 2."
gc.get_count(),"Return the current collection  counts as a tuple of (count0, count1,
count2)."
gc.get_threshold(),"Return the current collection thresholds as a tuple of (threshold0,
threshold1, threshold2)."
gc.get_referrers(*objs),"Return the list of objects that directly refer to any of objs. This function
will only locate those containers which support garbage collection; extension
types which do refer to other objects but do not support garbage collection will
not be found.
Note that objects which have already been dereferenced, but which live in cycles
and have not yet been collected by the garbage collector can be listed among the
resulting referrers.  To get only currently live objects, call collect()
before calling get_referrers().
Care must be taken when using objects returned by get_referrers() because
some of them could still be under construction and hence in a temporarily
invalid state. Avoid using get_referrers() for any purpose other than
debugging."
gc.get_referents(*objs),"Return a list of objects directly referred to by any of the arguments. The
referents returned are those objects visited by the arguments’ C-level
tp_traverse methods (if any), and may not be all objects actually
directly reachable.  tp_traverse methods are supported only by objects
that support garbage collection, and are only required to visit objects that may
be involved in a cycle.  So, for example, if an integer is directly reachable
from an argument, that integer object may or may not appear in the result list."
gc.is_tracked(obj),"Returns True if the object is currently tracked by the garbage collector,
False otherwise.  As a general rule, instances of atomic types aren’t
tracked and instances of non-atomic types (containers, user-defined
objects…) are.  However, some type-specific optimizations can be present
in order to suppress the garbage collector footprint of simple instances
(e.g. dicts containing only atomic keys and values):
>>> gc.is_tracked(0)
False
>>> gc.is_tracked(""a"")
False
>>> gc.is_tracked([])
True
>>> gc.is_tracked({})
False
>>> gc.is_tracked({""a"": 1})
False
>>> gc.is_tracked({""a"": []})
True



New in version 3.1."
gc.freeze(),"Freeze all the objects tracked by gc - move them to a permanent generation
and ignore all the future collections. This can be used before a POSIX
fork() call to make the gc copy-on-write friendly or to speed up collection.
Also collection before a POSIX fork() call may free pages for future
allocation which can cause copy-on-write too so it’s advised to disable gc
in parent process and freeze before fork and enable gc in child process.

New in version 3.7."
gc.unfreeze(),"Unfreeze the objects in the permanent generation, put them back into the
oldest generation.

New in version 3.7."
gc.get_freeze_count(),"Return the number of objects in the permanent generation.

New in version 3.7."
"inspect.getmembers(object[, predicate])","Return all the members of an object in a list of (name, value)
pairs sorted by name. If the optional predicate argument—which will be
called with the value object of each member—is supplied, only members
for which the predicate returns a true value are included.

Note
getmembers() will only return class attributes defined in the
metaclass when the argument is a class and those attributes have been
listed in the metaclass’ custom __dir__()."
inspect.getmodulename(path),"Return the name of the module named by the file path, without including the
names of enclosing packages. The file extension is checked against all of
the entries in importlib.machinery.all_suffixes(). If it matches,
the final path component is returned with the extension removed.
Otherwise, None is returned.
Note that this function only returns a meaningful name for actual
Python modules - paths that potentially refer to Python packages will
still return None.

Changed in version 3.3: The function is based directly on importlib."
inspect.ismodule(object),Return True if the object is a module.
inspect.isclass(object),"Return True if the object is a class, whether built-in or created in Python
code."
inspect.ismethod(object),Return True if the object is a bound method written in Python.
inspect.isfunction(object),"Return True if the object is a Python function, which includes functions
created by a lambda expression."
inspect.isgeneratorfunction(object),"Return True if the object is a Python generator function.

Changed in version 3.8: Functions wrapped in functools.partial() now return True if the
wrapped function is a Python generator function."
inspect.isgenerator(object),Return True if the object is a generator.
inspect.iscoroutinefunction(object),"Return True if the object is a coroutine function
(a function defined with an async def syntax).

New in version 3.5.


Changed in version 3.8: Functions wrapped in functools.partial() now return True if the
wrapped function is a coroutine function."
inspect.iscoroutine(object),"Return True if the object is a coroutine created by an
async def function.

New in version 3.5."
inspect.isawaitable(object),"Return True if the object can be used in await expression.
Can also be used to distinguish generator-based coroutines from regular
generators:
def gen():
    yield
@types.coroutine
def gen_coro():
    yield

assert not isawaitable(gen())
assert isawaitable(gen_coro())



New in version 3.5."
inspect.isasyncgenfunction(object),"Return True if the object is an asynchronous generator function,
for example:
>>> async def agen():
...     yield 1
...
>>> inspect.isasyncgenfunction(agen)
True



New in version 3.6.


Changed in version 3.8: Functions wrapped in functools.partial() now return True if the
wrapped function is a asynchronous generator function."
inspect.isasyncgen(object),"Return True if the object is an asynchronous generator iterator
created by an asynchronous generator function.

New in version 3.6."
inspect.istraceback(object),Return True if the object is a traceback.
inspect.isframe(object),Return True if the object is a frame.
inspect.iscode(object),Return True if the object is a code.
inspect.isbuiltin(object),Return True if the object is a built-in function or a bound built-in method.
inspect.isroutine(object),Return True if the object is a user-defined or built-in function or method.
inspect.isabstract(object),Return True if the object is an abstract base class.
inspect.ismethoddescriptor(object),"Return True if the object is a method descriptor, but not if
ismethod(), isclass(), isfunction() or isbuiltin()
are true.
This, for example, is true of int.__add__.  An object passing this test
has a __get__() method but not a __set__()
method, but beyond that the set of attributes varies.  A
__name__ attribute is usually
sensible, and __doc__ often is.
Methods implemented via descriptors that also pass one of the other tests
return False from the ismethoddescriptor() test, simply because the
other tests promise more – you can, e.g., count on having the
__func__ attribute (etc) when an object passes ismethod()."
inspect.isdatadescriptor(object),"Return True if the object is a data descriptor.
Data descriptors have a __set__ or a __delete__ method.
Examples are properties (defined in Python), getsets, and members.  The
latter two are defined in C and there are more specific tests available for
those types, which is robust across Python implementations.  Typically, data
descriptors will also have __name__ and __doc__ attributes
(properties, getsets, and members have both of these attributes), but this is
not guaranteed."
inspect.isgetsetdescriptor(object),"Return True if the object is a getset descriptor.

CPython implementation detail: getsets are attributes defined in extension modules via
PyGetSetDef structures.  For Python implementations without such
types, this method will always return False."
inspect.ismemberdescriptor(object),"Return True if the object is a member descriptor.

CPython implementation detail: Member descriptors are attributes defined in extension modules via
PyMemberDef structures.  For Python implementations without such
types, this method will always return False."
inspect.getdoc(object),"Get the documentation string for an object, cleaned up with cleandoc().
If the documentation string for an object is not provided and the object is
a class, a method, a property or a descriptor, retrieve the documentation
string from the inheritance hierarchy.

Changed in version 3.5: Documentation strings are now inherited if not overridden."
inspect.getcomments(object),"Return in a single string any lines of comments immediately preceding the
object’s source code (for a class, function, or method), or at the top of the
Python source file (if the object is a module).  If the object’s source code
is unavailable, return None.  This could happen if the object has been
defined in C or the interactive shell."
inspect.getfile(object),"Return the name of the (text or binary) file in which an object was defined.
This will fail with a TypeError if the object is a built-in module,
class, or function."
inspect.getmodule(object),Try to guess which module an object was defined in.
inspect.getsourcefile(object),"Return the name of the Python source file in which an object was defined.  This
will fail with a TypeError if the object is a built-in module, class, or
function."
inspect.getsourcelines(object),"Return a list of source lines and starting line number for an object. The
argument may be a module, class, method, function, traceback, frame, or code
object.  The source code is returned as a list of the lines corresponding to the
object and the line number indicates where in the original source file the first
line of code was found.  An OSError is raised if the source code cannot
be retrieved.

Changed in version 3.3: OSError is raised instead of IOError, now an alias of the
former."
inspect.getsource(object),"Return the text of the source code for an object. The argument may be a module,
class, method, function, traceback, frame, or code object.  The source code is
returned as a single string.  An OSError is raised if the source code
cannot be retrieved.

Changed in version 3.3: OSError is raised instead of IOError, now an alias of the
former."
inspect.cleandoc(doc),"Clean up indentation from docstrings that are indented to line up with blocks
of code.
All leading whitespace is removed from the first line.  Any leading whitespace
that can be uniformly removed from the second line onwards is removed.  Empty
lines at the beginning and end are subsequently removed.  Also, all tabs are
expanded to spaces."
"inspect.signature(callable, *, follow_wrapped=True)","Return a Signature object for the given callable:
>>> from inspect import signature
>>> def foo(a, *, b:int, **kwargs):
...     pass

>>> sig = signature(foo)

>>> str(sig)
'(a, *, b:int, **kwargs)'

>>> str(sig.parameters['b'])
'b:int'

>>> sig.parameters['b'].annotation
<class 'int'>


Accepts a wide range of Python callables, from plain functions and classes to
functools.partial() objects.
Raises ValueError if no signature can be provided, and
TypeError if that type of object is not supported.
A slash(/) in the signature of a function denotes that the parameters prior
to it are positional-only. For more info, see
the FAQ entry on positional-only parameters.

New in version 3.5: follow_wrapped parameter. Pass False to get a signature of
callable specifically (callable.__wrapped__ will not be used to
unwrap decorated callables.)


Note
Some callables may not be introspectable in certain implementations of
Python.  For example, in CPython, some built-in functions defined in
C provide no metadata about their arguments."
"inspect.getclasstree(classes, unique=False)","Arrange the given list of classes into a hierarchy of nested lists. Where a
nested list appears, it contains classes derived from the class whose entry
immediately precedes the list.  Each entry is a 2-tuple containing a class and a
tuple of its base classes.  If the unique argument is true, exactly one entry
appears in the returned structure for each class in the given list.  Otherwise,
classes using multiple inheritance and their descendants will appear multiple
times."
inspect.getargspec(func),"Get the names and default values of a Python function’s parameters. A
named tuple ArgSpec(args, varargs, keywords, defaults) is
returned. args is a list of the parameter names. varargs and keywords
are the names of the * and ** parameters or None. defaults is a
tuple of default argument values or None if there are no default
arguments; if this tuple has n elements, they correspond to the last
n elements listed in args.

Deprecated since version 3.0: Use getfullargspec() for an updated API that is usually a drop-in
replacement, but also correctly handles function annotations and
keyword-only parameters.
Alternatively, use signature() and
Signature Object, which provide a
more structured introspection API for callables."
inspect.getfullargspec(func),"Get the names and default values of a Python function’s parameters.  A
named tuple is returned:
FullArgSpec(args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults,
annotations)
args is a list of the positional parameter names.
varargs is the name of the * parameter or None if arbitrary
positional arguments are not accepted.
varkw is the name of the ** parameter or None if arbitrary
keyword arguments are not accepted.
defaults is an n-tuple of default argument values corresponding to the
last n positional parameters, or None if there are no such defaults
defined.
kwonlyargs is a list of keyword-only parameter names in declaration order.
kwonlydefaults is a dictionary mapping parameter names from kwonlyargs
to the default values used if no argument is supplied.
annotations is a dictionary mapping parameter names to annotations.
The special key ""return"" is used to report the function return value
annotation (if any).
Note that signature() and
Signature Object provide the recommended
API for callable introspection, and support additional behaviours (like
positional-only arguments) that are sometimes encountered in extension module
APIs. This function is retained primarily for use in code that needs to
maintain compatibility with the Python 2 inspect module API.

Changed in version 3.4: This function is now based on signature(), but still ignores
__wrapped__ attributes and includes the already bound first
parameter in the signature output for bound methods.


Changed in version 3.6: This method was previously documented as deprecated in favour of
signature() in Python 3.5, but that decision has been reversed
in order to restore a clearly supported standard interface for
single-source Python 2/3 code migrating away from the legacy
getargspec() API.


Changed in version 3.7: Python only explicitly guaranteed that it preserved the declaration
order of keyword-only parameters as of version 3.7, although in practice
this order had always been preserved in Python 3."
inspect.getargvalues(frame),"Get information about arguments passed into a particular frame.  A
named tuple ArgInfo(args, varargs, keywords, locals) is
returned. args is a list of the argument names.  varargs and keywords
are the names of the * and ** arguments or None.  locals is the
locals dictionary of the given frame.

Note
This function was inadvertently marked as deprecated in Python 3.5."
"inspect.formatargspec(args[, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations[, formatarg, formatvarargs, formatvarkw, formatvalue, formatreturns, formatannotations]])","Format a pretty argument spec from the values returned by
getfullargspec().
The first seven arguments are (args, varargs, varkw,
defaults, kwonlyargs, kwonlydefaults, annotations).
The other six arguments are functions that are called to turn argument names,
* argument name, ** argument name, default values, return annotation
and individual annotations into strings, respectively.
For example:
>>> from inspect import formatargspec, getfullargspec
>>> def f(a: int, b: float):
...     pass
...
>>> formatargspec(*getfullargspec(f))
'(a: int, b: float)'



Deprecated since version 3.5: Use signature() and
Signature Object, which provide a
better introspecting API for callables."
"inspect.formatargvalues(args[, varargs, varkw, locals, formatarg, formatvarargs, formatvarkw, formatvalue])","Format a pretty argument spec from the four values returned by
getargvalues().  The format* arguments are the corresponding optional
formatting functions that are called to turn names and values into strings.

Note
This function was inadvertently marked as deprecated in Python 3.5."
inspect.getmro(cls),"Return a tuple of class cls’s base classes, including cls, in method resolution
order.  No class appears more than once in this tuple. Note that the method
resolution order depends on cls’s type.  Unless a very peculiar user-defined
metatype is in use, cls will be the first element of the tuple."
"inspect.getcallargs(func, /, *args, **kwds)","Bind the args and kwds to the argument names of the Python function or
method func, as if it was called with them. For bound methods, bind also the
first argument (typically named self) to the associated instance. A dict
is returned, mapping the argument names (including the names of the * and
** arguments, if any) to their values from args and kwds. In case of
invoking func incorrectly, i.e. whenever func(*args, **kwds) would raise
an exception because of incompatible signature, an exception of the same type
and the same or similar message is raised. For example:
>>> from inspect import getcallargs
>>> def f(a, b=1, *pos, **named):
...     pass
>>> getcallargs(f, 1, 2, 3) == {'a': 1, 'named': {}, 'b': 2, 'pos': (3,)}
True
>>> getcallargs(f, a=2, x=4) == {'a': 2, 'named': {'x': 4}, 'b': 1, 'pos': ()}
True
>>> getcallargs(f)
Traceback (most recent call last):
...
TypeError: f() missing 1 required positional argument: 'a'



New in version 3.2.


Deprecated since version 3.5: Use Signature.bind() and Signature.bind_partial() instead."
inspect.getclosurevars(func),"Get the mapping of external name references in a Python function or
method func to their current values. A
named tuple ClosureVars(nonlocals, globals, builtins, unbound)
is returned. nonlocals maps referenced names to lexical closure
variables, globals to the function’s module globals and builtins to
the builtins visible from the function body. unbound is the set of names
referenced in the function that could not be resolved at all given the
current module globals and builtins.
TypeError is raised if func is not a Python function or method.

New in version 3.3."
"inspect.unwrap(func, *, stop=None)","Get the object wrapped by func. It follows the chain of __wrapped__
attributes returning the last object in the chain.
stop is an optional callback accepting an object in the wrapper chain
as its sole argument that allows the unwrapping to be terminated early if
the callback returns a true value. If the callback never returns a true
value, the last object in the chain is returned as usual. For example,
signature() uses this to stop unwrapping if any object in the
chain has a __signature__ attribute defined.
ValueError is raised if a cycle is encountered.

New in version 3.4."
"inspect.getframeinfo(frame, context=1)","Get information about a frame or traceback object.  A named tuple
Traceback(filename, lineno, function, code_context, index) is returned."
"inspect.getouterframes(frame, context=1)","Get a list of frame records for a frame and all outer frames.  These frames
represent the calls that lead to the creation of frame. The first entry in the
returned list represents frame; the last entry represents the outermost call
on frame’s stack.

Changed in version 3.5: A list of named tuples
FrameInfo(frame, filename, lineno, function, code_context, index)
is returned."
"inspect.getinnerframes(traceback, context=1)","Get a list of frame records for a traceback’s frame and all inner frames.  These
frames represent calls made as a consequence of frame.  The first entry in the
list represents traceback; the last entry represents where the exception was
raised.

Changed in version 3.5: A list of named tuples
FrameInfo(frame, filename, lineno, function, code_context, index)
is returned."
inspect.currentframe(),"Return the frame object for the caller’s stack frame.

CPython implementation detail: This function relies on Python stack frame support in the interpreter,
which isn’t guaranteed to exist in all implementations of Python.  If
running in an implementation without Python stack frame support this
function returns None."
inspect.stack(context=1),"Return a list of frame records for the caller’s stack.  The first entry in the
returned list represents the caller; the last entry represents the outermost
call on the stack.

Changed in version 3.5: A list of named tuples
FrameInfo(frame, filename, lineno, function, code_context, index)
is returned."
inspect.trace(context=1),"Return a list of frame records for the stack between the current frame and the
frame in which an exception currently being handled was raised in.  The first
entry in the list represents the caller; the last entry represents where the
exception was raised.

Changed in version 3.5: A list of named tuples
FrameInfo(frame, filename, lineno, function, code_context, index)
is returned."
"inspect.getattr_static(obj, attr, default=None)","Retrieve attributes without triggering dynamic lookup via the
descriptor protocol, __getattr__() or __getattribute__().
Note: this function may not be able to retrieve all attributes
that getattr can fetch (like dynamically created attributes)
and may find attributes that getattr can’t (like descriptors
that raise AttributeError). It can also return descriptors objects
instead of instance members.
If the instance __dict__ is shadowed by another member (for
example a property) then this function will be unable to find instance
members.

New in version 3.2."
inspect.getgeneratorstate(generator),"Get current state of a generator-iterator.

Possible states are:
GEN_CREATED: Waiting to start execution.
GEN_RUNNING: Currently being executed by the interpreter.
GEN_SUSPENDED: Currently suspended at a yield expression.
GEN_CLOSED: Execution has completed.




New in version 3.2."
inspect.getcoroutinestate(coroutine),"Get current state of a coroutine object.  The function is intended to be
used with coroutine objects created by async def functions, but
will accept any coroutine-like object that has cr_running and
cr_frame attributes.

Possible states are:
CORO_CREATED: Waiting to start execution.
CORO_RUNNING: Currently being executed by the interpreter.
CORO_SUSPENDED: Currently suspended at an await expression.
CORO_CLOSED: Execution has completed.




New in version 3.5."
inspect.getgeneratorlocals(generator),"Get the mapping of live local variables in generator to their current
values.  A dictionary is returned that maps from variable names to values.
This is the equivalent of calling locals() in the body of the
generator, and all the same caveats apply.
If generator is a generator with no currently associated frame,
then an empty dictionary is returned.  TypeError is raised if
generator is not a Python generator object.

CPython implementation detail: This function relies on the generator exposing a Python stack frame
for introspection, which isn’t guaranteed to be the case in all
implementations of Python. In such cases, this function will always
return an empty dictionary.


New in version 3.3."
inspect.getcoroutinelocals(coroutine),"This function is analogous to getgeneratorlocals(), but
works for coroutine objects created by async def functions.

New in version 3.5."
"bind(*args, **kwargs)","Create a mapping from positional and keyword arguments to parameters.
Returns BoundArguments if *args and **kwargs match the
signature, or raises a TypeError."
"bind_partial(*args, **kwargs)","Works the same way as Signature.bind(), but allows the omission of
some required arguments (mimics functools.partial() behavior.)
Returns BoundArguments, or raises a TypeError if the
passed arguments do not match the signature."
"replace(*[, parameters][, return_annotation])","Create a new Signature instance based on the instance replace was invoked
on.  It is possible to pass different parameters and/or
return_annotation to override the corresponding properties of the base
signature.  To remove return_annotation from the copied Signature, pass in
Signature.empty.
>>> def test(a, b):
...     pass
>>> sig = signature(test)
>>> new_sig = sig.replace(return_annotation=""new return anno"")
>>> str(new_sig)
""(a, b) -> 'new return anno'"""
"classmethod from_callable(obj, *, follow_wrapped=True)","Return a Signature (or its subclass) object for a given callable
obj.  Pass follow_wrapped=False to get a signature of obj
without unwrapping its __wrapped__ chain.
This method simplifies subclassing of Signature:
class MySignature(Signature):
    pass
sig = MySignature.from_callable(min)
assert isinstance(sig, MySignature)



New in version 3.5."
"replace(*[, name][, kind][, default][, annotation])","Create a new Parameter instance based on the instance replaced was invoked
on.  To override a Parameter attribute, pass the corresponding
argument.  To remove a default value or/and an annotation from a
Parameter, pass Parameter.empty.
>>> from inspect import Parameter
>>> param = Parameter('foo', Parameter.KEYWORD_ONLY, default=42)
>>> str(param)
'foo=42'

>>> str(param.replace()) # Will create a shallow copy of 'param'
'foo=42'

>>> str(param.replace(default=Parameter.empty, annotation='spam'))
""foo:'spam'""




Changed in version 3.4: In Python 3.3 Parameter objects were allowed to have name set
to None if their kind was set to POSITIONAL_ONLY.
This is no longer permitted."
apply_defaults(),"Set default values for missing arguments.
For variable-positional arguments (*args) the default is an
empty tuple.
For variable-keyword arguments (**kwargs) the default is an
empty dict.
>>> def foo(a, b='ham', *args): pass
>>> ba = inspect.signature(foo).bind('spam')
>>> ba.apply_defaults()
>>> ba.arguments
OrderedDict([('a', 'spam'), ('b', 'ham'), ('args', ())])



New in version 3.5."
site.main(),"Adds all the standard site-specific directories to the module search
path.  This function is called automatically when this module is imported,
unless the Python interpreter was started with the -S flag.

Changed in version 3.3: This function used to be called unconditionally."
"site.addsitedir(sitedir, known_paths=None)","Add a directory to sys.path and process its .pth files.  Typically
used in sitecustomize or usercustomize (see above)."
site.getsitepackages(),"Return a list containing all global site-packages directories.

New in version 3.2."
site.getuserbase(),"Return the path of the user base directory, USER_BASE.  If it is not
initialized yet, this function will also set it, respecting
PYTHONUSERBASE.

New in version 3.2."
site.getusersitepackages(),"Return the path of the user-specific site-packages directory,
USER_SITE.  If it is not initialized yet, this function will also set
it, respecting PYTHONNOUSERSITE and USER_BASE.

New in version 3.2."
"code.interact(banner=None, readfunc=None, local=None, exitmsg=None)","Convenience function to run a read-eval-print loop.  This creates a new
instance of InteractiveConsole and sets readfunc to be used as
the InteractiveConsole.raw_input() method, if provided.  If local is
provided, it is passed to the InteractiveConsole constructor for
use as the default namespace for the interpreter loop.  The interact()
method of the instance is then run with banner and exitmsg passed as the
banner and exit message to use, if provided.  The console object is discarded
after use.

Changed in version 3.6: Added exitmsg parameter."
"code.compile_command(source, filename=""<input>"", symbol=""single"")","This function is useful for programs that want to emulate Python’s interpreter
main loop (a.k.a. the read-eval-print loop).  The tricky part is to determine
when the user has entered an incomplete command that can be completed by
entering more text (as opposed to a complete command or a syntax error).  This
function almost always makes the same decision as the real interpreter main
loop.
source is the source string; filename is the optional filename from which
source was read, defaulting to '<input>'; and symbol is the optional
grammar start symbol, which should be either 'single' (the default) or
'eval'.
Returns a code object (the same as compile(source, filename, symbol)) if the
command is complete and valid; None if the command is incomplete; raises
SyntaxError if the command is complete and contains a syntax error, or
raises OverflowError or ValueError if the command contains an
invalid literal."
"InteractiveInterpreter.runsource(source, filename=""<input>"", symbol=""single"")","Compile and run some source in the interpreter. Arguments are the same as for
compile_command(); the default for filename is '<input>', and for
symbol is 'single'.  One of several things can happen:

The input is incorrect; compile_command() raised an exception
(SyntaxError or OverflowError).  A syntax traceback will be
printed by calling the showsyntaxerror() method.  runsource()
returns False.
The input is incomplete, and more input is required; compile_command()
returned None. runsource() returns True.
The input is complete; compile_command() returned a code object.  The
code is executed by calling the runcode() (which also handles run-time
exceptions, except for SystemExit). runsource() returns False.

The return value can be used to decide whether to use sys.ps1 or sys.ps2
to prompt the next line."
InteractiveInterpreter.runcode(code),"Execute a code object. When an exception occurs, showtraceback() is called
to display a traceback.  All exceptions are caught except SystemExit,
which is allowed to propagate.
A note about KeyboardInterrupt: this exception may occur elsewhere in
this code, and may not always be caught.  The caller should be prepared to deal
with it."
InteractiveInterpreter.showsyntaxerror(filename=None),"Display the syntax error that just occurred.  This does not display a stack
trace because there isn’t one for syntax errors. If filename is given, it is
stuffed into the exception instead of the default filename provided by Python’s
parser, because it always uses '<string>' when reading from a string. The
output is written by the write() method."
InteractiveInterpreter.showtraceback(),"Display the exception that just occurred.  We remove the first stack item
because it is within the interpreter object implementation. The output is
written by the write() method.

Changed in version 3.5: The full chained traceback is displayed instead
of just the primary traceback."
InteractiveInterpreter.write(data),"Write a string to the standard error stream (sys.stderr). Derived classes
should override this to provide the appropriate output handling as needed."
"InteractiveConsole.interact(banner=None, exitmsg=None)","Closely emulate the interactive Python console. The optional banner argument
specify the banner to print before the first interaction; by default it prints a
banner similar to the one printed by the standard Python interpreter, followed
by the class name of the console object in parentheses (so as not to confuse
this with the real interpreter – since it’s so close!).
The optional exitmsg argument specifies an exit message printed when exiting.
Pass the empty string to suppress the exit message. If exitmsg is not given or
None, a default message is printed.

Changed in version 3.4: To suppress printing any banner, pass an empty string.


Changed in version 3.6: Print an exit message when exiting."
InteractiveConsole.push(line),"Push a line of source text to the interpreter. The line should not have a
trailing newline; it may have internal newlines.  The line is appended to a
buffer and the interpreter’s runsource() method is called with the
concatenated contents of the buffer as source.  If this indicates that the
command was executed or invalid, the buffer is reset; otherwise, the command is
incomplete, and the buffer is left as it was after the line was appended.  The
return value is True if more input is required, False if the line was
dealt with in some way (this is the same as runsource())."
InteractiveConsole.resetbuffer(),Remove any unhandled source text from the input buffer.
"InteractiveConsole.raw_input(prompt="""")","Write a prompt and read a line.  The returned line does not include the trailing
newline.  When the user enters the EOF key sequence, EOFError is raised.
The base implementation reads from sys.stdin; a subclass may replace this
with a different implementation."
"codeop.compile_command(source, filename=""<input>"", symbol=""single"")","Tries to compile source, which should be a string of Python code and return a
code object if source is valid Python code. In that case, the filename
attribute of the code object will be filename, which defaults to
'<input>'. Returns None if source is not valid Python code, but is a
prefix of valid Python code.
If there is a problem with source, an exception will be raised.
SyntaxError is raised if there is invalid Python syntax, and
OverflowError or ValueError if there is an invalid literal.
The symbol argument determines whether source is compiled as a statement
('single', the default) or as an expression ('eval').  Any
other value will cause ValueError to  be raised.

Note
It is possible (but not likely) that the parser stops parsing with a
successful outcome before reaching the end of the source; in this case,
trailing symbols may be ignored instead of causing an error.  For example,
a backslash followed by two newlines may be followed by arbitrary garbage.
This will be fixed once the API for the parser is better."
"find_module(fullname[, path])","Search for a module specified by fullname. fullname must be the fully
qualified (dotted) module name. It returns the zipimporter instance itself
if the module was found, or None if it wasn’t. The optional
path argument is ignored—it’s there for compatibility with the
importer protocol."
get_code(fullname),"Return the code object for the specified module. Raise
ZipImportError if the module couldn’t be found."
get_data(pathname),"Return the data associated with pathname. Raise OSError if the
file wasn’t found.

Changed in version 3.3: IOError used to be raised instead of OSError."
get_filename(fullname),"Return the value __file__ would be set to if the specified module
was imported. Raise ZipImportError if the module couldn’t be
found.

New in version 3.1."
get_source(fullname),"Return the source code for the specified module. Raise
ZipImportError if the module couldn’t be found, return
None if the archive does contain the module, but has no source
for it."
is_package(fullname),"Return True if the module specified by fullname is a package. Raise
ZipImportError if the module couldn’t be found."
load_module(fullname),"Load the module specified by fullname. fullname must be the fully
qualified (dotted) module name. It returns the imported module, or raises
ZipImportError if it wasn’t found."
"pkgutil.extend_path(path, name)","Extend the search path for the modules which comprise a package.  Intended
use is to place the following code in a package’s __init__.py:
from pkgutil import extend_path
__path__ = extend_path(__path__, __name__)


This will add to the package’s __path__ all subdirectories of directories
on sys.path named after the package.  This is useful if one wants to
distribute different parts of a single logical package as multiple
directories.
It also looks for *.pkg files beginning where * matches the
name argument.  This feature is similar to *.pth files (see the
site module for more information), except that it doesn’t special-case
lines starting with import.  A *.pkg file is trusted at face
value: apart from checking for duplicates, all entries found in a
*.pkg file are added to the path, regardless of whether they exist
on the filesystem.  (This is a feature.)
If the input path is not a list (as is the case for frozen packages) it is
returned unchanged.  The input path is not modified; an extended copy is
returned.  Items are only appended to the copy at the end.
It is assumed that sys.path is a sequence.  Items of sys.path
that are not strings referring to existing directories are ignored. Unicode
items on sys.path that cause errors when used as filenames may cause
this function to raise an exception (in line with os.path.isdir()
behavior)."
pkgutil.find_loader(fullname),"Retrieve a module loader for the given fullname.
This is a backwards compatibility wrapper around
importlib.util.find_spec() that converts most failures to
ImportError and only returns the loader rather than the full
ModuleSpec.

Changed in version 3.3: Updated to be based directly on importlib rather than relying
on the package internal PEP 302 import emulation.


Changed in version 3.4: Updated to be based on PEP 451"
pkgutil.get_importer(path_item),"Retrieve a finder for the given path_item.
The returned finder is cached in sys.path_importer_cache if it was
newly created by a path hook.
The cache (or part of it) can be cleared manually if a rescan of
sys.path_hooks is necessary.

Changed in version 3.3: Updated to be based directly on importlib rather than relying
on the package internal PEP 302 import emulation."
pkgutil.get_loader(module_or_name),"Get a loader object for module_or_name.
If the module or package is accessible via the normal import mechanism, a
wrapper around the relevant part of that machinery is returned.  Returns
None if the module cannot be found or imported.  If the named module is
not already imported, its containing package (if any) is imported, in order
to establish the package __path__.

Changed in version 3.3: Updated to be based directly on importlib rather than relying
on the package internal PEP 302 import emulation.


Changed in version 3.4: Updated to be based on PEP 451"
pkgutil.iter_importers(fullname=''),"Yield finder objects for the given module name.
If fullname contains a ‘.’, the finders will be for the package
containing fullname, otherwise they will be all registered top level
finders (i.e. those on both sys.meta_path and sys.path_hooks).
If the named module is in a package, that package is imported as a side
effect of invoking this function.
If no module name is specified, all top level finders are produced.

Changed in version 3.3: Updated to be based directly on importlib rather than relying
on the package internal PEP 302 import emulation."
"pkgutil.iter_modules(path=None, prefix='')","Yields ModuleInfo for all submodules on path, or, if
path is None, all top-level modules on sys.path.
path should be either None or a list of paths to look for modules in.
prefix is a string to output on the front of every module name on output.

Note
Only works for a finder which defines an iter_modules()
method. This interface is non-standard, so the module also provides
implementations for importlib.machinery.FileFinder and
zipimport.zipimporter.


Changed in version 3.3: Updated to be based directly on importlib rather than relying
on the package internal PEP 302 import emulation."
"pkgutil.walk_packages(path=None, prefix='', onerror=None)","Yields ModuleInfo for all modules recursively on
path, or, if path is None, all accessible modules.
path should be either None or a list of paths to look for modules in.
prefix is a string to output on the front of every module name on output.
Note that this function must import all packages (not all modules!) on
the given path, in order to access the __path__ attribute to find
submodules.
onerror is a function which gets called with one argument (the name of the
package which was being imported) if any exception occurs while trying to
import a package.  If no onerror function is supplied, ImportErrors
are caught and ignored, while all other exceptions are propagated,
terminating the search.
Examples:
# list all modules python can access
walk_packages()

# list all submodules of ctypes
walk_packages(ctypes.__path__, ctypes.__name__ + '.')



Note
Only works for a finder which defines an iter_modules()
method. This interface is non-standard, so the module also provides
implementations for importlib.machinery.FileFinder and
zipimport.zipimporter.


Changed in version 3.3: Updated to be based directly on importlib rather than relying
on the package internal PEP 302 import emulation."
"pkgutil.get_data(package, resource)","Get a resource from a package.
This is a wrapper for the loader
get_data API.  The
package argument should be the name of a package, in standard module format
(foo.bar).  The resource argument should be in the form of a relative
filename, using / as the path separator.  The parent directory name
.. is not allowed, and nor is a rooted name (starting with a /).
The function returns a binary string that is the contents of the specified
resource.
For packages located in the filesystem, which have already been imported,
this is the rough equivalent of:
d = os.path.dirname(sys.modules[package].__file__)
data = open(os.path.join(d, resource), 'rb').read()


If the package cannot be located or loaded, or it uses a loader
which does not support get_data,
then None is returned.  In particular, the loader for
namespace packages does not support
get_data."
"modulefinder.AddPackagePath(pkg_name, path)",Record that the package named pkg_name can be found in the specified path.
"modulefinder.ReplacePackage(oldname, newname)","Allows specifying that the module named oldname is in fact the package named
newname."
report(),"Print a report to standard output that lists the modules imported by the
script and their paths, as well as modules that are missing or seem to be
missing."
run_script(pathname),"Analyze the contents of the pathname file, which must contain Python
code."
"runpy.run_module(mod_name, init_globals=None, run_name=None, alter_sys=False)","Execute the code of the specified module and return the resulting module
globals dictionary. The module’s code is first located using the standard
import mechanism (refer to PEP 302 for details) and then executed in a
fresh module namespace.
The mod_name argument should be an absolute module name.
If the module name refers to a package rather than a normal
module, then that package is imported and the __main__ submodule within
that package is then executed and the resulting module globals dictionary
returned.
The optional dictionary argument init_globals may be used to pre-populate
the module’s globals dictionary before the code is executed. The supplied
dictionary will not be modified. If any of the special global variables
below are defined in the supplied dictionary, those definitions are
overridden by run_module().
The special global variables __name__, __spec__, __file__,
__cached__, __loader__ and __package__ are set in the globals
dictionary before the module code is executed (Note that this is a
minimal set of variables - other variables may be set implicitly as an
interpreter implementation detail).
__name__ is set to run_name if this optional argument is not
None, to mod_name + '.__main__' if the named module is a
package and to the mod_name argument otherwise.
__spec__ will be set appropriately for the actually imported
module (that is, __spec__.name will always be mod_name or
mod_name + '.__main__, never run_name).
__file__, __cached__, __loader__ and __package__ are
set as normal based on the module spec.
If the argument alter_sys is supplied and evaluates to True,
then sys.argv[0] is updated with the value of __file__ and
sys.modules[__name__] is updated with a temporary module object for the
module being executed. Both sys.argv[0] and sys.modules[__name__]
are restored to their original values before the function returns.
Note that this manipulation of sys is not thread-safe. Other threads
may see the partially initialised module, as well as the altered list of
arguments. It is recommended that the sys module be left alone when
invoking this function from threaded code.

See also
The -m option offering equivalent functionality from the
command line.


Changed in version 3.1: Added ability to execute packages by looking for a __main__ submodule.


Changed in version 3.2: Added __cached__ global variable (see PEP 3147).


Changed in version 3.4: Updated to take advantage of the module spec feature added by
PEP 451. This allows __cached__ to be set correctly for modules
run this way, as well as ensuring the real module name is always
accessible as __spec__.name."
"runpy.run_path(file_path, init_globals=None, run_name=None)","Execute the code at the named filesystem location and return the resulting
module globals dictionary. As with a script name supplied to the CPython
command line, the supplied path may refer to a Python source file, a
compiled bytecode file or a valid sys.path entry containing a __main__
module (e.g. a zipfile containing a top-level __main__.py file).
For a simple script, the specified code is simply executed in a fresh
module namespace. For a valid sys.path entry (typically a zipfile or
directory), the entry is first added to the beginning of sys.path. The
function then looks for and executes a __main__ module using the
updated path. Note that there is no special protection against invoking
an existing __main__ entry located elsewhere on sys.path if
there is no such module at the specified location.
The optional dictionary argument init_globals may be used to pre-populate
the module’s globals dictionary before the code is executed. The supplied
dictionary will not be modified. If any of the special global variables
below are defined in the supplied dictionary, those definitions are
overridden by run_path().
The special global variables __name__, __spec__, __file__,
__cached__, __loader__ and __package__ are set in the globals
dictionary before the module code is executed (Note that this is a
minimal set of variables - other variables may be set implicitly as an
interpreter implementation detail).
__name__ is set to run_name if this optional argument is not
None and to '<run_path>' otherwise.
If the supplied path directly references a script file (whether as source
or as precompiled byte code), then __file__ will be set to the
supplied path, and __spec__, __cached__, __loader__ and
__package__ will all be set to None.
If the supplied path is a reference to a valid sys.path entry, then
__spec__ will be set appropriately for the imported __main__
module (that is, __spec__.name will always be __main__).
__file__, __cached__, __loader__ and __package__ will be
set as normal based on the module spec.
A number of alterations are also made to the sys module. Firstly,
sys.path may be altered as described above. sys.argv[0] is updated
with the value of file_path and sys.modules[__name__] is updated
with a temporary module object for the module being executed. All
modifications to items in sys are reverted before the function
returns.
Note that, unlike run_module(), the alterations made to sys
are not optional in this function as these adjustments are essential to
allowing the execution of sys.path entries. As the thread-safety
limitations still apply, use of this function in threaded code should be
either serialised with the import lock or delegated to a separate process.

See also
Interface options for equivalent functionality on the
command line (python path/to/script).


New in version 3.2.


Changed in version 3.4: Updated to take advantage of the module spec feature added by
PEP 451. This allows __cached__ to be set correctly in the
case where __main__ is imported from a valid sys.path entry rather
than being executed directly."
"importlib.__import__(name, globals=None, locals=None, fromlist=(), level=0)","An implementation of the built-in __import__() function.

Note
Programmatic importing of modules should use import_module()
instead of this function."
"importlib.import_module(name, package=None)","Import a module. The name argument specifies what module to
import in absolute or relative terms
(e.g. either pkg.mod or ..mod). If the name is
specified in relative terms, then the package argument must be set to
the name of the package which is to act as the anchor for resolving the
package name (e.g. import_module('..mod', 'pkg.subpkg') will import
pkg.mod).
The import_module() function acts as a simplifying wrapper around
importlib.__import__(). This means all semantics of the function are
derived from importlib.__import__(). The most important difference
between these two functions is that import_module() returns the
specified package or module (e.g. pkg.mod), while __import__()
returns the top-level package or module (e.g. pkg).
If you are dynamically importing a module that was created since the
interpreter began execution (e.g., created a Python source file), you may
need to call invalidate_caches() in order for the new module to be
noticed by the import system.

Changed in version 3.3: Parent packages are automatically imported."
"importlib.find_loader(name, path=None)","Find the loader for a module, optionally within the specified path. If the
module is in sys.modules, then sys.modules[name].__loader__ is
returned (unless the loader would be None or is not set, in which case
ValueError is raised). Otherwise a search using sys.meta_path
is done. None is returned if no loader is found.
A dotted name does not have its parents implicitly imported as that requires
loading them and that may not be desired. To properly import a submodule you
will need to import all parent packages of the submodule and use the correct
argument to path.

New in version 3.3.


Changed in version 3.4: If __loader__ is not set, raise ValueError, just like when the
attribute is set to None.


Deprecated since version 3.4: Use importlib.util.find_spec() instead."
importlib.invalidate_caches(),"Invalidate the internal caches of finders stored at
sys.meta_path. If a finder implements invalidate_caches() then it
will be called to perform the invalidation.  This function should be called
if any modules are created/installed while your program is running to
guarantee all finders will notice the new module’s existence.

New in version 3.3."
importlib.reload(module),"Reload a previously imported module.  The argument must be a module object,
so it must have been successfully imported before.  This is useful if you
have edited the module source file using an external editor and want to try
out the new version without leaving the Python interpreter.  The return value
is the module object (which can be different if re-importing causes a
different object to be placed in sys.modules).
When reload() is executed:

Python module’s code is recompiled and the module-level code re-executed,
defining a new set of objects which are bound to names in the module’s
dictionary by reusing the loader which originally loaded the
module.  The init function of extension modules is not called a second
time.
As with all other objects in Python the old objects are only reclaimed
after their reference counts drop to zero.
The names in the module namespace are updated to point to any new or
changed objects.
Other references to the old objects (such as names external to the module) are
not rebound to refer to the new objects and must be updated in each namespace
where they occur if that is desired.

There are a number of other caveats:
When a module is reloaded, its dictionary (containing the module’s global
variables) is retained.  Redefinitions of names will override the old
definitions, so this is generally not a problem.  If the new version of a
module does not define a name that was defined by the old version, the old
definition remains.  This feature can be used to the module’s advantage if it
maintains a global table or cache of objects — with a try
statement it can test for the table’s presence and skip its initialization if
desired:
try:
    cache
except NameError:
    cache = {}


It is generally not very useful to reload built-in or dynamically loaded
modules.  Reloading sys, __main__, builtins and other
key modules is not recommended.  In many cases extension modules are not
designed to be initialized more than once, and may fail in arbitrary ways
when reloaded.
If a module imports objects from another module using from …
import …, calling reload() for the other module does not
redefine the objects imported from it — one way around this is to
re-execute the from statement, another is to use import
and qualified names (module.name) instead.
If a module instantiates instances of a class, reloading the module that
defines the class does not affect the method definitions of the instances —
they continue to use the old class definition.  The same is true for derived
classes.

New in version 3.4.


Changed in version 3.7: ModuleNotFoundError is raised when the module being reloaded lacks
a ModuleSpec."
"importlib.resources.open_binary(package, resource)","Open for binary reading the resource within package.
package is either a name or a module object which conforms to the
Package requirements.  resource is the name of the resource to open
within package; it may not contain path separators and it may not have
sub-resources (i.e. it cannot be a directory).  This function returns a
typing.BinaryIO instance, a binary I/O stream open for reading."
"importlib.resources.open_text(package, resource, encoding='utf-8', errors='strict')","Open for text reading the resource within package.  By default, the
resource is opened for reading as UTF-8.
package is either a name or a module object which conforms to the
Package requirements.  resource is the name of the resource to open
within package; it may not contain path separators and it may not have
sub-resources (i.e. it cannot be a directory).  encoding and errors
have the same meaning as with built-in open().
This function returns a typing.TextIO instance, a text I/O stream open
for reading."
"importlib.resources.read_binary(package, resource)","Read and return the contents of the resource within package as
bytes.
package is either a name or a module object which conforms to the
Package requirements.  resource is the name of the resource to open
within package; it may not contain path separators and it may not have
sub-resources (i.e. it cannot be a directory).  This function returns the
contents of the resource as bytes."
"importlib.resources.read_text(package, resource, encoding='utf-8', errors='strict')","Read and return the contents of resource within package as a str.
By default, the contents are read as strict UTF-8.
package is either a name or a module object which conforms to the
Package requirements.  resource is the name of the resource to open
within package; it may not contain path separators and it may not have
sub-resources (i.e. it cannot be a directory).  encoding and errors
have the same meaning as with built-in open().  This function
returns the contents of the resource as str."
"importlib.resources.path(package, resource)","Return the path to the resource as an actual file system path.  This
function returns a context manager for use in a with statement.
The context manager provides a pathlib.Path object.
Exiting the context manager cleans up any temporary file created when the
resource needs to be extracted from e.g. a zip file.
package is either a name or a module object which conforms to the
Package requirements.  resource is the name of the resource to open
within package; it may not contain path separators and it may not have
sub-resources (i.e. it cannot be a directory)."
"importlib.resources.is_resource(package, name)","Return True if there is a resource named name in the package,
otherwise False.  Remember that directories are not resources!
package is either a name or a module object which conforms to the
Package requirements."
importlib.resources.contents(package),"Return an iterable over the named items within the package.  The iterable
returns str resources (e.g. files) and non-resources
(e.g. directories).  The iterable does not recurse into subdirectories.
package is either a name or a module object which conforms to the
Package requirements."
importlib.machinery.all_suffixes(),"Returns a combined list of strings representing all file suffixes for
modules recognized by the standard import machinery. This is a
helper for code which simply needs to know if a filesystem path
potentially refers to a module without needing any details on the kind
of module (for example, inspect.getmodulename()).

New in version 3.3."
"importlib.util.cache_from_source(path, debug_override=None, *, optimization=None)","Return the PEP 3147/PEP 488 path to the byte-compiled file associated
with the source path.  For example, if path is /foo/bar/baz.py the return
value would be /foo/bar/__pycache__/baz.cpython-32.pyc for Python 3.2.
The cpython-32 string comes from the current magic tag (see
get_tag(); if sys.implementation.cache_tag is not defined then
NotImplementedError will be raised).
The optimization parameter is used to specify the optimization level of the
bytecode file. An empty string represents no optimization, so
/foo/bar/baz.py with an optimization of '' will result in a
bytecode path of /foo/bar/__pycache__/baz.cpython-32.pyc. None causes
the interpreter’s optimization level to be used. Any other value’s string
representation is used, so /foo/bar/baz.py with an optimization of
2 will lead to the bytecode path of
/foo/bar/__pycache__/baz.cpython-32.opt-2.pyc. The string representation
of optimization can only be alphanumeric, else ValueError is raised.
The debug_override parameter is deprecated and can be used to override
the system’s value for __debug__. A True value is the equivalent of
setting optimization to the empty string. A False value is the same as
setting optimization to 1. If both debug_override an optimization
are not None then TypeError is raised.

New in version 3.4.


Changed in version 3.5: The optimization parameter was added and the debug_override parameter
was deprecated.


Changed in version 3.6: Accepts a path-like object."
importlib.util.source_from_cache(path),"Given the path to a PEP 3147 file name, return the associated source code
file path.  For example, if path is
/foo/bar/__pycache__/baz.cpython-32.pyc the returned path would be
/foo/bar/baz.py.  path need not exist, however if it does not conform
to PEP 3147 or PEP 488 format, a ValueError is raised. If
sys.implementation.cache_tag is not defined,
NotImplementedError is raised.

New in version 3.4.


Changed in version 3.6: Accepts a path-like object."
importlib.util.decode_source(source_bytes),"Decode the given bytes representing source code and return it as a string
with universal newlines (as required by
importlib.abc.InspectLoader.get_source()).

New in version 3.4."
"importlib.util.resolve_name(name, package)","Resolve a relative module name to an absolute one.
If  name has no leading dots, then name is simply returned. This
allows for usage such as
importlib.util.resolve_name('sys', __package__) without doing a
check to see if the package argument is needed.
ValueError is raised if name is a relative module name but
package is a false value (e.g. None or the empty string).
ValueError is also raised a relative name would escape its containing
package (e.g. requesting ..bacon from within the spam package).

New in version 3.3."
"importlib.util.find_spec(name, package=None)","Find the spec for a module, optionally relative to
the specified package name. If the module is in sys.modules,
then sys.modules[name].__spec__ is returned (unless the spec would be
None or is not set, in which case ValueError is raised).
Otherwise a search using sys.meta_path is done. None is
returned if no spec is found.
If name is for a submodule (contains a dot), the parent module is
automatically imported.
name and package work the same as for import_module().

New in version 3.4.


Changed in version 3.7: Raises ModuleNotFoundError instead of AttributeError if
package is in fact not a package (i.e. lacks a __path__
attribute)."
importlib.util.module_from_spec(spec),"Create a new module based on spec and
spec.loader.create_module.
If spec.loader.create_module
does not return None, then any pre-existing attributes will not be reset.
Also, no AttributeError will be raised if triggered while accessing
spec or setting an attribute on the module.
This function is preferred over using types.ModuleType to create a
new module as spec is used to set as many import-controlled attributes on
the module as possible.

New in version 3.5."
@importlib.util.module_for_loader,"A decorator for importlib.abc.Loader.load_module()
to handle selecting the proper
module object to load with. The decorated method is expected to have a call
signature taking two positional arguments
(e.g. load_module(self, module)) for which the second argument
will be the module object to be used by the loader.
Note that the decorator will not work on static methods because of the
assumption of two arguments.
The decorated method will take in the name of the module to be loaded
as expected for a loader. If the module is not found in
sys.modules then a new one is constructed. Regardless of where the
module came from, __loader__ set to self and __package__
is set based on what importlib.abc.InspectLoader.is_package() returns
(if available). These attributes are set unconditionally to support
reloading.
If an exception is raised by the decorated method and a module was added to
sys.modules, then the module will be removed to prevent a partially
initialized module from being in left in sys.modules. If the module
was already in sys.modules then it is left alone.

Changed in version 3.3: __loader__ and __package__ are automatically set
(when possible).


Changed in version 3.4: Set __name__, __loader__ __package__
unconditionally to support reloading.


Deprecated since version 3.4: The import machinery now directly performs all the functionality
provided by this function."
@importlib.util.set_loader,"A decorator for importlib.abc.Loader.load_module()
to set the __loader__
attribute on the returned module. If the attribute is already set the
decorator does nothing. It is assumed that the first positional argument to
the wrapped method (i.e. self) is what __loader__ should be set
to.

Changed in version 3.4: Set __loader__ if set to None, as if the attribute does not
exist.


Deprecated since version 3.4: The import machinery takes care of this automatically."
@importlib.util.set_package,"A decorator for importlib.abc.Loader.load_module() to set the
__package__ attribute on the returned module. If __package__
is set and has a value other than None it will not be changed.

Deprecated since version 3.4: The import machinery takes care of this automatically."
"importlib.util.spec_from_loader(name, loader, *, origin=None, is_package=None)","A factory function for creating a ModuleSpec instance based
on a loader.  The parameters have the same meaning as they do for
ModuleSpec.  The function uses available loader APIs, such as
InspectLoader.is_package(), to fill in any missing
information on the spec.

New in version 3.4."
"importlib.util.spec_from_file_location(name, location, *, loader=None, submodule_search_locations=None)","A factory function for creating a ModuleSpec instance based
on the path to a file.  Missing information will be filled in on the
spec by making use of loader APIs and by the implication that the
module will be file-based.

New in version 3.4.


Changed in version 3.6: Accepts a path-like object."
importlib.util.source_hash(source_bytes),"Return the hash of source_bytes as bytes. A hash-based .pyc file embeds
the source_hash() of the corresponding source file’s contents in its
header.

New in version 3.7."
"abstractmethod find_module(fullname, path=None)","An abstract method for finding a loader for the specified
module.  Originally specified in PEP 302, this method was meant
for use in sys.meta_path and in the path-based import subsystem.

Changed in version 3.4: Returns None when called instead of raising
NotImplementedError."
"find_spec(fullname, path, target=None)","An abstract method for finding a spec for
the specified module.  If this is a top-level import, path will
be None.  Otherwise, this is a search for a subpackage or
module and path will be the value of __path__ from the
parent package. If a spec cannot be found, None is returned.
When passed in, target is a module object that the finder may
use to make a more educated guess about what spec to return.
importlib.util.spec_from_loader() may be useful for implementing
concrete MetaPathFinders.

New in version 3.4."
"find_module(fullname, path)","A legacy method for finding a loader for the specified
module.  If this is a top-level import, path will be None.
Otherwise, this is a search for a subpackage or module and path
will be the value of __path__ from the parent
package. If a loader cannot be found, None is returned.
If find_spec() is defined, backwards-compatible functionality is
provided.

Changed in version 3.4: Returns None when called instead of raising
NotImplementedError. Can use find_spec() to provide
functionality.


Deprecated since version 3.4: Use find_spec() instead."
invalidate_caches(),"An optional method which, when called, should invalidate any internal
cache used by the finder. Used by importlib.invalidate_caches()
when invalidating the caches of all finders on sys.meta_path.

Changed in version 3.4: Returns None when called instead of NotImplemented."
"find_spec(fullname, target=None)","An abstract method for finding a spec for
the specified module.  The finder will search for the module only
within the path entry to which it is assigned.  If a spec
cannot be found, None is returned.  When passed in, target
is a module object that the finder may use to make a more educated
guess about what spec to return. importlib.util.spec_from_loader()
may be useful for implementing concrete PathEntryFinders.

New in version 3.4."
find_loader(fullname),"A legacy method for finding a loader for the specified
module.  Returns a 2-tuple of (loader, portion) where portion
is a sequence of file system locations contributing to part of a namespace
package. The loader may be None while specifying portion to
signify the contribution of the file system locations to a namespace
package. An empty list can be used for portion to signify the loader
is not part of a namespace package. If loader is None and
portion is the empty list then no loader or location for a namespace
package were found (i.e. failure to find anything for the module).
If find_spec() is defined then backwards-compatible functionality is
provided.

Changed in version 3.4: Returns (None, []) instead of raising NotImplementedError.
Uses find_spec() when available to provide functionality.


Deprecated since version 3.4: Use find_spec() instead."
find_module(fullname),"A concrete implementation of Finder.find_module() which is
equivalent to self.find_loader(fullname)[0].

Deprecated since version 3.4: Use find_spec() instead."
invalidate_caches(),"An optional method which, when called, should invalidate any internal
cache used by the finder. Used by PathFinder.invalidate_caches()
when invalidating the caches of all cached finders."
create_module(spec),"A method that returns the module object to use when
importing a module.  This method may return None,
indicating that default module creation semantics should take place.

New in version 3.4.


Changed in version 3.5: Starting in Python 3.6, this method will not be optional when
exec_module() is defined."
exec_module(module),"An abstract method that executes the module in its own namespace
when a module is imported or reloaded.  The module should already
be initialized when exec_module() is called. When this method exists,
create_module() must be defined.

New in version 3.4.


Changed in version 3.6: create_module() must also be defined."
load_module(fullname),"A legacy method for loading a module. If the module cannot be
loaded, ImportError is raised, otherwise the loaded module is
returned.
If the requested module already exists in sys.modules, that
module should be used and reloaded.
Otherwise the loader should create a new module and insert it into
sys.modules before any loading begins, to prevent recursion
from the import. If the loader inserted a module and the load fails, it
must be removed by the loader from sys.modules; modules already
in sys.modules before the loader began execution should be left
alone (see importlib.util.module_for_loader()).
The loader should set several attributes on the module.
(Note that some of these attributes can change when a module is
reloaded):


__name__The name of the module.




__file__The path to where the module data is stored (not set for built-in
modules).




__cached__The path to where a compiled version of the module is/should be
stored (not set when the attribute would be inappropriate).




__path__A list of strings specifying the search path within a
package. This attribute is not set on modules.




__package__The parent package for the module/package. If the module is
top-level then it has a value of the empty string. The
importlib.util.module_for_loader() decorator can handle the
details for __package__.




__loader__The loader used to load the module. The
importlib.util.module_for_loader() decorator can handle the
details for __package__.




When exec_module() is available then backwards-compatible
functionality is provided.

Changed in version 3.4: Raise ImportError when called instead of
NotImplementedError. Functionality provided when
exec_module() is available.


Deprecated since version 3.4: The recommended API for loading a module is exec_module()
(and create_module()).  Loaders should implement
it instead of load_module().  The import machinery takes care of
all the other responsibilities of load_module() when exec_module()
is implemented."
module_repr(module),"A legacy method which when implemented calculates and returns the
given module’s repr, as a string. The module type’s default repr() will
use the result of this method as appropriate.

New in version 3.3.


Changed in version 3.4: Made optional instead of an abstractmethod.


Deprecated since version 3.4: The import machinery now takes care of this automatically."
abstractmethod open_resource(resource),"Returns an opened, file-like object for binary reading
of the resource.
If the resource cannot be found, FileNotFoundError is
raised."
abstractmethod resource_path(resource),"Returns the file system path to the resource.
If the resource does not concretely exist on the file system,
raise FileNotFoundError."
abstractmethod is_resource(name),"Returns True if the named name is considered a resource.
FileNotFoundError is raised if name does not exist."
abstractmethod contents(),"Returns an iterable of strings over the contents of
the package. Do note that it is not required that all names
returned by the iterator be actual resources, e.g. it is
acceptable to return names for which is_resource() would
be false.
Allowing non-resource names to be returned is to allow for
situations where how a package and its resources are stored
are known a priori and the non-resource names would be useful.
For instance, returning subdirectory names is allowed so that
when it is known that the package and resources are stored on
the file system then those subdirectory names can be used
directly.
The abstract method returns an iterable of no items."
abstractmethod get_data(path),"An abstract method to return the bytes for the data located at path.
Loaders that have a file-like storage back-end
that allows storing arbitrary data
can implement this abstract method to give direct access
to the data stored. OSError is to be raised if the path cannot
be found. The path is expected to be constructed using a module’s
__file__ attribute or an item from a package’s __path__.

Changed in version 3.4: Raises OSError instead of NotImplementedError."
get_code(fullname),"Return the code object for a module, or None if the module does not
have a code object (as would be the case, for example, for a built-in
module).  Raise an ImportError if loader cannot find the
requested module.

Note
While the method has a default implementation, it is suggested that
it be overridden if possible for performance.


Changed in version 3.4: No longer abstract and a concrete implementation is provided."
abstractmethod get_source(fullname),"An abstract method to return the source of a module. It is returned as
a text string using universal newlines, translating all
recognized line separators into '\n' characters.  Returns None
if no source is available (e.g. a built-in module). Raises
ImportError if the loader cannot find the module specified.

Changed in version 3.4: Raises ImportError instead of NotImplementedError."
is_package(fullname),"An abstract method to return a true value if the module is a package, a
false value otherwise. ImportError is raised if the
loader cannot find the module.

Changed in version 3.4: Raises ImportError instead of NotImplementedError."
"static source_to_code(data, path='<string>')","Create a code object from Python source.
The data argument can be whatever the compile() function
supports (i.e. string or bytes). The path argument should be
the “path” to where the source code originated from, which can be an
abstract concept (e.g. location in a zip file).
With the subsequent code object one can execute it in a module by
running exec(code, module.__dict__).

New in version 3.4.


Changed in version 3.5: Made the method static."
exec_module(module),"Implementation of Loader.exec_module().

New in version 3.4."
load_module(fullname),"Implementation of Loader.load_module().

Deprecated since version 3.4: use exec_module() instead."
abstractmethod get_filename(fullname),"An abstract method that is to return the value of __file__ for
the specified module. If no path is available, ImportError is
raised.
If source code is available, then the method should return the path to
the source file, regardless of whether a bytecode was used to load the
module.

Changed in version 3.4: Raises ImportError instead of NotImplementedError."
load_module(fullname),"Calls super’s load_module().

Deprecated since version 3.4: Use Loader.exec_module() instead."
abstractmethod get_filename(fullname),Returns path.
abstractmethod get_data(path),Reads path as a binary file and returns the bytes from it.
path_stats(path),"Optional abstract method which returns a dict containing
metadata about the specified path.  Supported dictionary keys are:

'mtime' (mandatory): an integer or floating-point number
representing the modification time of the source code;
'size' (optional): the size in bytes of the source code.

Any other keys in the dictionary are ignored, to allow for future
extensions. If the path cannot be handled, OSError is raised.

New in version 3.3.


Changed in version 3.4: Raise OSError instead of NotImplementedError."
path_mtime(path),"Optional abstract method which returns the modification time for the
specified path.

Deprecated since version 3.3: This method is deprecated in favour of path_stats().  You don’t
have to implement it, but it is still available for compatibility
purposes. Raise OSError if the path cannot be handled.


Changed in version 3.4: Raise OSError instead of NotImplementedError."
"set_data(path, data)","Optional abstract method which writes the specified bytes to a file
path. Any intermediate directories which do not exist are to be created
automatically.
When writing to the path fails because the path is read-only
(errno.EACCES/PermissionError), do not propagate the
exception.

Changed in version 3.4: No longer raises NotImplementedError when called."
get_code(fullname),Concrete implementation of InspectLoader.get_code().
exec_module(module),"Concrete implementation of Loader.exec_module().

New in version 3.4."
load_module(fullname),"Concrete implementation of Loader.load_module().

Deprecated since version 3.4: Use exec_module() instead."
get_source(fullname),Concrete implementation of InspectLoader.get_source().
is_package(fullname),"Concrete implementation of InspectLoader.is_package(). A module
is determined to be a package if its file path (as provided by
ExecutionLoader.get_filename()) is a file named
__init__ when the file extension is removed and the module name
itself does not end in __init__."
"classmethod find_spec(fullname, path=None, target=None)","Class method that attempts to find a spec
for the module specified by fullname on sys.path or, if
defined, on path. For each path entry that is searched,
sys.path_importer_cache is checked. If a non-false object
is found then it is used as the path entry finder to look
for the module being searched for. If no entry is found in
sys.path_importer_cache, then sys.path_hooks is
searched for a finder for the path entry and, if found, is stored
in sys.path_importer_cache along with being queried about
the module. If no finder is ever found then None is both
stored in the cache and returned.

New in version 3.4.


Changed in version 3.5: If the current working directory – represented by an empty string –
is no longer valid then None is returned but no value is cached
in sys.path_importer_cache."
"classmethod find_module(fullname, path=None)","A legacy wrapper around find_spec().

Deprecated since version 3.4: Use find_spec() instead."
classmethod invalidate_caches(),"Calls importlib.abc.PathEntryFinder.invalidate_caches() on all
finders stored in sys.path_importer_cache that define the method.
Otherwise entries in sys.path_importer_cache set to None are
deleted.

Changed in version 3.7: Entries of None in sys.path_importer_cache are deleted."
"find_spec(fullname, target=None)","Attempt to find the spec to handle fullname within path.

New in version 3.4."
find_loader(fullname),Attempt to find the loader to handle fullname within path.
invalidate_caches(),Clear out the internal cache.
classmethod path_hook(*loader_details),"A class method which returns a closure for use on sys.path_hooks.
An instance of FileFinder is returned by the closure using the
path argument given to the closure directly and loader_details
indirectly.
If the argument to the closure is not an existing directory,
ImportError is raised."
is_package(fullname),Return True if path appears to be for a package.
path_stats(path),Concrete implementation of importlib.abc.SourceLoader.path_stats().
"set_data(path, data)",Concrete implementation of importlib.abc.SourceLoader.set_data().
load_module(name=None),"Concrete implementation of importlib.abc.Loader.load_module() where
specifying the name of the module to load is optional.

Deprecated since version 3.6: Use importlib.abc.Loader.exec_module() instead."
is_package(fullname),Determines if the module is a package based on path.
get_code(fullname),Returns the code object for name created from path.
get_source(fullname),"Returns None as bytecode files have no source when this loader is
used."
load_module(name=None),
create_module(spec),"Creates the module object from the given specification in accordance
with PEP 489.

New in version 3.5."
exec_module(module),"Initializes the given module object in accordance with PEP 489.

New in version 3.5."
is_package(fullname),"Returns True if the file path points to a package’s __init__
module based on EXTENSION_SUFFIXES."
get_code(fullname),Returns None as extension modules lack a code object.
get_source(fullname),Returns None as extension modules do not have source code.
get_filename(fullname),"Returns path.

New in version 3.4."
classmethod factory(loader),"A static method which returns a callable that creates a lazy loader. This
is meant to be used in situations where the loader is passed by class
instead of by instance.
suffixes = importlib.machinery.SOURCE_SUFFIXES
loader = importlib.machinery.SourceFileLoader
lazy_loader = importlib.util.LazyLoader.factory(loader)
finder = importlib.machinery.FileFinder(path, (lazy_loader, suffixes))"
parser.expr(source),"The expr() function parses the parameter source as if it were an input
to compile(source, 'file.py', 'eval').  If the parse succeeds, an ST object
is created to hold the internal parse tree representation, otherwise an
appropriate exception is raised."
parser.suite(source),"The suite() function parses the parameter source as if it were an input
to compile(source, 'file.py', 'exec').  If the parse succeeds, an ST object
is created to hold the internal parse tree representation, otherwise an
appropriate exception is raised."
parser.sequence2st(sequence),"This function accepts a parse tree represented as a sequence and builds an
internal representation if possible.  If it can validate that the tree conforms
to the Python grammar and all nodes are valid node types in the host version of
Python, an ST object is created from the internal representation and returned
to the called.  If there is a problem creating the internal representation, or
if the tree cannot be validated, a ParserError exception is raised.  An
ST object created this way should not be assumed to compile correctly; normal
exceptions raised by compilation may still be initiated when the ST object is
passed to compilest().  This may indicate problems not related to syntax
(such as a MemoryError exception), but may also be due to constructs such
as the result of parsing del f(0), which escapes the Python parser but is
checked by the bytecode compiler.
Sequences representing terminal tokens may be represented as either two-element
lists of the form (1, 'name') or as three-element lists of the form (1,
'name', 56).  If the third element is present, it is assumed to be a valid
line number.  The line number may be specified for any subset of the terminal
symbols in the input tree."
parser.tuple2st(sequence),"This is the same function as sequence2st().  This entry point is
maintained for backward compatibility."
"parser.st2list(st, line_info=False, col_info=False)","This function accepts an ST object from the caller in st and returns a
Python list representing the equivalent parse tree.  The resulting list
representation can be used for inspection or the creation of a new parse tree in
list form.  This function does not fail so long as memory is available to build
the list representation.  If the parse tree will only be used for inspection,
st2tuple() should be used instead to reduce memory consumption and
fragmentation.  When the list representation is required, this function is
significantly faster than retrieving a tuple representation and converting that
to nested lists.
If line_info is true, line number information will be included for all
terminal tokens as a third element of the list representing the token.  Note
that the line number provided specifies the line on which the token ends.
This information is omitted if the flag is false or omitted."
"parser.st2tuple(st, line_info=False, col_info=False)","This function accepts an ST object from the caller in st and returns a
Python tuple representing the equivalent parse tree.  Other than returning a
tuple instead of a list, this function is identical to st2list().
If line_info is true, line number information will be included for all
terminal tokens as a third element of the list representing the token.  This
information is omitted if the flag is false or omitted."
"parser.compilest(st, filename='<syntax-tree>')","The Python byte compiler can be invoked on an ST object to produce code objects
which can be used as part of a call to the built-in exec() or eval()
functions. This function provides the interface to the compiler, passing the
internal parse tree from st to the parser, using the source file name
specified by the filename parameter. The default value supplied for filename
indicates that the source was an ST object.
Compiling an ST object may result in exceptions related to compilation; an
example would be a SyntaxError caused by the parse tree for del f(0):
this statement is considered legal within the formal grammar for Python but is
not a legal language construct.  The SyntaxError raised for this
condition is actually generated by the Python byte-compiler normally, which is
why it can be raised at this point by the parser module.  Most causes of
compilation failure can be diagnosed programmatically by inspection of the parse
tree."
parser.isexpr(st),"When st represents an 'eval' form, this function returns True, otherwise
it returns False.  This is useful, since code objects normally cannot be queried
for this information using existing built-in functions.  Note that the code
objects created by compilest() cannot be queried like this either, and
are identical to those created by the built-in compile() function."
parser.issuite(st),"This function mirrors isexpr() in that it reports whether an ST object
represents an 'exec' form, commonly known as a “suite.”  It is not safe to
assume that this function is equivalent to not isexpr(st), as additional
syntactic fragments may be supported in the future."
ST.compile(filename='<syntax-tree>'),"Same as compilest(st, filename)."
ST.isexpr(),Same as isexpr(st).
ST.issuite(),Same as issuite(st).
"ST.tolist(line_info=False, col_info=False)","Same as st2list(st, line_info, col_info)."
"ST.totuple(line_info=False, col_info=False)","Same as st2tuple(st, line_info, col_info)."
"ast.parse(source, filename='<unknown>', mode='exec', *, type_comments=False, feature_version=None)","Parse the source into an AST node.  Equivalent to compile(source,
filename, mode, ast.PyCF_ONLY_AST).
If type_comments=True is given, the parser is modified to check
and return type comments as specified by PEP 484 and PEP 526.
This is equivalent to adding ast.PyCF_TYPE_COMMENTS to the
flags passed to compile().  This will report syntax errors
for misplaced type comments.  Without this flag, type comments will
be ignored, and the type_comment field on selected AST nodes
will always be None.  In addition, the locations of # type:
ignore comments will be returned as the type_ignores
attribute of Module (otherwise it is always an empty list).
In addition, if mode is 'func_type', the input syntax is
modified to correspond to PEP 484 “signature type comments”,
e.g. (str, int) -> List[str].
Also, setting feature_version to a tuple (major, minor)
will attempt to parse using that Python version’s grammar.
Currently major must equal to 3.  For example, setting
feature_version=(3, 4) will allow the use of async and
await as variable names.  The lowest supported version is
(3, 4); the highest is sys.version_info[0:2].

Warning
It is possible to crash the Python interpreter with a
sufficiently large/complex string due to stack depth limitations
in Python’s AST compiler.


Changed in version 3.8: Added type_comments, mode='func_type' and feature_version."
ast.literal_eval(node_or_string),"Safely evaluate an expression node or a string containing a Python literal or
container display.  The string or node provided may only consist of the
following Python literal structures: strings, bytes, numbers, tuples, lists,
dicts, sets, booleans, and None.
This can be used for safely evaluating strings containing Python values from
untrusted sources without the need to parse the values oneself.  It is not
capable of evaluating arbitrarily complex expressions, for example involving
operators or indexing.

Warning
It is possible to crash the Python interpreter with a
sufficiently large/complex string due to stack depth limitations
in Python’s AST compiler.


Changed in version 3.2: Now allows bytes and set literals."
"ast.get_docstring(node, clean=True)","Return the docstring of the given node (which must be a
FunctionDef, AsyncFunctionDef, ClassDef,
or Module node), or None if it has no docstring.
If clean is true, clean up the docstring’s indentation with
inspect.cleandoc().

Changed in version 3.5: AsyncFunctionDef is now supported."
"ast.get_source_segment(source, node, *, padded=False)","Get source code segment of the source that generated node.
If some location information (lineno, end_lineno,
col_offset, or end_col_offset) is missing, return None.
If padded is True, the first line of a multi-line statement will
be padded with spaces to match its original position.

New in version 3.8."
ast.fix_missing_locations(node),"When you compile a node tree with compile(), the compiler expects
lineno and col_offset attributes for every node that supports
them.  This is rather tedious to fill in for generated nodes, so this helper
adds these attributes recursively where not already set, by setting them to
the values of the parent node.  It works recursively starting at node."
"ast.increment_lineno(node, n=1)","Increment the line number and end line number of each node in the tree
starting at node by n. This is useful to “move code” to a different
location in a file."
"ast.copy_location(new_node, old_node)","Copy source location (lineno, col_offset, end_lineno,
and end_col_offset) from old_node to new_node if possible,
and return new_node."
ast.iter_fields(node),"Yield a tuple of (fieldname, value) for each field in node._fields
that is present on node."
ast.iter_child_nodes(node),"Yield all direct child nodes of node, that is, all fields that are nodes
and all items of fields that are lists of nodes."
ast.walk(node),"Recursively yield all descendant nodes in the tree starting at node
(including node itself), in no specified order.  This is useful if you only
want to modify nodes in place and don’t care about the context."
"ast.dump(node, annotate_fields=True, include_attributes=False)","Return a formatted dump of the tree in node.  This is mainly useful for
debugging purposes.  If annotate_fields is true (by default),
the returned string will show the names and the values for fields.
If annotate_fields is false, the result string will be more compact by
omitting unambiguous field names.  Attributes such as line
numbers and column offsets are not dumped by default.  If this is wanted,
include_attributes can be set to true."
visit(node),"Visit a node.  The default implementation calls the method called
self.visit_classname where classname is the name of the node
class, or generic_visit() if that method doesn’t exist."
generic_visit(node),"This visitor calls visit() on all children of the node.
Note that child nodes of nodes that have a custom visitor method won’t be
visited unless the visitor calls generic_visit() or visits them
itself."
"symtable.symtable(code, filename, compile_type)","Return the toplevel SymbolTable for the Python source code.
filename is the name of the file containing the code.  compile_type is
like the mode argument to compile()."
get_type(),"Return the type of the symbol table.  Possible values are 'class',
'module', and 'function'."
get_id(),Return the table’s identifier.
get_name(),"Return the table’s name.  This is the name of the class if the table is
for a class, the name of the function if the table is for a function, or
'top' if the table is global (get_type() returns 'module')."
get_lineno(),Return the number of the first line in the block this table represents.
is_optimized(),Return True if the locals in this table can be optimized.
is_nested(),Return True if the block is a nested class or function.
has_children(),"Return True if the block has nested namespaces within it.  These can
be obtained with get_children()."
has_exec(),Return True if the block uses exec.
get_identifiers(),Return a list of names of symbols in this table.
lookup(name),Lookup name in the table and return a Symbol instance.
get_symbols(),Return a list of Symbol instances for names in the table.
get_children(),Return a list of the nested symbol tables.
get_parameters(),Return a tuple containing names of parameters to this function.
get_locals(),Return a tuple containing names of locals in this function.
get_globals(),Return a tuple containing names of globals in this function.
get_nonlocals(),Return a tuple containing names of nonlocals in this function.
get_frees(),Return a tuple containing names of free variables in this function.
get_methods(),Return a tuple containing the names of methods declared in the class.
get_name(),Return the symbol’s name.
is_referenced(),Return True if the symbol is used in its block.
is_imported(),Return True if the symbol is created from an import statement.
is_parameter(),Return True if the symbol is a parameter.
is_global(),Return True if the symbol is global.
is_nonlocal(),Return True if the symbol is nonlocal.
is_declared_global(),Return True if the symbol is declared global with a global statement.
is_local(),Return True if the symbol is local to its block.
is_free(),"Return True if the symbol is referenced in its block, but not assigned
to."
is_assigned(),Return True if the symbol is assigned to in its block.
is_namespace(),"Return True if name binding introduces new namespace.
If the name is used as the target of a function or class statement, this
will be true.
For example:
>>> table = symtable.symtable(""def some_func(): pass"", ""string"", ""exec"")
>>> table.lookup(""some_func"").is_namespace()
True


Note that a single name can be bound to multiple objects.  If the result
is True, the name may also be bound to other objects, like an int or
list, that does not introduce a new namespace."
get_namespaces(),Return a list of namespaces bound to this name.
get_namespace(),"Return the namespace bound to this name.  If more than one namespace is
bound, ValueError is raised."
token.ISTERMINAL(x),Return True for terminal token values.
token.ISNONTERMINAL(x),Return True for non-terminal token values.
token.ISEOF(x),Return True if x is the marker indicating the end of input.
keyword.iskeyword(s),Return True if s is a Python keyword.
tokenize.tokenize(readline),"The tokenize() generator requires one argument, readline, which
must be a callable object which provides the same interface as the
io.IOBase.readline() method of file objects.  Each call to the
function should return one line of input as bytes.
The generator produces 5-tuples with these members: the token type; the
token string; a 2-tuple (srow, scol) of ints specifying the row and
column where the token begins in the source; a 2-tuple (erow, ecol) of
ints specifying the row and column where the token ends in the source; and
the line on which the token was found. The line passed (the last tuple item)
is the physical line.  The 5 tuple is returned as a named tuple
with the field names:
type string start end line.
The returned named tuple has an additional property named
exact_type that contains the exact operator type for
OP tokens.  For all other token types exact_type
equals the named tuple type field.

Changed in version 3.1: Added support for named tuples.


Changed in version 3.3: Added support for exact_type.

tokenize() determines the source encoding of the file by looking for a
UTF-8 BOM or encoding cookie, according to PEP 263."
tokenize.generate_tokens(readline),"Tokenize a source reading unicode strings instead of bytes.
Like tokenize(), the readline argument is a callable returning
a single line of input. However, generate_tokens() expects readline
to return a str object rather than bytes.
The result is an iterator yielding named tuples, exactly like
tokenize(). It does not yield an ENCODING token."
tokenize.untokenize(iterable),"Converts tokens back into Python source code.  The iterable must return
sequences with at least two elements, the token type and the token string.
Any additional sequence elements are ignored.
The reconstructed script is returned as a single string.  The result is
guaranteed to tokenize back to match the input so that the conversion is
lossless and round-trips are assured.  The guarantee applies only to the
token type and token string as the spacing between tokens (column
positions) may change.
It returns bytes, encoded using the ENCODING token, which
is the first token sequence output by tokenize(). If there is no
encoding token in the input, it returns a str instead."
tokenize.detect_encoding(readline),"The detect_encoding() function is used to detect the encoding that
should be used to decode a Python source file. It requires one argument,
readline, in the same way as the tokenize() generator.
It will call readline a maximum of twice, and return the encoding used
(as a string) and a list of any lines (not decoded from bytes) it has read
in.
It detects the encoding from the presence of a UTF-8 BOM or an encoding
cookie as specified in PEP 263. If both a BOM and a cookie are present,
but disagree, a SyntaxError will be raised. Note that if the BOM is found,
'utf-8-sig' will be returned as an encoding.
If no encoding is specified, then the default of 'utf-8' will be
returned.
Use open() to open Python source files: it uses
detect_encoding() to detect the file encoding."
tokenize.open(filename),"Open a file in read only mode using the encoding detected by
detect_encoding().

New in version 3.2."
tabnanny.check(file_or_dir),"If file_or_dir is a directory and not a symbolic link, then recursively
descend the directory tree named by file_or_dir, checking all .py
files along the way.  If file_or_dir is an ordinary Python source file, it
is checked for whitespace related problems.  The diagnostic messages are
written to standard output using the print() function."
tabnanny.process_tokens(tokens),"This function is used by check() to process tokens generated by the
tokenize module."
"pyclbr.readmodule(module, path=None)","Return a dictionary mapping module-level class names to class
descriptors.  If possible, descriptors for imported base classes are
included.  Parameter module is a string with the name of the module
to read; it may be the name of a module within a package.  If given,
path is a sequence of directory paths prepended to sys.path,
which is used to locate the module source code."
"pyclbr.readmodule_ex(module, path=None)","Return a dictionary-based tree containing a function or class
descriptors for each function and class defined in the module with a
def or class statement.  The returned dictionary maps
module-level function and class names to their descriptors.  Nested
objects are entered into the children dictionary of their parent.  As
with readmodule, module names the module to be read and path is
prepended to sys.path.  If the module being read is a package, the
returned dictionary has a key '__path__' whose value is a list
containing the package search path."
"py_compile.compile(file, cfile=None, dfile=None, doraise=False, optimize=-1, invalidation_mode=PycInvalidationMode.TIMESTAMP, quiet=0)","Compile a source file to byte-code and write out the byte-code cache file.
The source code is loaded from the file named file.  The byte-code is
written to cfile, which defaults to the PEP 3147/PEP 488 path, ending
in .pyc.
For example, if file is /foo/bar/baz.py cfile will default to
/foo/bar/__pycache__/baz.cpython-32.pyc for Python 3.2.  If dfile is
specified, it is used as the name of the source file in error messages when
instead of file.  If doraise is true, a PyCompileError is raised
when an error is encountered while compiling file. If doraise is false
(the default), an error string is written to sys.stderr, but no exception
is raised.  This function returns the path to byte-compiled file, i.e.
whatever cfile value was used.
The doraise and quiet arguments determine how errors are handled while
compiling file. If quiet is 0 or 1, and doraise is false, the default
behaviour is enabled: an error string is written to sys.stderr, and the
function returns None instead of a path. If doraise is true,
a PyCompileError is raised instead. However if quiet is 2,
no message is written, and doraise has no effect.
If the path that cfile becomes (either explicitly specified or computed)
is a symlink or non-regular file, FileExistsError will be raised.
This is to act as a warning that import will turn those paths into regular
files if it is allowed to write byte-compiled files to those paths. This is
a side-effect of import using file renaming to place the final byte-compiled
file into place to prevent concurrent file writing issues.
optimize controls the optimization level and is passed to the built-in
compile() function.  The default of -1 selects the optimization
level of the current interpreter.
invalidation_mode should be a member of the PycInvalidationMode
enum and controls how the generated bytecode cache is invalidated at
runtime.  The default is PycInvalidationMode.CHECKED_HASH if
the SOURCE_DATE_EPOCH environment variable is set, otherwise
the default is PycInvalidationMode.TIMESTAMP.

Changed in version 3.2: Changed default value of cfile to be PEP 3147-compliant.  Previous
default was file + 'c' ('o' if optimization was enabled).
Also added the optimize parameter.


Changed in version 3.4: Changed code to use importlib for the byte-code cache file writing.
This means file creation/writing semantics now match what importlib
does, e.g. permissions, write-and-move semantics, etc. Also added the
caveat that FileExistsError is raised if cfile is a symlink or
non-regular file.


Changed in version 3.7: The invalidation_mode parameter was added as specified in PEP 552.
If the SOURCE_DATE_EPOCH environment variable is set,
invalidation_mode will be forced to
PycInvalidationMode.CHECKED_HASH.


Changed in version 3.7.2: The SOURCE_DATE_EPOCH environment variable no longer
overrides the value of the invalidation_mode argument, and determines
its default value instead.


Changed in version 3.8: The quiet parameter was added."
py_compile.main(args=None),"Compile several source files.  The files named in args (or on the command
line, if args is None) are compiled and the resulting byte-code is
cached in the normal manner.  This function does not search a directory
structure to locate source files; it only compiles files named explicitly.
If '-' is the only parameter in args, the list of files is taken from
standard input.

Changed in version 3.2: Added support for '-'."
"compileall.compile_dir(dir, maxlevels=10, ddir=None, force=False, rx=None, quiet=0, legacy=False, optimize=-1, workers=1, invalidation_mode=None)","Recursively descend the directory tree named by dir, compiling all .py
files along the way. Return a true value if all the files compiled successfully,
and a false value otherwise.
The maxlevels parameter is used to limit the depth of the recursion; it
defaults to 10.
If ddir is given, it is prepended to the path to each file being compiled
for use in compilation time tracebacks, and is also compiled in to the
byte-code file, where it will be used in tracebacks and other messages in
cases where the source file does not exist at the time the byte-code file is
executed.
If force is true, modules are re-compiled even if the timestamps are up to
date.
If rx is given, its search method is called on the complete path to each
file considered for compilation, and if it returns a true value, the file
is skipped.
If quiet is False or 0 (the default), the filenames and other
information are printed to standard out. Set to 1, only errors are
printed. Set to 2, all output is suppressed.
If legacy is true, byte-code files are written to their legacy locations
and names, which may overwrite byte-code files created by another version of
Python.  The default is to write files to their PEP 3147 locations and
names, which allows byte-code files from multiple versions of Python to
coexist.
optimize specifies the optimization level for the compiler.  It is passed to
the built-in compile() function.
The argument workers specifies how many workers are used to
compile files in parallel. The default is to not use multiple workers.
If the platform can’t use multiple workers and workers argument is given,
then sequential compilation will be used as a fallback.  If workers
is 0, the number of cores in the system is used.  If workers is
lower than 0, a ValueError will be raised.
invalidation_mode should be a member of the
py_compile.PycInvalidationMode enum and controls how the generated
pycs are invalidated at runtime.

Changed in version 3.2: Added the legacy and optimize parameter.


Changed in version 3.5: Added the workers parameter.


Changed in version 3.5: quiet parameter was changed to a multilevel value.


Changed in version 3.5: The legacy parameter only writes out .pyc files, not .pyo files
no matter what the value of optimize is.


Changed in version 3.6: Accepts a path-like object.


Changed in version 3.7: The invalidation_mode parameter was added.


Changed in version 3.7.2: The invalidation_mode parameter’s default value is updated to None.


Changed in version 3.8: Setting workers to 0 now chooses the optimal number of cores."
"compileall.compile_file(fullname, ddir=None, force=False, rx=None, quiet=0, legacy=False, optimize=-1, invalidation_mode=None)","Compile the file with path fullname. Return a true value if the file
compiled successfully, and a false value otherwise.
If ddir is given, it is prepended to the path to the file being compiled
for use in compilation time tracebacks, and is also compiled in to the
byte-code file, where it will be used in tracebacks and other messages in
cases where the source file does not exist at the time the byte-code file is
executed.
If rx is given, its search method is passed the full path name to the
file being compiled, and if it returns a true value, the file is not
compiled and True is returned.
If quiet is False or 0 (the default), the filenames and other
information are printed to standard out. Set to 1, only errors are
printed. Set to 2, all output is suppressed.
If legacy is true, byte-code files are written to their legacy locations
and names, which may overwrite byte-code files created by another version of
Python.  The default is to write files to their PEP 3147 locations and
names, which allows byte-code files from multiple versions of Python to
coexist.
optimize specifies the optimization level for the compiler.  It is passed to
the built-in compile() function.
invalidation_mode should be a member of the
py_compile.PycInvalidationMode enum and controls how the generated
pycs are invalidated at runtime.

New in version 3.2.


Changed in version 3.5: quiet parameter was changed to a multilevel value.


Changed in version 3.5: The legacy parameter only writes out .pyc files, not .pyo files
no matter what the value of optimize is.


Changed in version 3.7: The invalidation_mode parameter was added.


Changed in version 3.7.2: The invalidation_mode parameter’s default value is updated to None."
"compileall.compile_path(skip_curdir=True, maxlevels=0, force=False, quiet=0, legacy=False, optimize=-1, invalidation_mode=None)","Byte-compile all the .py files found along sys.path. Return a
true value if all the files compiled successfully, and a false value otherwise.
If skip_curdir is true (the default), the current directory is not included
in the search.  All other parameters are passed to the compile_dir()
function.  Note that unlike the other compile functions, maxlevels
defaults to 0.

Changed in version 3.2: Added the legacy and optimize parameter.


Changed in version 3.5: quiet parameter was changed to a multilevel value.


Changed in version 3.5: The legacy parameter only writes out .pyc files, not .pyo files
no matter what the value of optimize is.


Changed in version 3.7: The invalidation_mode parameter was added.


Changed in version 3.7.2: The invalidation_mode parameter’s default value is updated to None."
dis.code_info(x),"Return a formatted multi-line string with detailed code object information
for the supplied function, generator, asynchronous generator, coroutine,
method, source code string or code object.
Note that the exact contents of code info strings are highly implementation
dependent and they may change arbitrarily across Python VMs or Python
releases.

New in version 3.2.


Changed in version 3.7: This can now handle coroutine and asynchronous generator objects."
"dis.show_code(x, *, file=None)","Print detailed code object information for the supplied function, method,
source code string or code object to file (or sys.stdout if file
is not specified).
This is a convenient shorthand for print(code_info(x), file=file),
intended for interactive exploration at the interpreter prompt.

New in version 3.2.


Changed in version 3.4: Added file parameter."
"dis.dis(x=None, *, file=None, depth=None)","Disassemble the x object.  x can denote either a module, a class, a
method, a function, a generator, an asynchronous generator, a coroutine,
a code object, a string of source code or a byte sequence of raw bytecode.
For a module, it disassembles all functions. For a class, it disassembles
all methods (including class and static methods). For a code object or
sequence of raw bytecode, it prints one line per bytecode instruction.
It also recursively disassembles nested code objects (the code of
comprehensions, generator expressions and nested functions, and the code
used for building nested classes).
Strings are first compiled to code objects with the compile()
built-in function before being disassembled.  If no object is provided, this
function disassembles the last traceback.
The disassembly is written as text to the supplied file argument if
provided and to sys.stdout otherwise.
The maximal depth of recursion is limited by depth unless it is None.
depth=0 means no recursion.

Changed in version 3.4: Added file parameter.


Changed in version 3.7: Implemented recursive disassembling and added depth parameter.


Changed in version 3.7: This can now handle coroutine and asynchronous generator objects."
"dis.distb(tb=None, *, file=None)","Disassemble the top-of-stack function of a traceback, using the last
traceback if none was passed.  The instruction causing the exception is
indicated.
The disassembly is written as text to the supplied file argument if
provided and to sys.stdout otherwise.

Changed in version 3.4: Added file parameter."
"dis.disassemble(code, lasti=-1, *, file=None)","Disassemble a code object, indicating the last instruction if lasti was
provided.  The output is divided in the following columns:

the line number, for the first instruction of each line
the current instruction, indicated as -->,
a labelled instruction, indicated with >>,
the address of the instruction,
the operation code name,
operation parameters, and
interpretation of the parameters in parentheses.

The parameter interpretation recognizes local and global variable names,
constant values, branch targets, and compare operators.
The disassembly is written as text to the supplied file argument if
provided and to sys.stdout otherwise.

Changed in version 3.4: Added file parameter."
"dis.get_instructions(x, *, first_line=None)","Return an iterator over the instructions in the supplied function, method,
source code string or code object.
The iterator generates a series of Instruction named tuples giving
the details of each operation in the supplied code.
If first_line is not None, it indicates the line number that should be
reported for the first source line in the disassembled code.  Otherwise, the
source line information (if any) is taken directly from the disassembled code
object.

New in version 3.4."
dis.findlinestarts(code),"This generator function uses the co_firstlineno and co_lnotab
attributes of the code object code to find the offsets which are starts of
lines in the source code.  They are generated as (offset, lineno) pairs.
See Objects/lnotab_notes.txt for the co_lnotab format and
how to decode it.

Changed in version 3.6: Line numbers can be decreasing. Before, they were always increasing."
dis.findlabels(code),"Detect all offsets in the code object code which are jump targets, and
return a list of these offsets."
"dis.stack_effect(opcode, oparg=None, *, jump=None)","Compute the stack effect of opcode with argument oparg.
If the code has a jump target and jump is True, stack_effect()
will return the stack effect of jumping.  If jump is False,
it will return the stack effect of not jumping. And if jump is
None (default), it will return the maximal stack effect of both cases.

New in version 3.4.


Changed in version 3.8: Added jump parameter."
classmethod from_traceback(tb),"Construct a Bytecode instance from the given traceback, setting
current_offset to the instruction responsible for the exception."
dis(),"Return a formatted view of the bytecode operations (the same as printed by
dis.dis(), but returned as a multi-line string)."
info(),"Return a formatted multi-line string with detailed information about the
code object, like code_info()."
"pickletools.dis(pickle, out=None, memo=None, indentlevel=4, annotate=0)","Outputs a symbolic disassembly of the pickle to the file-like
object out, defaulting to sys.stdout.  pickle can be a
string or a file-like object.  memo can be a Python dictionary
that will be used as the pickle’s memo; it can be used to perform
disassemblies across multiple pickles created by the same
pickler. Successive levels, indicated by MARK opcodes in the
stream, are indented by indentlevel spaces.  If a nonzero value
is given to annotate, each opcode in the output is annotated with
a short description.  The value of annotate is used as a hint for
the column where annotation should start.

New in version 3.2: The annotate argument."
pickletools.genops(pickle),"Provides an iterator over all of the opcodes in a pickle, returning a
sequence of (opcode, arg, pos) triples.  opcode is an instance of an
OpcodeInfo class; arg is the decoded value, as a Python object, of
the opcode’s argument; pos is the position at which this opcode is located.
pickle can be a string or a file-like object."
pickletools.optimize(picklestring),"Returns a new equivalent pickle string after eliminating unused PUT
opcodes. The optimized pickle is shorter, takes less transmission time,
requires less storage space, and unpickles more efficiently."
formatter.end_paragraph(blanklines),"Close any open paragraphs and insert at least blanklines before the next
paragraph."
formatter.add_line_break(),"Add a hard line break if one does not already exist.  This does not break the
logical paragraph."
"formatter.add_hor_rule(*args, **kw)","Insert a horizontal rule in the output.  A hard break is inserted if there is
data in the current paragraph, but the logical paragraph is not broken.  The
arguments and keywords are passed on to the writer’s send_line_break()
method."
formatter.add_flowing_data(data),"Provide data which should be formatted with collapsed whitespace. Whitespace
from preceding and successive calls to add_flowing_data() is considered as
well when the whitespace collapse is performed.  The data which is passed to
this method is expected to be word-wrapped by the output device.  Note that any
word-wrapping still must be performed by the writer object due to the need to
rely on device and font information."
formatter.add_literal_data(data),"Provide data which should be passed to the writer unchanged. Whitespace,
including newline and tab characters, are considered legal in the value of
data."
"formatter.add_label_data(format, counter)","Insert a label which should be placed to the left of the current left margin.
This should be used for constructing bulleted or numbered lists.  If the
format value is a string, it is interpreted as a format specification for
counter, which should be an integer. The result of this formatting becomes the
value of the label; if format is not a string it is used as the label value
directly. The label value is passed as the only argument to the writer’s
send_label_data() method.  Interpretation of non-string label values is
dependent on the associated writer.
Format specifications are strings which, in combination with a counter value,
are used to compute label values.  Each character in the format string is copied
to the label value, with some characters recognized to indicate a transform on
the counter value.  Specifically, the character '1' represents the counter
value formatter as an Arabic number, the characters 'A' and 'a'
represent alphabetic representations of the counter value in upper and lower
case, respectively, and 'I' and 'i' represent the counter value in Roman
numerals, in upper and lower case.  Note that the alphabetic and roman
transforms require that the counter value be greater than zero."
formatter.flush_softspace(),"Send any pending whitespace buffered from a previous call to
add_flowing_data() to the associated writer object.  This should be called
before any direct manipulation of the writer object."
formatter.push_alignment(align),"Push a new alignment setting onto the alignment stack.  This may be
AS_IS if no change is desired.  If the alignment value is changed from
the previous setting, the writer’s new_alignment() method is called with
the align value."
formatter.pop_alignment(),Restore the previous alignment.
"formatter.push_font((size, italic, bold, teletype))","Change some or all font properties of the writer object.  Properties which are
not set to AS_IS are set to the values passed in while others are
maintained at their current settings.  The writer’s new_font() method is
called with the fully resolved font specification."
formatter.pop_font(),Restore the previous font.
formatter.push_margin(margin),"Increase the number of left margin indentations by one, associating the logical
tag margin with the new indentation.  The initial margin level is 0.
Changed values of the logical tag must be true values; false values other than
AS_IS are not sufficient to change the margin."
formatter.pop_margin(),Restore the previous margin.
formatter.push_style(*styles),"Push any number of arbitrary style specifications.  All styles are pushed onto
the styles stack in order.  A tuple representing the entire stack, including
AS_IS values, is passed to the writer’s new_styles() method."
formatter.pop_style(n=1),"Pop the last n style specifications passed to push_style().  A tuple
representing the revised stack, including AS_IS values, is passed to
the writer’s new_styles() method."
formatter.set_spacing(spacing),Set the spacing style for the writer.
formatter.assert_line_data(flag=1),"Inform the formatter that data has been added to the current paragraph
out-of-band.  This should be used when the writer has been manipulated
directly.  The optional flag argument can be set to false if the writer
manipulations produced a hard line break at the end of the output."
writer.flush(),Flush any buffered output or device control events.
writer.new_alignment(align),"Set the alignment style.  The align value can be any object, but by convention
is a string or None, where None indicates that the writer’s “preferred”
alignment should be used. Conventional align values are 'left',
'center', 'right', and 'justify'."
writer.new_font(font),"Set the font style.  The value of font will be None, indicating that the
device’s default font should be used, or a tuple of the form (size,
italic, bold, teletype).  Size will be a string indicating the size of
font that should be used; specific strings and their interpretation must be
defined by the application.  The italic, bold, and teletype values are
Boolean values specifying which of those font attributes should be used."
"writer.new_margin(margin, level)","Set the margin level to the integer level and the logical tag to margin.
Interpretation of the logical tag is at the writer’s discretion; the only
restriction on the value of the logical tag is that it not be a false value for
non-zero values of level."
writer.new_spacing(spacing),Set the spacing style to spacing.
writer.new_styles(styles),"Set additional styles.  The styles value is a tuple of arbitrary values; the
value AS_IS should be ignored.  The styles tuple may be interpreted
either as a set or as a stack depending on the requirements of the application
and writer implementation."
writer.send_line_break(),Break the current line.
writer.send_paragraph(blankline),"Produce a paragraph separation of at least blankline blank lines, or the
equivalent.  The blankline value will be an integer.  Note that the
implementation will receive a call to send_line_break() before this call
if a line break is needed;  this method should not include ending the last line
of the paragraph. It is only responsible for vertical spacing between
paragraphs."
"writer.send_hor_rule(*args, **kw)","Display a horizontal rule on the output device.  The arguments to this method
are entirely application- and writer-specific, and should be interpreted with
care.  The method implementation may assume that a line break has already been
issued via send_line_break()."
writer.send_flowing_data(data),"Output character data which may be word-wrapped and re-flowed as needed.  Within
any sequence of calls to this method, the writer may assume that spans of
multiple whitespace characters have been collapsed to single space characters."
writer.send_literal_data(data),"Output character data which has already been formatted for display.  Generally,
this should be interpreted to mean that line breaks indicated by newline
characters should be preserved and no new line breaks should be introduced.  The
data may contain embedded newline and tab characters, unlike data provided to
the send_formatted_data() interface."
writer.send_label_data(data),"Set data to the left of the current left margin, if possible. The value of
data is not restricted; treatment of non-string values is entirely
application- and writer-dependent.  This method will only be called at the
beginning of a line."
"msilib.FCICreate(cabname, files)","Create a new CAB file named cabname. files must be a list of tuples, each
containing the name of the file on disk, and the name of the file inside the CAB
file.
The files are added to the CAB file in the order they appear in the list. All
files are added into a single CAB file, using the MSZIP compression algorithm.
Callbacks to Python for the various steps of MSI creation are currently not
exposed."
msilib.UuidCreate(),"Return the string representation of a new unique identifier. This wraps the
Windows API functions UuidCreate() and UuidToString()."
"msilib.OpenDatabase(path, persist)","Return a new database object by calling MsiOpenDatabase.   path is the file
name of the MSI file; persist can be one of the constants
MSIDBOPEN_CREATEDIRECT, MSIDBOPEN_CREATE, MSIDBOPEN_DIRECT,
MSIDBOPEN_READONLY, or MSIDBOPEN_TRANSACT, and may include the flag
MSIDBOPEN_PATCHFILE. See the Microsoft documentation for the meaning of
these flags; depending on the flags, an existing database is opened, or a new
one created."
msilib.CreateRecord(count),"Return a new record object by calling MSICreateRecord(). count is the
number of fields of the record."
"msilib.init_database(name, schema, ProductName, ProductCode, ProductVersion, Manufacturer)","Create and return a new database name, initialize it with schema, and set
the properties ProductName, ProductCode, ProductVersion, and
Manufacturer.
schema must be a module object containing tables and
_Validation_records attributes; typically, msilib.schema should be
used.
The database will contain just the schema and the validation records when this
function returns."
"msilib.add_data(database, table, records)","Add all records to the table named table in database.
The table argument must be one of the predefined tables in the MSI schema,
e.g. 'Feature', 'File', 'Component', 'Dialog', 'Control',
etc.
records should be a list of tuples, each one containing all fields of a
record according to the schema of the table.  For optional fields,
None can be passed.
Field values can be ints, strings, or instances of the Binary class."
"msilib.add_tables(database, module)","Add all table content from module to database. module must contain an
attribute tables listing all tables for which content should be added, and one
attribute per table that has the actual content.
This is typically used to install the sequence tables."
"msilib.add_stream(database, name, path)","Add the file path into the _Stream table of database, with the stream
name name."
msilib.gen_uuid(),"Return a new UUID, in the format that MSI typically requires (i.e. in curly
braces, and with all hexdigits in upper-case)."
Database.OpenView(sql),"Return a view object, by calling MSIDatabaseOpenView(). sql is the SQL
statement to execute."
Database.Commit(),"Commit the changes pending in the current transaction, by calling
MSIDatabaseCommit()."
Database.GetSummaryInformation(count),"Return a new summary information object, by calling
MsiGetSummaryInformation().  count is the maximum number of updated
values."
Database.Close(),"Close the database object, through MsiCloseHandle().

New in version 3.7."
View.Execute(params),"Execute the SQL query of the view, through MSIViewExecute(). If
params is not None, it is a record describing actual values of the
parameter tokens in the query."
View.GetColumnInfo(kind),"Return a record describing the columns of the view, through calling
MsiViewGetColumnInfo(). kind can be either MSICOLINFO_NAMES or
MSICOLINFO_TYPES."
View.Fetch(),"Return a result record of the query, through calling MsiViewFetch()."
"View.Modify(kind, data)","Modify the view, by calling MsiViewModify(). kind can be one of
MSIMODIFY_SEEK, MSIMODIFY_REFRESH, MSIMODIFY_INSERT,
MSIMODIFY_UPDATE, MSIMODIFY_ASSIGN, MSIMODIFY_REPLACE,
MSIMODIFY_MERGE, MSIMODIFY_DELETE, MSIMODIFY_INSERT_TEMPORARY,
MSIMODIFY_VALIDATE, MSIMODIFY_VALIDATE_NEW,
MSIMODIFY_VALIDATE_FIELD, or MSIMODIFY_VALIDATE_DELETE.
data must be a record describing the new data."
View.Close(),"Close the view, through MsiViewClose()."
SummaryInformation.GetProperty(field),"Return a property of the summary, through MsiSummaryInfoGetProperty().
field is the name of the property, and can be one of the constants
PID_CODEPAGE, PID_TITLE, PID_SUBJECT, PID_AUTHOR,
PID_KEYWORDS, PID_COMMENTS, PID_TEMPLATE, PID_LASTAUTHOR,
PID_REVNUMBER, PID_LASTPRINTED, PID_CREATE_DTM,
PID_LASTSAVE_DTM, PID_PAGECOUNT, PID_WORDCOUNT, PID_CHARCOUNT,
PID_APPNAME, or PID_SECURITY."
SummaryInformation.GetPropertyCount(),"Return the number of summary properties, through
MsiSummaryInfoGetPropertyCount()."
"SummaryInformation.SetProperty(field, value)","Set a property through MsiSummaryInfoSetProperty(). field can have the
same values as in GetProperty(), value is the new value of the property.
Possible value types are integer and string."
SummaryInformation.Persist(),"Write the modified properties to the summary information stream, using
MsiSummaryInfoPersist()."
Record.GetFieldCount(),"Return the number of fields of the record, through
MsiRecordGetFieldCount()."
Record.GetInteger(field),"Return the value of field as an integer where possible.  field must
be an integer."
Record.GetString(field),"Return the value of field as a string where possible.  field must
be an integer."
"Record.SetString(field, value)","Set field to value through MsiRecordSetString(). field must be an
integer; value a string."
"Record.SetStream(field, value)","Set field to the contents of the file named value, through
MsiRecordSetStream(). field must be an integer; value a string."
"Record.SetInteger(field, value)","Set field to value through MsiRecordSetInteger(). Both field and
value must be an integer."
Record.ClearData(),"Set all fields of the record to 0, through MsiRecordClearData()."
"append(full, file, logical)","Add the file with the pathname full to the CAB file, under the name
logical.  If there is already a file named logical, a new file name is
created.
Return the index of the file in the CAB file, and the new name of the file
inside the CAB file."
commit(database),"Generate a CAB file, add it as a stream to the MSI file, put it into the
Media table, and remove the generated file from the disk."
"start_component(component=None, feature=None, flags=None, keyfile=None, uuid=None)","Add an entry to the Component table, and make this component the current
component for this directory. If no component name is given, the directory
name is used. If no feature is given, the current feature is used. If no
flags are given, the directory’s default flags are used. If no keyfile
is given, the KeyPath is left null in the Component table."
"add_file(file, src=None, version=None, language=None)","Add a file to the current component of the directory, starting a new one
if there is no current component. By default, the file name in the source
and the file table will be identical. If the src file is specified, it
is interpreted relative to the current directory. Optionally, a version
and a language can be specified for the entry in the File table."
"glob(pattern, exclude=None)","Add a list of files to the current component as specified in the glob
pattern.  Individual files can be excluded in the exclude list."
remove_pyc(),Remove .pyc files on uninstall.
set_current(),"Make this feature the current feature of msilib. New components are
automatically added to the default feature, unless a feature is explicitly
specified."
"event(event, argument, condition=1, ordering=None)",Make an entry into the ControlEvent table for this control.
"mapping(event, attribute)",Make an entry into the EventMapping table for this control.
"condition(action, condition)",Make an entry into the ControlCondition table for this control.
"add(name, x, y, width, height, text, value=None)","Add a radio button named name to the group, at the coordinates x, y,
width, height, and with the label text. If value is None, it
defaults to name."
"control(name, type, x, y, width, height, attributes, property, text, control_next, help)","Return a new Control object. An entry in the Control table is
made with the specified parameters.
This is a generic method; for specific types, specialized methods are
provided."
"text(name, x, y, width, height, attributes, text)",Add and return a Text control.
"bitmap(name, x, y, width, height, text)",Add and return a Bitmap control.
"line(name, x, y, width, height)",Add and return a Line control.
"pushbutton(name, x, y, width, height, attributes, text, next_control)",Add and return a PushButton control.
"radiogroup(name, x, y, width, height, attributes, property, text, next_control)",Add and return a RadioButtonGroup control.
"checkbox(name, x, y, width, height, attributes, property, text, next_control)",Add and return a CheckBox control.
"msvcrt.locking(fd, mode, nbytes)","Lock part of a file based on file descriptor fd from the C runtime.  Raises
OSError on failure.  The locked region of the file extends from the
current file position for nbytes bytes, and may continue beyond the end of the
file.  mode must be one of the LK_* constants listed below. Multiple
regions in a file may be locked at the same time, but may not overlap.  Adjacent
regions are not merged; they must be unlocked individually.
Raises an auditing event msvcrt.locking with arguments fd, mode, nbytes."
"msvcrt.setmode(fd, flags)","Set the line-end translation mode for the file descriptor fd. To set it to
text mode, flags should be os.O_TEXT; for binary, it should be
os.O_BINARY."
"msvcrt.open_osfhandle(handle, flags)","Create a C runtime file descriptor from the file handle handle.  The flags
parameter should be a bitwise OR of os.O_APPEND, os.O_RDONLY,
and os.O_TEXT.  The returned file descriptor may be used as a parameter
to os.fdopen() to create a file object.
Raises an auditing event msvcrt.open_osfhandle with arguments handle, flags."
msvcrt.get_osfhandle(fd),"Return the file handle for the file descriptor fd.  Raises OSError if
fd is not recognized.
Raises an auditing event msvcrt.get_osfhandle with argument fd."
msvcrt.kbhit(),Return True if a keypress is waiting to be read.
msvcrt.getch(),"Read a keypress and return the resulting character as a byte string.
Nothing is echoed to the console.  This call will block if a keypress
is not already available, but will not wait for Enter to be
pressed. If the pressed key was a special function key, this will
return '\000' or '\xe0'; the next call will return the keycode.
The Control-C keypress cannot be read with this function."
msvcrt.getwch(),"Wide char variant of getch(), returning a Unicode value."
msvcrt.getche(),"Similar to getch(), but the keypress will be echoed if it  represents a
printable character."
msvcrt.getwche(),"Wide char variant of getche(), returning a Unicode value."
msvcrt.putch(char),Print the byte string char to the console without buffering.
msvcrt.putwch(unicode_char),"Wide char variant of putch(), accepting a Unicode value."
msvcrt.ungetch(char),"Cause the byte string char to be “pushed back” into the console buffer;
it will be the next character read by getch() or getche()."
msvcrt.ungetwch(unicode_char),"Wide char variant of ungetch(), accepting a Unicode value."
msvcrt.heapmin(),"Force the malloc() heap to clean itself up and return unused blocks to
the operating system.  On failure, this raises OSError."
winreg.CloseKey(hkey),"Closes a previously opened registry key.  The hkey argument specifies a
previously opened key.

Note
If hkey is not closed using this method (or via hkey.Close()), it is closed when the hkey object is destroyed by
Python."
"winreg.ConnectRegistry(computer_name, key)","Establishes a connection to a predefined registry handle on another computer,
and returns a handle object.
computer_name is the name of the remote computer, of the form
r""\\computername"".  If None, the local computer is used.
key is the predefined handle to connect to.
The return value is the handle of the opened key. If the function fails, an
OSError exception is raised.
Raises an auditing event winreg.ConnectRegistry with arguments computer_name, key.

Changed in version 3.3: See above."
"winreg.CreateKey(key, sub_key)","Creates or opens the specified key, returning a
handle object.
key is an already open key, or one of the predefined
HKEY_* constants.
sub_key is a string that names the key this method opens or creates.
If key is one of the predefined keys, sub_key may be None. In that
case, the handle returned is the same key handle passed in to the function.
If the key already exists, this function opens the existing key.
The return value is the handle of the opened key. If the function fails, an
OSError exception is raised.
Raises an auditing event winreg.CreateKey with arguments key, sub_key, access.
Raises an auditing event winreg.OpenKey/result with argument key.

Changed in version 3.3: See above."
"winreg.CreateKeyEx(key, sub_key, reserved=0, access=KEY_WRITE)","Creates or opens the specified key, returning a
handle object.
key is an already open key, or one of the predefined
HKEY_* constants.
sub_key is a string that names the key this method opens or creates.
reserved is a reserved integer, and must be zero. The default is zero.
access is an integer that specifies an access mask that describes the desired
security access for the key.  Default is KEY_WRITE.  See
Access Rights for other allowed values.
If key is one of the predefined keys, sub_key may be None. In that
case, the handle returned is the same key handle passed in to the function.
If the key already exists, this function opens the existing key.
The return value is the handle of the opened key. If the function fails, an
OSError exception is raised.
Raises an auditing event winreg.CreateKey with arguments key, sub_key, access.
Raises an auditing event winreg.OpenKey/result with argument key.

New in version 3.2.


Changed in version 3.3: See above."
"winreg.DeleteKey(key, sub_key)","Deletes the specified key.
key is an already open key, or one of the predefined
HKEY_* constants.
sub_key is a string that must be a subkey of the key identified by the key
parameter.  This value must not be None, and the key may not have subkeys.
This method can not delete keys with subkeys.
If the method succeeds, the entire key, including all of its values, is removed.
If the method fails, an OSError exception is raised.
Raises an auditing event winreg.DeleteKey with arguments key, sub_key, access.

Changed in version 3.3: See above."
"winreg.DeleteKeyEx(key, sub_key, access=KEY_WOW64_64KEY, reserved=0)","Deletes the specified key.

Note
The DeleteKeyEx() function is implemented with the RegDeleteKeyEx
Windows API function, which is specific to 64-bit versions of Windows.
See the RegDeleteKeyEx documentation.

key is an already open key, or one of the predefined
HKEY_* constants.
sub_key is a string that must be a subkey of the key identified by the
key parameter. This value must not be None, and the key may not have
subkeys.
reserved is a reserved integer, and must be zero. The default is zero.
access is an integer that specifies an access mask that describes the desired
security access for the key.  Default is KEY_WOW64_64KEY.  See
Access Rights for other allowed values.
This method can not delete keys with subkeys.
If the method succeeds, the entire key, including all of its values, is
removed. If the method fails, an OSError exception is raised.
On unsupported Windows versions, NotImplementedError is raised.
Raises an auditing event winreg.DeleteKey with arguments key, sub_key, access.

New in version 3.2.


Changed in version 3.3: See above."
"winreg.DeleteValue(key, value)","Removes a named value from a registry key.
key is an already open key, or one of the predefined
HKEY_* constants.
value is a string that identifies the value to remove.
Raises an auditing event winreg.DeleteValue with arguments key, value."
"winreg.EnumKey(key, index)","Enumerates subkeys of an open registry key, returning a string.
key is an already open key, or one of the predefined
HKEY_* constants.
index is an integer that identifies the index of the key to retrieve.
The function retrieves the name of one subkey each time it is called.  It is
typically called repeatedly until an OSError exception is
raised, indicating, no more values are available.
Raises an auditing event winreg.EnumKey with arguments key, index.

Changed in version 3.3: See above."
"winreg.EnumValue(key, index)","Enumerates values of an open registry key, returning a tuple.
key is an already open key, or one of the predefined
HKEY_* constants.
index is an integer that identifies the index of the value to retrieve.
The function retrieves the name of one subkey each time it is called. It is
typically called repeatedly, until an OSError exception is
raised, indicating no more values.
The result is a tuple of 3 items:






Index
Meaning



0
A string that identifies the value name

1
An object that holds the value data, and
whose type depends on the underlying
registry type

2
An integer that identifies the type of the
value data (see table in docs for
SetValueEx())



Raises an auditing event winreg.EnumValue with arguments key, index.

Changed in version 3.3: See above."
winreg.ExpandEnvironmentStrings(str),"Expands environment variable placeholders %NAME% in strings like
REG_EXPAND_SZ:
>>> ExpandEnvironmentStrings('%windir%')
'C:\\Windows'


Raises an auditing event winreg.ExpandEnvironmentStrings with argument str."
winreg.FlushKey(key),"Writes all the attributes of a key to the registry.
key is an already open key, or one of the predefined
HKEY_* constants.
It is not necessary to call FlushKey() to change a key. Registry changes are
flushed to disk by the registry using its lazy flusher.  Registry changes are
also flushed to disk at system shutdown.  Unlike CloseKey(), the
FlushKey() method returns only when all the data has been written to the
registry. An application should only call FlushKey() if it requires
absolute certainty that registry changes are on disk.

Note
If you don’t know whether a FlushKey() call is required, it probably
isn’t."
"winreg.LoadKey(key, sub_key, file_name)","Creates a subkey under the specified key and stores registration information
from a specified file into that subkey.
key is a handle returned by ConnectRegistry() or one of the constants
HKEY_USERS or HKEY_LOCAL_MACHINE.
sub_key is a string that identifies the subkey to load.
file_name is the name of the file to load registry data from. This file must
have been created with the SaveKey() function. Under the file allocation
table (FAT) file system, the filename may not have an extension.
A call to LoadKey() fails if the calling process does not have the
SE_RESTORE_PRIVILEGE privilege.  Note that privileges are different
from permissions – see the RegLoadKey documentation for
more details.
If key is a handle returned by ConnectRegistry(), then the path
specified in file_name is relative to the remote computer.
Raises an auditing event winreg.LoadKey with arguments key, sub_key, file_name."
"winreg.OpenKey(key, sub_key, reserved=0, access=KEY_READ)","Opens the specified key, returning a handle object.
key is an already open key, or one of the predefined
HKEY_* constants.
sub_key is a string that identifies the sub_key to open.
reserved is a reserved integer, and must be zero.  The default is zero.
access is an integer that specifies an access mask that describes the desired
security access for the key.  Default is KEY_READ.  See Access
Rights for other allowed values.
The result is a new handle to the specified key.
If the function fails, OSError is raised.
Raises an auditing event winreg.OpenKey with arguments key, sub_key, access.
Raises an auditing event winreg.OpenKey/result with argument key.

Changed in version 3.2: Allow the use of named arguments.


Changed in version 3.3: See above."
winreg.QueryInfoKey(key),"Returns information about a key, as a tuple.
key is an already open key, or one of the predefined
HKEY_* constants.
The result is a tuple of 3 items:






Index
Meaning



0
An integer giving the number of sub keys
this key has.

1
An integer giving the number of values this
key has.

2
An integer giving when the key was last
modified (if available) as 100’s of
nanoseconds since Jan 1, 1601.



Raises an auditing event winreg.QueryInfoKey with argument key."
"winreg.QueryValue(key, sub_key)","Retrieves the unnamed value for a key, as a string.
key is an already open key, or one of the predefined
HKEY_* constants.
sub_key is a string that holds the name of the subkey with which the value is
associated.  If this parameter is None or empty, the function retrieves the
value set by the SetValue() method for the key identified by key.
Values in the registry have name, type, and data components. This method
retrieves the data for a key’s first value that has a NULL name. But the
underlying API call doesn’t return the type, so always use
QueryValueEx() if possible.
Raises an auditing event winreg.QueryValue with arguments key, sub_key, value_name."
"winreg.QueryValueEx(key, value_name)","Retrieves the type and data for a specified value name associated with
an open registry key.
key is an already open key, or one of the predefined
HKEY_* constants.
value_name is a string indicating the value to query.
The result is a tuple of 2 items:






Index
Meaning



0
The value of the registry item.

1
An integer giving the registry type for
this value (see table in docs for
SetValueEx())



Raises an auditing event winreg.QueryValue with arguments key, sub_key, value_name."
"winreg.SaveKey(key, file_name)","Saves the specified key, and all its subkeys to the specified file.
key is an already open key, or one of the predefined
HKEY_* constants.
file_name is the name of the file to save registry data to.  This file
cannot already exist. If this filename includes an extension, it cannot be
used on file allocation table (FAT) file systems by the LoadKey()
method.
If key represents a key on a remote computer, the path described by
file_name is relative to the remote computer. The caller of this method must
possess the SeBackupPrivilege security privilege.  Note that
privileges are different than permissions – see the
Conflicts Between User Rights and Permissions documentation
for more details.
This function passes NULL for security_attributes to the API.
Raises an auditing event winreg.SaveKey with arguments key, file_name."
"winreg.SetValue(key, sub_key, type, value)","Associates a value with a specified key.
key is an already open key, or one of the predefined
HKEY_* constants.
sub_key is a string that names the subkey with which the value is associated.
type is an integer that specifies the type of the data. Currently this must be
REG_SZ, meaning only strings are supported.  Use the SetValueEx()
function for support for other data types.
value is a string that specifies the new value.
If the key specified by the sub_key parameter does not exist, the SetValue
function creates it.
Value lengths are limited by available memory. Long values (more than 2048
bytes) should be stored as files with the filenames stored in the configuration
registry.  This helps the registry perform efficiently.
The key identified by the key parameter must have been opened with
KEY_SET_VALUE access.
Raises an auditing event winreg.SetValue with arguments key, sub_key, type, value."
"winreg.SetValueEx(key, value_name, reserved, type, value)","Stores data in the value field of an open registry key.
key is an already open key, or one of the predefined
HKEY_* constants.
value_name is a string that names the subkey with which the value is
associated.
reserved can be anything – zero is always passed to the API.
type is an integer that specifies the type of the data. See
Value Types for the available types.
value is a string that specifies the new value.
This method can also set additional value and type information for the specified
key.  The key identified by the key parameter must have been opened with
KEY_SET_VALUE access.
To open the key, use the CreateKey() or OpenKey() methods.
Value lengths are limited by available memory. Long values (more than 2048
bytes) should be stored as files with the filenames stored in the configuration
registry.  This helps the registry perform efficiently.
Raises an auditing event winreg.SetValue with arguments key, sub_key, type, value."
winreg.DisableReflectionKey(key),"Disables registry reflection for 32-bit processes running on a 64-bit
operating system.
key is an already open key, or one of the predefined HKEY_* constants.
Will generally raise NotImplementedError if executed on a 32-bit operating
system.
If the key is not on the reflection list, the function succeeds but has no
effect.  Disabling reflection for a key does not affect reflection of any
subkeys.
Raises an auditing event winreg.DisableReflectionKey with argument key."
winreg.EnableReflectionKey(key),"Restores registry reflection for the specified disabled key.
key is an already open key, or one of the predefined HKEY_* constants.
Will generally raise NotImplementedError if executed on a 32-bit operating
system.
Restoring reflection for a key does not affect reflection of any subkeys.
Raises an auditing event winreg.EnableReflectionKey with argument key."
winreg.QueryReflectionKey(key),"Determines the reflection state for the specified key.
key is an already open key, or one of the predefined
HKEY_* constants.
Returns True if reflection is disabled.
Will generally raise NotImplementedError if executed on a 32-bit
operating system.
Raises an auditing event winreg.QueryReflectionKey with argument key."
PyHKEY.Close(),"Closes the underlying Windows handle.
If the handle is already closed, no error is raised."
PyHKEY.Detach(),"Detaches the Windows handle from the handle object.
The result is an integer that holds the value of the handle before it is
detached.  If the handle is already detached or closed, this will return
zero.
After calling this function, the handle is effectively invalidated, but the
handle is not closed.  You would call this function when you need the
underlying Win32 handle to exist beyond the lifetime of the handle object.
Raises an auditing event winreg.PyHKEY.Detach with argument key."
PyHKEY.__enter__(),"The HKEY object implements __enter__() and
__exit__() and thus supports the context protocol for the
with statement:
with OpenKey(HKEY_LOCAL_MACHINE, ""foo"") as key:
    ...  # work with key


will automatically close key when control leaves the with block."
"winsound.Beep(frequency, duration)","Beep the PC’s speaker. The frequency parameter specifies frequency, in hertz,
of the sound, and must be in the range 37 through 32,767. The duration
parameter specifies the number of milliseconds the sound should last.  If the
system is not able to beep the speaker, RuntimeError is raised."
"winsound.PlaySound(sound, flags)","Call the underlying PlaySound() function from the Platform API.  The
sound parameter may be a filename, a system sound alias, audio data as a
bytes-like object, or None.  Its
interpretation depends on the value of flags, which can be a bitwise ORed
combination of the constants described below. If the sound parameter is
None, any currently playing waveform sound is stopped. If the system
indicates an error, RuntimeError is raised."
winsound.MessageBeep(type=MB_OK),"Call the underlying MessageBeep() function from the Platform API.  This
plays a sound as specified in the registry.  The type argument specifies which
sound to play; possible values are -1, MB_ICONASTERISK,
MB_ICONEXCLAMATION, MB_ICONHAND, MB_ICONQUESTION, and MB_OK, all
described below.  The value -1 produces a “simple beep”; this is the final
fallback if a sound cannot be played otherwise.  If the system indicates an
error, RuntimeError is raised."
pwd.getpwuid(uid),Return the password database entry for the given numeric user ID.
pwd.getpwnam(name),Return the password database entry for the given user name.
pwd.getpwall(),"Return a list of all available password database entries, in arbitrary order."
spwd.getspnam(name),"Return the shadow password database entry for the given user name.

Changed in version 3.6: Raises a PermissionError instead of KeyError if the user
doesn’t have privileges."
spwd.getspall(),"Return a list of all available shadow password database entries, in arbitrary
order."
grp.getgrgid(gid),"Return the group database entry for the given numeric group ID. KeyError
is raised if the entry asked for cannot be found.

Deprecated since version 3.6: Since Python 3.6 the support of non-integer arguments like floats or
strings in getgrgid() is deprecated."
grp.getgrnam(name),"Return the group database entry for the given group name. KeyError is
raised if the entry asked for cannot be found."
grp.getgrall(),"Return a list of all available group entries, in arbitrary order."
"crypt.crypt(word, salt=None)","word will usually be a user’s password as typed at a prompt or  in a graphical
interface.  The optional salt is either a string as returned from
mksalt(), one of the crypt.METHOD_* values (though not all
may be available on all platforms), or a full encrypted password
including salt, as returned by this function.  If salt is not
provided, the strongest method will be used (as returned by
methods()).
Checking a password is usually done by passing the plain-text password
as word and the full results of a previous crypt() call,
which should be the same as the results of this call.
salt (either a random 2 or 16 character string, possibly prefixed with
$digit$ to indicate the method) which will be used to perturb the
encryption algorithm.  The characters in salt must be in the set
[./a-zA-Z0-9], with the exception of Modular Crypt Format which
prefixes a $digit$.
Returns the hashed password as a string, which will be composed of
characters from the same alphabet as the salt.
Since a few crypt(3) extensions allow different values, with
different sizes in the salt, it is recommended to use  the full crypted
password as salt when checking for a password.

Changed in version 3.3: Accept crypt.METHOD_* values in addition to strings for salt."
"crypt.mksalt(method=None, *, rounds=None)","Return a randomly generated salt of the specified method.  If no
method is given, the strongest method available as returned by
methods() is used.
The return value is a string suitable for passing as the salt argument
to crypt().
rounds specifies the number of rounds for METHOD_SHA256,
METHOD_SHA512 and METHOD_BLOWFISH.
For METHOD_SHA256 and METHOD_SHA512 it must be an integer between
1000 and 999_999_999, the default is 5000.  For
METHOD_BLOWFISH it must be a power of two between 16 (24)
and 2_147_483_648 (231), the default is 4096
(212).

New in version 3.3.


Changed in version 3.7: Added the rounds parameter."
termios.tcgetattr(fd),"Return a list containing the tty attributes for file descriptor fd, as
follows: [iflag, oflag, cflag, lflag, ispeed, ospeed, cc] where cc is a
list of the tty special characters (each a string of length 1, except the
items with indices VMIN and VTIME, which are integers when
these fields are defined).  The interpretation of the flags and the speeds as
well as the indexing in the cc array must be done using the symbolic
constants defined in the termios module."
"termios.tcsetattr(fd, when, attributes)","Set the tty attributes for file descriptor fd from the attributes, which is
a list like the one returned by tcgetattr().  The when argument
determines when the attributes are changed: TCSANOW to change
immediately, TCSADRAIN to change after transmitting all queued output,
or TCSAFLUSH to change after transmitting all queued output and
discarding all queued input."
"termios.tcsendbreak(fd, duration)","Send a break on file descriptor fd.  A zero duration sends a break for
0.25–0.5 seconds; a nonzero duration has a system dependent meaning."
termios.tcdrain(fd),Wait until all output written to file descriptor fd has been transmitted.
"termios.tcflush(fd, queue)","Discard queued data on file descriptor fd.  The queue selector specifies
which queue: TCIFLUSH for the input queue, TCOFLUSH for the
output queue, or TCIOFLUSH for both queues."
"termios.tcflow(fd, action)","Suspend or resume input or output on file descriptor fd.  The action
argument can be TCOOFF to suspend output, TCOON to restart
output, TCIOFF to suspend input, or TCION to restart input."
"tty.setraw(fd, when=termios.TCSAFLUSH)","Change the mode of the file descriptor fd to raw. If when is omitted, it
defaults to termios.TCSAFLUSH, and is passed to
termios.tcsetattr()."
"tty.setcbreak(fd, when=termios.TCSAFLUSH)","Change the mode of file descriptor fd to cbreak. If when is omitted, it
defaults to termios.TCSAFLUSH, and is passed to
termios.tcsetattr()."
pty.fork(),"Fork. Connect the child’s controlling terminal to a pseudo-terminal. Return
value is (pid, fd). Note that the child  gets pid 0, and the fd is
invalid. The parent’s return value is the pid of the child, and fd is a
file descriptor connected to the child’s controlling terminal (and also to the
child’s standard input and output)."
pty.openpty(),"Open a new pseudo-terminal pair, using os.openpty() if possible, or
emulation code for generic Unix systems. Return a pair of file descriptors
(master, slave), for the master and the slave end, respectively."
"pty.spawn(argv[, master_read[, stdin_read]])","Spawn a process, and connect its controlling terminal with the current
process’s standard io. This is often used to baffle programs which insist on
reading from the controlling terminal. It is expected that the process
spawned behind the pty will eventually terminate, and when it does spawn
will return.
The functions master_read and stdin_read are passed a file descriptor
which they should read from, and they should always return a byte string. In
order to force spawn to return before the child process exits an
OSError should be thrown.
The default implementation for both functions will read and return up to 1024
bytes each time the function is called. The master_read callback is passed
the pseudoterminal’s master file descriptor to read output from the child
process, and stdin_read is passed file descriptor 0, to read from the
parent process’s standard input.
Returning an empty byte string from either callback is interpreted as an
end-of-file (EOF) condition, and that callback will not be called after
that. If stdin_read signals EOF the controlling terminal can no longer
communicate with the parent process OR the child process. Unless the child
process will quit without any input, spawn will then loop forever. If
master_read signals EOF the same behavior results (on linux at least).
If both callbacks signal EOF then spawn will probably never return, unless
select throws an error on your platform when passed three empty lists. This
is a bug, documented in issue 26228.
Raises an auditing event pty.spawn with argument argv.

Changed in version 3.4: spawn() now returns the status value from os.waitpid()
on the child process."
"fcntl.fcntl(fd, cmd, arg=0)","Perform the operation cmd on file descriptor fd (file objects providing
a fileno() method are accepted as well).  The values used
for cmd are operating system dependent, and are available as constants
in the fcntl module, using the same names as used in the relevant C
header files. The argument arg can either be an integer value, or a
bytes object. With an integer value, the return value of this
function is the integer return value of the C fcntl() call.  When
the argument is bytes it represents a binary structure, e.g. created by
struct.pack(). The binary data is copied to a buffer whose address is
passed to the C fcntl() call.  The return value after a successful
call is the contents of the buffer, converted to a bytes object.
The length of the returned object will be the same as the length of the
arg argument. This is limited to 1024 bytes. If the information returned
in the buffer by the operating system is larger than 1024 bytes, this is
most likely to result in a segmentation violation or a more subtle data
corruption.
If the fcntl() fails, an OSError is raised.
Raises an auditing event fcntl.fcntl with arguments fd, cmd, arg."
"fcntl.ioctl(fd, request, arg=0, mutate_flag=True)","This function is identical to the fcntl() function, except
that the argument handling is even more complicated.
The request parameter is limited to values that can fit in 32-bits.
Additional constants of interest for use as the request argument can be
found in the termios module, under the same names as used in
the relevant C header files.
The parameter arg can be one of an integer, an object supporting the
read-only buffer interface (like bytes) or an object supporting
the read-write buffer interface (like bytearray).
In all but the last case, behaviour is as for the fcntl()
function.
If a mutable buffer is passed, then the behaviour is determined by the value of
the mutate_flag parameter.
If it is false, the buffer’s mutability is ignored and behaviour is as for a
read-only buffer, except that the 1024 byte limit mentioned above is avoided –
so long as the buffer you pass is at least as long as what the operating system
wants to put there, things should work.
If mutate_flag is true (the default), then the buffer is (in effect) passed
to the underlying ioctl() system call, the latter’s return code is
passed back to the calling Python, and the buffer’s new contents reflect the
action of the ioctl().  This is a slight simplification, because if the
supplied buffer is less than 1024 bytes long it is first copied into a static
buffer 1024 bytes long which is then passed to ioctl() and copied back
into the supplied buffer.
If the ioctl() fails, an OSError exception is raised.
An example:
>>> import array, fcntl, struct, termios, os
>>> os.getpgrp()
13341
>>> struct.unpack('h', fcntl.ioctl(0, termios.TIOCGPGRP, ""  ""))[0]
13341
>>> buf = array.array('h', [0])
>>> fcntl.ioctl(0, termios.TIOCGPGRP, buf, 1)
0
>>> buf
array('h', [13341])


Raises an auditing event fcntl.ioctl with arguments fd, request, arg."
"fcntl.flock(fd, operation)","Perform the lock operation operation on file descriptor fd (file objects providing
a fileno() method are accepted as well). See the Unix manual
flock(2) for details.  (On some systems, this function is emulated
using fcntl().)
If the flock() fails, an OSError exception is raised.
Raises an auditing event fcntl.flock with arguments fd, operation."
"fcntl.lockf(fd, cmd, len=0, start=0, whence=0)","This is essentially a wrapper around the fcntl() locking calls.
fd is the file descriptor (file objects providing a fileno()
method are accepted as well) of the file to lock or unlock, and cmd
is one of the following values:

LOCK_UN – unlock
LOCK_SH – acquire a shared lock
LOCK_EX – acquire an exclusive lock

When cmd is LOCK_SH or LOCK_EX, it can also be
bitwise ORed with LOCK_NB to avoid blocking on lock acquisition.
If LOCK_NB is used and the lock cannot be acquired, an
OSError will be raised and the exception will have an errno
attribute set to EACCES or EAGAIN (depending on the
operating system; for portability, check for both values).  On at least some
systems, LOCK_EX can only be used if the file descriptor refers to a
file opened for writing.
len is the number of bytes to lock, start is the byte offset at
which the lock starts, relative to whence, and whence is as with
io.IOBase.seek(), specifically:

0 – relative to the start of the file (os.SEEK_SET)
1 – relative to the current buffer position (os.SEEK_CUR)
2 – relative to the end of the file (os.SEEK_END)

The default for start is 0, which means to start at the beginning of the file.
The default for len is 0 which means to lock to the end of the file.  The
default for whence is also 0.
Raises an auditing event fcntl.lockf with arguments fd, cmd, len, start, whence."
Template.reset(),Restore a pipeline template to its initial state.
Template.clone(),"Return a new, equivalent, pipeline template."
Template.debug(flag),"If flag is true, turn debugging on. Otherwise, turn debugging off. When
debugging is on, commands to be executed are printed, and the shell is given
set -x command to be more verbose."
"Template.append(cmd, kind)","Append a new action at the end. The cmd variable must be a valid bourne shell
command. The kind variable consists of two letters.
The first letter can be either of '-' (which means the command reads its
standard input), 'f' (which means the commands reads a given file on the
command line) or '.' (which means the commands reads no input, and hence
must be first.)
Similarly, the second letter can be either of '-' (which means  the command
writes to standard output), 'f' (which means the  command writes a file on
the command line) or '.' (which means the command does not write anything,
and hence must be last.)"
"Template.prepend(cmd, kind)","Add a new action at the beginning. See append() for explanations of the
arguments."
"Template.open(file, mode)","Return a file-like object, open to file, but read from or written to by the
pipeline.  Note that only one of 'r', 'w' may be given."
"Template.copy(infile, outfile)",Copy infile to outfile through the pipe.
resource.getrlimit(resource),"Returns a tuple (soft, hard) with the current soft and hard limits of
resource. Raises ValueError if an invalid resource is specified, or
error if the underlying system call fails unexpectedly."
"resource.setrlimit(resource, limits)","Sets new limits of consumption of resource. The limits argument must be a
tuple (soft, hard) of two integers describing the new limits. A value of
RLIM_INFINITY can be used to request a limit that is
unlimited.
Raises ValueError if an invalid resource is specified, if the new soft
limit exceeds the hard limit, or if a process tries to raise its hard limit.
Specifying a limit of RLIM_INFINITY when the hard or
system limit for that resource is not unlimited will result in a
ValueError.  A process with the effective UID of super-user can
request any valid limit value, including unlimited, but ValueError
will still be raised if the requested limit exceeds the system imposed
limit.
setrlimit may also raise error if the underlying system call
fails.
VxWorks only supports setting RLIMIT_NOFILE.
Raises an auditing event resource.setrlimit with arguments resource, limits."
"resource.prlimit(pid, resource[, limits])","Combines setrlimit() and getrlimit() in one function and
supports to get and set the resources limits of an arbitrary process. If
pid is 0, then the call applies to the current process. resource and
limits have the same meaning as in setrlimit(), except that
limits is optional.
When limits is not given the function returns the resource limit of the
process pid. When limits is given the resource limit of the process is
set and the former resource limit is returned.
Raises ProcessLookupError when pid can’t be found and
PermissionError when the user doesn’t have CAP_SYS_RESOURCE for
the process.
Raises an auditing event resource.prlimit with arguments pid, resource, limits.
Availability: Linux 2.6.36 or later with glibc 2.13 or later.

New in version 3.4."
resource.getrusage(who),"This function returns an object that describes the resources consumed by either
the current process or its children, as specified by the who parameter.  The
who parameter should be specified using one of the RUSAGE_*
constants described below.
A simple example:
from resource import *
import time

# a non CPU-bound task
time.sleep(3)
print(getrusage(RUSAGE_SELF))

# a CPU-bound task
for i in range(10 ** 8):
   _ = 1 + 1
print(getrusage(RUSAGE_SELF))


The fields of the return value each describe how a particular system resource
has been used, e.g. amount of time spent running is user mode or number of times
the process was swapped out of main memory. Some values are dependent on the
clock tick internal, e.g. the amount of memory the process is using.
For backward compatibility, the return value is also accessible as a tuple of 16
elements.
The fields ru_utime and ru_stime of the return value are
floating point values representing the amount of time spent executing in user
mode and the amount of time spent executing in system mode, respectively. The
remaining values are integers. Consult the getrusage(2) man page for
detailed information about these values. A brief summary is presented here:







Index
Field
Resource



0
ru_utime
time in user mode (float seconds)

1
ru_stime
time in system mode (float seconds)

2
ru_maxrss
maximum resident set size

3
ru_ixrss
shared memory size

4
ru_idrss
unshared memory size

5
ru_isrss
unshared stack size

6
ru_minflt
page faults not requiring I/O

7
ru_majflt
page faults requiring I/O

8
ru_nswap
number of swap outs

9
ru_inblock
block input operations

10
ru_oublock
block output operations

11
ru_msgsnd
messages sent

12
ru_msgrcv
messages received

13
ru_nsignals
signals received

14
ru_nvcsw
voluntary context switches

15
ru_nivcsw
involuntary context switches



This function will raise a ValueError if an invalid who parameter is
specified. It may also raise error exception in unusual circumstances."
resource.getpagesize(),"Returns the number of bytes in a system page. (This need not be the same as the
hardware page size.)"
"nis.match(key, mapname, domain=default_domain)","Return the match for key in map mapname, or raise an error
(nis.error) if there is none. Both should be strings, key is 8-bit
clean. Return value is an arbitrary array of bytes (may contain NULL and
other joys).
Note that mapname is first checked if it is an alias to another name.
The domain argument allows overriding the NIS domain used for the lookup. If
unspecified, lookup is in the default NIS domain."
"nis.cat(mapname, domain=default_domain)","Return a dictionary mapping key to value such that match(key,
mapname)==value. Note that both keys and values of the dictionary are
arbitrary arrays of bytes.
Note that mapname is first checked if it is an alias to another name.
The domain argument allows overriding the NIS domain used for the lookup. If
unspecified, lookup is in the default NIS domain."
nis.maps(domain=default_domain),"Return a list of all valid maps.
The domain argument allows overriding the NIS domain used for the lookup. If
unspecified, lookup is in the default NIS domain."
nis.get_default_domain(),Return the system default NIS domain.
syslog.syslog(message),"Send the string message to the system logger.  A trailing newline is added
if necessary.  Each message is tagged with a priority composed of a
facility and a level.  The optional priority argument, which defaults
to LOG_INFO, determines the message priority.  If the facility is
not encoded in priority using logical-or (LOG_INFO | LOG_USER), the
value given in the openlog() call is used.
If openlog() has not been called prior to the call to syslog(),
openlog() will be called with no arguments.
Raises an auditing event syslog.syslog with arguments priority, message."
"syslog.openlog([ident[, logoption[, facility]]])","Logging options of subsequent syslog() calls can be set by calling
openlog().  syslog() will call openlog() with no arguments
if the log is not currently open.
The optional ident keyword argument is a string which is prepended to every
message, and defaults to sys.argv[0] with leading path components
stripped.  The optional logoption keyword argument (default is 0) is a bit
field – see below for possible values to combine.  The optional facility
keyword argument (default is LOG_USER) sets the default facility for
messages which do not have a facility explicitly encoded.
Raises an auditing event syslog.openlog with arguments ident, logoption, facility.

Changed in version 3.2: In previous versions, keyword arguments were not allowed, and ident was
required.  The default for ident was dependent on the system libraries,
and often was python instead of the name of the Python program file."
syslog.closelog(),"Reset the syslog module values and call the system library closelog().
This causes the module to behave as it does when initially imported.  For
example, openlog() will be called on the first syslog() call (if
openlog() hasn’t already been called), and ident and other
openlog() parameters are reset to defaults.
Raises an auditing event syslog.closelog with no arguments."
syslog.setlogmask(maskpri),"Set the priority mask to maskpri and return the previous mask value.  Calls
to syslog() with a priority level not set in maskpri are ignored.
The default is to log all priorities.  The function LOG_MASK(pri)
calculates the mask for the individual priority pri.  The function
LOG_UPTO(pri) calculates the mask for all priorities up to and including
pri.
Raises an auditing event syslog.setlogmask with argument maskpri."
OptionParser.get_option_group(opt_str),"Return the OptionGroup to which the short or long option
string opt_str (e.g. '-o' or '--option') belongs. If
there’s no such OptionGroup, return None."
OptionParser.print_version(file=None),"Print the version message for the current program (self.version) to
file (default stdout).  As with print_usage(), any occurrence
of %prog in self.version is replaced with the name of the current
program.  Does nothing if self.version is empty or undefined."
OptionParser.get_version(),"Same as print_version() but returns the version string instead of
printing it."
OptionParser.add_option(option),"To define an option with only a short option string:
parser.add_option(""-f"", attr=value, ...)


And to define an option with only a long option string:
parser.add_option(""--foo"", attr=value, ...)


The keyword arguments define attributes of the new Option object.  The most
important option attribute is action, and it largely
determines which other attributes are relevant or required.  If you pass
irrelevant option attributes, or fail to pass required ones, optparse
raises an OptionError exception explaining your mistake.
An option’s action determines what optparse does when it encounters
this option on the command-line.  The standard option actions hard-coded into
optparse are:

""store""store this option’s argument (default)

""store_const""store a constant value

""store_true""store True

""store_false""store False

""append""append this option’s argument to a list

""append_const""append a constant value to a list

""count""increment a counter by one

""callback""call a specified function

""help""print a usage message including all options and the documentation for them


(If you don’t supply an action, the default is ""store"".  For this action,
you may also supply type and dest option
attributes; see Standard option actions.)"
OptionParser.disable_interspersed_args(),"Set parsing to stop on the first non-option.  For example, if -a and
-b are both simple options that take no arguments, optparse
normally accepts this syntax:
prog -a arg1 -b arg2


and treats it as equivalent to
prog -a -b arg1 arg2


To disable this feature, call disable_interspersed_args().  This
restores traditional Unix syntax, where option parsing stops with the first
non-option argument.
Use this if you have a command processor which runs another command which has
options of its own and you want to make sure these options don’t get
confused.  For example, each command might have a different set of options."
OptionParser.enable_interspersed_args(),"Set parsing to not stop on the first non-option, allowing interspersing
switches with command arguments.  This is the default behavior."
OptionParser.get_option(opt_str),"Returns the Option instance with the option string opt_str, or None if
no options have that option string."
OptionParser.has_option(opt_str),"Return True if the OptionParser has an option with option string opt_str
(e.g., -q or --verbose)."
OptionParser.remove_option(opt_str),"If the OptionParser has an option corresponding to opt_str, that
option is removed.  If that option provided any other option strings, all of
those option strings become invalid. If opt_str does not occur in any
option belonging to this OptionParser, raises ValueError."
OptionParser.set_usage(usage),"Set the usage string according to the rules described above for the usage
constructor keyword argument.  Passing None sets the default usage
string; use optparse.SUPPRESS_USAGE to suppress a usage message."
OptionParser.print_usage(file=None),"Print the usage message for the current program (self.usage) to file
(default stdout).  Any occurrence of the string %prog in self.usage
is replaced with the name of the current program.  Does nothing if
self.usage is empty or not defined."
OptionParser.get_usage(),"Same as print_usage() but returns the usage string instead of
printing it."
"OptionParser.set_defaults(dest=value, ...)","Set default values for several option destinations at once.  Using
set_defaults() is the preferred way to set default values for options,
since multiple options can share the same destination.  For example, if
several “mode” options all set the same destination, any one of them can set
the default, and the last one wins:
parser.add_option(""--advanced"", action=""store_const"",
                  dest=""mode"", const=""advanced"",
                  default=""novice"")    # overridden below
parser.add_option(""--novice"", action=""store_const"",
                  dest=""mode"", const=""novice"",
                  default=""advanced"")  # overrides above setting


To avoid this confusion, use set_defaults():
parser.set_defaults(mode=""advanced"")
parser.add_option(""--advanced"", action=""store_const"",
                  dest=""mode"", const=""advanced"")
parser.add_option(""--novice"", action=""store_const"",
                  dest=""mode"", const=""novice"")"
imp.get_magic(),"Return the magic string value used to recognize byte-compiled code files
(.pyc files).  (This value may be different for each Python version.)

Deprecated since version 3.4: Use importlib.util.MAGIC_NUMBER instead."
imp.get_suffixes(),"Return a list of 3-element tuples, each describing a particular type of
module. Each triple has the form (suffix, mode, type), where suffix is
a string to be appended to the module name to form the filename to search
for, mode is the mode string to pass to the built-in open() function
to open the file (this can be 'r' for text files or 'rb' for binary
files), and type is the file type, which has one of the values
PY_SOURCE, PY_COMPILED, or C_EXTENSION, described
below.

Deprecated since version 3.3: Use the constants defined on importlib.machinery instead."
"imp.find_module(name[, path])","Try to find the module name.  If path is omitted or None, the list of
directory names given by sys.path is searched, but first a few special
places are searched: the function tries to find a built-in module with the
given name (C_BUILTIN), then a frozen module (PY_FROZEN),
and on some systems some other places are looked in as well (on Windows, it
looks in the registry which may point to a specific file).
Otherwise, path must be a list of directory names; each directory is
searched for files with any of the suffixes returned by get_suffixes()
above.  Invalid names in the list are silently ignored (but all list items
must be strings).
If search is successful, the return value is a 3-element tuple (file,
pathname, description):
file is an open file object positioned at the beginning, pathname
is the pathname of the file found, and description is a 3-element tuple as
contained in the list returned by get_suffixes() describing the kind of
module found.
If the module is built-in or frozen then file and pathname are both None
and the description tuple contains empty strings for its suffix and mode;
the module type is indicated as given in parentheses above.  If the search
is unsuccessful, ImportError is raised.  Other exceptions indicate
problems with the arguments or environment.
If the module is a package, file is None, pathname is the package
path and the last item in the description tuple is PKG_DIRECTORY.
This function does not handle hierarchical module names (names containing
dots).  In order to find P.M, that is, submodule M of package P, use
find_module() and load_module() to find and load package P, and
then use find_module() with the path argument set to P.__path__.
When P itself has a dotted name, apply this recipe recursively.

Deprecated since version 3.3: Use importlib.util.find_spec() instead unless Python 3.3
compatibility is required, in which case use
importlib.find_loader(). For example usage of the former case,
see the Examples section of the importlib
documentation."
"imp.load_module(name, file, pathname, description)","Load a module that was previously found by find_module() (or by an
otherwise conducted search yielding compatible results).  This function does
more than importing the module: if the module was already imported, it will
reload the module!  The name argument indicates the full
module name (including the package name, if this is a submodule of a
package).  The file argument is an open file, and pathname is the
corresponding file name; these can be None and '', respectively, when
the module is a package or not being loaded from a file.  The description
argument is a tuple, as would be returned by get_suffixes(), describing
what kind of module must be loaded.
If the load is successful, the return value is the module object; otherwise,
an exception (usually ImportError) is raised.
Important: the caller is responsible for closing the file argument, if
it was not None, even when an exception is raised.  This is best done
using a try … finally statement.

Deprecated since version 3.3: If previously used in conjunction with imp.find_module() then
consider using importlib.import_module(), otherwise use the loader
returned by the replacement you chose for imp.find_module(). If you
called imp.load_module() and related functions directly with file
path arguments then use a combination of
importlib.util.spec_from_file_location() and
importlib.util.module_from_spec(). See the Examples
section of the importlib documentation for details of the various
approaches."
imp.new_module(name),"Return a new empty module object called name.  This object is not inserted
in sys.modules.

Deprecated since version 3.4: Use importlib.util.module_from_spec() instead."
imp.reload(module),"Reload a previously imported module.  The argument must be a module object, so
it must have been successfully imported before.  This is useful if you have
edited the module source file using an external editor and want to try out the
new version without leaving the Python interpreter.  The return value is the
module object (the same as the module argument).
When reload(module) is executed:

Python modules’ code is recompiled and the module-level code reexecuted,
defining a new set of objects which are bound to names in the module’s
dictionary.  The init function of extension modules is not called a second
time.
As with all other objects in Python the old objects are only reclaimed after
their reference counts drop to zero.
The names in the module namespace are updated to point to any new or changed
objects.
Other references to the old objects (such as names external to the module) are
not rebound to refer to the new objects and must be updated in each namespace
where they occur if that is desired.

There are a number of other caveats:
When a module is reloaded, its dictionary (containing the module’s global
variables) is retained.  Redefinitions of names will override the old
definitions, so this is generally not a problem.  If the new version of a module
does not define a name that was defined by the old version, the old definition
remains.  This feature can be used to the module’s advantage if it maintains a
global table or cache of objects — with a try statement it can test
for the table’s presence and skip its initialization if desired:
try:
    cache
except NameError:
    cache = {}


It is legal though generally not very useful to reload built-in or dynamically
loaded modules, except for sys, __main__ and builtins.
In many cases, however, extension modules are not designed to be initialized
more than once, and may fail in arbitrary ways when reloaded.
If a module imports objects from another module using from …
import …, calling reload() for the other module does not
redefine the objects imported from it — one way around this is to re-execute
the from statement, another is to use import and qualified
names (module.*name*) instead.
If a module instantiates instances of a class, reloading the module that defines
the class does not affect the method definitions of the instances — they
continue to use the old class definition.  The same is true for derived classes.

Changed in version 3.3: Relies on both __name__ and __loader__ being defined on the module
being reloaded instead of just __name__.


Deprecated since version 3.4: Use importlib.reload() instead."
"imp.cache_from_source(path, debug_override=None)","Return the PEP 3147 path to the byte-compiled file associated with the
source path.  For example, if path is /foo/bar/baz.py the return
value would be /foo/bar/__pycache__/baz.cpython-32.pyc for Python 3.2.
The cpython-32 string comes from the current magic tag (see
get_tag(); if sys.implementation.cache_tag is not defined then
NotImplementedError will be raised). By passing in True or
False for debug_override you can override the system’s value for
__debug__, leading to optimized bytecode.
path need not exist.

Changed in version 3.3: If sys.implementation.cache_tag is None, then
NotImplementedError is raised.


Deprecated since version 3.4: Use importlib.util.cache_from_source() instead.


Changed in version 3.5: The debug_override parameter no longer creates a .pyo file."
imp.source_from_cache(path),"Given the path to a PEP 3147 file name, return the associated source code
file path.  For example, if path is
/foo/bar/__pycache__/baz.cpython-32.pyc the returned path would be
/foo/bar/baz.py.  path need not exist, however if it does not conform
to PEP 3147 format, a ValueError is raised. If
sys.implementation.cache_tag is not defined,
NotImplementedError is raised.

Changed in version 3.3: Raise NotImplementedError when
sys.implementation.cache_tag is not defined.


Deprecated since version 3.4: Use importlib.util.source_from_cache() instead."
imp.get_tag(),"Return the PEP 3147 magic tag string matching this version of Python’s
magic number, as returned by get_magic().

Deprecated since version 3.4: Use sys.implementation.cache_tag directly starting
in Python 3.3."
imp.lock_held(),"Return True if the global import lock is currently held, else
False. On platforms without threads, always return False.
On platforms with threads, a thread executing an import first holds a
global import lock, then sets up a per-module lock for the rest of the
import.  This blocks other threads from importing the same module until
the original import completes, preventing other threads from seeing
incomplete module objects constructed by the original thread.  An
exception is made for circular imports, which by construction have to
expose an incomplete module object at some point.

Changed in version 3.3: The locking scheme has changed to per-module locks for
the most part.  A global import lock is kept for some critical tasks,
such as initializing the per-module locks.


Deprecated since version 3.4."
imp.acquire_lock(),"Acquire the interpreter’s global import lock for the current thread.
This lock should be used by import hooks to ensure thread-safety when
importing modules.
Once a thread has acquired the import lock, the same thread may acquire it
again without blocking; the thread must release it once for each time it has
acquired it.
On platforms without threads, this function does nothing.

Changed in version 3.3: The locking scheme has changed to per-module locks for
the most part.  A global import lock is kept for some critical tasks,
such as initializing the per-module locks.


Deprecated since version 3.4."
imp.release_lock(),"Release the interpreter’s global import lock. On platforms without
threads, this function does nothing.

Changed in version 3.3: The locking scheme has changed to per-module locks for
the most part.  A global import lock is kept for some critical tasks,
such as initializing the per-module locks.


Deprecated since version 3.4."
"find_module(fullname[, path])","This method always returns None, indicating that the requested module could
not be found."
